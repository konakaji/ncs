{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A demo using Hydrogen Hamiltonian with GPT-QE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T00:45:05.027528Z",
     "start_time": "2023-10-02T00:45:03.890399Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from gqe.mingpt.utils import set_seed\n",
    "\n",
    "set_seed(3407)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T00:45:09.117775Z",
     "start_time": "2023-10-02T00:45:05.033318Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converged SCF energy = -14.9345493818237\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "paulis [+IIIYZXIIIIII, +IIIYZZZXIIII, +IIIYZZZZZXII, +IIIYZZZZZZZX, +IIXXIIIIIIYX, +IIXXIIIIYXII, +IIXXIIYXIIII, +IIXXYXIIIIII, +IIXYIIIIIIYY, +IIXYIIIIYYII, +IIXYIIYYIIII, +IIXYYYIIIIII, +IIYXIIIIIIYY, +IIYXIIIIYYII, +IIYXIIYYIIII, +IIYXYYIIIIII, +IIYYIIIIIIYX, +IIYYIIIIYXII, +IIYYIIYXIIII, +IIYYYXIIIIII, +IIYZXIIIIIII, +IIYZZZXIIIII, +IIYZZZZZXIII, +IIYZZZZZZZXI, +IXXIIYZZZZXI, +IXXIYZZZZZZX, +IXYIIXZZZZXI, +IXYIYZZZZZZY, +IXZXIYZZZZZX, +IXZYIXZZZZZX, +IXZYIYZZZZZY, +IYXIIXZZZZXI, +IYXIYZZZZZZY, +IYYIIYZZZZXI, +IYYIYZZZZZZX, +IYZXIXZZZZZX, +IYZXIYZZZZZY, +IYZYIYZZZZZX, +IYZZZXIIIIII, +IYZZZZZXIIII, +IYZZZZZZZXII, +IYZZZZZZZZZX, +XXIIIIIIIIYX, +XXIIIIIIYXII, +XXIIIIYXIIII, +XXIIYXIIIIII, +XYIIIIIIIIYY, +XYIIIIIIYYII, +XYIIIIYYIIII, +XYIIYYIIIIII, +XZXIYZZZZZXI, +XZYIXZZZZZXI, +XZYIYZZZZZYI, +XZZXIYZZZZXI, +XZZXYZZZZZZX, +XZZYIXZZZZXI, +XZZYYZZZZZZY, +YXIIIIIIIIYY, +YXIIIIIIYYII, +YXIIIIYYIIII, +YXIIYYIIIIII, +YYIIIIIIIIYX, +YYIIIIIIYXII, +YYIIIIYXIIII, +YYIIYXIIIIII, +YZXIXZZZZZXI, +YZXIYZZZZZYI, +YZYIYZZZZZXI, +YZZXIXZZZZXI, +YZZXYZZZZZZY, +YZZYIYZZZZXI, +YZZYYZZZZZZX, +YZZZXIIIIIII, +YZZZZZXIIIII, +YZZZZZZZXIII, +YZZZZZZZZZXI, +IIIIIIIIII]\n"
     ]
    }
   ],
   "source": [
    "from qwrapper.operator import PauliObservable\n",
    "from gqe.mingpt.cost import EnergyCost\n",
    "from qswift.compiler import DefaultOperatorPool\n",
    "from benchmark.molecule import DiatomicMolecularHamiltonian\n",
    "from gqe.operator_pool.uccsd import UCCSD, do_generate_molecule\n",
    "from gqe.common.initializer import HFStateInitializer\n",
    "from gqe.common.util import get_device\n",
    "from gqe.mingpt.callback import DefaultCallback, PrintMonitor, FileMonitor\n",
    "\n",
    "# molecule = generate_molecule(\"Li\", \"H\", 1.596, \"sto-3g\", bravyi_kitaev=False)\n",
    "bond_length = 4.0\n",
    "geometry = f\"H 0.0 0.0 0.0\\n\" + f\"Be 0.0 0.0 {bond_length}\\n\" + f\"H 0.0 0.0 {2 * bond_length}\\n\"\n",
    "molecule = do_generate_molecule(geometry, \"sto-3g\", bravyi_kitaev=False)\n",
    "nqubit = 12\n",
    "\n",
    "# prepare Hamiltonian\n",
    "hamiltonian = DiatomicMolecularHamiltonian(nqubit, molecule, bravyi_kitaev=False)\n",
    "\n",
    "# prepare operator_pool\n",
    "uccsd = UCCSD(nqubit, molecule)\n",
    "paulis = uccsd.paulis\n",
    "paulis.append(PauliObservable(\"IIIIIIIIII\"))\n",
    "print('paulis', paulis)\n",
    "num_operators = len(paulis)\n",
    "initializer = HFStateInitializer(n_electrons=4)\n",
    "pool = DefaultOperatorPool(paulis)\n",
    "cost = EnergyCost(hamiltonian, initializer, pool,\n",
    "                  [1/160, -1/160, 1/80, -1/80, 1/40, -1/40, 0.05, -0.05, 0.1, -0.1, 0.2, -0.2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## FCI energy by diagonalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T00:47:20.729015Z",
     "start_time": "2023-10-02T00:45:09.119342Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-15.33649467289809\n"
     ]
    }
   ],
   "source": [
    "from qwrapper.hamiltonian import compute_ground_state\n",
    "\n",
    "print(compute_ground_state(hamiltonian))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T00:47:20.738947Z",
     "start_time": "2023-10-02T00:47:20.736013Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hf state: -14.934549381823707\n"
     ]
    }
   ],
   "source": [
    "print(\"hf state:\", hamiltonian.exact_value(initializer.init_circuit(12, [], \"qulacs\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Setup for GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T00:47:22.360120Z",
     "start_time": "2023-10-02T00:47:20.743921Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 85.79M\n"
     ]
    }
   ],
   "source": [
    "# create a GPT instance\n",
    "from gqe.mingpt.model import GPT\n",
    "\n",
    "model_config = GPT.get_default_config()\n",
    "model_config.model_type = 'gpt2'\n",
    "model_config.vocab_size = cost.vocab_size()\n",
    "model_config.n_gates = 30  # The number of gates for each circuit\n",
    "model_config.block_size = model_config.n_gates\n",
    "model_config.temperature = 5  # Each gate is generated with probability exp(-temperature * logit)\n",
    "model_config.embd_pdrop = 0.1\n",
    "model_config.resid_pdrop = 0.1\n",
    "model_config.attn_pdrop = 0.1\n",
    "model_config.std = 0.02\n",
    "model_config.energy_offset = 14\n",
    "model = GPT(model_config, cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T00:47:22.447619Z",
     "start_time": "2023-10-02T00:47:22.362017Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on device mps\n"
     ]
    }
   ],
   "source": [
    "# create a Trainer object\n",
    "from gqe.mingpt.trainer import Trainer\n",
    "\n",
    "train_config = Trainer.get_default_config()\n",
    "train_config.learning_rate = 5e-7  # the model we're using is so small that we can go a bit faster\n",
    "train_config.max_iters = 1000\n",
    "train_config.num_workers = 10\n",
    "train_config.n_samples = 50\n",
    "trainer = Trainer(train_config, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T00:48:28.602400Z",
     "start_time": "2023-10-02T00:47:22.451833Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter_dt 0.00s; iter 0: train loss 0.14985 temperature: 5\n",
      "mean_logits tensor([-14.9388, -14.9528, -15.0071, -15.0647, -14.8301, -14.8985, -15.0804,\n",
      "        -14.8169, -15.0770, -15.0296, -14.9578, -14.8626, -14.8198, -14.8334,\n",
      "        -14.7787, -14.9138, -14.9562, -15.1092, -15.0414, -14.9065, -15.0057,\n",
      "        -15.0122, -14.7064, -15.0227, -14.7585, -14.9664, -14.8754, -14.8604,\n",
      "        -15.0395, -15.0138, -14.9117, -14.8076, -15.0506, -15.0247, -15.2137,\n",
      "        -14.9663, -14.9443, -14.9499, -15.0470, -14.9670, -15.0601, -14.9286,\n",
      "        -15.1159, -14.9852, -14.8846, -15.0560, -14.9432, -15.0407, -15.2327,\n",
      "        -14.7911], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-14.8369, -14.8863, -14.8611, -14.9317, -14.8004, -14.7980, -15.1061,\n",
      "        -14.6344, -14.9618, -14.8628, -14.8188, -14.8261, -15.0032, -14.9624,\n",
      "        -14.9481, -15.0096, -14.6682, -15.0220, -14.9498, -15.0486, -14.9168,\n",
      "        -14.9275, -15.0003, -14.8577, -15.0809, -14.9733, -14.8389, -14.9229,\n",
      "        -15.0513, -14.8717, -14.7457, -14.8895, -14.7878, -14.8630, -14.9399,\n",
      "        -15.1966, -14.7570, -14.9582, -14.9721, -14.9299, -15.0325, -14.7900,\n",
      "        -14.9809, -14.9539, -15.0410, -15.0204, -14.9911, -14.8283, -14.9742,\n",
      "        -14.9702], device='mps:0')\n",
      "mean: tensor(-14.9200, device='mps:0')\n",
      "current min: -15.1966305\n",
      "iter_dt 1696207657.00s; iter 1: train loss 0.14839 temperature: 5.01\n",
      "mean_logits tensor([-14.9650, -14.8823, -14.9314, -14.6470, -14.9552, -15.0026, -14.8067,\n",
      "        -14.8810, -14.9239, -14.8028, -14.9588, -14.9597, -15.0362, -15.0015,\n",
      "        -14.8302, -14.8765, -14.9654, -14.8845, -14.7860, -14.9944, -14.7294,\n",
      "        -14.7948, -14.6935, -14.8522, -14.8551, -14.9545, -14.8414, -14.8342,\n",
      "        -14.8398, -14.7988, -14.8467, -14.8875, -14.7301, -14.8391, -14.9179,\n",
      "        -14.8677, -14.8023, -14.7804, -14.7675, -15.0094, -14.8749, -14.7707,\n",
      "        -14.9926, -14.9118, -14.8658, -14.8565, -14.9816, -14.9894, -14.7877,\n",
      "        -14.8531], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-14.8714, -14.9012, -14.6874, -15.0081, -14.9457, -15.1074, -14.8936,\n",
      "        -14.9292, -14.8154, -14.9393, -14.9012, -15.1855, -14.9321, -14.9424,\n",
      "        -14.8262, -14.8917, -14.9844, -14.6922, -15.0338, -14.9592, -14.7785,\n",
      "        -15.0587, -14.9174, -14.8991, -14.8563, -14.6818, -14.8233, -14.7735,\n",
      "        -14.7512, -15.1688, -14.8319, -14.9242, -14.9192, -14.8693, -14.6700,\n",
      "        -14.8565, -14.8511, -15.0543, -14.9932, -15.0409, -14.7707, -14.9999,\n",
      "        -15.0517, -14.8880, -14.8247, -14.9456, -15.0343, -14.8590, -15.0691,\n",
      "        -15.0841], device='mps:0')\n",
      "mean: tensor(-14.9139, device='mps:0')\n",
      "current min: -15.1966305\n",
      "iter_dt 4.11s; iter 2: train loss 0.14807 temperature: 5.02\n",
      "mean_logits tensor([-14.7670, -15.0214, -14.7163, -14.9172, -14.9998, -14.9333, -14.9399,\n",
      "        -14.7724, -14.9783, -14.9693, -14.7150, -14.7688, -14.8102, -14.8809,\n",
      "        -14.9418, -14.9506, -14.6356, -14.9710, -14.9178, -14.7297, -14.9786,\n",
      "        -14.7047, -14.6507, -14.7624, -14.8020, -14.8004, -14.7595, -15.1910,\n",
      "        -14.8371, -14.7409, -14.9132, -14.8382, -14.8315, -14.8050, -15.0846,\n",
      "        -14.8886, -14.9846, -14.9304, -14.9102, -14.8303, -14.8657, -14.9543,\n",
      "        -14.7469, -14.8084, -14.9597, -14.8201, -14.8762, -14.9657, -14.8911,\n",
      "        -15.0736], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-14.9308, -15.1116, -15.1346, -14.9203, -14.9355, -14.8763, -14.9467,\n",
      "        -14.9336, -14.9891, -15.0786, -14.9133, -14.8489, -14.8142, -14.8115,\n",
      "        -15.0340, -14.8695, -14.8403, -15.0969, -14.9517, -14.8914, -15.0106,\n",
      "        -14.7813, -14.9473, -14.9007, -14.7157, -14.8152, -14.8390, -14.6442,\n",
      "        -14.9015, -14.8297, -15.0167, -14.9314, -15.0537, -14.8961, -15.2313,\n",
      "        -15.0168, -14.8856, -15.1491, -15.1101, -14.9591, -14.9369, -14.9812,\n",
      "        -14.9445, -14.9085, -14.8572, -14.8821, -15.0087, -14.8020, -14.8945,\n",
      "        -15.0720], device='mps:0')\n",
      "mean: tensor(-14.9370, device='mps:0')\n",
      "current min: -15.231336\n",
      "iter_dt 4.20s; iter 3: train loss 0.16940 temperature: 5.029999999999999\n",
      "mean_logits tensor([-14.9370, -14.9255, -14.8422, -15.0674, -14.9698, -14.8427, -14.7995,\n",
      "        -15.0215, -15.0739, -14.9614, -15.0512, -15.0342, -14.9385, -14.8615,\n",
      "        -15.0438, -14.9081, -15.0068, -14.9241, -14.9743, -14.7374, -15.1109,\n",
      "        -14.9666, -14.8335, -14.9982, -14.8873, -14.8612, -14.9313, -14.9334,\n",
      "        -14.9935, -15.0135, -14.8236, -14.9571, -15.0923, -15.2352, -14.9623,\n",
      "        -14.8615, -15.0587, -14.7415, -14.8118, -14.9302, -14.8781, -14.9600,\n",
      "        -14.8054, -14.8867, -14.9108, -14.7822, -14.8359, -15.0153, -14.8313,\n",
      "        -14.6566], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-14.8290, -14.8638, -14.9768, -14.7055, -15.0818, -14.8331, -15.0877,\n",
      "        -15.0616, -14.9537, -15.0384, -15.0568, -14.8035, -14.8317, -14.9946,\n",
      "        -15.2439, -14.6786, -14.9474, -15.1087, -14.8878, -15.0834, -15.0460,\n",
      "        -14.8861, -15.1426, -15.1616, -15.1250, -14.6434, -14.9236, -14.9768,\n",
      "        -14.8365, -14.8240, -14.7947, -14.9666, -15.1361, -14.9472, -14.9941,\n",
      "        -14.9343, -14.8871, -14.7081, -14.9939, -14.9846, -14.8301, -14.8797,\n",
      "        -14.7784, -15.0591, -14.8561, -14.8939, -14.7704, -14.8863, -14.9567,\n",
      "        -14.9866], device='mps:0')\n",
      "mean: tensor(-14.9376, device='mps:0')\n",
      "current min: -15.243927\n",
      "iter_dt 4.29s; iter 4: train loss 0.16810 temperature: 5.039999999999999\n",
      "mean_logits tensor([-14.9145, -14.8053, -14.8674, -14.8544, -14.9731, -15.0440, -14.9301,\n",
      "        -14.8622, -14.9218, -14.8346, -14.9539, -15.0707, -14.8292, -14.7751,\n",
      "        -14.9936, -14.9965, -14.9990, -14.9340, -14.7976, -14.9922, -14.6798,\n",
      "        -14.8976, -14.9894, -14.9960, -14.9705, -14.9739, -14.7142, -15.1305,\n",
      "        -14.9673, -14.9675, -14.8761, -14.8791, -14.8855, -14.6990, -14.7916,\n",
      "        -14.8209, -14.8489, -14.8279, -15.1092, -15.0269, -14.9729, -15.0312,\n",
      "        -15.0308, -14.9617, -14.9114, -15.1651, -14.8805, -14.9478, -15.0750,\n",
      "        -15.0534], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-14.8948, -14.8223, -14.8578, -14.8109, -14.9974, -15.1492, -15.1640,\n",
      "        -14.8030, -15.0216, -15.1128, -14.9355, -15.1589, -15.0408, -14.6839,\n",
      "        -15.0513, -14.9760, -14.9107, -15.1458, -15.2518, -14.9958, -14.9343,\n",
      "        -15.0455, -14.8960, -15.0758, -14.9877, -15.1692, -14.8812, -15.2265,\n",
      "        -14.8313, -14.9387, -14.9437, -14.8246, -14.8813, -14.5679, -14.8429,\n",
      "        -15.1713, -14.8368, -15.0753, -15.0787, -15.2094, -15.1044, -14.6854,\n",
      "        -14.8912, -15.1709, -14.8324, -15.1148, -14.9367, -14.8727, -14.8945,\n",
      "        -15.1190], device='mps:0')\n",
      "mean: tensor(-14.9765, device='mps:0')\n",
      "current min: -15.251825\n",
      "iter_dt 4.35s; iter 5: train loss 0.16589 temperature: 5.049999999999999\n",
      "mean_logits tensor([-14.8820, -14.9287, -14.9632, -14.9485, -14.7825, -14.9445, -15.0537,\n",
      "        -14.9567, -15.1004, -14.9557, -15.0449, -14.8073, -14.8816, -14.9795,\n",
      "        -15.0522, -14.9320, -14.7682, -14.8782, -15.0775, -14.9775, -15.0114,\n",
      "        -14.8364, -14.8154, -14.8506, -14.8736, -14.8876, -14.9245, -14.9794,\n",
      "        -14.8736, -14.8931, -15.0136, -14.9963, -15.0434, -14.8688, -14.7066,\n",
      "        -14.9813, -14.7685, -14.8698, -14.7655, -14.8318, -14.9148, -14.9091,\n",
      "        -14.9268, -14.8820, -14.7866, -14.8362, -14.7449, -14.7344, -14.8995,\n",
      "        -14.9563], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-14.9700, -14.8791, -14.9597, -15.0661, -14.9322, -15.0224, -14.9955,\n",
      "        -15.0919, -15.1512, -14.9697, -15.1632, -15.0013, -14.9417, -15.1936,\n",
      "        -15.1949, -14.9750, -14.9010, -15.0122, -15.1719, -14.7556, -15.1142,\n",
      "        -14.7918, -15.2277, -14.9780, -15.0618, -15.0791, -14.9560, -14.9349,\n",
      "        -14.9415, -14.9208, -14.9763, -15.0669, -14.9366, -14.9153, -15.0448,\n",
      "        -14.8305, -14.9119, -14.9861, -15.0233, -15.0241, -14.8238, -15.1579,\n",
      "        -14.8739, -14.8894, -15.2071, -15.0369, -14.8099, -14.8428, -14.8586,\n",
      "        -15.0697], device='mps:0')\n",
      "mean: tensor(-14.9928, device='mps:0')\n",
      "current min: -15.251825\n",
      "iter_dt 4.35s; iter 6: train loss 0.22922 temperature: 5.059999999999999\n",
      "mean_logits tensor([-14.6753, -15.0117, -15.0609, -14.8454, -14.9943, -14.8925, -15.1501,\n",
      "        -14.9748, -14.9871, -14.9560, -15.1180, -14.9962, -15.0269, -14.9196,\n",
      "        -14.8748, -14.8355, -14.8943, -14.9888, -14.7514, -14.9006, -14.9106,\n",
      "        -15.0304, -15.0219, -15.0056, -14.8157, -14.8641, -14.9467, -14.8954,\n",
      "        -15.3369, -15.1232, -15.0834, -15.0239, -15.0466, -15.2830, -14.9832,\n",
      "        -14.8447, -15.0379, -14.9995, -14.9759, -14.9642, -15.0723, -14.9190,\n",
      "        -15.0002, -14.8111, -14.9726, -15.0350, -14.9546, -14.9544, -14.9362,\n",
      "        -15.0352], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-14.8360, -15.0292, -15.0962, -14.7761, -15.2108, -15.1199, -14.9018,\n",
      "        -14.9640, -14.8842, -15.1692, -14.9403, -15.0816, -15.2017, -15.1072,\n",
      "        -15.0454, -15.0009, -14.7143, -14.8524, -14.8246, -14.7308, -15.0091,\n",
      "        -15.1761, -14.9802, -15.2112, -14.7515, -15.0480, -15.0558, -14.8030,\n",
      "        -14.9312, -15.1695, -14.9370, -15.1803, -14.9883, -14.9317, -15.1544,\n",
      "        -15.1876, -15.0957, -15.0256, -15.1538, -14.8267, -14.8180, -14.9763,\n",
      "        -14.9996, -15.1563, -14.9845, -15.1103, -14.9068, -15.2142, -14.8678,\n",
      "        -14.9337], device='mps:0')\n",
      "mean: tensor(-15.0014, device='mps:0')\n",
      "current min: -15.251825\n",
      "iter_dt 4.43s; iter 7: train loss 0.25005 temperature: 5.0699999999999985\n",
      "mean_logits tensor([-14.9905, -15.1230, -14.7325, -14.8192, -14.9989, -15.0619, -15.2068,\n",
      "        -15.0386, -14.9630, -14.8730, -14.9706, -14.9853, -15.0767, -15.0100,\n",
      "        -15.0642, -14.9698, -14.9441, -14.9976, -15.2175, -14.9802, -15.1217,\n",
      "        -14.9316, -15.0169, -15.0839, -14.9511, -14.9870, -14.8667, -15.0663,\n",
      "        -14.8324, -14.9909, -14.8206, -14.9104, -14.8957, -15.3031, -14.9307,\n",
      "        -14.9006, -14.8590, -14.8657, -15.0584, -15.0060, -14.8522, -15.0592,\n",
      "        -15.0150, -14.8559, -15.0229, -15.1272, -15.1169, -14.9139, -14.8633,\n",
      "        -14.9283], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-15.0849, -14.9529, -14.8098, -15.1961, -15.2098, -15.1667, -15.1681,\n",
      "        -14.8851, -15.1716, -15.1393, -15.0740, -15.1959, -14.8106, -14.9966,\n",
      "        -15.1755, -15.1178, -15.1677, -14.9740, -14.8417, -15.1522, -15.2520,\n",
      "        -15.0664, -15.1724, -15.2301, -14.9190, -14.8035, -14.8468, -15.1440,\n",
      "        -14.8833, -14.9198, -15.0166, -15.1259, -15.0653, -14.8730, -14.8370,\n",
      "        -15.0495, -14.8757, -15.1426, -14.8847, -15.1002, -15.0837, -14.9634,\n",
      "        -15.2495, -14.8910, -15.0748, -15.2118, -15.2227, -14.9372, -15.1594,\n",
      "        -14.9783], device='mps:0')\n",
      "mean: tensor(-15.0454, device='mps:0')\n",
      "current min: -15.251996\n",
      "iter_dt 4.32s; iter 8: train loss 0.38307 temperature: 5.079999999999998\n",
      "mean_logits tensor([-15.3681, -15.0754, -14.9011, -15.1417, -15.0203, -14.8015, -14.9554,\n",
      "        -14.9758, -15.3068, -15.1034, -15.0492, -15.0774, -14.9786, -15.1647,\n",
      "        -15.0489, -14.8651, -14.9805, -14.9700, -14.9708, -15.0549, -15.0609,\n",
      "        -14.8756, -15.0236, -15.0770, -15.0881, -14.9272, -14.8874, -15.1135,\n",
      "        -15.1504, -15.0676, -15.0672, -15.0558, -15.0712, -14.9821, -15.3471,\n",
      "        -15.0282, -15.2261, -15.1819, -15.1160, -15.1430, -15.0066, -14.9834,\n",
      "        -15.4021, -15.0493, -15.0528, -15.0915, -14.8270, -15.1270, -14.9519,\n",
      "        -14.9239], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-14.5506, -15.2474, -15.1462, -15.0258, -15.0914, -14.8656, -15.1831,\n",
      "        -14.9205, -15.0870, -14.7080, -15.0534, -15.2316, -14.9940, -15.1666,\n",
      "        -15.0603, -15.0000, -15.1438, -15.1695, -15.0947, -15.1508, -15.1153,\n",
      "        -14.8713, -15.1890, -14.8796, -14.7602, -14.9187, -15.1200, -15.1194,\n",
      "        -14.9482, -15.1945, -15.1163, -15.1930, -15.2246, -15.1091, -15.0498,\n",
      "        -14.8944, -15.0744, -15.2861, -14.8643, -15.2301, -14.9784, -15.0827,\n",
      "        -14.6868, -14.7227, -15.1182, -15.0736, -15.0322, -15.1759, -15.0949,\n",
      "        -14.8109], device='mps:0')\n",
      "mean: tensor(-15.0365, device='mps:0')\n",
      "current min: -15.286092\n",
      "iter_dt 4.38s; iter 9: train loss 0.70304 temperature: 5.089999999999998\n",
      "mean_logits tensor([-15.1689, -15.2323, -15.0163, -15.0728, -15.1033, -15.1614, -14.9972,\n",
      "        -15.1771, -15.1869, -15.0848, -15.1608, -15.2149, -15.0852, -15.3914,\n",
      "        -14.8971, -15.0980, -14.8882, -14.9763, -15.2306, -15.3283, -14.8672,\n",
      "        -15.0269, -14.8785, -14.9988, -15.1045, -14.9013, -15.0409, -14.9428,\n",
      "        -15.1404, -14.9651, -15.0680, -15.3616, -15.0282, -15.0166, -15.0000,\n",
      "        -15.1169, -15.4159, -15.0809, -15.1837, -15.1585, -14.9377, -15.2186,\n",
      "        -15.1582, -15.2003, -14.9994, -14.9013, -15.5145, -14.9538, -14.8952,\n",
      "        -15.1760], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-15.0256, -15.1851, -15.0393, -15.1893, -15.1856, -15.1511, -14.9247,\n",
      "        -15.0634, -15.1098, -15.0608, -14.9765, -14.7661, -15.0977, -14.7643,\n",
      "        -14.9751, -15.2850, -15.0670, -15.2448, -14.8741, -14.7719, -15.2064,\n",
      "        -15.1416, -14.9377, -15.1423, -15.1565, -14.9244, -15.1170, -15.1213,\n",
      "        -15.1941, -14.9114, -14.8218, -14.6535, -15.2236, -14.8764, -15.0980,\n",
      "        -15.0117, -14.5082, -15.0255, -14.8996, -15.0610, -15.1859, -15.1585,\n",
      "        -15.1779, -15.1709, -15.1624, -15.1983, -14.4449, -15.1568, -14.9991,\n",
      "        -15.1774], device='mps:0')\n",
      "mean: tensor(-15.0324, device='mps:0')\n",
      "current min: -15.286092\n",
      "iter_dt 4.34s; iter 10: train loss 0.24794 temperature: 5.099999999999998\n",
      "mean_logits tensor([-14.8249, -15.3438, -15.1476, -15.0997, -14.8833, -15.1342, -15.2350,\n",
      "        -14.9204, -15.0701, -15.1412, -15.1889, -15.1296, -15.2292, -15.1446,\n",
      "        -15.1343, -15.0629, -15.2181, -15.1212, -14.9479, -15.0361, -14.9711,\n",
      "        -15.0098, -15.1628, -15.1238, -14.9344, -15.0888, -14.9942, -15.0905,\n",
      "        -15.1400, -15.0470, -15.0601, -14.9682, -15.0208, -15.0939, -15.0918,\n",
      "        -15.0169, -14.9644, -15.2495, -14.8368, -14.9210, -14.9893, -15.0305,\n",
      "        -15.1492, -14.9745, -15.0405, -15.0700, -14.8542, -14.9540, -14.9083,\n",
      "        -15.2381], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-14.8646, -14.7777, -14.9827, -15.2764, -14.8037, -15.1687, -15.0607,\n",
      "        -14.9947, -15.1349, -14.7573, -15.1427, -15.0221, -14.9529, -15.1858,\n",
      "        -15.2628, -15.0178, -15.1936, -15.0594, -14.7142, -15.0612, -14.8405,\n",
      "        -15.1191, -15.0171, -15.2605, -15.0145, -15.2137, -15.1579, -15.2306,\n",
      "        -15.1399, -15.1208, -15.1801, -15.2005, -15.0423, -15.0251, -15.1362,\n",
      "        -14.9660, -15.2312, -15.0428, -15.1509, -14.9971, -15.2467, -15.1931,\n",
      "        -15.2388, -15.1275, -15.0293, -15.0580, -15.0652, -15.0884, -15.0170,\n",
      "        -14.9318], device='mps:0')\n",
      "mean: tensor(-15.0703, device='mps:0')\n",
      "current min: -15.286092\n",
      "iter_dt 4.45s; iter 11: train loss 0.42521 temperature: 5.109999999999998\n",
      "mean_logits tensor([-14.8516, -15.3140, -15.0128, -14.9251, -15.0226, -14.9940, -14.9982,\n",
      "        -15.0328, -14.9700, -15.0814, -14.9398, -15.1378, -14.9629, -15.2503,\n",
      "        -14.9399, -14.8835, -15.2650, -15.1139, -14.9565, -15.0246, -14.8568,\n",
      "        -15.0180, -15.0990, -14.9857, -15.0448, -14.9745, -14.9443, -15.3408,\n",
      "        -15.2171, -14.9607, -15.1684, -15.0463, -14.9911, -15.1498, -15.2733,\n",
      "        -15.0885, -15.3837, -15.0792, -14.8275, -15.1237, -15.1553, -15.2031,\n",
      "        -15.1414, -15.0012, -15.0512, -14.9511, -14.9895, -14.9407, -15.0667,\n",
      "        -14.8432], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-15.0505, -14.6723, -15.1017, -14.7693, -15.1958, -14.9281, -15.2165,\n",
      "        -15.0323, -15.1051, -15.2077, -15.1916, -15.2457, -15.1472, -15.2708,\n",
      "        -14.8770, -15.1330, -15.2035, -14.8884, -14.9769, -15.0829, -14.7927,\n",
      "        -14.9691, -15.2271, -15.2115, -15.0418, -15.1702, -15.1171, -14.7386,\n",
      "        -14.6224, -15.0332, -15.0413, -14.8941, -15.1369, -15.2322, -15.1444,\n",
      "        -15.1131, -14.6270, -15.0198, -14.8226, -14.9047, -15.1294, -15.0647,\n",
      "        -15.1747, -15.0742, -14.8793, -15.2240, -14.9219, -15.0242, -14.7066,\n",
      "        -15.1306], device='mps:0')\n",
      "mean: tensor(-15.0297, device='mps:0')\n",
      "current min: -15.286092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_monitor = FileMonitor()\n",
    "callback_generator = DefaultCallback(model, monitors=[PrintMonitor(), file_monitor], del_temperature=0.01)\n",
    "trainer.set_callback('on_batch_end', callback_generator.generate())\n",
    "trainer.run()\n",
    "torch.save(model.state_dict(), '../saved_models/gptqe_test_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(file_monitor.min_energy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cost.sequence.tool = \"qiskit\"\n",
    "print(file_monitor.min_indices)\n",
    "cost.sequence._get_circuit(file_monitor.min_indices).qc.draw(output=\"mpl\", plot_barriers=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
