{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A demo using Hydrogen Hamiltonian with GPT-QE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T15:49:42.708426Z",
     "start_time": "2023-10-06T15:49:42.699961Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from gqe.mingpt.utils import set_seed\n",
    "\n",
    "set_seed(3407)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converged SCF energy = -15.0242100060364\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "paulis [+IIIYZXIIIIII, +IIIYZZZXIIII, +IIIYZZZZZXII, +IIIYZZZZZZZX, +IIXXIIIIIIYX, +IIXXIIIIYXII, +IIXXIIYXIIII, +IIXXYXIIIIII, +IIXYIIIIIIYY, +IIXYIIIIYYII, +IIXYIIYYIIII, +IIXYYYIIIIII, +IIYXIIIIIIYY, +IIYXIIIIYYII, +IIYXIIYYIIII, +IIYXYYIIIIII, +IIYYIIIIIIYX, +IIYYIIIIYXII, +IIYYIIYXIIII, +IIYYYXIIIIII, +IIYZXIIIIIII, +IIYZZZXIIIII, +IIYZZZZZXIII, +IIYZZZZZZZXI, +IXXIIYZZZZXI, +IXXIYZZZZZZX, +IXYIIXZZZZXI, +IXYIYZZZZZZY, +IXZXIYZZZZZX, +IXZYIXZZZZZX, +IXZYIYZZZZZY, +IYXIIXZZZZXI, +IYXIYZZZZZZY, +IYYIIYZZZZXI, +IYYIYZZZZZZX, +IYZXIXZZZZZX, +IYZXIYZZZZZY, +IYZYIYZZZZZX, +IYZZZXIIIIII, +IYZZZZZXIIII, +IYZZZZZZZXII, +IYZZZZZZZZZX, +XXIIIIIIIIYX, +XXIIIIIIYXII, +XXIIIIYXIIII, +XXIIYXIIIIII, +XYIIIIIIIIYY, +XYIIIIIIYYII, +XYIIIIYYIIII, +XYIIYYIIIIII, +XZXIYZZZZZXI, +XZYIXZZZZZXI, +XZYIYZZZZZYI, +XZZXIYZZZZXI, +XZZXYZZZZZZX, +XZZYIXZZZZXI, +XZZYYZZZZZZY, +YXIIIIIIIIYY, +YXIIIIIIYYII, +YXIIIIYYIIII, +YXIIYYIIIIII, +YYIIIIIIIIYX, +YYIIIIIIYXII, +YYIIIIYXIIII, +YYIIYXIIIIII, +YZXIXZZZZZXI, +YZXIYZZZZZYI, +YZYIYZZZZZXI, +YZZXIXZZZZXI, +YZZXYZZZZZZY, +YZZYIYZZZZXI, +YZZYYZZZZZZX, +YZZZXIIIIIII, +YZZZZZXIIIII, +YZZZZZZZXIII, +YZZZZZZZZZXI, +IIIIIIIIII]\n"
     ]
    }
   ],
   "source": [
    "from qwrapper.operator import PauliObservable\n",
    "from gqe.mingpt.cost import EnergyCost\n",
    "from qswift.compiler import DefaultOperatorPool\n",
    "from benchmark.molecule import DiatomicMolecularHamiltonian\n",
    "from gqe.operator_pool.uccsd import UCCSD, do_generate_molecule\n",
    "from gqe.common.initializer import HFStateInitializer\n",
    "from gqe.util import get_device\n",
    "from gqe.mingpt.callback import DefaultCallback, PretrainMonitor, PrintMonitor, FileMonitor\n",
    "\n",
    "# molecule = generate_molecule(\"Li\", \"H\", 1.596, \"sto-3g\", bravyi_kitaev=False)\n",
    "bond_length = 3.0\n",
    "geometry = f\"H 0.0 0.0 0.0\\n\" + f\"Be 0.0 0.0 {bond_length}\\n\" + f\"H 0.0 0.0 {2 * bond_length}\\n\"\n",
    "molecule = do_generate_molecule(geometry, \"sto-3g\", bravyi_kitaev=False)\n",
    "nqubit = 12\n",
    "\n",
    "# prepare Hamiltonian\n",
    "hamiltonian = DiatomicMolecularHamiltonian(nqubit, molecule, bravyi_kitaev=False)\n",
    "\n",
    "# prepare operator_pool\n",
    "uccsd = UCCSD(nqubit, molecule)\n",
    "paulis = uccsd.paulis\n",
    "paulis.append(PauliObservable(\"IIIIIIIIII\"))\n",
    "print('paulis', paulis)\n",
    "num_operators = len(paulis)\n",
    "initializer = HFStateInitializer(n_electrons=4)\n",
    "pool = DefaultOperatorPool(paulis)\n",
    "cost = EnergyCost(hamiltonian, initializer, pool,\n",
    "                  [1 / 320, -1 / 320, 1 / 160, -1 / 160, 1 / 80, -1 / 80, 1 / 40, -1 / 40, 0.05, -0.05, 0.1, -0.1, 0.2,\n",
    "                   -0.2])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-06T15:49:43.212640Z",
     "start_time": "2023-10-06T15:49:42.809417Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## FCI energy by diagonalization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "from qwrapper.hamiltonian import compute_ground_state\n",
    "\n",
    "#print(compute_ground_state(hamiltonian))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-06T15:49:43.215735Z",
     "start_time": "2023-10-06T15:49:43.213215Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hf state: -15.024210006036476\n"
     ]
    }
   ],
   "source": [
    "print(\"hf state:\", hamiltonian.exact_value(initializer.init_circuit(12, [], \"qulacs\")))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-06T15:49:43.230111Z",
     "start_time": "2023-10-06T15:49:43.216851Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup for GPT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-06T15:49:43.250207Z",
     "start_time": "2023-10-06T15:49:43.234737Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a GPT instance\n",
    "from gqe.mingpt.model import GPT\n",
    "\n",
    "\n",
    "def get_gpt(n_gates):\n",
    "    model_config = GPT.get_default_config()\n",
    "    model_config.model_type = 'gpt2'\n",
    "    model_config.vocab_size = cost.vocab_size()\n",
    "    model_config.n_gates = n_gates  # The number of gates for each circuit\n",
    "    model_config.block_size = model_config.n_gates\n",
    "    model_config.temperature = 5  # Each gate is generated with probability exp(-temperature * logit)\n",
    "    model_config.embd_pdrop = 0\n",
    "    model_config.resid_pdrop = 0\n",
    "    model_config.attn_pdrop = 0\n",
    "    model_config.std = 0.02\n",
    "    model_config.energy_offset = 14\n",
    "    model_config.embd_pdrop = 0\n",
    "    model_config.resid_pdrop = 0\n",
    "    model_config.attn_pdrop = 0\n",
    "    return GPT(model_config, cost)\n",
    "\n",
    "\n",
    "from gqe.mingpt.trainer import Trainer\n",
    "\n",
    "train_config = Trainer.get_default_config()\n",
    "train_config.learning_rate = 5e-7  # the model we're using is so small that we can go a bit faster\n",
    "train_config.max_iters = 3\n",
    "train_config.num_workers = 10\n",
    "train_config.n_samples = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 85.89M\n",
      "running on device mps\n",
      "iter_dt 0.00s; iter 0: train loss 0.00179 temperature: 100\n",
      "mean_logits tensor([-15.2740, -15.2824, -15.2714, -15.2725, -15.2750, -15.2824, -15.2799,\n",
      "        -15.2794, -15.2817, -15.2726, -15.2767, -15.2761, -15.2808, -15.2827,\n",
      "        -15.2772, -15.2716, -15.2768, -15.2799, -15.2753, -15.2825, -15.2813,\n",
      "        -15.2800, -15.2753, -15.2816, -15.2682, -15.2850, -15.2801, -15.2782,\n",
      "        -15.2771, -15.2797, -15.2829, -15.2769, -15.2756, -15.2813, -15.2800,\n",
      "        -15.2712, -15.2771, -15.2855, -15.2764, -15.2800, -15.2754, -15.2802,\n",
      "        -15.2705, -15.2849, -15.2739, -15.2753, -15.2877, -15.2858, -15.2772,\n",
      "        -15.2790], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-15.2452, -15.2740, -15.2650, -15.2631, -15.2761, -15.2631, -15.2692,\n",
      "        -15.2647, -15.2698, -15.2781, -15.2660, -15.2661, -15.2731, -15.2714,\n",
      "        -15.2751, -15.2660, -15.2706, -15.2621, -15.2694, -15.2691, -15.2629,\n",
      "        -15.2744, -15.2739, -15.2709, -15.2697, -15.2631, -15.2734, -15.2664,\n",
      "        -15.2687, -15.2704, -15.2645, -15.2692, -15.2701, -15.2672, -15.2661,\n",
      "        -15.2703, -15.2635, -15.2710, -15.2708, -15.2690, -15.2730, -15.2668,\n",
      "        -15.2595, -15.2756, -15.2647, -15.2717, -15.2766, -15.2718, -15.2607,\n",
      "        -15.2603], device='mps:0')\n",
      "mean: tensor(-15.2683, device='mps:0')\n",
      "current min: -15.2780905\n",
      "iter_dt 1696607728.44s; iter 1: train loss 0.00630 temperature: 100.01\n",
      "mean_logits tensor([-15.2440, -15.2505, -15.2535, -15.2514, -15.2510, -15.2495, -15.2423,\n",
      "        -15.2567, -15.2366, -15.2474, -15.2401, -15.2458, -15.2447, -15.2482,\n",
      "        -15.2441, -15.2398, -15.2389, -15.2430, -15.2495, -15.2444, -15.2473,\n",
      "        -15.2413, -15.2430, -15.2432, -15.2439, -15.2440, -15.2335, -15.2321,\n",
      "        -15.2457, -15.2427, -15.2427, -15.2451, -15.2353, -15.2414, -15.2464,\n",
      "        -15.2494, -15.2404, -15.2363, -15.2440, -15.2489, -15.2401, -15.2375,\n",
      "        -15.2456, -15.2395, -15.2439, -15.2382, -15.2488, -15.2449, -15.2477,\n",
      "        -15.2424], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-15.2680, -15.2688, -15.2678, -15.2607, -15.2654, -15.2587, -15.2607,\n",
      "        -15.2654, -15.2711, -15.2613, -15.2669, -15.2730, -15.2679, -15.2630,\n",
      "        -15.2763, -15.2686, -15.2587, -15.2589, -15.2717, -15.2650, -15.2678,\n",
      "        -15.2643, -15.2568, -15.2492, -15.2678, -15.2689, -15.2531, -15.2750,\n",
      "        -15.2768, -15.2733, -15.2612, -15.2690, -15.2720, -15.2601, -15.2581,\n",
      "        -15.2730, -15.2718, -15.2638, -15.2715, -15.2625, -15.2464, -15.2618,\n",
      "        -15.2646, -15.2705, -15.2571, -15.2586, -15.2715, -15.2623, -15.2551,\n",
      "        -15.2699], device='mps:0')\n",
      "mean: tensor(-15.2650, device='mps:0')\n",
      "current min: -15.2780905\n",
      "iter_dt 1.41s; iter 2: train loss 0.00283 temperature: 100.02000000000001\n",
      "mean_logits tensor([-15.2521, -15.2474, -15.2481, -15.2614, -15.2512, -15.2430, -15.2564,\n",
      "        -15.2545, -15.2490, -15.2558, -15.2605, -15.2521, -15.2480, -15.2473,\n",
      "        -15.2465, -15.2516, -15.2581, -15.2490, -15.2554, -15.2522, -15.2459,\n",
      "        -15.2561, -15.2457, -15.2413, -15.2576, -15.2481, -15.2535, -15.2437,\n",
      "        -15.2389, -15.2473, -15.2499, -15.2497, -15.2467, -15.2546, -15.2513,\n",
      "        -15.2499, -15.2490, -15.2393, -15.2565, -15.2516, -15.2467, -15.2505,\n",
      "        -15.2438, -15.2308, -15.2522, -15.2485, -15.2494, -15.2571, -15.2520,\n",
      "        -15.2500], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-15.2673, -15.2701, -15.2688, -15.2703, -15.2783, -15.2420, -15.2644,\n",
      "        -15.2392, -15.2741, -15.2766, -15.2654, -15.2406, -15.2514, -15.2537,\n",
      "        -15.2614, -15.2698, -15.2445, -15.2554, -15.2732, -15.2599, -15.2411,\n",
      "        -15.2561, -15.2680, -15.2633, -15.2636, -15.2438, -15.2467, -15.2492,\n",
      "        -15.2538, -15.2694, -15.2621, -15.2761, -15.2477, -15.2619, -15.2747,\n",
      "        -15.2668, -15.2565, -15.2636, -15.2673, -15.2532, -15.2629, -15.2615,\n",
      "        -15.2517, -15.2559, -15.2654, -15.2224, -15.2614, -15.2685, -15.2671,\n",
      "        -15.2519], device='mps:0')\n",
      "mean: tensor(-15.2596, device='mps:0')\n",
      "current min: -15.27828\n",
      "iter_dt 1.49s; iter 3: train loss 0.00283 temperature: 100.03000000000002\n",
      "mean_logits tensor([-15.2704, -15.2767, -15.2695, -15.2541, -15.2728, -15.2678, -15.2694,\n",
      "        -15.2641, -15.2615, -15.2700, -15.2608, -15.2581, -15.2623, -15.2671,\n",
      "        -15.2600, -15.2687, -15.2647, -15.2686, -15.2715, -15.2693, -15.2589,\n",
      "        -15.2672, -15.2640, -15.2676, -15.2618, -15.2727, -15.2668, -15.2653,\n",
      "        -15.2588, -15.2759, -15.2672, -15.2732, -15.2620, -15.2627, -15.2703,\n",
      "        -15.2645, -15.2719, -15.2710, -15.2716, -15.2744, -15.2582, -15.2706,\n",
      "        -15.2720, -15.2759, -15.2678, -15.2709, -15.2670, -15.2702, -15.2711,\n",
      "        -15.2612], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-15.2595, -15.2576, -15.2609, -15.2426, -15.2407, -15.2478, -15.2535,\n",
      "        -15.2610, -15.2350, -15.2674, -15.2751, -15.2616, -15.2624, -15.2653,\n",
      "        -15.2606, -15.2641, -15.2478, -15.2703, -15.2375, -15.2732, -15.2372,\n",
      "        -15.2679, -15.2627, -15.2426, -15.2479, -15.2643, -15.2335, -15.2555,\n",
      "        -15.2540, -15.2613, -15.2224, -15.2623, -15.2776, -15.2568, -15.2576,\n",
      "        -15.2693, -15.2728, -15.2629, -15.2619, -15.2613, -15.2748, -15.2753,\n",
      "        -15.2620, -15.2613, -15.2653, -15.2715, -15.2498, -15.2667, -15.2663,\n",
      "        -15.2593], device='mps:0')\n",
      "mean: tensor(-15.2586, device='mps:0')\n",
      "current min: -15.27828\n",
      "iter_dt 1.41s; iter 4: train loss 0.00221 temperature: 100.04000000000002\n",
      "mean_logits tensor([-15.2784, -15.2611, -15.2717, -15.2764, -15.2692, -15.2713, -15.2600,\n",
      "        -15.2639, -15.2732, -15.2632, -15.2720, -15.2744, -15.2687, -15.2691,\n",
      "        -15.2696, -15.2619, -15.2582, -15.2730, -15.2642, -15.2681, -15.2665,\n",
      "        -15.2613, -15.2548, -15.2700, -15.2722, -15.2734, -15.2578, -15.2720,\n",
      "        -15.2698, -15.2667, -15.2687, -15.2686, -15.2670, -15.2680, -15.2697,\n",
      "        -15.2679, -15.2707, -15.2768, -15.2698, -15.2676, -15.2663, -15.2732,\n",
      "        -15.2668, -15.2641, -15.2622, -15.2723, -15.2670, -15.2711, -15.2626,\n",
      "        -15.2726], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-15.2603, -15.2659, -15.2719, -15.2596, -15.2449, -15.2418, -15.2615,\n",
      "        -15.2447, -15.2577, -15.2549, -15.2727, -15.2662, -15.2659, -15.2654,\n",
      "        -15.2574, -15.2665, -15.2550, -15.2731, -15.2611, -15.2714, -15.2631,\n",
      "        -15.2505, -15.2487, -15.2633, -15.2704, -15.2384, -15.2427, -15.2648,\n",
      "        -15.2747, -15.2759, -15.2549, -15.2559, -15.2431, -15.2725, -15.2571,\n",
      "        -15.2492, -15.2633, -15.2655, -15.2620, -15.2614, -15.2344, -15.2598,\n",
      "        -15.2606, -15.2733, -15.2428, -15.2642, -15.2656, -15.2569, -15.2604,\n",
      "        -15.2556], device='mps:0')\n",
      "mean: tensor(-15.2594, device='mps:0')\n",
      "current min: -15.27828\n",
      "iter_dt 1.43s; iter 5: train loss 0.00167 temperature: 100.05000000000003\n",
      "mean_logits tensor([-15.2556, -15.2535, -15.2588, -15.2662, -15.2572, -15.2590, -15.2698,\n",
      "        -15.2418, -15.2571, -15.2518, -15.2537, -15.2709, -15.2507, -15.2573,\n",
      "        -15.2582, -15.2577, -15.2530, -15.2553, -15.2653, -15.2738, -15.2613,\n",
      "        -15.2575, -15.2570, -15.2593, -15.2552, -15.2593, -15.2582, -15.2624,\n",
      "        -15.2547, -15.2689, -15.2563, -15.2549, -15.2631, -15.2569, -15.2671,\n",
      "        -15.2557, -15.2553, -15.2603, -15.2590, -15.2645, -15.2576, -15.2546,\n",
      "        -15.2694, -15.2631, -15.2670, -15.2559, -15.2698, -15.2681, -15.2660,\n",
      "        -15.2570], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-15.2472, -15.2685, -15.2652, -15.2599, -15.2730, -15.2486, -15.2578,\n",
      "        -15.2506, -15.2640, -15.2480, -15.2488, -15.2553, -15.2608, -15.2553,\n",
      "        -15.2713, -15.2550, -15.2301, -15.2597, -15.2342, -15.2608, -15.2507,\n",
      "        -15.2739, -15.2608, -15.2619, -15.2738, -15.2590, -15.2602, -15.2629,\n",
      "        -15.2708, -15.2621, -15.2705, -15.2470, -15.2643, -15.2599, -15.2585,\n",
      "        -15.2477, -15.2502, -15.2705, -15.2246, -15.2673, -15.2627, -15.2490,\n",
      "        -15.2641, -15.2720, -15.2516, -15.2610, -15.2578, -15.2655, -15.2532,\n",
      "        -15.2545], device='mps:0')\n",
      "mean: tensor(-15.2580, device='mps:0')\n",
      "current min: -15.27828\n",
      "iter_dt 1.46s; iter 6: train loss 0.00240 temperature: 100.06000000000003\n",
      "mean_logits tensor([-15.2526, -15.2537, -15.2437, -15.2551, -15.2442, -15.2499, -15.2456,\n",
      "        -15.2491, -15.2531, -15.2444, -15.2506, -15.2503, -15.2550, -15.2503,\n",
      "        -15.2507, -15.2457, -15.2452, -15.2522, -15.2518, -15.2514, -15.2550,\n",
      "        -15.2487, -15.2413, -15.2460, -15.2556, -15.2563, -15.2469, -15.2435,\n",
      "        -15.2487, -15.2561, -15.2464, -15.2454, -15.2472, -15.2477, -15.2533,\n",
      "        -15.2470, -15.2446, -15.2511, -15.2490, -15.2482, -15.2499, -15.2591,\n",
      "        -15.2512, -15.2399, -15.2495, -15.2568, -15.2601, -15.2527, -15.2502,\n",
      "        -15.2472], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-15.2706, -15.2671, -15.2698, -15.2595, -15.2743, -15.2671, -15.2506,\n",
      "        -15.2646, -15.2493, -15.2481, -15.2524, -15.2510, -15.2578, -15.2458,\n",
      "        -15.2565, -15.2610, -15.2591, -15.2640, -15.2592, -15.2601, -15.2673,\n",
      "        -15.2607, -15.2602, -15.2633, -15.2750, -15.2643, -15.2511, -15.2625,\n",
      "        -15.2663, -15.2668, -15.2589, -15.2564, -15.2756, -15.2551, -15.2578,\n",
      "        -15.2520, -15.2586, -15.2567, -15.2484, -15.2616, -15.2625, -15.2750,\n",
      "        -15.2769, -15.2598, -15.2602, -15.2659, -15.2679, -15.2617, -15.2615,\n",
      "        -15.2700], device='mps:0')\n",
      "mean: tensor(-15.2614, device='mps:0')\n",
      "current min: -15.27828\n",
      "iter_dt 1.47s; iter 7: train loss 0.00321 temperature: 100.07000000000004\n",
      "mean_logits tensor([-15.2505, -15.2485, -15.2525, -15.2491, -15.2535, -15.2539, -15.2470,\n",
      "        -15.2445, -15.2492, -15.2553, -15.2418, -15.2522, -15.2483, -15.2484,\n",
      "        -15.2477, -15.2490, -15.2468, -15.2506, -15.2482, -15.2448, -15.2472,\n",
      "        -15.2496, -15.2474, -15.2492, -15.2460, -15.2474, -15.2526, -15.2475,\n",
      "        -15.2596, -15.2461, -15.2501, -15.2540, -15.2429, -15.2443, -15.2543,\n",
      "        -15.2446, -15.2515, -15.2438, -15.2498, -15.2600, -15.2512, -15.2478,\n",
      "        -15.2508, -15.2574, -15.2539, -15.2497, -15.2528, -15.2484, -15.2577,\n",
      "        -15.2496], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-15.2466, -15.2645, -15.2713, -15.2543, -15.2650, -15.2693, -15.2545,\n",
      "        -15.2658, -15.2624, -15.2634, -15.2695, -15.2638, -15.2719, -15.2690,\n",
      "        -15.2620, -15.2675, -15.2718, -15.2516, -15.2600, -15.2620, -15.2606,\n",
      "        -15.2582, -15.2588, -15.2465, -15.2614, -15.2660, -15.2575, -15.2743,\n",
      "        -15.2750, -15.2670, -15.2647, -15.2728, -15.2759, -15.2705, -15.2694,\n",
      "        -15.2615, -15.2611, -15.2636, -15.2517, -15.2685, -15.2577, -15.2745,\n",
      "        -15.2624, -15.2670, -15.2696, -15.2721, -15.2628, -15.2503, -15.2647,\n",
      "        -15.2541], device='mps:0')\n",
      "mean: tensor(-15.2637, device='mps:0')\n",
      "current min: -15.27828\n",
      "iter_dt 1.41s; iter 8: train loss 0.00221 temperature: 100.08000000000004\n",
      "mean_logits tensor([-15.2558, -15.2608, -15.2667, -15.2578, -15.2580, -15.2567, -15.2500,\n",
      "        -15.2515, -15.2608, -15.2574, -15.2608, -15.2590, -15.2608, -15.2646,\n",
      "        -15.2554, -15.2628, -15.2529, -15.2571, -15.2583, -15.2578, -15.2569,\n",
      "        -15.2519, -15.2610, -15.2556, -15.2542, -15.2624, -15.2610, -15.2632,\n",
      "        -15.2394, -15.2556, -15.2588, -15.2597, -15.2617, -15.2459, -15.2558,\n",
      "        -15.2557, -15.2563, -15.2555, -15.2655, -15.2585, -15.2555, -15.2510,\n",
      "        -15.2661, -15.2617, -15.2574, -15.2588, -15.2636, -15.2365, -15.2596,\n",
      "        -15.2565], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-15.2694, -15.2709, -15.2750, -15.2466, -15.2629, -15.2640, -15.2662,\n",
      "        -15.2766, -15.2657, -15.2686, -15.2709, -15.2705, -15.2709, -15.2656,\n",
      "        -15.2592, -15.2774, -15.2630, -15.2714, -15.2693, -15.2466, -15.2587,\n",
      "        -15.2589, -15.2639, -15.2614, -15.2755, -15.2663, -15.2632, -15.2466,\n",
      "        -15.2673, -15.2574, -15.2605, -15.2746, -15.2712, -15.2646, -15.2709,\n",
      "        -15.2684, -15.2688, -15.2774, -15.2711, -15.2562, -15.2296, -15.2685,\n",
      "        -15.2509, -15.2712, -15.2745, -15.2670, -15.2606, -15.2710, -15.2627,\n",
      "        -15.2582], device='mps:0')\n",
      "mean: tensor(-15.2650, device='mps:0')\n",
      "current min: -15.27828\n",
      "iter_dt 1.43s; iter 9: train loss 0.00117 temperature: 100.09000000000005\n",
      "mean_logits tensor([-15.2628, -15.2749, -15.2690, -15.2680, -15.2709, -15.2625, -15.2593,\n",
      "        -15.2746, -15.2677, -15.2715, -15.2694, -15.2569, -15.2644, -15.2733,\n",
      "        -15.2738, -15.2741, -15.2737, -15.2726, -15.2621, -15.2654, -15.2671,\n",
      "        -15.2741, -15.2588, -15.2615, -15.2663, -15.2720, -15.2640, -15.2660,\n",
      "        -15.2743, -15.2741, -15.2700, -15.2664, -15.2634, -15.2659, -15.2698,\n",
      "        -15.2741, -15.2677, -15.2741, -15.2639, -15.2765, -15.2607, -15.2697,\n",
      "        -15.2717, -15.2770, -15.2741, -15.2678, -15.2641, -15.2588, -15.2728,\n",
      "        -15.2738], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-15.2628, -15.2633, -15.2482, -15.2678, -15.2573, -15.2671, -15.2628,\n",
      "        -15.2613, -15.2515, -15.2620, -15.2644, -15.2612, -15.2591, -15.2698,\n",
      "        -15.2723, -15.2709, -15.2750, -15.2648, -15.2616, -15.2658, -15.2598,\n",
      "        -15.2709, -15.2643, -15.2675, -15.2360, -15.2648, -15.2465, -15.2687,\n",
      "        -15.2685, -15.2709, -15.2618, -15.2785, -15.2509, -15.2588, -15.2578,\n",
      "        -15.2709, -15.2454, -15.2709, -15.2539, -15.2726, -15.2554, -15.2677,\n",
      "        -15.2590, -15.2718, -15.2684, -15.2632, -15.2616, -15.2701, -15.2637,\n",
      "        -15.2646], device='mps:0')\n",
      "mean: tensor(-15.2631, device='mps:0')\n",
      "current min: -15.278541\n",
      "iter_dt 1.43s; iter 10: train loss 0.00288 temperature: 100.10000000000005\n",
      "mean_logits tensor([-15.2692, -15.2735, -15.2639, -15.2688, -15.2699, -15.2802, -15.2697,\n",
      "        -15.2699, -15.2721, -15.2668, -15.2707, -15.2687, -15.2815, -15.2735,\n",
      "        -15.2685, -15.2669, -15.2689, -15.2562, -15.2803, -15.2622, -15.2783,\n",
      "        -15.2652, -15.2661, -15.2671, -15.2782, -15.2795, -15.2641, -15.2719,\n",
      "        -15.2741, -15.2624, -15.2722, -15.2671, -15.2765, -15.2714, -15.2706,\n",
      "        -15.2740, -15.2625, -15.2621, -15.2730, -15.2748, -15.2713, -15.2679,\n",
      "        -15.2674, -15.2726, -15.2702, -15.2652, -15.2763, -15.2711, -15.2646,\n",
      "        -15.2711], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-15.2650, -15.2617, -15.2698, -15.2642, -15.2623, -15.2577, -15.2547,\n",
      "        -15.2635, -15.2595, -15.2673, -15.2465, -15.2565, -15.2617, -15.2689,\n",
      "        -15.2587, -15.2480, -15.2535, -15.2751, -15.2615, -15.2470, -15.2709,\n",
      "        -15.2733, -15.2536, -15.2783, -15.2594, -15.2684, -15.2633, -15.2605,\n",
      "        -15.2603, -15.2631, -15.2465, -15.2684, -15.2466, -15.2585, -15.2666,\n",
      "        -15.2510, -15.2687, -15.2652, -15.2674, -15.2548, -15.2612, -15.2540,\n",
      "        -15.2513, -15.2658, -15.2627, -15.2583, -15.2383, -15.2608, -15.2537,\n",
      "        -15.2360], device='mps:0')\n",
      "mean: tensor(-15.2598, device='mps:0')\n",
      "current min: -15.278541\n",
      "iter_dt 1.44s; iter 11: train loss 0.00182 temperature: 100.11000000000006\n",
      "mean_logits tensor([-15.2687, -15.2696, -15.2688, -15.2604, -15.2633, -15.2715, -15.2691,\n",
      "        -15.2793, -15.2689, -15.2773, -15.2621, -15.2675, -15.2663, -15.2606,\n",
      "        -15.2716, -15.2688, -15.2689, -15.2624, -15.2628, -15.2751, -15.2768,\n",
      "        -15.2723, -15.2785, -15.2710, -15.2727, -15.2732, -15.2708, -15.2784,\n",
      "        -15.2707, -15.2739, -15.2731, -15.2633, -15.2779, -15.2663, -15.2723,\n",
      "        -15.2787, -15.2754, -15.2725, -15.2734, -15.2677, -15.2668, -15.2618,\n",
      "        -15.2692, -15.2714, -15.2718, -15.2659, -15.2593, -15.2631, -15.2730,\n",
      "        -15.2779], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-15.2666, -15.2644, -15.2640, -15.2632, -15.2508, -15.2539, -15.2677,\n",
      "        -15.2640, -15.2678, -15.2578, -15.2622, -15.2442, -15.2611, -15.2687,\n",
      "        -15.2646, -15.2619, -15.2679, -15.2749, -15.2482, -15.2666, -15.2610,\n",
      "        -15.2666, -15.2690, -15.2598, -15.2660, -15.2701, -15.2582, -15.2519,\n",
      "        -15.2617, -15.2515, -15.2670, -15.2618, -15.2532, -15.2574, -15.2614,\n",
      "        -15.2644, -15.2671, -15.2642, -15.2546, -15.2619, -15.2655, -15.2632,\n",
      "        -15.2697, -15.2612, -15.2468, -15.2590, -15.2582, -15.2436, -15.2619,\n",
      "        -15.2676], device='mps:0')\n",
      "mean: tensor(-15.2613, device='mps:0')\n",
      "current min: -15.278541\n",
      "iter_dt 1.42s; iter 12: train loss 0.00096 temperature: 100.12000000000006\n",
      "mean_logits tensor([-15.2566, -15.2632, -15.2585, -15.2648, -15.2648, -15.2619, -15.2712,\n",
      "        -15.2558, -15.2695, -15.2648, -15.2672, -15.2644, -15.2658, -15.2620,\n",
      "        -15.2531, -15.2679, -15.2681, -15.2712, -15.2703, -15.2661, -15.2602,\n",
      "        -15.2665, -15.2631, -15.2638, -15.2657, -15.2667, -15.2648, -15.2559,\n",
      "        -15.2632, -15.2667, -15.2586, -15.2556, -15.2568, -15.2662, -15.2524,\n",
      "        -15.2602, -15.2533, -15.2667, -15.2678, -15.2689, -15.2712, -15.2646,\n",
      "        -15.2627, -15.2666, -15.2736, -15.2552, -15.2659, -15.2643, -15.2622,\n",
      "        -15.2627], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-15.2677, -15.2691, -15.2635, -15.2648, -15.2659, -15.2670, -15.2676,\n",
      "        -15.2614, -15.2621, -15.2688, -15.2641, -15.2612, -15.2622, -15.2566,\n",
      "        -15.2687, -15.2666, -15.2612, -15.2676, -15.2746, -15.2634, -15.2603,\n",
      "        -15.2693, -15.2645, -15.2733, -15.2670, -15.2670, -15.2512, -15.2660,\n",
      "        -15.2727, -15.2684, -15.2658, -15.2627, -15.2618, -15.2701, -15.2771,\n",
      "        -15.2755, -15.2697, -15.2696, -15.2694, -15.2610, -15.2676, -15.2380,\n",
      "        -15.2678, -15.2519, -15.2630, -15.2658, -15.2769, -15.2633, -15.2652,\n",
      "        -15.2652], device='mps:0')\n",
      "mean: tensor(-15.2654, device='mps:0')\n",
      "current min: -15.278541\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[51], line 20\u001B[0m\n\u001B[1;32m     17\u001B[0m trainer\u001B[38;5;241m.\u001B[39mset_callback(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mon_batch_end\u001B[39m\u001B[38;5;124m'\u001B[39m, DefaultCallback(model, monitors\u001B[38;5;241m=\u001B[39m[PrintMonitor(), file_monitor],\n\u001B[1;32m     18\u001B[0m                                                      del_temperature\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.01\u001B[39m)\u001B[38;5;241m.\u001B[39mgenerate())\n\u001B[1;32m     19\u001B[0m file_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../output/trajectory_beh2_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn_gates\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mseed\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtemperature\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.json\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 20\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m torch\u001B[38;5;241m.\u001B[39msave(model\u001B[38;5;241m.\u001B[39mstate_dict(), \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../saved_models/gptqe_train_beh2_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn_gates\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mseed\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtemperature\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m     22\u001B[0m file_monitor\u001B[38;5;241m.\u001B[39msave(file_name)\n",
      "File \u001B[0;32m~/PycharmProjects/gqe/gqe/mingpt/trainer.py:95\u001B[0m, in \u001B[0;36mTrainer.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m     94\u001B[0m     \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_samples, \u001B[38;5;241m1\u001B[39m, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mint)\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m---> 95\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss, detail \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     96\u001B[0m     \u001B[38;5;66;03m# backprop and update the parameters\u001B[39;00m\n\u001B[1;32m     97\u001B[0m     model\u001B[38;5;241m.\u001B[39mzero_grad(set_to_none\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/PycharmProjects/gqe/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/PycharmProjects/gqe/gqe/mingpt/model.py:354\u001B[0m, in \u001B[0;36mGPT.forward\u001B[0;34m(self, idx, energies)\u001B[0m\n\u001B[1;32m    353\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, idx, energies\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m--> 354\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcost\u001B[49m\u001B[43m(\u001B[49m\u001B[43midx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menergies\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    355\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[0;32m~/PycharmProjects/gqe/gqe/mingpt/model.py:296\u001B[0m, in \u001B[0;36mGPT.cost\u001B[0;34m(self, idx, energies)\u001B[0m\n\u001B[1;32m    294\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m energies \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    295\u001B[0m     idx_output, logits_base \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgenerate(idx, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_gates)\n\u001B[0;32m--> 296\u001B[0m     energies \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cost\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menergy\u001B[49m\u001B[43m(\u001B[49m\u001B[43midx_output\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    297\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    298\u001B[0m     idx_output \u001B[38;5;241m=\u001B[39m idx[:, \u001B[38;5;241m1\u001B[39m:]\n",
      "File \u001B[0;32m~/PycharmProjects/gqe/gqe/mingpt/cost.py:64\u001B[0m, in \u001B[0;36mEnergyCost.energy\u001B[0;34m(self, idx)\u001B[0m\n\u001B[1;32m     62\u001B[0m         seq\u001B[38;5;241m.\u001B[39mextend(final_seq)\n\u001B[1;32m     63\u001B[0m         final_seq \u001B[38;5;241m=\u001B[39m seq\n\u001B[0;32m---> 64\u001B[0m     energies\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msequence\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfinal_seq\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mtensor(energies, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat)\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n",
      "File \u001B[0;32m~/PycharmProjects/gqe/venv/lib/python3.8/site-packages/qswift/sequence.py:69\u001B[0m, in \u001B[0;36mSequence.evaluate\u001B[0;34m(self, indices)\u001B[0m\n\u001B[1;32m     67\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mevaluate\u001B[39m(\u001B[38;5;28mself\u001B[39m, indices):\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnshot \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m---> 69\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mobservable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexact_value\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_circuit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindices\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     70\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     71\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m h, p \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobservable\u001B[38;5;241m.\u001B[39mhs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobservable\u001B[38;5;241m.\u001B[39mpaulis):\n",
      "File \u001B[0;32m~/PycharmProjects/gqe/venv/lib/python3.8/site-packages/qwrapper/obs.py:164\u001B[0m, in \u001B[0;36mHamiltonian.exact_value\u001B[0;34m(self, qc)\u001B[0m\n\u001B[1;32m    162\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_qulacs_obs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    163\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_qulacs_obs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_qulacs_obs()\n\u001B[0;32m--> 164\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_qulacs_obs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_expectation_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43mqc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_state\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_identity\n\u001B[1;32m    165\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_matrix \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    166\u001B[0m     matrix \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mdiag(np\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;28mpow\u001B[39m(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnqubit), dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mcomplex128))\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from gqe.mingpt.data import EnergyDataset\n",
    "\n",
    "# print(files)\n",
    "seed = 31\n",
    "temperature = 100\n",
    "n_gates = 12\n",
    "model = get_gpt(n_gates)\n",
    "model.load_state_dict(torch.load(f'../saved_models/gptqe_train_beh2_{n_gates}_{seed}_50'))\n",
    "set_seed(seed)\n",
    "file_monitor = FileMonitor()\n",
    "train_config.max_iters = 200\n",
    "train_config.n_samples = 50\n",
    "model.temperature = temperature\n",
    "train_config.learning_rate = 5e-7\n",
    "trainer = Trainer(train_config, model)\n",
    "trainer.set_callback('on_batch_end', DefaultCallback(model, monitors=[PrintMonitor(), file_monitor],\n",
    "                                                     del_temperature=0.01).generate())\n",
    "file_name = f\"../output/trajectory_beh2_{n_gates}_{seed}_{temperature}.json\"\n",
    "trainer.run()\n",
    "torch.save(model.state_dict(), f'../saved_models/gptqe_train_beh2_{n_gates}_{seed}_{temperature}')\n",
    "file_monitor.save(file_name)\n",
    "# files.append(file_name)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-06T15:55:46.898100Z",
     "start_time": "2023-10-06T15:55:24.812025Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# file_name = f\"../output/trajectory_beh2_{n_gates}_{seed}_{temperature}.json\"\n",
    "# torch.save(model.state_dict(), f'../saved_models/gptqe_train_beh2_{n_gates}_{seed}_{temperature}')\n",
    "# file_monitor.save(file_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
