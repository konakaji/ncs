{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A demo using Hydrogen Hamiltonian with GPT-QE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-27T23:06:14.501078Z",
     "start_time": "2023-09-27T23:06:14.488658Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from gqe.mingpt.utils import set_seed\n",
    "\n",
    "set_seed(3407)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converged SCF energy = -1.97060224599968\n",
      "paulis [+IIIIIXIIIIII, +IIIIIXZYIIII, +IIIIIXZZZYII, +IIIIIXZZZZZY, +IIIIIYZXIIII, +IIIIIYZZZXII, +IIIIIYZZZZZX, +IIIIXIIIIIII, +IIIIXXIIIIXY, +IIIIXXIIIIYX, +IIIIXXIIXYII, +IIIIXXIIYXII, +IIIIXXIXZZYI, +IIIIXXIYZZXI, +IIIIXXXYIIII, +IIIIXXXZZZZY, +IIIIXXYXIIII, +IIIIXXYZZZZX, +IIIIXYIIIIXX, +IIIIXYIIIIYY, +IIIIXYIIXXII, +IIIIXYIIYYII, +IIIIXYIXZZXI, +IIIIXYIYZZYI, +IIIIXYXXIIII, +IIIIXYXZZZZX, +IIIIXYYYIIII, +IIIIXYYZZZZY, +IIIIXZYIIIII, +IIIIXZZZYIII, +IIIIXZZZZZYI, +IIIIYXIIIIXX, +IIIIYXIIIIYY, +IIIIYXIIXXII, +IIIIYXIIYYII, +IIIIYXIXZZXI, +IIIIYXIYZZYI, +IIIIYXXXIIII, +IIIIYXXZZZZX, +IIIIYXYYIIII, +IIIIYXYZZZZY, +IIIIYYIIIIXY, +IIIIYYIIIIYX, +IIIIYYIIXYII, +IIIIYYIIYXII, +IIIIYYIXZZYI, +IIIIYYIYZZXI, +IIIIYYXYIIII, +IIIIYYXZZZZY, +IIIIYYYXIIII, +IIIIYYYZZZZX, +IIIIYZXIIIII, +IIIIYZZZXIII, +IIIIYZZZZZXI, +IIIXIIIIIIII, +IIIXXIIIIXYI, +IIIXXIIIIYXI, +IIIXXIIIXZZY, +IIIXXIIIYZZX, +IIIXXIIXYIII, +IIIXXIIYXIII, +IIIXXIXZZYII, +IIIXXIYZZXII, +IIIXYIIIIXXI, +IIIXYIIIIYYI, +IIIXYIIIXZZX, +IIIXYIIIYZZY, +IIIXYIIXXIII, +IIIXYIIYYIII, +IIIXYIXZZXII, +IIIXYIYZZYII, +IIIXZXIIIXZY, +IIIXZXIIIYZX, +IIIXZXIXZYII, +IIIXZXIYZXII, +IIIXZYIIIXZX, +IIIXZYIIIYZY, +IIIXZYIXZXII, +IIIXZYIYZYII, +IIIXZZZYIIII, +IIIXZZZZZYII, +IIIXZZZZZZZY, +IIIYXIIIIXXI, +IIIYXIIIIYYI, +IIIYXIIIXZZX, +IIIYXIIIYZZY, +IIIYXIIXXIII, +IIIYXIIYYIII, +IIIYXIXZZXII, +IIIYXIYZZYII, +IIIYYIIIIXYI, +IIIYYIIIIYXI, +IIIYYIIIXZZY, +IIIYYIIIYZZX, +IIIYYIIXYIII, +IIIYYIIYXIII, +IIIYYIXZZYII, +IIIYYIYZZXII, +IIIYZXIIIXZX, +IIIYZXIIIYZY, +IIIYZXIXZXII, +IIIYZXIYZYII, +IIIYZYIIIXZY, +IIIYZYIIIYZX, +IIIYZYIXZYII, +IIIYZYIYZXII, +IIIYZZZXIIII, +IIIYZZZZZXII, +IIIYZZZZZZZX, +IIXIIIIIIIII, +IIXXIIIIIIXY, +IIXXIIIIIIYX, +IIXXIIIIXYII, +IIXXIIIIYXII, +IIXXIIIXZZYI, +IIXXIIIYZZXI, +IIXXIIXYIIII, +IIXXIIXZZZZY, +IIXXIIYXIIII, +IIXXIIYZZZZX, +IIXYIIIIIIXX, +IIXYIIIIIIYY, +IIXYIIIIXXII, +IIXYIIIIYYII, +IIXYIIIXZZXI, +IIXYIIIYZZYI, +IIXYIIXXIIII, +IIXYIIXZZZZX, +IIXYIIYYIIII, +IIXYIIYZZZZY, +IIXZXIIIXZYI, +IIXZXIIIYZXI, +IIXZXIXZYIII, +IIXZXIYZXIII, +IIXZYIIIXZXI, +IIXZYIIIYZYI, +IIXZYIXZXIII, +IIXZYIYZYIII, +IIXZZXIIIXYI, +IIXZZXIIIYXI, +IIXZZXIIXZZY, +IIXZZXIIYZZX, +IIXZZXIXYIII, +IIXZZXIYXIII, +IIXZZXXZZYII, +IIXZZXYZZXII, +IIXZZYIIIXXI, +IIXZZYIIIYYI, +IIXZZYIIXZZX, +IIXZZYIIYZZY, +IIXZZYIXXIII, +IIXZZYIYYIII, +IIXZZYXZZXII, +IIXZZYYZZYII, +IIXZZZYIIIII, +IIXZZZZZYIII, +IIXZZZZZZZYI, +IIYXIIIIIIXX, +IIYXIIIIIIYY, +IIYXIIIIXXII, +IIYXIIIIYYII, +IIYXIIIXZZXI, +IIYXIIIYZZYI, +IIYXIIXXIIII, +IIYXIIXZZZZX, +IIYXIIYYIIII, +IIYXIIYZZZZY, +IIYYIIIIIIXY, +IIYYIIIIIIYX, +IIYYIIIIXYII, +IIYYIIIIYXII, +IIYYIIIXZZYI, +IIYYIIIYZZXI, +IIYYIIXYIIII, +IIYYIIXZZZZY, +IIYYIIYXIIII, +IIYYIIYZZZZX, +IIYZXIIIXZXI, +IIYZXIIIYZYI, +IIYZXIXZXIII, +IIYZXIYZYIII, +IIYZYIIIXZYI, +IIYZYIIIYZXI, +IIYZYIXZYIII, +IIYZYIYZXIII, +IIYZZXIIIXXI, +IIYZZXIIIYYI, +IIYZZXIIXZZX, +IIYZZXIIYZZY, +IIYZZXIXXIII, +IIYZZXIYYIII, +IIYZZXXZZXII, +IIYZZXYZZYII, +IIYZZYIIIXYI, +IIYZZYIIIYXI, +IIYZZYIIXZZY, +IIYZZYIIYZZX, +IIYZZYIXYIII, +IIYZZYIYXIII, +IIYZZYXZZYII, +IIYZZYYZZXII, +IIYZZZXIIIII, +IIYZZZZZXIII, +IIYZZZZZZZXI, +IXIIIIIIIIII, +IXXIIIIIIXYI, +IXXIIIIIIYXI, +IXXIIIIIXZZY, +IXXIIIIIYZZX, +IXXIIIIXYIII, +IXXIIIIYXIII, +IXXIIIXZZYII, +IXXIIIYZZXII, +IXYIIIIIIXXI, +IXYIIIIIIYYI, +IXYIIIIIXZZX, +IXYIIIIIYZZY, +IXYIIIIXXIII, +IXYIIIIYYIII, +IXYIIIXZZXII, +IXYIIIYZZYII, +IXZXIIIIIXZY, +IXZXIIIIIYZX, +IXZXIIIXZYII, +IXZXIIIYZXII, +IXZYIIIIIXZX, +IXZYIIIIIYZY, +IXZYIIIXZXII, +IXZYIIIYZYII, +IXZZXIIIIIXY, +IXZZXIIIIIYX, +IXZZXIIIXYII, +IXZZXIIIYXII, +IXZZXIIXZZYI, +IXZZXIIYZZXI, +IXZZXIXYIIII, +IXZZXIXZZZZY, +IXZZXIYXIIII, +IXZZXIYZZZZX, +IXZZYIIIIIXX, +IXZZYIIIIIYY, +IXZZYIIIXXII, +IXZZYIIIYYII, +IXZZYIIXZZXI, +IXZZYIIYZZYI, +IXZZYIXXIIII, +IXZZYIXZZZZX, +IXZZYIYYIIII, +IXZZYIYZZZZY, +IXZZZXIXZZZY, +IXZZZXIYZZZX, +IXZZZYIXZZZX, +IXZZZYIYZZZY, +IXZZZZZYIIII, +IXZZZZZZZYII, +IXZZZZZZZZZY, +IYXIIIIIIXXI, +IYXIIIIIIYYI, +IYXIIIIIXZZX, +IYXIIIIIYZZY, +IYXIIIIXXIII, +IYXIIIIYYIII, +IYXIIIXZZXII, +IYXIIIYZZYII, +IYYIIIIIIXYI, +IYYIIIIIIYXI, +IYYIIIIIXZZY, +IYYIIIIIYZZX, +IYYIIIIXYIII, +IYYIIIIYXIII, +IYYIIIXZZYII, +IYYIIIYZZXII, +IYZXIIIIIXZX, +IYZXIIIIIYZY, +IYZXIIIXZXII, +IYZXIIIYZYII, +IYZYIIIIIXZY, +IYZYIIIIIYZX, +IYZYIIIXZYII, +IYZYIIIYZXII, +IYZZXIIIIIXX, +IYZZXIIIIIYY, +IYZZXIIIXXII, +IYZZXIIIYYII, +IYZZXIIXZZXI, +IYZZXIIYZZYI, +IYZZXIXXIIII, +IYZZXIXZZZZX, +IYZZXIYYIIII, +IYZZXIYZZZZY, +IYZZYIIIIIXY, +IYZZYIIIIIYX, +IYZZYIIIXYII, +IYZZYIIIYXII, +IYZZYIIXZZYI, +IYZZYIIYZZXI, +IYZZYIXYIIII, +IYZZYIXZZZZY, +IYZZYIYXIIII, +IYZZYIYZZZZX, +IYZZZXIXZZZX, +IYZZZXIYZZZY, +IYZZZYIXZZZY, +IYZZZYIYZZZX, +IYZZZZZXIIII, +IYZZZZZZZXII, +IYZZZZZZZZZX, +XIIIIIIIIIII, +XXIIIIIIIIXY, +XXIIIIIIIIYX, +XXIIIIIIXYII, +XXIIIIIIYXII, +XXIIIIIXZZYI, +XXIIIIIYZZXI, +XXIIIIXYIIII, +XXIIIIXZZZZY, +XXIIIIYXIIII, +XXIIIIYZZZZX, +XYIIIIIIIIXX, +XYIIIIIIIIYY, +XYIIIIIIXXII, +XYIIIIIIYYII, +XYIIIIIXZZXI, +XYIIIIIYZZYI, +XYIIIIXXIIII, +XYIIIIXZZZZX, +XYIIIIYYIIII, +XYIIIIYZZZZY, +XZXIIIIIXZYI, +XZXIIIIIYZXI, +XZXIIIXZYIII, +XZXIIIYZXIII, +XZYIIIIIXZXI, +XZYIIIIIYZYI, +XZYIIIXZXIII, +XZYIIIYZYIII, +XZZXIIIIIXYI, +XZZXIIIIIYXI, +XZZXIIIIXZZY, +XZZXIIIIYZZX, +XZZXIIIXYIII, +XZZXIIIYXIII, +XZZXIIXZZYII, +XZZXIIYZZXII, +XZZYIIIIIXXI, +XZZYIIIIIYYI, +XZZYIIIIXZZX, +XZZYIIIIYZZY, +XZZYIIIXXIII, +XZZYIIIYYIII, +XZZYIIXZZXII, +XZZYIIYZZYII, +XZZZXIXZZZYI, +XZZZXIYZZZXI, +XZZZYIXZZZXI, +XZZZYIYZZZYI, +XZZZZXIIIIXY, +XZZZZXIIIIYX, +XZZZZXIIXYII, +XZZZZXIIYXII, +XZZZZXIXZZYI, +XZZZZXIYZZXI, +XZZZZXXYIIII, +XZZZZXXZZZZY, +XZZZZXYXIIII, +XZZZZXYZZZZX, +XZZZZYIIIIXX, +XZZZZYIIIIYY, +XZZZZYIIXXII, +XZZZZYIIYYII, +XZZZZYIXZZXI, +XZZZZYIYZZYI, +XZZZZYXXIIII, +XZZZZYXZZZZX, +XZZZZYYYIIII, +XZZZZYYZZZZY, +XZZZZZYIIIII, +XZZZZZZZYIII, +XZZZZZZZZZYI, +YXIIIIIIIIXX, +YXIIIIIIIIYY, +YXIIIIIIXXII, +YXIIIIIIYYII, +YXIIIIIXZZXI, +YXIIIIIYZZYI, +YXIIIIXXIIII, +YXIIIIXZZZZX, +YXIIIIYYIIII, +YXIIIIYZZZZY, +YYIIIIIIIIXY, +YYIIIIIIIIYX, +YYIIIIIIXYII, +YYIIIIIIYXII, +YYIIIIIXZZYI, +YYIIIIIYZZXI, +YYIIIIXYIIII, +YYIIIIXZZZZY, +YYIIIIYXIIII, +YYIIIIYZZZZX, +YZXIIIIIXZXI, +YZXIIIIIYZYI, +YZXIIIXZXIII, +YZXIIIYZYIII, +YZYIIIIIXZYI, +YZYIIIIIYZXI, +YZYIIIXZYIII, +YZYIIIYZXIII, +YZZXIIIIIXXI, +YZZXIIIIIYYI, +YZZXIIIIXZZX, +YZZXIIIIYZZY, +YZZXIIIXXIII, +YZZXIIIYYIII, +YZZXIIXZZXII, +YZZXIIYZZYII, +YZZYIIIIIXYI, +YZZYIIIIIYXI, +YZZYIIIIXZZY, +YZZYIIIIYZZX, +YZZYIIIXYIII, +YZZYIIIYXIII, +YZZYIIXZZYII, +YZZYIIYZZXII, +YZZZXIXZZZXI, +YZZZXIYZZZYI, +YZZZYIXZZZYI, +YZZZYIYZZZXI, +YZZZZXIIIIXX, +YZZZZXIIIIYY, +YZZZZXIIXXII, +YZZZZXIIYYII, +YZZZZXIXZZXI, +YZZZZXIYZZYI, +YZZZZXXXIIII, +YZZZZXXZZZZX, +YZZZZXYYIIII, +YZZZZXYZZZZY, +YZZZZYIIIIXY, +YZZZZYIIIIYX, +YZZZZYIIXYII, +YZZZZYIIYXII, +YZZZZYIXZZYI, +YZZZZYIYZZXI, +YZZZZYXYIIII, +YZZZZYXZZZZY, +YZZZZYYXIIII, +YZZZZYYZZZZX, +YZZZZZXIIIII, +YZZZZZZZXIII, +YZZZZZZZZZXI, +IIIIIIIIII]\n"
     ]
    }
   ],
   "source": [
    "from qwrapper.operator import PauliObservable\n",
    "from gqe.mingpt.cost import EnergyCost\n",
    "from qswift.compiler import DefaultOperatorPool\n",
    "from benchmark.molecule import DiatomicMolecularHamiltonian\n",
    "from gqe.operator_pool.uccsd import UCCSD, do_generate_molecule\n",
    "from gqe.common.initializer import HFStateInitializer\n",
    "from gqe.util import get_device\n",
    "from gqe.mingpt.callback import DefaultCallback, PrintMonitor, FileMonitor\n",
    "\n",
    "# molecule = generate_molecule(\"Li\", \"H\", 1.596, \"sto-3g\", bravyi_kitaev=False)\n",
    "bond_length = 3.0\n",
    "geometry = f\"H 0.0 0.0 0.0\\n\" + f\"H 0.0 0.0 {bond_length}\\n\" + f\"H 0.0 0.0 {2 * bond_length}\\n\"\n",
    "geometry += f\"H 0.0 0.0 {3 * bond_length}\\n\" + f\"H 0.0 0.0 {4 * bond_length}\\n\" + f\"H 0.0 0.0 {5 * bond_length}\\n\"\n",
    "molecule = do_generate_molecule(geometry, \"sto-3g\", bravyi_kitaev=False)\n",
    "nqubit = 12\n",
    "\n",
    "# prepare Hamiltonian\n",
    "hamiltonian = DiatomicMolecularHamiltonian(nqubit, molecule, bravyi_kitaev=False)\n",
    "\n",
    "# prepare operator_pool\n",
    "uccsd = UCCSD(nqubit, molecule)\n",
    "paulis = uccsd.paulis\n",
    "paulis.append(PauliObservable(\"IIIIIIIIII\"))\n",
    "print('paulis', paulis)\n",
    "num_operators = len(paulis)\n",
    "initializer = HFStateInitializer(n_electrons=6)\n",
    "pool = DefaultOperatorPool(paulis)\n",
    "# time_pool = [1 / 320, -1 / 320, 1 / 160, -1 / 160, 1 / 80, -1 / 80, 1 / 40, -1 / 40, 0.05, -0.05, 0.1, -0.1, 0.2, -0.2, 0.4, -0.4, 0.8, -0.8]\n",
    "time_pool = [1 / (2 ** j) for j in range(2, 12)]\n",
    "time_pool.extend([-1 / (2 ** j) for j in range(2, 12)])\n",
    "cost = EnergyCost(hamiltonian, initializer, pool, time_pool)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-28T00:43:57.902005Z",
     "start_time": "2023-09-28T00:43:57.060992Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## FCI energy by diagonalization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.800958899654439\n"
     ]
    }
   ],
   "source": [
    "from qwrapper.hamiltonian import compute_ground_state\n",
    "\n",
    "print(compute_ground_state(hamiltonian))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T23:12:18.706463Z",
     "start_time": "2023-09-27T23:06:15.419984Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hf state: -1.9706022459996853\n"
     ]
    }
   ],
   "source": [
    "print(\"hf state:\", hamiltonian.exact_value(initializer.init_circuit(12, [], \"qulacs\")))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-27T23:12:18.723661Z",
     "start_time": "2023-09-27T23:12:18.721248Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup for GPT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T00:31:58.537335Z",
     "start_time": "2023-09-28T00:31:58.535478Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a GPT instance\n",
    "from gqe.mingpt.model import GPT\n",
    "\n",
    "num_layers = 12\n",
    "\n",
    "\n",
    "def generate_model_config():\n",
    "    model_config = GPT.get_default_config()\n",
    "    model_config.model_type = 'gpt2'\n",
    "    model_config.vocab_size = cost.vocab_size()\n",
    "    model_config.n_gates = 5  # The number of gates for each circuit\n",
    "    model_config.block_size = model_config.n_gates\n",
    "    model_config.temperature = 5  # Each gate is generated with probability exp(-temperature * logit)\n",
    "    model_config.embd_pdrop = 0.1\n",
    "    model_config.resid_pdrop = 0.1\n",
    "    model_config.attn_pdrop = 0.1\n",
    "    model_config.std = 0.02\n",
    "    model_config.energy_offset = 1\n",
    "    return model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T01:15:49.613134Z",
     "start_time": "2023-09-28T01:15:49.558150Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a Trainer object\n",
    "from gqe.mingpt.trainer import Trainer\n",
    "from gqe.mingpt.layer import LayerWiseTrainer\n",
    "\n",
    "\n",
    "def generate_train_config():\n",
    "    train_config = Trainer.get_default_config()\n",
    "    train_config.learning_rate = 5e-7  # the model we're using is so small that we can go a bit faster\n",
    "    train_config.max_iters = 100\n",
    "    train_config.num_workers = 10\n",
    "    train_config.n_samples = 50\n",
    "    return train_config\n",
    "\n",
    "\n",
    "trainer = LayerWiseTrainer(generate_train_config, generate_model_config, cost, num_layers, get_device())"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-28T01:38:04.714155Z",
     "start_time": "2023-09-28T01:15:53.222752Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: 1 starts running\n",
      "number of parameters: 91.99M\n",
      "running on device mps\n",
      "iter_dt 0.00s; iter 0: train loss 0.33718 temperature: 5\n",
      "mean_logits tensor([-2.3561, -2.0183, -2.2393, -2.3006, -1.8072, -1.9265, -1.9937, -2.2464,\n",
      "        -1.7399, -1.8959, -2.2233, -2.0834, -2.0592, -2.0900, -2.0204, -2.1247,\n",
      "        -2.2222, -1.8461, -2.1762, -1.9636, -2.0597, -2.2928, -2.0009, -1.6004,\n",
      "        -1.8242, -2.3260, -1.8684, -2.0300, -2.2221, -1.6224, -1.9560, -1.9384,\n",
      "        -2.3869, -2.0354, -2.2541, -1.8855, -1.8910, -2.1361, -1.8264, -2.2053,\n",
      "        -2.1988, -1.6047, -2.0655, -1.7232, -1.6968, -2.0199, -2.2574, -1.9825,\n",
      "        -1.9537, -1.5838], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9899, -1.9821, -2.0146, -1.9794, -1.9204, -1.9234, -1.9620, -1.9925,\n",
      "        -1.9596, -2.0111, -2.0243, -2.0039, -1.9827, -1.9798, -2.0014, -1.9509,\n",
      "        -1.9802, -1.9388, -1.9823, -1.9701, -1.9875, -1.9791, -1.9041, -1.9818,\n",
      "        -1.9138, -1.9661, -1.9658, -1.9606, -2.0398, -1.9594, -1.9702, -1.9449,\n",
      "        -1.9583, -1.9918, -1.9713, -1.9459, -1.9718, -1.9699, -1.9745, -1.9771,\n",
      "        -1.9462, -1.9672, -1.9411, -1.9349, -1.9669, -2.0044, -1.9652, -1.9194,\n",
      "        -1.9835, -1.9715], device='mps:0')\n",
      "mean: tensor(-1.9697, device='mps:0')\n",
      "iter_dt 1695863760.68s; iter 1: train loss 0.45138 temperature: 5.05\n",
      "mean_logits tensor([-1.6367, -1.7545, -1.4994, -2.3977, -2.4439, -1.9323, -1.9146, -1.4133,\n",
      "        -1.5958, -1.7851, -2.0831, -1.6219, -1.8837, -2.2254, -1.4606, -1.9826,\n",
      "        -1.9876, -1.7921, -1.7577, -1.6028, -2.1808, -2.1369, -1.6012, -1.8129,\n",
      "        -1.8315, -2.2770, -1.8562, -1.9262, -2.0275, -2.0238, -2.0500, -1.3672,\n",
      "        -2.2544, -1.5258, -1.8822, -2.1318, -1.6040, -2.0793, -2.3402, -1.8937,\n",
      "        -1.8963, -1.8984, -1.6747, -2.0634, -1.9913, -2.0509, -2.0114, -2.1474,\n",
      "        -2.2902, -1.8270], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9593, -1.9876, -1.9603, -1.9722, -1.9554, -1.9725, -1.9117, -1.9682,\n",
      "        -1.9719, -1.9523, -1.9587, -1.9683, -1.9294, -1.9588, -1.9618, -1.9600,\n",
      "        -2.0221, -1.9269, -1.9264, -2.0029, -1.9275, -1.9153, -1.9845, -1.9526,\n",
      "        -1.9726, -1.9821, -1.9458, -1.9780, -2.0089, -1.9946, -1.9722, -1.9752,\n",
      "        -1.9802, -1.9480, -1.9594, -1.9910, -1.9959, -1.9727, -1.9276, -1.9143,\n",
      "        -1.9490, -1.9598, -1.9645, -1.9693, -1.9829, -1.9609, -1.9454, -2.0007,\n",
      "        -1.9884, -2.0425], device='mps:0')\n",
      "mean: tensor(-1.9658, device='mps:0')\n",
      "iter_dt 1.06s; iter 2: train loss 0.44906 temperature: 5.1\n",
      "mean_logits tensor([-2.0212, -2.0438, -1.6648, -2.4232, -1.9139, -2.4613, -1.9807, -1.8000,\n",
      "        -1.6381, -2.0211, -2.0664, -1.6009, -1.5707, -1.8183, -1.8611, -1.6756,\n",
      "        -2.1165, -1.9866, -2.0648, -1.8122, -1.8415, -2.1223, -1.9777, -2.2242,\n",
      "        -1.8090, -1.9581, -2.2898, -1.9666, -1.5976, -2.0231, -1.7019, -1.7795,\n",
      "        -1.7008, -2.6186, -1.9391, -2.2759, -2.1604, -1.8990, -1.9422, -1.7372,\n",
      "        -1.9761, -2.1371, -2.0039, -1.6125, -1.8943, -1.9601, -1.8544, -1.5990,\n",
      "        -1.6341, -2.0650], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9706, -1.9434, -1.9382, -1.9371, -1.9362, -1.9611, -1.9636, -1.9723,\n",
      "        -1.9829, -1.9724, -1.9646, -1.9811, -1.9330, -1.9756, -1.9614, -1.9601,\n",
      "        -1.9761, -1.9687, -1.9807, -1.9866, -2.0017, -1.9093, -1.9691, -1.9620,\n",
      "        -1.9739, -1.9821, -1.9714, -2.0334, -1.9746, -1.9512, -2.0355, -2.0162,\n",
      "        -1.9417, -2.0320, -1.9877, -1.9517, -1.9661, -1.9705, -1.9843, -1.9678,\n",
      "        -1.9962, -1.9670, -1.9559, -1.9695, -1.9412, -1.9543, -1.9649, -1.9879,\n",
      "        -1.9681, -1.9726], device='mps:0')\n",
      "mean: tensor(-1.9705, device='mps:0')\n",
      "iter_dt 1.03s; iter 3: train loss 0.35114 temperature: 5.1499999999999995\n",
      "mean_logits tensor([-1.7468, -1.7099, -2.0522, -1.8487, -1.7723, -2.0984, -2.1508, -2.0712,\n",
      "        -2.3414, -2.3466, -1.7800, -2.1285, -2.1117, -2.4059, -2.0078, -2.0985,\n",
      "        -1.8588, -2.0082, -1.9151, -2.0119, -1.7873, -2.3211, -1.8621, -2.1713,\n",
      "        -1.9475, -2.1756, -2.0712, -1.5970, -2.2506, -1.7684, -2.2101, -1.8589,\n",
      "        -1.7817, -2.3497, -1.9324, -1.7077, -1.9065, -2.0594, -1.8634, -1.7184,\n",
      "        -1.5121, -1.7620, -1.7131, -1.8099, -1.5835, -2.0217, -1.5507, -1.9044,\n",
      "        -1.8345, -2.0111], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9697, -1.9739, -1.9423, -1.9722, -1.9744, -1.9813, -1.9615, -1.9642,\n",
      "        -1.9117, -2.0331, -1.9834, -1.8964, -1.9526, -1.9539, -1.9703, -1.9737,\n",
      "        -1.9839, -1.9876, -1.9698, -1.9746, -1.9556, -2.0334, -1.9268, -1.9579,\n",
      "        -1.9268, -1.9239, -1.9523, -1.9684, -1.9752, -1.9173, -2.0270, -1.9707,\n",
      "        -1.9746, -1.9714, -1.9175, -1.9601, -1.9885, -2.0605, -1.9600, -1.9810,\n",
      "        -1.9770, -1.9550, -1.9541, -1.8927, -1.9615, -1.9693, -1.9875, -1.9571,\n",
      "        -1.9815, -1.9233], device='mps:0')\n",
      "mean: tensor(-1.9648, device='mps:0')\n",
      "iter_dt 1.05s; iter 4: train loss 0.31841 temperature: 5.199999999999999\n",
      "mean_logits tensor([-2.2114, -1.8560, -2.0073, -2.1469, -2.0134, -2.3076, -1.7845, -1.8840,\n",
      "        -1.5046, -1.9605, -1.6677, -1.9384, -1.5617, -1.6788, -1.8709, -2.3055,\n",
      "        -2.2584, -1.5843, -1.8975, -2.2745, -1.7818, -1.6131, -1.8987, -1.8922,\n",
      "        -2.1789, -1.7211, -1.8063, -1.8756, -2.1714, -1.8513, -1.5898, -1.8329,\n",
      "        -1.8312, -1.7456, -1.9987, -1.9428, -1.9147, -1.7962, -1.5942, -1.5902,\n",
      "        -1.7540, -2.0742, -1.7943, -1.9921, -2.1040, -1.7937, -1.6357, -1.7831,\n",
      "        -1.9681, -1.8998], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9711, -2.0173, -1.9646, -1.9223, -1.9687, -1.9768, -1.9755, -1.9785,\n",
      "        -1.9977, -1.9880, -1.9543, -1.9706, -1.9689, -1.9497, -1.9146, -1.9707,\n",
      "        -1.9725, -2.0073, -1.9655, -1.9379, -1.9648, -1.9851, -1.9698, -1.9905,\n",
      "        -2.0087, -1.9786, -1.9422, -1.9709, -1.9715, -1.9873, -1.9613, -1.9158,\n",
      "        -1.9857, -1.9732, -1.9759, -2.0893, -1.9780, -1.9223, -2.0084, -1.9652,\n",
      "        -1.9885, -1.9664, -1.9436, -1.9365, -1.9571, -1.9948, -1.9689, -1.9171,\n",
      "        -2.0242, -2.0079], device='mps:0')\n",
      "mean: tensor(-1.9724, device='mps:0')\n",
      "iter_dt 1.06s; iter 5: train loss 0.37760 temperature: 5.249999999999999\n",
      "mean_logits tensor([-2.1599, -1.8133, -2.0182, -2.1781, -1.7613, -1.6279, -2.3627, -2.0163,\n",
      "        -2.1550, -1.6320, -1.8027, -1.8059, -1.7588, -1.9860, -1.9175, -2.1852,\n",
      "        -1.9456, -1.7965, -1.8851, -2.0673, -2.0119, -1.7446, -2.0193, -2.2582,\n",
      "        -1.9203, -1.5832, -2.1743, -1.6114, -2.4051, -1.4501, -1.9910, -1.4836,\n",
      "        -1.9088, -1.6991, -2.0408, -1.7441, -2.1864, -2.2555, -2.2556, -1.6591,\n",
      "        -2.2688, -1.8766, -1.9410, -1.5426, -1.9061, -1.9932, -1.8958, -1.9162,\n",
      "        -1.9904, -1.2281], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9632, -1.9844, -1.9843, -1.9507, -1.9171, -1.9864, -2.0377, -1.9335,\n",
      "        -1.9700, -1.8495, -1.9928, -1.9615, -1.9169, -1.9760, -2.0206, -1.9124,\n",
      "        -1.9668, -1.9691, -2.0039, -1.9722, -2.0050, -1.9770, -2.0017, -1.9805,\n",
      "        -1.9740, -1.9857, -1.9423, -1.9774, -1.9698, -1.9804, -1.9365, -1.9689,\n",
      "        -1.9809, -1.9163, -2.0299, -1.8908, -1.9868, -1.9654, -1.9570, -1.9937,\n",
      "        -2.0037, -2.0263, -1.9080, -1.9644, -1.9663, -1.9835, -1.9545, -1.9672,\n",
      "        -1.9488, -1.9790], device='mps:0')\n",
      "mean: tensor(-1.9678, device='mps:0')\n",
      "iter_dt 1.14s; iter 6: train loss 0.35009 temperature: 5.299999999999999\n",
      "mean_logits tensor([-2.0399, -1.8054, -1.7478, -2.0245, -1.7755, -2.1176, -2.2206, -2.0136,\n",
      "        -2.2817, -1.8440, -1.9983, -2.1478, -1.9949, -2.1291, -1.4346, -2.1918,\n",
      "        -1.9844, -1.9996, -1.9339, -2.5301, -2.1800, -1.7776, -1.6039, -1.7114,\n",
      "        -2.0235, -1.9584, -2.2070, -1.7393, -1.9433, -1.8248, -2.0758, -1.9205,\n",
      "        -1.6402, -1.4438, -2.1829, -2.1801, -1.7320, -2.0618, -1.8761, -1.9940,\n",
      "        -1.7445, -1.4237, -2.0304, -1.8418, -1.8519, -2.3734, -2.1340, -2.0343,\n",
      "        -1.7451, -1.9096], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9803, -1.9309, -1.9698, -1.9709, -1.9679, -2.0196, -1.9296, -1.9583,\n",
      "        -1.9606, -2.0557, -1.9837, -1.9584, -2.0702, -1.9736, -2.0006, -2.0701,\n",
      "        -1.9646, -2.0088, -1.9419, -1.9911, -1.9972, -1.9733, -1.9328, -1.9705,\n",
      "        -1.9490, -1.9733, -1.9702, -1.9142, -1.9622, -1.9566, -1.9147, -1.9534,\n",
      "        -1.8987, -1.9453, -1.9811, -1.9954, -1.9658, -1.9503, -1.9811, -1.9941,\n",
      "        -1.9699, -1.9610, -2.0331, -1.9679, -1.9642, -1.9441, -1.9502, -1.9864,\n",
      "        -1.9727, -1.9678], device='mps:0')\n",
      "mean: tensor(-1.9721, device='mps:0')\n",
      "iter_dt 1.17s; iter 7: train loss 0.41454 temperature: 5.349999999999999\n",
      "mean_logits tensor([-1.7025, -1.6545, -2.0150, -1.7571, -1.9549, -2.4072, -1.9896, -1.9298,\n",
      "        -2.2585, -1.9971, -1.6865, -1.8005, -2.3930, -2.0709, -1.9364, -2.0577,\n",
      "        -2.1266, -1.9693, -2.2984, -2.3470, -1.6964, -1.8840, -2.0181, -1.8749,\n",
      "        -2.0255, -1.7602, -1.7778, -2.3560, -1.7407, -1.8925, -1.3863, -2.1275,\n",
      "        -1.8663, -1.5441, -2.1001, -1.8482, -1.9243, -1.8334, -2.3077, -2.3871,\n",
      "        -1.8793, -1.8508, -1.6228, -2.1139, -1.9332, -2.1382, -1.8100, -1.6068,\n",
      "        -1.8696, -2.2222], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9345, -1.9712, -1.9876, -1.9595, -2.0023, -1.9622, -1.9793, -1.9703,\n",
      "        -1.9674, -1.9922, -1.9722, -2.0166, -1.9760, -1.9408, -2.0070, -2.0124,\n",
      "        -1.9178, -1.9870, -2.0357, -1.9869, -1.9691, -1.9725, -1.9706, -2.0058,\n",
      "        -1.9669, -1.9573, -1.9467, -1.9184, -1.9741, -1.9603, -1.9741, -1.9620,\n",
      "        -1.9692, -1.9611, -1.9632, -1.9426, -1.9587, -1.9432, -1.8690, -1.9711,\n",
      "        -1.9242, -1.9706, -1.9588, -1.9778, -1.9201, -1.9709, -1.9404, -1.8959,\n",
      "        -1.9683, -2.0072], device='mps:0')\n",
      "mean: tensor(-1.9654, device='mps:0')\n",
      "iter_dt 1.08s; iter 8: train loss 0.31903 temperature: 5.399999999999999\n",
      "mean_logits tensor([-1.6557, -1.7248, -1.8899, -2.0806, -1.6798, -1.8780, -2.0025, -2.5304,\n",
      "        -1.9710, -1.8950, -2.0514, -1.8104, -2.1122, -2.2451, -1.8105, -1.9454,\n",
      "        -2.0000, -1.9419, -1.4300, -1.7448, -1.9631, -2.2312, -1.5656, -1.8783,\n",
      "        -1.9290, -1.8337, -2.0664, -2.0071, -1.9287, -1.9349, -1.7492, -1.8724,\n",
      "        -2.1841, -1.5064, -2.1071, -2.0126, -2.3447, -1.7360, -1.7574, -1.6746,\n",
      "        -1.8617, -1.7636, -2.0924, -1.9295, -1.6253, -1.8236, -1.9345, -1.8384,\n",
      "        -1.9549, -2.1079], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9639, -1.9699, -1.9663, -1.9480, -2.0235, -1.9727, -1.9465, -1.9742,\n",
      "        -1.8901, -1.9739, -1.9437, -1.9784, -1.9139, -1.9670, -1.9674, -1.9406,\n",
      "        -1.9707, -1.9914, -1.9001, -1.9416, -2.0272, -1.9081, -1.9779, -1.9290,\n",
      "        -1.9769, -1.9541, -1.9859, -1.9924, -1.9641, -1.9335, -1.9527, -1.9705,\n",
      "        -1.9650, -1.9795, -1.9841, -1.9503, -1.9600, -1.9688, -1.9433, -1.9752,\n",
      "        -1.9857, -1.9784, -1.9322, -2.0067, -1.9726, -1.9633, -1.9109, -1.9670,\n",
      "        -1.9210, -1.9923], device='mps:0')\n",
      "mean: tensor(-1.9614, device='mps:0')\n",
      "iter_dt 1.07s; iter 9: train loss 0.43079 temperature: 5.449999999999998\n",
      "mean_logits tensor([-1.9901, -2.1019, -2.1497, -1.9623, -2.0924, -1.9615, -1.7763, -2.3830,\n",
      "        -2.1774, -2.1700, -1.7877, -2.1147, -1.6854, -2.3771, -2.0012, -1.6465,\n",
      "        -2.3268, -2.0888, -1.6636, -1.9218, -1.7087, -2.0745, -1.9053, -1.7435,\n",
      "        -2.5304, -1.6847, -1.9095, -1.8953, -1.9128, -1.7532, -2.2426, -2.0301,\n",
      "        -1.9154, -1.9266, -1.9755, -1.8825, -2.0282, -1.9621, -1.8652, -1.5163,\n",
      "        -1.9176, -1.7882, -1.6551, -1.7573, -1.7672, -2.4936, -1.9060, -1.8185,\n",
      "        -1.8552, -1.7535], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9599, -1.9474, -1.9752, -1.8746, -1.9836, -1.9758, -1.9491, -1.9782,\n",
      "        -1.9830, -1.9270, -1.9738, -1.9569, -1.9840, -1.9473, -1.9355, -1.9615,\n",
      "        -1.9657, -1.9858, -1.9533, -1.9792, -1.8563, -1.9045, -1.9426, -1.9593,\n",
      "        -1.8999, -1.9698, -1.9910, -1.9880, -1.9728, -1.9629, -1.9692, -1.9442,\n",
      "        -1.9684, -1.9576, -1.9935, -1.9789, -1.9559, -1.9832, -1.9860, -2.0032,\n",
      "        -1.9501, -1.9737, -1.9530, -1.9379, -1.9856, -1.9696, -1.9133, -1.9792,\n",
      "        -1.9687, -1.9787], device='mps:0')\n",
      "mean: tensor(-1.9599, device='mps:0')\n",
      "iter_dt 1.04s; iter 10: train loss 0.41811 temperature: 5.499999999999998\n",
      "mean_logits tensor([-2.1025, -2.0544, -1.8492, -1.7652, -2.1039, -2.1384, -1.8769, -1.8628,\n",
      "        -1.9785, -1.8897, -2.3405, -1.5103, -1.6045, -2.1187, -1.6918, -2.1579,\n",
      "        -2.0955, -2.0174, -2.4396, -2.1702, -1.8177, -2.2453, -1.7641, -2.2615,\n",
      "        -1.9130, -1.8884, -2.0030, -1.8624, -2.1835, -1.6281, -1.9615, -1.8822,\n",
      "        -1.8592, -1.7463, -2.3320, -2.2043, -1.6064, -1.9261, -1.8959, -1.9813,\n",
      "        -2.0716, -1.4911, -1.6465, -2.2039, -2.1661, -1.8956, -2.2020, -2.1421,\n",
      "        -1.3231, -2.3126], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9676, -1.9666, -1.9573, -1.9400, -2.0076, -1.9708, -1.9502, -1.9480,\n",
      "        -1.9790, -2.0089, -1.9707, -1.9772, -1.9690, -1.9770, -1.9607, -1.8711,\n",
      "        -1.9675, -1.9422, -1.9423, -1.9259, -1.9725, -1.9427, -1.9672, -1.9733,\n",
      "        -1.9726, -2.0014, -1.8906, -1.9773, -1.9554, -1.9880, -1.9495, -1.9310,\n",
      "        -1.9755, -1.9918, -1.9098, -2.0301, -1.9272, -1.9544, -1.9452, -1.9731,\n",
      "        -1.9927, -1.9732, -1.9562, -1.9420, -2.0126, -1.9699, -1.9460, -1.9714,\n",
      "        -1.9768, -1.9496], device='mps:0')\n",
      "mean: tensor(-1.9624, device='mps:0')\n",
      "iter_dt 1.02s; iter 11: train loss 0.33723 temperature: 5.549999999999998\n",
      "mean_logits tensor([-1.9570, -2.1933, -2.2055, -1.8089, -1.4670, -2.0356, -2.3238, -1.7883,\n",
      "        -1.8754, -1.9303, -1.9962, -2.1013, -1.9057, -2.0106, -1.8073, -1.7527,\n",
      "        -1.8971, -2.1146, -1.8880, -1.8805, -1.6512, -1.9722, -1.8943, -1.8480,\n",
      "        -1.9185, -2.1770, -1.9768, -1.8282, -2.1046, -1.8064, -1.8366, -2.1047,\n",
      "        -1.7835, -1.9588, -2.0357, -2.2608, -2.1582, -2.2725, -1.6738, -1.8147,\n",
      "        -2.4079, -1.6040, -1.9024, -2.0931, -1.5615, -1.8960, -1.4846, -2.1005,\n",
      "        -2.1111, -2.4386], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9463, -1.9099, -1.9284, -1.9364, -1.9469, -1.9690, -1.9668, -1.9857,\n",
      "        -1.9773, -1.9714, -2.0031, -1.9806, -1.9127, -2.0109, -1.8914, -1.9632,\n",
      "        -2.0653, -1.9615, -1.9745, -1.9870, -1.9695, -2.0294, -1.9437, -1.9626,\n",
      "        -1.9503, -2.0142, -1.9895, -1.9444, -1.9881, -1.9729, -1.9348, -1.9662,\n",
      "        -1.9533, -1.9725, -1.9724, -2.0342, -1.9682, -1.9126, -1.8900, -1.9623,\n",
      "        -1.9656, -1.9705, -1.9791, -1.9606, -1.9760, -1.9656, -1.9620, -1.9781,\n",
      "        -1.9713, -1.9197], device='mps:0')\n",
      "mean: tensor(-1.9654, device='mps:0')\n",
      "iter_dt 1.02s; iter 12: train loss 0.28220 temperature: 5.599999999999998\n",
      "mean_logits tensor([-2.1489, -2.0023, -1.6625, -2.0864, -1.8515, -1.8667, -1.7352, -2.3129,\n",
      "        -2.1823, -1.9816, -1.9958, -2.1634, -1.7686, -1.8839, -1.6813, -1.5777,\n",
      "        -1.7075, -2.3122, -1.6553, -2.0519, -1.9941, -1.8714, -2.1640, -2.1827,\n",
      "        -1.9779, -1.9633, -1.9936, -1.9192, -2.0976, -2.0710, -1.8858, -1.8811,\n",
      "        -1.4887, -2.0981, -1.6105, -1.6981, -1.9170, -1.4915, -1.9254, -1.8772,\n",
      "        -2.2352, -1.9705, -2.2438, -2.0754, -2.3246, -2.0326, -1.9716, -1.8778,\n",
      "        -1.8598, -1.9018], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9897, -1.9664, -1.9928, -1.9573, -1.9731, -1.9708, -1.9711, -2.0036,\n",
      "        -2.0006, -1.9871, -1.9594, -2.0096, -1.9376, -1.9416, -1.9768, -2.0013,\n",
      "        -1.9840, -1.9677, -1.9660, -2.0040, -1.9954, -1.9168, -1.9211, -1.9260,\n",
      "        -2.0225, -1.9914, -1.9562, -2.0211, -1.9516, -2.0621, -1.9666, -1.9383,\n",
      "        -1.9775, -1.9579, -1.9588, -2.0011, -1.9702, -1.9689, -1.9749, -2.0053,\n",
      "        -1.9417, -1.9558, -1.9721, -2.0252, -1.9958, -1.9572, -1.9921, -1.9965,\n",
      "        -1.9631, -1.9255], device='mps:0')\n",
      "mean: tensor(-1.9754, device='mps:0')\n",
      "iter_dt 1.05s; iter 13: train loss 0.42922 temperature: 5.649999999999998\n",
      "mean_logits tensor([-2.1806, -2.0314, -1.5428, -1.9338, -1.5190, -1.7612, -1.8327, -2.0674,\n",
      "        -2.3603, -1.4880, -1.8597, -1.8437, -2.1046, -1.8560, -2.1836, -1.8260,\n",
      "        -1.8965, -2.0581, -2.1301, -2.2373, -1.9703, -1.7332, -1.7450, -1.9170,\n",
      "        -2.3635, -1.8662, -1.7626, -2.4628, -1.9057, -2.3847, -2.0540, -2.1799,\n",
      "        -2.2277, -2.4234, -1.8615, -1.8879, -1.7423, -1.6084, -2.0206, -2.0442,\n",
      "        -2.0055, -1.7567, -1.8986, -1.9814, -1.8648, -2.0203, -2.2275, -1.8052,\n",
      "        -2.2892, -2.0868], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9120, -1.9646, -1.9709, -1.9653, -1.9798, -1.9540, -1.9755, -1.9529,\n",
      "        -1.9780, -1.9762, -1.9555, -1.9733, -1.9769, -1.9083, -1.9749, -1.9568,\n",
      "        -1.9373, -1.9744, -1.9598, -1.9601, -1.9675, -1.9152, -1.9586, -1.9158,\n",
      "        -1.9566, -1.9746, -1.9681, -2.0444, -1.9115, -1.9670, -1.9673, -1.9220,\n",
      "        -1.9932, -1.9247, -1.9949, -1.9749, -1.9681, -2.0194, -1.9697, -1.9177,\n",
      "        -2.0072, -1.9743, -1.9753, -1.9435, -1.9705, -1.9588, -1.9171, -1.9782,\n",
      "        -1.9715, -1.9639], device='mps:0')\n",
      "mean: tensor(-1.9620, device='mps:0')\n",
      "iter_dt 1.03s; iter 14: train loss 0.39878 temperature: 5.6999999999999975\n",
      "mean_logits tensor([-2.1983, -2.2153, -2.0155, -2.1713, -2.1031, -1.7537, -1.6884, -2.2577,\n",
      "        -2.0644, -2.0444, -1.9533, -1.9371, -1.9470, -1.8387, -1.8926, -1.8449,\n",
      "        -2.2382, -2.2166, -1.9701, -2.0184, -1.6716, -1.8284, -2.2178, -1.8782,\n",
      "        -2.0636, -1.5987, -1.6586, -2.1504, -2.0435, -1.9737, -1.8551, -1.9272,\n",
      "        -2.1963, -1.5685, -1.8263, -2.1261, -2.1233, -1.6556, -1.4641, -2.0122,\n",
      "        -1.9971, -1.8941, -1.9954, -2.0718, -1.8282, -1.9001, -1.9426, -2.0614,\n",
      "        -2.6863, -1.9906], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9595, -1.8247, -1.9696, -2.0055, -1.9892, -1.9683, -1.9522, -1.9716,\n",
      "        -1.9837, -1.9484, -1.9792, -1.9296, -1.9683, -1.9701, -1.9853, -1.9716,\n",
      "        -1.9699, -1.9967, -1.9051, -1.9443, -1.9754, -1.9783, -1.9795, -1.9675,\n",
      "        -1.9387, -1.9718, -1.9648, -1.9591, -1.9593, -1.9545, -1.9818, -1.9674,\n",
      "        -1.9720, -1.9514, -1.9992, -1.9690, -1.9045, -1.9708, -2.0217, -1.9728,\n",
      "        -1.9830, -1.9673, -1.8729, -1.9884, -1.9232, -2.0067, -1.9184, -1.9641,\n",
      "        -1.9571, -1.9439], device='mps:0')\n",
      "mean: tensor(-1.9615, device='mps:0')\n",
      "iter_dt 1.05s; iter 15: train loss 0.43704 temperature: 5.749999999999997\n",
      "mean_logits tensor([-1.8453, -1.6627, -2.0710, -1.8004, -1.9386, -2.0071, -2.1256, -1.9692,\n",
      "        -2.1228, -2.3995, -1.8428, -1.8798, -1.6347, -1.6871, -2.0624, -2.2039,\n",
      "        -2.0988, -2.0665, -1.5918, -1.6220, -1.7663, -1.6503, -2.2026, -2.1260,\n",
      "        -1.5572, -1.9348, -1.8825, -1.8452, -2.4264, -2.3137, -1.9719, -1.8290,\n",
      "        -1.7733, -1.9235, -1.6257, -2.1073, -2.0877, -1.8523, -1.8711, -1.7614,\n",
      "        -1.7740, -2.1163, -1.9538, -2.1063, -1.6851, -2.5219, -2.1661, -1.7247,\n",
      "        -2.5096, -1.7507], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9474, -2.0047, -1.9800, -1.9918, -1.9911, -1.9481, -2.0093, -1.9695,\n",
      "        -1.9733, -2.0300, -1.9034, -2.0157, -1.9702, -1.9643, -1.9637, -2.0055,\n",
      "        -1.9915, -1.9650, -1.9854, -1.9935, -1.8523, -1.9598, -1.9701, -1.9868,\n",
      "        -2.0008, -1.9550, -1.9976, -1.9860, -1.9687, -2.0180, -2.0089, -1.9718,\n",
      "        -1.8841, -1.9974, -1.9797, -1.9728, -2.0392, -1.9690, -1.9128, -1.9634,\n",
      "        -1.9711, -1.9726, -1.8636, -2.0286, -1.9619, -2.0059, -1.9882, -1.9972,\n",
      "        -1.9708, -1.9885], device='mps:0')\n",
      "mean: tensor(-1.9749, device='mps:0')\n",
      "iter_dt 1.10s; iter 16: train loss 0.64415 temperature: 5.799999999999997\n",
      "mean_logits tensor([-1.7003, -1.8020, -1.9193, -2.0001, -1.7214, -2.1006, -2.3530, -2.1870,\n",
      "        -1.8625, -2.1041, -2.2868, -1.9611, -1.9917, -1.8800, -2.3612, -1.9133,\n",
      "        -1.9998, -2.6557, -2.0423, -1.9626, -2.2708, -1.6685, -2.0908, -1.9415,\n",
      "        -1.8254, -1.8801, -2.2324, -1.9946, -2.0495, -1.9268, -1.6525, -2.2128,\n",
      "        -2.0570, -2.3417, -1.9155, -1.6143, -1.8292, -1.7256, -2.7050, -1.8719,\n",
      "        -1.9622, -1.7929, -2.0044, -1.8376, -2.4031, -2.1592, -1.8684, -2.2935,\n",
      "        -1.8961, -1.9104], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9625, -2.0085, -1.9524, -1.9729, -1.9955, -1.9995, -1.8944, -1.9880,\n",
      "        -1.9544, -1.8998, -2.0301, -1.9712, -1.9981, -1.9635, -1.9087, -1.9391,\n",
      "        -1.9543, -1.9458, -1.9897, -1.9794, -1.9725, -1.8902, -1.9841, -1.9672,\n",
      "        -2.0300, -1.9823, -1.9087, -1.9896, -1.9682, -1.9322, -1.9623, -1.8972,\n",
      "        -1.8551, -1.9679, -1.9395, -1.9674, -1.8351, -2.0287, -1.9742, -1.9939,\n",
      "        -1.9709, -1.9551, -1.9618, -1.9004, -1.9802, -1.9541, -1.9946, -1.9867,\n",
      "        -1.9765, -1.9761], device='mps:0')\n",
      "mean: tensor(-1.9602, device='mps:0')\n",
      "iter_dt 1.08s; iter 17: train loss 0.33271 temperature: 5.849999999999997\n",
      "mean_logits tensor([-1.9702, -2.3835, -2.0577, -2.1799, -2.2497, -1.8761, -2.3242, -2.0928,\n",
      "        -2.0291, -2.0295, -2.2271, -1.8216, -1.6639, -2.0335, -2.0646, -1.7840,\n",
      "        -1.7684, -2.0655, -2.0171, -2.0551, -1.8432, -1.9339, -1.9614, -1.7799,\n",
      "        -2.2371, -1.9425, -2.3353, -1.9549, -2.2210, -1.9970, -1.4988, -2.1626,\n",
      "        -2.0777, -1.9689, -1.8348, -2.1135, -1.9334, -1.8856, -2.0439, -2.3173,\n",
      "        -1.7300, -1.5724, -1.9446, -2.1728, -1.8899, -2.0773, -2.3417, -2.1084,\n",
      "        -1.8103, -1.6745], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9717, -1.9459, -1.9738, -1.9797, -1.9200, -1.9648, -1.9547, -1.9861,\n",
      "        -1.9973, -1.9398, -1.9707, -1.8933, -2.0171, -1.9952, -1.9767, -1.9388,\n",
      "        -2.0028, -1.9681, -1.9512, -1.9543, -1.9504, -1.9702, -2.0401, -1.9909,\n",
      "        -1.9905, -1.9432, -1.9848, -1.9736, -1.8840, -1.9824, -1.9539, -1.9737,\n",
      "        -1.9355, -1.9427, -1.9697, -1.9670, -1.9223, -1.9813, -1.9892, -1.9807,\n",
      "        -1.9488, -1.9689, -1.9654, -1.9795, -2.0183, -1.9658, -1.9737, -1.9702,\n",
      "        -1.9420, -1.9845], device='mps:0')\n",
      "mean: tensor(-1.9669, device='mps:0')\n",
      "iter_dt 1.09s; iter 18: train loss 0.43396 temperature: 5.899999999999997\n",
      "mean_logits tensor([-1.6333, -1.9680, -1.9698, -2.2916, -2.3443, -1.8879, -2.0584, -1.7399,\n",
      "        -1.9259, -2.0723, -1.5261, -1.9826, -2.1130, -1.8563, -2.2606, -1.9030,\n",
      "        -1.9692, -1.5953, -1.7865, -2.0162, -2.5437, -2.2867, -1.8394, -1.9022,\n",
      "        -2.1518, -2.2144, -2.0613, -1.7401, -1.2601, -2.1579, -1.9878, -1.6794,\n",
      "        -1.4929, -1.7604, -2.0268, -2.1906, -2.1036, -1.9113, -2.1228, -1.7874,\n",
      "        -1.7200, -1.8020, -1.9866, -2.0327, -2.3519, -1.8727, -2.2844, -1.7748,\n",
      "        -1.7624, -1.8193], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9316, -1.9569, -1.9768, -1.9676, -1.9379, -1.9842, -1.9427, -1.9713,\n",
      "        -1.9597, -2.0057, -1.9747, -1.9395, -1.9646, -1.9385, -1.9718, -1.9556,\n",
      "        -1.9771, -1.9753, -1.9560, -1.9991, -1.9690, -1.9452, -1.9979, -1.9265,\n",
      "        -1.9703, -1.9322, -1.9586, -2.0199, -1.9753, -1.9742, -1.9902, -1.9703,\n",
      "        -1.9748, -1.9422, -1.9543, -1.9737, -1.9866, -1.9655, -1.9690, -1.9565,\n",
      "        -1.9804, -1.9689, -2.0053, -1.9982, -1.9839, -1.9045, -1.9287, -1.9699,\n",
      "        -1.9257, -1.9702], device='mps:0')\n",
      "mean: tensor(-1.9655, device='mps:0')\n",
      "iter_dt 1.05s; iter 19: train loss 0.56422 temperature: 5.949999999999997\n",
      "mean_logits tensor([-1.9270, -2.4553, -2.2330, -1.8816, -1.6591, -1.7674, -1.7970, -2.1348,\n",
      "        -1.3585, -2.0270, -1.8754, -2.0402, -2.2854, -1.9596, -1.7954, -1.9967,\n",
      "        -1.8615, -1.7779, -2.1643, -1.9939, -2.0693, -2.5127, -2.0325, -1.6824,\n",
      "        -1.7731, -2.1887, -2.2589, -2.2817, -1.7901, -2.3094, -2.3867, -2.2505,\n",
      "        -2.3164, -2.2398, -2.0584, -1.7730, -2.0747, -2.2938, -2.4303, -2.1287,\n",
      "        -1.8063, -2.0157, -1.8475, -2.2595, -1.8756, -1.9512, -2.1190, -2.1580,\n",
      "        -2.2019, -1.5491], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9772, -1.8994, -1.9933, -1.9513, -1.9575, -1.9493, -1.9733, -1.9636,\n",
      "        -1.9496, -1.9732, -2.0012, -1.9622, -1.9580, -1.9539, -1.9843, -1.9712,\n",
      "        -1.9334, -1.9606, -1.8494, -1.9526, -1.9034, -1.9714, -1.9125, -1.9519,\n",
      "        -1.9709, -1.9383, -1.9719, -1.9986, -1.9589, -1.9910, -1.9562, -1.9937,\n",
      "        -1.9692, -2.0149, -1.9772, -1.9876, -1.9917, -1.9430, -1.9646, -1.9367,\n",
      "        -1.9916, -1.9160, -2.0320, -1.9452, -1.9215, -2.0238, -1.9611, -1.9913,\n",
      "        -1.9637, -1.9716], device='mps:0')\n",
      "mean: tensor(-1.9627, device='mps:0')\n",
      "iter_dt 1.08s; iter 20: train loss 0.30786 temperature: 5.9999999999999964\n",
      "mean_logits tensor([-1.8104, -2.0733, -1.8110, -1.7173, -2.1330, -1.8123, -1.9043, -1.9803,\n",
      "        -1.4897, -1.6508, -2.1693, -1.9764, -1.6975, -1.5034, -1.8122, -1.7303,\n",
      "        -2.2459, -1.8998, -1.8146, -1.6755, -2.2000, -1.8426, -2.0421, -1.7751,\n",
      "        -2.1301, -1.8540, -1.9807, -2.1182, -2.2742, -2.3863, -1.7582, -2.2197,\n",
      "        -1.9971, -2.0865, -1.7155, -1.7730, -1.9288, -2.0754, -2.2248, -1.6882,\n",
      "        -1.9813, -1.7366, -1.9365, -2.0525, -2.1501, -1.5949, -1.9702, -1.7822,\n",
      "        -2.1943, -2.0081], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9384, -1.9406, -1.9424, -1.9466, -1.9779, -2.0080, -1.9724, -2.0044,\n",
      "        -2.0158, -1.9649, -1.9664, -1.9892, -1.9242, -1.9667, -1.9602, -1.9713,\n",
      "        -1.9413, -1.9696, -2.0171, -1.9739, -1.9329, -1.9801, -1.9450, -1.9761,\n",
      "        -1.9637, -1.9288, -1.9689, -1.9193, -1.9146, -2.0267, -1.9289, -1.9607,\n",
      "        -1.9629, -2.0220, -1.9517, -1.9348, -1.9137, -1.9162, -1.9879, -1.9903,\n",
      "        -1.9695, -1.9626, -1.9904, -1.9766, -2.0061, -2.0204, -1.9592, -1.9766,\n",
      "        -1.9313, -1.9356], device='mps:0')\n",
      "mean: tensor(-1.9649, device='mps:0')\n",
      "iter_dt 1.06s; iter 21: train loss 0.37047 temperature: 6.049999999999996\n",
      "mean_logits tensor([-1.7634, -1.9117, -1.8110, -1.8225, -1.9143, -2.0310, -1.5106, -1.5138,\n",
      "        -2.0702, -1.7178, -1.8190, -2.1389, -2.1080, -1.9088, -1.8822, -2.0798,\n",
      "        -2.2341, -1.3962, -1.8642, -2.1123, -2.1767, -2.0345, -1.8704, -2.1288,\n",
      "        -2.0956, -2.3759, -2.2693, -2.4814, -2.2001, -1.4655, -1.8080, -2.2021,\n",
      "        -1.6476, -2.0604, -1.7793, -1.7891, -2.1472, -2.0056, -1.9575, -1.9488,\n",
      "        -2.1844, -1.4600, -1.9903, -1.9942, -2.1216, -2.2173, -1.8116, -1.7685,\n",
      "        -1.8511, -1.7624], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9493, -1.9591, -1.9699, -1.9894, -1.9146, -1.9674, -1.9711, -1.9700,\n",
      "        -2.0358, -1.9739, -2.0035, -1.9465, -1.9676, -1.9916, -1.8967, -1.9694,\n",
      "        -1.9840, -1.9665, -1.9233, -1.9635, -1.9862, -2.0125, -1.8990, -1.9754,\n",
      "        -1.9779, -1.9330, -1.9408, -1.9559, -1.9532, -1.9442, -1.9528, -1.9483,\n",
      "        -1.9699, -2.0158, -1.9591, -1.9672, -1.9919, -1.9789, -1.9235, -2.0009,\n",
      "        -2.0229, -1.8752, -1.9813, -1.9483, -1.8920, -1.9719, -2.0161, -1.9634,\n",
      "        -1.9729, -1.9637], device='mps:0')\n",
      "mean: tensor(-1.9641, device='mps:0')\n",
      "iter_dt 1.06s; iter 22: train loss 0.31870 temperature: 6.099999999999996\n",
      "mean_logits tensor([-2.1281, -1.4776, -1.7302, -1.9386, -2.1251, -2.3300, -1.5123, -2.1766,\n",
      "        -1.7882, -2.0257, -2.0753, -2.0799, -1.7610, -2.0223, -1.7676, -1.8978,\n",
      "        -2.1694, -1.9813, -1.8816, -2.1586, -2.1691, -1.3270, -2.0652, -1.8094,\n",
      "        -2.1911, -2.1882, -2.3783, -2.0652, -1.8645, -1.8207, -2.2335, -2.0784,\n",
      "        -1.9854, -2.2220, -1.7423, -1.7916, -1.8616, -1.8259, -1.9143, -1.9591,\n",
      "        -1.4997, -1.8753, -1.8441, -1.9120, -1.9939, -2.2783, -1.6361, -2.0745,\n",
      "        -1.9434, -2.0107], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0060, -1.9610, -1.9853, -1.9888, -1.9522, -1.9383, -1.9609, -1.8751,\n",
      "        -1.9640, -1.9173, -1.9868, -1.9551, -1.9612, -1.9737, -2.0161, -1.9732,\n",
      "        -1.9766, -1.9725, -1.9619, -1.9693, -1.9736, -1.8926, -1.9216, -1.9667,\n",
      "        -2.0065, -1.9868, -1.9640, -1.9430, -1.9706, -1.9208, -1.9810, -1.9572,\n",
      "        -1.9217, -1.9544, -1.9694, -1.9848, -1.9333, -1.9542, -1.9109, -1.9812,\n",
      "        -1.9754, -2.0119, -1.9777, -1.9809, -1.8771, -1.9729, -1.9222, -1.9153,\n",
      "        -1.9613, -1.9385], device='mps:0')\n",
      "mean: tensor(-1.9585, device='mps:0')\n",
      "iter_dt 1.03s; iter 23: train loss 0.55732 temperature: 6.149999999999996\n",
      "mean_logits tensor([-2.1409, -1.8847, -2.4831, -2.1390, -1.9955, -1.9251, -2.3416, -1.9990,\n",
      "        -1.8462, -2.2175, -2.1072, -2.1379, -2.0614, -2.1072, -1.8927, -2.1900,\n",
      "        -2.0022, -1.5739, -1.5430, -2.1517, -1.8950, -2.3075, -2.0865, -1.7294,\n",
      "        -2.0169, -1.8072, -2.1680, -1.8866, -2.2558, -2.6433, -2.0856, -1.9470,\n",
      "        -2.0411, -2.0040, -1.9571, -1.4810, -2.0167, -1.7622, -1.8440, -2.4125,\n",
      "        -1.6210, -2.1134, -2.0646, -1.6720, -2.1349, -2.0491, -2.2343, -1.9804,\n",
      "        -2.2438, -2.4613], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9056, -1.9504, -1.9572, -1.9965, -1.9817, -1.9823, -1.9065, -1.9795,\n",
      "        -1.9492, -1.9497, -2.0042, -2.0609, -1.9665, -1.9169, -1.9640, -1.9006,\n",
      "        -1.9511, -1.8982, -1.9830, -2.0077, -1.9909, -1.9653, -1.8957, -1.9832,\n",
      "        -1.9305, -1.9092, -1.9672, -1.9087, -1.9673, -1.9738, -1.8810, -1.9311,\n",
      "        -1.9707, -1.9690, -1.9969, -1.9707, -1.8959, -1.9656, -1.9112, -2.0248,\n",
      "        -1.9449, -1.9703, -1.9850, -1.9729, -1.9494, -1.9634, -1.9672, -1.9376,\n",
      "        -1.9842, -1.9554], device='mps:0')\n",
      "mean: tensor(-1.9570, device='mps:0')\n",
      "iter_dt 1.05s; iter 24: train loss 0.41523 temperature: 6.199999999999996\n",
      "mean_logits tensor([-2.3496, -2.2159, -2.4017, -2.0262, -1.7082, -1.9523, -2.1002, -1.6437,\n",
      "        -1.7179, -1.7605, -1.5667, -1.8477, -2.1522, -1.8417, -1.7799, -1.9145,\n",
      "        -2.2512, -1.9443, -2.1909, -1.9286, -1.6987, -1.8262, -1.8960, -1.6155,\n",
      "        -1.8219, -2.1210, -1.9511, -1.9185, -1.8867, -1.8776, -2.1814, -1.5629,\n",
      "        -1.9433, -1.8034, -1.7295, -2.0307, -1.7742, -1.9992, -1.7546, -2.2976,\n",
      "        -1.9774, -1.9569, -2.5274, -1.8931, -2.4685, -1.9811, -1.8784, -2.0872,\n",
      "        -2.0846, -1.7565], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9922, -1.9583, -1.9939, -2.0222, -1.9643, -1.9668, -1.9110, -1.9248,\n",
      "        -1.8978, -1.9668, -1.9776, -1.9827, -1.9648, -1.9105, -2.0133, -1.9571,\n",
      "        -1.9677, -1.9995, -1.9497, -1.9760, -1.9821, -1.9705, -2.0046, -1.9935,\n",
      "        -1.9476, -1.9814, -1.9779, -1.9727, -1.9762, -1.9802, -2.0008, -2.0196,\n",
      "        -1.9655, -1.9802, -1.9430, -1.9715, -1.9336, -1.9720, -1.9785, -1.9690,\n",
      "        -1.9453, -1.9544, -1.9489, -1.9575, -1.9457, -1.9456, -2.0132, -2.0091,\n",
      "        -1.9717, -1.9321], device='mps:0')\n",
      "mean: tensor(-1.9688, device='mps:0')\n",
      "iter_dt 1.10s; iter 25: train loss 0.22845 temperature: 6.249999999999996\n",
      "mean_logits tensor([-2.1092, -2.0633, -1.9973, -2.0550, -2.1201, -1.8753, -2.1086, -2.0075,\n",
      "        -2.1689, -2.3648, -1.8081, -1.5289, -1.9820, -2.0274, -1.6016, -1.8383,\n",
      "        -1.7433, -1.8209, -1.8436, -2.0981, -2.0839, -2.0190, -2.0184, -2.0042,\n",
      "        -1.9996, -1.9222, -2.0553, -2.2918, -2.0599, -1.9407, -1.9352, -1.8967,\n",
      "        -2.1652, -2.0415, -1.7819, -1.5299, -1.7673, -1.8424, -1.8780, -2.0007,\n",
      "        -1.8722, -2.2468, -1.8418, -1.6232, -1.7773, -1.7838, -1.8700, -2.2356,\n",
      "        -1.9624, -1.6659], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9299, -1.9618, -1.9904, -1.9525, -1.9995, -2.0567, -1.9582, -1.9850,\n",
      "        -1.9429, -1.9655, -2.0310, -1.9749, -1.9940, -1.9757, -1.9189, -1.9834,\n",
      "        -1.9651, -1.9976, -1.9682, -1.9645, -1.9026, -1.9652, -1.9715, -1.9847,\n",
      "        -1.9456, -1.9748, -1.9976, -1.9839, -1.9705, -1.9605, -1.9707, -1.9072,\n",
      "        -2.0615, -1.9680, -1.9678, -1.9146, -1.9592, -1.9782, -1.9694, -1.9816,\n",
      "        -1.9602, -1.9531, -1.9864, -1.9895, -1.9694, -1.9101, -1.9631, -1.9562,\n",
      "        -1.9635, -1.9653], device='mps:0')\n",
      "mean: tensor(-1.9694, device='mps:0')\n",
      "iter_dt 1.11s; iter 26: train loss 0.26415 temperature: 6.299999999999995\n",
      "mean_logits tensor([-1.7916, -1.8843, -1.7658, -2.1141, -1.6286, -1.9541, -1.8448, -1.6451,\n",
      "        -2.1093, -1.9174, -1.8351, -1.9677, -1.8493, -2.4082, -1.9132, -2.2210,\n",
      "        -2.1209, -2.1368, -2.1129, -2.0136, -2.1542, -2.1842, -2.0558, -1.9917,\n",
      "        -1.6417, -1.9252, -1.5144, -1.6406, -2.1084, -2.2326, -2.0880, -1.8569,\n",
      "        -1.4627, -1.7923, -1.6536, -1.8594, -1.9403, -1.8137, -1.6884, -2.1825,\n",
      "        -2.1572, -2.0386, -1.8482, -1.9602, -1.8975, -1.9002, -2.0251, -1.8980,\n",
      "        -2.0330, -1.6799], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0003, -1.9575, -1.9986, -1.9773, -1.9693, -1.9819, -1.9438, -1.8857,\n",
      "        -1.8940, -1.9764, -1.9471, -1.9131, -1.9928, -1.9713, -1.8979, -1.9559,\n",
      "        -1.9558, -1.9843, -1.9745, -1.9421, -1.9700, -1.9672, -1.9793, -1.9895,\n",
      "        -1.9780, -1.9562, -2.0086, -1.8879, -1.9976, -2.0227, -1.9083, -1.9912,\n",
      "        -1.9982, -1.9560, -1.9717, -1.9425, -1.9954, -1.9856, -1.9231, -1.9972,\n",
      "        -1.8923, -2.0003, -2.0253, -1.9617, -1.9692, -1.9793, -1.9816, -1.9645,\n",
      "        -1.9980, -1.9390], device='mps:0')\n",
      "mean: tensor(-1.9651, device='mps:0')\n",
      "iter_dt 1.06s; iter 27: train loss 0.32663 temperature: 6.349999999999995\n",
      "mean_logits tensor([-2.0783, -2.0613, -2.0395, -2.1785, -2.0660, -1.7224, -1.9158, -1.9843,\n",
      "        -1.8825, -1.7997, -2.0884, -1.9951, -2.0302, -2.0581, -2.0833, -2.0657,\n",
      "        -1.8409, -1.8374, -2.1348, -1.9040, -1.8999, -2.0682, -1.7712, -2.1307,\n",
      "        -1.9021, -1.8366, -1.5140, -2.1805, -1.7331, -1.8091, -2.1287, -2.0323,\n",
      "        -2.1265, -1.5311, -2.0600, -2.1630, -1.6989, -2.2906, -2.2160, -2.1893,\n",
      "        -1.6421, -1.1562, -2.0710, -1.6961, -2.3635, -2.0313, -1.9627, -2.3385,\n",
      "        -2.2216, -1.6888], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9734, -2.0107, -1.9276, -1.9491, -1.9740, -1.9684, -1.9433, -1.9192,\n",
      "        -1.9773, -1.9715, -1.9690, -1.9701, -1.9765, -1.9824, -1.9793, -1.9205,\n",
      "        -1.9860, -1.9731, -1.8862, -1.9728, -1.9620, -1.9717, -1.9241, -1.9978,\n",
      "        -2.0362, -1.9858, -1.9895, -1.9410, -1.9287, -1.9229, -1.9524, -2.0006,\n",
      "        -1.9649, -1.9711, -2.0153, -1.9844, -1.9488, -1.9405, -1.9609, -1.9237,\n",
      "        -2.0495, -1.9711, -2.0508, -1.9417, -1.9844, -1.9752, -1.9691, -1.9709,\n",
      "        -1.9723, -1.9231], device='mps:0')\n",
      "mean: tensor(-1.9672, device='mps:0')\n",
      "iter_dt 1.11s; iter 28: train loss 0.31858 temperature: 6.399999999999995\n",
      "mean_logits tensor([-1.9029, -2.0182, -2.0726, -1.9404, -2.0674, -2.0089, -1.9754, -2.0922,\n",
      "        -1.8515, -1.9734, -2.1967, -2.2773, -1.9106, -2.0279, -2.1505, -2.2528,\n",
      "        -2.0788, -2.0938, -2.4079, -2.2206, -1.6186, -1.5741, -1.7165, -1.9222,\n",
      "        -1.5227, -2.0170, -2.1657, -1.9059, -1.6302, -1.6522, -2.2513, -1.7510,\n",
      "        -2.2240, -1.9165, -2.0948, -2.1642, -2.2456, -2.0737, -1.8024, -1.9275,\n",
      "        -2.1430, -2.0683, -1.8408, -2.2409, -2.2160, -1.7253, -1.8800, -2.2133,\n",
      "        -2.0485, -2.0898], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9805, -1.9976, -1.9373, -1.9719, -1.9462, -1.9494, -1.9060, -1.9912,\n",
      "        -1.9556, -1.9159, -1.9590, -1.9726, -1.9639, -1.9636, -1.9973, -1.9711,\n",
      "        -1.9845, -1.9574, -2.0048, -2.0539, -1.9870, -1.9651, -1.9481, -1.9680,\n",
      "        -1.9789, -1.9311, -1.9607, -1.9860, -1.9539, -1.9478, -1.9954, -1.9922,\n",
      "        -1.9314, -1.9959, -1.9566, -1.9822, -1.8726, -1.9727, -1.9815, -1.9767,\n",
      "        -1.9659, -1.9680, -1.9112, -1.9034, -1.9411, -1.9760, -1.9309, -1.9756,\n",
      "        -1.9627, -1.9774], device='mps:0')\n",
      "mean: tensor(-1.9635, device='mps:0')\n",
      "iter_dt 1.14s; iter 29: train loss 0.44766 temperature: 6.449999999999995\n",
      "mean_logits tensor([-1.9574, -1.9832, -1.6314, -1.7679, -2.3907, -2.0911, -1.9243, -1.8366,\n",
      "        -2.0951, -1.9764, -1.6524, -1.5125, -1.9257, -1.6836, -2.0088, -1.9393,\n",
      "        -1.5207, -2.4041, -2.0442, -1.8555, -2.0043, -1.9960, -1.9662, -1.8722,\n",
      "        -1.6638, -2.0009, -2.4364, -2.0411, -2.4298, -2.1512, -1.8332, -1.8518,\n",
      "        -1.7566, -2.5171, -1.8083, -1.7373, -2.0631, -2.0595, -1.9892, -1.9943,\n",
      "        -2.0482, -1.8529, -1.6292, -1.6236, -2.0168, -1.5838, -2.0049, -2.0182,\n",
      "        -1.7718, -2.3415], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9120, -1.9229, -1.9737, -1.9103, -1.9650, -1.9962, -1.9978, -1.9628,\n",
      "        -2.0105, -1.9650, -1.9632, -1.9568, -1.9513, -1.9494, -1.9282, -1.9850,\n",
      "        -1.8607, -1.8990, -1.9151, -1.9621, -1.9484, -1.9240, -1.9578, -1.9737,\n",
      "        -1.9525, -1.9641, -1.9572, -2.0175, -1.9622, -1.9881, -1.9587, -1.9552,\n",
      "        -1.9633, -1.9601, -1.9247, -2.0098, -1.9638, -1.9686, -1.9622, -1.9413,\n",
      "        -2.0128, -1.9738, -1.9693, -1.9545, -1.9857, -1.9997, -1.9747, -1.9683,\n",
      "        -1.9770, -1.9703], device='mps:0')\n",
      "mean: tensor(-1.9605, device='mps:0')\n",
      "iter_dt 1.08s; iter 30: train loss 0.44523 temperature: 6.499999999999995\n",
      "mean_logits tensor([-2.0809, -2.5101, -1.9671, -1.7296, -1.8718, -1.8708, -2.2760, -2.2077,\n",
      "        -1.8318, -2.3196, -2.1610, -2.0655, -1.8549, -2.1179, -2.0079, -2.1466,\n",
      "        -1.8500, -2.1545, -1.8326, -2.0652, -1.8872, -2.0920, -1.6034, -1.9680,\n",
      "        -2.1475, -2.2079, -1.9903, -2.2218, -2.1218, -2.0294, -2.1201, -1.8701,\n",
      "        -1.7722, -1.9692, -2.5421, -1.8345, -1.8551, -2.2018, -1.5349, -2.2901,\n",
      "        -1.8855, -2.1248, -2.1799, -1.5695, -2.3126, -2.0663, -2.3284, -2.0922,\n",
      "        -2.2121, -1.9159], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9990, -1.9520, -1.9712, -1.9869, -1.9783, -1.9235, -1.9969, -1.8917,\n",
      "        -1.9666, -2.0156, -1.9380, -1.9871, -1.9294, -1.9986, -1.9614, -1.9636,\n",
      "        -1.9951, -1.9495, -1.9786, -1.9618, -1.9856, -1.9366, -1.9407, -1.9591,\n",
      "        -1.9615, -1.9594, -1.9631, -1.9673, -2.0110, -1.9453, -1.9692, -1.9768,\n",
      "        -1.9191, -1.9044, -1.8874, -1.9669, -1.9664, -1.9562, -1.9164, -2.0387,\n",
      "        -1.9260, -1.9685, -1.9684, -1.9025, -1.9840, -1.9712, -1.9876, -1.9586,\n",
      "        -2.0224, -2.0165], device='mps:0')\n",
      "mean: tensor(-1.9636, device='mps:0')\n",
      "iter_dt 1.07s; iter 31: train loss 0.22893 temperature: 6.5499999999999945\n",
      "mean_logits tensor([-1.9999, -1.7624, -2.0529, -1.7598, -2.1770, -2.2725, -1.9170, -1.9055,\n",
      "        -1.9238, -2.1743, -1.7660, -1.5383, -2.0757, -2.2179, -1.9125, -1.7378,\n",
      "        -1.9136, -2.2392, -1.8777, -1.9212, -1.8992, -2.0371, -1.8149, -2.1136,\n",
      "        -1.8376, -2.1388, -1.7614, -1.8542, -1.9825, -1.7932, -2.2766, -1.9535,\n",
      "        -2.1094, -1.9072, -1.9382, -1.6828, -2.2510, -1.8739, -1.8045, -2.0029,\n",
      "        -2.1361, -1.8961, -2.1357, -1.8853, -2.0845, -1.8115, -2.2639, -2.1011,\n",
      "        -2.2439, -2.1476], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9333, -1.9014, -1.9608, -1.9719, -1.9132, -1.9174, -1.9837, -1.9710,\n",
      "        -1.9149, -1.9581, -1.9284, -1.9579, -1.9961, -1.9813, -2.0027, -2.0109,\n",
      "        -2.0169, -1.9651, -1.9495, -1.9391, -1.9833, -1.9719, -1.9593, -1.9321,\n",
      "        -1.9651, -1.9753, -1.9535, -1.9720, -1.9747, -1.9688, -1.9801, -1.9691,\n",
      "        -1.9641, -1.9597, -1.8958, -1.9105, -1.9923, -1.9766, -1.9666, -1.9429,\n",
      "        -1.9832, -2.0008, -1.9503, -1.9529, -2.0209, -1.9850, -1.9703, -1.9706,\n",
      "        -1.9800, -1.9783], device='mps:0')\n",
      "mean: tensor(-1.9636, device='mps:0')\n",
      "iter_dt 1.07s; iter 32: train loss 0.37688 temperature: 6.599999999999994\n",
      "mean_logits tensor([-2.3174, -1.9313, -1.6481, -1.9388, -1.9546, -2.2022, -2.2981, -1.9609,\n",
      "        -2.0832, -2.3078, -1.8514, -2.0566, -2.1728, -2.0714, -1.9824, -1.8653,\n",
      "        -2.0744, -1.9628, -1.5021, -1.8116, -2.1289, -1.9413, -2.1583, -1.9494,\n",
      "        -1.8055, -2.0758, -2.0488, -2.0586, -1.9477, -2.0966, -2.3701, -2.0225,\n",
      "        -2.2079, -1.7230, -1.7711, -2.0628, -1.8153, -1.7464, -1.9457, -1.9953,\n",
      "        -2.0729, -2.5029, -1.7781, -1.6087, -2.2138, -2.3525, -1.9801, -2.1785,\n",
      "        -2.1159, -1.6446], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9883, -1.9485, -1.9527, -1.9708, -1.9835, -1.9720, -1.9605, -1.9660,\n",
      "        -1.9805, -1.9471, -1.9585, -1.9768, -1.9910, -1.9720, -1.9750, -1.9946,\n",
      "        -1.9228, -1.9626, -1.9761, -1.9704, -1.9444, -1.9328, -1.9965, -1.9610,\n",
      "        -1.9832, -1.9519, -1.9143, -1.9663, -2.0331, -1.9642, -1.9554, -1.9710,\n",
      "        -1.9832, -1.9708, -1.9517, -1.9609, -1.9850, -1.9995, -1.9588, -1.9082,\n",
      "        -1.9073, -1.9433, -1.9683, -1.9553, -1.9961, -1.9472, -1.9625, -2.0376,\n",
      "        -1.9307, -1.9770], device='mps:0')\n",
      "mean: tensor(-1.9657, device='mps:0')\n",
      "iter_dt 1.02s; iter 33: train loss 0.26958 temperature: 6.649999999999994\n",
      "mean_logits tensor([-2.0297, -1.7742, -2.3295, -2.1941, -1.7794, -2.0320, -1.8675, -2.0276,\n",
      "        -1.8206, -2.0087, -1.8806, -1.9073, -1.9925, -2.2443, -1.6947, -1.9940,\n",
      "        -2.3385, -1.7789, -1.9824, -2.1686, -1.8502, -2.2041, -2.0745, -2.0013,\n",
      "        -1.8109, -2.0191, -2.1042, -2.1322, -1.8323, -1.8520, -2.1802, -2.0975,\n",
      "        -2.0966, -1.9166, -1.9851, -1.5262, -2.1801, -1.7071, -1.8372, -1.9717,\n",
      "        -2.0361, -1.8612, -2.2388, -2.1422, -2.0608, -2.0466, -2.1943, -2.1300,\n",
      "        -2.2225, -2.2975], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9868, -1.9501, -1.9980, -1.9828, -1.9735, -1.9985, -2.0077, -1.9671,\n",
      "        -1.9803, -2.0395, -1.9021, -1.9114, -1.9157, -1.9551, -1.9818, -2.0369,\n",
      "        -1.9489, -1.9693, -1.9187, -2.0001, -1.9367, -1.9428, -1.9583, -1.9667,\n",
      "        -1.9502, -1.9568, -1.9528, -1.9473, -1.9531, -2.0793, -1.9760, -1.9762,\n",
      "        -2.0130, -1.9512, -2.0801, -1.9989, -1.9336, -1.9785, -1.9716, -2.0062,\n",
      "        -2.0272, -1.9665, -2.0114, -1.9699, -1.9773, -1.9839, -2.0060, -1.9081,\n",
      "        -1.9135, -1.9639], device='mps:0')\n",
      "mean: tensor(-1.9736, device='mps:0')\n",
      "iter_dt 1.15s; iter 34: train loss 0.44084 temperature: 6.699999999999994\n",
      "mean_logits tensor([-1.9101, -2.2288, -2.1842, -2.2215, -2.1633, -1.7826, -1.9781, -2.0984,\n",
      "        -2.1725, -2.0421, -2.0693, -2.0324, -2.2102, -2.3831, -2.0945, -1.7037,\n",
      "        -2.1790, -2.0073, -1.9513, -1.9530, -1.9650, -1.9995, -2.0579, -2.2062,\n",
      "        -1.8846, -2.2187, -1.9270, -1.8974, -2.5870, -1.8767, -1.8942, -2.0915,\n",
      "        -2.0296, -1.8371, -1.6214, -1.8940, -2.0584, -1.9758, -2.4699, -2.0384,\n",
      "        -1.8894, -2.3403, -2.0063, -2.1466, -2.5533, -1.7770, -2.0360, -1.8942,\n",
      "        -2.2333, -2.1124], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9928, -1.9669, -2.0135, -1.9805, -1.9980, -1.9715, -1.9545, -1.9611,\n",
      "        -1.9075, -1.9758, -1.9561, -1.9521, -1.9730, -2.0020, -2.0183, -1.9008,\n",
      "        -1.9213, -1.9755, -1.9836, -1.9613, -1.9765, -1.9671, -1.9657, -2.0598,\n",
      "        -1.9172, -2.0186, -1.9455, -1.9820, -2.0241, -1.9604, -1.9792, -2.0022,\n",
      "        -1.9655, -1.9714, -1.9514, -1.9728, -1.9835, -1.9166, -1.9874, -1.9692,\n",
      "        -1.9835, -1.9114, -1.9363, -2.0191, -1.9707, -2.0079, -2.0225, -1.9737,\n",
      "        -1.9877, -1.9620], device='mps:0')\n",
      "mean: tensor(-1.9731, device='mps:0')\n",
      "iter_dt 1.11s; iter 35: train loss 0.40002 temperature: 6.749999999999994\n",
      "mean_logits tensor([-1.5966, -1.8410, -1.9146, -2.1267, -2.0657, -1.7162, -1.7847, -2.0810,\n",
      "        -2.0137, -2.2607, -1.6270, -1.6803, -1.9453, -2.3596, -1.9155, -1.9286,\n",
      "        -1.7928, -2.4552, -2.0271, -2.0717, -2.2430, -1.8297, -2.0464, -2.3544,\n",
      "        -1.8708, -1.8479, -1.8780, -2.0792, -2.3237, -2.2454, -2.0079, -2.0041,\n",
      "        -2.2939, -2.0039, -2.1685, -1.9201, -2.2071, -1.8953, -1.6896, -2.1470,\n",
      "        -1.8496, -2.0470, -2.0384, -2.4116, -2.1118, -1.7664, -2.3459, -2.2582,\n",
      "        -2.1774, -2.0108], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9269, -1.9441, -1.9069, -1.9766, -1.9793, -1.9190, -1.9950, -1.9756,\n",
      "        -2.0332, -1.9438, -1.9566, -1.9684, -1.9660, -1.9977, -1.8702, -1.9112,\n",
      "        -1.9562, -2.0451, -1.9638, -1.9413, -1.9014, -2.0201, -1.9569, -1.9723,\n",
      "        -1.9789, -1.9151, -1.9780, -1.9385, -1.9768, -1.9495, -1.9611, -1.9406,\n",
      "        -2.0399, -1.9622, -1.9788, -1.8987, -1.9521, -1.9415, -1.9466, -1.9708,\n",
      "        -1.9701, -1.9223, -1.9671, -1.9644, -1.9569, -1.9647, -1.9691, -1.9394,\n",
      "        -1.9717, -1.9834], device='mps:0')\n",
      "mean: tensor(-1.9593, device='mps:0')\n",
      "iter_dt 1.06s; iter 36: train loss 0.41913 temperature: 6.799999999999994\n",
      "mean_logits tensor([-2.3143, -1.9183, -2.1671, -2.1016, -2.1998, -2.5419, -2.1137, -2.0223,\n",
      "        -1.9869, -2.1607, -1.8176, -2.0179, -2.1598, -1.9640, -2.2152, -1.7752,\n",
      "        -1.6438, -1.6293, -1.6924, -2.0750, -1.9993, -1.8195, -2.2237, -2.0261,\n",
      "        -2.0993, -1.6423, -1.6390, -1.8257, -2.2225, -1.7510, -2.1993, -2.0449,\n",
      "        -2.3257, -2.0555, -2.0109, -2.2242, -1.9940, -2.2139, -1.8938, -2.0798,\n",
      "        -1.9123, -2.0252, -1.8650, -2.0509, -2.4688, -1.9898, -2.3309, -1.9827,\n",
      "        -2.0786, -2.0847], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0305, -1.9519, -1.9438, -1.9871, -1.9173, -1.9567, -1.9710, -1.9605,\n",
      "        -1.9373, -2.0416, -1.9168, -1.9000, -1.9344, -1.9072, -1.9791, -1.9707,\n",
      "        -1.9558, -1.9733, -2.0208, -2.0009, -1.9195, -1.9688, -1.9884, -1.8857,\n",
      "        -1.9621, -1.9765, -1.9669, -1.9471, -1.9591, -1.9966, -1.9991, -1.9390,\n",
      "        -1.9725, -1.9784, -1.9061, -1.9529, -2.0049, -1.9186, -1.9601, -1.9963,\n",
      "        -1.9948, -1.9060, -1.9362, -1.9699, -1.9248, -1.9773, -2.0193, -1.9615,\n",
      "        -2.0069, -1.9155], device='mps:0')\n",
      "mean: tensor(-1.9613, device='mps:0')\n",
      "iter_dt 1.08s; iter 37: train loss 0.38641 temperature: 6.849999999999993\n",
      "mean_logits tensor([-1.8926, -2.2461, -1.7162, -1.9457, -2.2508, -2.0974, -2.1905, -2.1204,\n",
      "        -1.9519, -2.1342, -1.9984, -2.4256, -1.6663, -1.6350, -1.9801, -2.3388,\n",
      "        -2.2974, -1.8570, -2.2725, -1.8008, -1.7331, -1.8810, -2.0894, -2.3611,\n",
      "        -2.0711, -1.5981, -1.9958, -1.5981, -2.1624, -2.2573, -2.0517, -1.8422,\n",
      "        -1.9241, -2.1064, -2.0498, -1.9251, -1.8793, -1.9482, -1.9639, -2.1899,\n",
      "        -1.9966, -1.8927, -1.9984, -2.3257, -1.9470, -2.2937, -2.0155, -2.1665,\n",
      "        -1.7150, -2.2615], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9703, -1.9902, -2.0077, -1.9726, -1.9717, -2.0060, -1.9552, -1.9556,\n",
      "        -1.9723, -1.9571, -1.9708, -2.0369, -1.9980, -2.0100, -1.9856, -1.9794,\n",
      "        -1.9743, -1.9687, -1.9586, -1.9041, -1.9951, -1.9811, -1.9094, -1.9812,\n",
      "        -1.9412, -1.9478, -1.9714, -1.9584, -1.9298, -1.9554, -1.9758, -1.9679,\n",
      "        -1.9624, -1.9699, -1.9546, -1.9411, -1.9939, -1.9580, -1.9778, -1.9406,\n",
      "        -1.9723, -1.9624, -1.9996, -1.9740, -1.9510, -1.9658, -1.8738, -1.8790,\n",
      "        -1.9877, -2.0155], device='mps:0')\n",
      "mean: tensor(-1.9668, device='mps:0')\n",
      "iter_dt 1.24s; iter 38: train loss 0.50653 temperature: 6.899999999999993\n",
      "mean_logits tensor([-1.8340, -1.9060, -1.9502, -2.0089, -1.8850, -1.9958, -1.9660, -2.2590,\n",
      "        -2.1125, -2.2245, -1.5859, -1.9314, -2.5551, -1.8823, -2.3232, -2.1505,\n",
      "        -1.6075, -1.9957, -1.9286, -1.8370, -1.8742, -2.3022, -1.6231, -2.0034,\n",
      "        -1.7370, -2.1481, -2.2802, -1.5870, -2.2202, -1.8445, -1.9342, -1.8252,\n",
      "        -2.3648, -2.3845, -1.8754, -2.3296, -2.0138, -2.1409, -2.2819, -2.1913,\n",
      "        -1.8263, -2.3377, -2.0503, -1.7606, -2.0528, -1.8904, -2.2463, -2.0710,\n",
      "        -1.8406, -1.4563], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9753, -1.9688, -1.9365, -2.0215, -1.9279, -1.9330, -1.9452, -1.9699,\n",
      "        -1.9746, -1.9595, -1.9634, -1.9996, -1.9134, -1.9745, -1.9412, -1.9502,\n",
      "        -1.9681, -1.9750, -2.0113, -1.9135, -1.9768, -1.9707, -1.9437, -1.9717,\n",
      "        -1.9787, -1.9749, -1.9481, -2.0226, -1.9858, -1.9929, -1.8635, -1.9689,\n",
      "        -1.9553, -1.9506, -1.9667, -1.9864, -1.9745, -1.9579, -1.9878, -1.9519,\n",
      "        -2.0252, -1.9687, -2.0165, -1.9358, -1.9815, -1.9530, -1.9971, -1.9782,\n",
      "        -1.9295, -1.9712], device='mps:0')\n",
      "mean: tensor(-1.9662, device='mps:0')\n",
      "iter_dt 1.09s; iter 39: train loss 0.19949 temperature: 6.949999999999993\n",
      "mean_logits tensor([-2.1309, -2.1653, -1.9662, -1.8430, -1.9365, -2.2163, -1.8669, -1.9256,\n",
      "        -1.9635, -1.8128, -1.9463, -2.0649, -2.0815, -2.0892, -2.2002, -1.9257,\n",
      "        -1.9150, -1.8515, -1.8124, -1.8477, -1.9505, -2.1683, -1.9487, -1.9346,\n",
      "        -2.2072, -2.0469, -1.8314, -2.0262, -2.1790, -1.9720, -1.9959, -2.0750,\n",
      "        -1.8232, -2.0388, -1.7609, -1.9898, -2.0025, -2.3967, -2.0840, -1.8686,\n",
      "        -1.7908, -2.0749, -1.7665, -2.1129, -1.9350, -2.3128, -2.0886, -1.9186,\n",
      "        -2.0247, -1.9447], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9438, -1.9326, -1.9518, -1.9548, -1.9023, -1.9508, -1.9420, -1.9199,\n",
      "        -1.9261, -1.9936, -1.9702, -1.9628, -1.9522, -1.9912, -1.9522, -1.9181,\n",
      "        -1.9842, -1.9715, -1.9851, -2.0180, -2.0223, -1.9789, -1.9696, -1.9598,\n",
      "        -1.9175, -1.9565, -1.9368, -1.9835, -2.0014, -1.9470, -1.9778, -1.9690,\n",
      "        -1.9433, -2.0069, -1.9719, -1.9683, -1.9670, -1.8902, -1.9724, -2.0123,\n",
      "        -2.0106, -1.8695, -1.9430, -1.9400, -1.9559, -1.9916, -1.9347, -1.9302,\n",
      "        -1.9894, -1.9986], device='mps:0')\n",
      "mean: tensor(-1.9608, device='mps:0')\n",
      "iter_dt 1.06s; iter 40: train loss 0.21282 temperature: 6.999999999999993\n",
      "mean_logits tensor([-1.8927, -1.9874, -1.9652, -1.8680, -2.1383, -2.1567, -1.5245, -1.8907,\n",
      "        -2.1139, -1.6445, -2.1616, -2.1225, -2.1661, -1.7939, -1.9271, -1.9311,\n",
      "        -1.9602, -2.2371, -1.9045, -1.9736, -1.9220, -1.9195, -2.0530, -1.9133,\n",
      "        -2.0673, -2.0371, -2.2787, -2.0917, -1.7619, -1.7471, -1.8702, -1.7930,\n",
      "        -1.9306, -2.1444, -2.1130, -2.1040, -1.9168, -2.0801, -1.7051, -2.0881,\n",
      "        -2.0548, -2.1791, -2.2315, -1.8189, -1.7718, -1.7873, -1.8578, -1.9413,\n",
      "        -2.3224, -2.1873], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9722, -1.9712, -1.9396, -1.9833, -1.9718, -1.9688, -2.0153, -1.9458,\n",
      "        -1.9706, -1.9491, -1.9619, -1.9653, -1.9701, -1.9348, -1.9564, -1.9903,\n",
      "        -1.8904, -1.9654, -1.9418, -1.9964, -1.9542, -1.9857, -1.9651, -1.9465,\n",
      "        -1.9755, -1.9106, -1.9556, -1.9621, -1.8778, -1.9639, -1.9625, -1.9818,\n",
      "        -1.9738, -1.9768, -1.9809, -1.9487, -1.8956, -1.9503, -1.9575, -1.9825,\n",
      "        -1.9770, -1.9843, -1.9616, -1.9711, -1.9317, -2.0019, -1.9783, -2.0167,\n",
      "        -1.9724, -1.9728], device='mps:0')\n",
      "mean: tensor(-1.9627, device='mps:0')\n",
      "iter_dt 1.03s; iter 41: train loss 0.26611 temperature: 7.049999999999993\n",
      "mean_logits tensor([-1.9788, -2.1063, -1.8502, -2.1550, -1.8084, -2.3378, -1.9513, -1.6891,\n",
      "        -2.1495, -1.9493, -1.9254, -2.2422, -1.9737, -1.8843, -2.1174, -2.1322,\n",
      "        -2.3393, -2.2482, -2.3977, -2.0728, -1.8862, -2.1507, -1.8635, -2.0535,\n",
      "        -1.8288, -2.0701, -1.8695, -2.0448, -1.9355, -1.8377, -2.0336, -2.0609,\n",
      "        -1.7677, -1.8399, -2.0430, -2.1293, -1.9133, -1.8855, -2.0113, -2.1937,\n",
      "        -1.6039, -2.3348, -2.0741, -1.7436, -1.8515, -2.0172, -1.9501, -2.0711,\n",
      "        -2.0904, -2.1634], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9669, -1.9387, -1.9183, -1.9547, -1.9713, -1.9811, -1.9670, -1.9775,\n",
      "        -1.9539, -1.9861, -1.9384, -1.9686, -1.9765, -1.8867, -1.8910, -1.9779,\n",
      "        -1.9761, -1.9621, -1.9621, -1.9535, -1.8721, -1.9916, -1.9969, -1.9613,\n",
      "        -1.9525, -1.9363, -1.9675, -1.9280, -1.9654, -1.9776, -1.9478, -1.9632,\n",
      "        -1.9320, -1.9598, -1.9942, -1.9664, -1.9905, -1.9533, -1.9439, -1.9775,\n",
      "        -2.0042, -1.9703, -1.9718, -1.9479, -1.9802, -1.9784, -1.9525, -1.9696,\n",
      "        -1.9721, -2.0172], device='mps:0')\n",
      "mean: tensor(-1.9610, device='mps:0')\n",
      "iter_dt 1.03s; iter 42: train loss 0.57703 temperature: 7.0999999999999925\n",
      "mean_logits tensor([-1.8658, -2.1748, -2.1084, -2.0760, -2.5151, -2.1561, -2.4464, -1.8578,\n",
      "        -2.2710, -2.2193, -2.2518, -2.0794, -1.8162, -2.2237, -1.6721, -1.9562,\n",
      "        -1.9986, -2.0511, -2.0471, -2.1755, -2.0994, -1.9661, -2.4050, -1.8985,\n",
      "        -2.3586, -2.1541, -1.8557, -2.1416, -1.9221, -1.8087, -2.4044, -1.8687,\n",
      "        -1.9153, -2.1975, -2.0776, -2.0631, -2.1024, -2.5145, -1.9969, -2.0385,\n",
      "        -2.1895, -1.7845, -2.0249, -1.9574, -2.3052, -2.0809, -2.4926, -1.8289,\n",
      "        -2.2947, -2.0056], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9679, -1.9707, -1.9565, -1.9751, -1.9721, -1.9953, -2.0145, -1.9563,\n",
      "        -1.9421, -1.9912, -1.9776, -1.9656, -1.9788, -1.9939, -1.9566, -1.9625,\n",
      "        -1.9516, -1.9630, -1.9336, -1.9663, -1.9728, -1.9682, -1.9810, -1.9859,\n",
      "        -1.9892, -1.9998, -1.9680, -1.9603, -1.9755, -1.9882, -1.9719, -1.9733,\n",
      "        -1.9615, -1.9154, -1.9715, -1.8883, -1.8892, -1.9335, -1.9671, -1.9524,\n",
      "        -1.9816, -1.9706, -2.0200, -1.9597, -1.9565, -1.9614, -1.9712, -1.9636,\n",
      "        -1.9697, -1.9970], device='mps:0')\n",
      "mean: tensor(-1.9671, device='mps:0')\n",
      "iter_dt 1.02s; iter 43: train loss 0.30679 temperature: 7.149999999999992\n",
      "mean_logits tensor([-1.8347, -1.7311, -2.2951, -2.2469, -1.9630, -1.8964, -2.0077, -1.8013,\n",
      "        -1.8823, -1.9597, -1.9510, -1.9116, -2.2192, -2.2056, -2.4027, -1.9189,\n",
      "        -2.2497, -2.0361, -2.1482, -1.9578, -1.8231, -1.8983, -2.3538, -2.0567,\n",
      "        -1.9969, -1.9701, -1.9236, -2.0509, -1.9723, -2.0459, -1.8505, -2.1995,\n",
      "        -2.2626, -1.8605, -1.9233, -1.8284, -1.7425, -1.6742, -1.9692, -2.1416,\n",
      "        -2.3003, -2.2879, -1.8891, -1.9413, -2.0706, -2.0678, -2.0276, -1.6322,\n",
      "        -1.6054, -1.5514], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9009, -1.9084, -1.9770, -1.9525, -1.9877, -1.9940, -1.9815, -1.9776,\n",
      "        -1.9492, -1.9692, -1.9764, -2.0038, -1.9724, -1.9365, -1.9704, -1.9613,\n",
      "        -1.9581, -1.9712, -2.0303, -1.9212, -1.9482, -1.9343, -1.9979, -1.9725,\n",
      "        -2.0089, -1.9275, -1.9938, -1.9334, -1.9789, -1.9121, -1.9693, -1.9687,\n",
      "        -1.9666, -1.9841, -1.9571, -1.9620, -1.9598, -1.9354, -1.9481, -2.0010,\n",
      "        -1.9578, -1.8899, -1.9614, -1.9765, -1.9681, -1.9790, -1.9893, -1.9617,\n",
      "        -1.9648, -1.9719], device='mps:0')\n",
      "mean: tensor(-1.9636, device='mps:0')\n",
      "iter_dt 1.02s; iter 44: train loss 0.51008 temperature: 7.199999999999992\n",
      "mean_logits tensor([-1.9063, -2.1020, -2.1973, -1.9088, -1.7779, -2.0801, -2.1734, -2.4942,\n",
      "        -1.9670, -1.7049, -1.8441, -2.1940, -2.0684, -2.2800, -2.1938, -2.2732,\n",
      "        -2.1685, -2.1446, -2.0640, -1.9997, -2.2104, -1.9404, -2.1152, -2.2080,\n",
      "        -2.3134, -2.3381, -2.1678, -2.1096, -2.0933, -1.8391, -2.1182, -1.9877,\n",
      "        -1.5820, -2.0567, -2.1505, -2.1229, -1.7544, -2.4363, -2.0849, -1.9572,\n",
      "        -2.1797, -1.7429, -1.8125, -2.2558, -1.9199, -2.2957, -2.0637, -2.3669,\n",
      "        -1.6574, -2.4262], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9574, -1.9690, -1.9630, -1.9743, -1.9565, -1.9827, -1.9624, -1.9925,\n",
      "        -1.9837, -2.0163, -1.9452, -1.8706, -1.9705, -1.9579, -1.9327, -1.9326,\n",
      "        -1.9723, -2.0052, -1.9309, -1.9690, -1.9700, -1.9821, -1.9894, -1.9851,\n",
      "        -1.9730, -1.9214, -1.9978, -1.9686, -1.9261, -1.9992, -1.9710, -1.9720,\n",
      "        -1.9800, -1.9695, -1.9695, -1.9695, -1.9112, -1.9698, -1.9667, -1.9688,\n",
      "        -1.9618, -1.9697, -1.9709, -1.9709, -1.9731, -1.9669, -1.9782, -1.9545,\n",
      "        -1.9888, -1.9602], device='mps:0')\n",
      "mean: tensor(-1.9660, device='mps:0')\n",
      "iter_dt 1.03s; iter 45: train loss 0.27897 temperature: 7.249999999999992\n",
      "mean_logits tensor([-1.8488, -2.2684, -2.0445, -2.0107, -2.0162, -2.1972, -2.1160, -2.0112,\n",
      "        -2.1083, -2.1320, -1.8815, -1.8913, -2.1136, -2.0806, -1.8104, -2.0534,\n",
      "        -1.8151, -1.6773, -1.9569, -1.9090, -1.7368, -2.0779, -2.0474, -1.6402,\n",
      "        -2.2062, -2.0498, -2.0160, -2.1210, -1.7986, -2.0808, -2.0883, -1.6056,\n",
      "        -2.3973, -1.8490, -2.4146, -1.9128, -1.8940, -1.6710, -2.0537, -1.8676,\n",
      "        -1.9311, -1.8879, -2.0084, -1.9432, -1.9976, -1.8064, -2.0363, -2.3744,\n",
      "        -2.2214, -2.3096], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9459, -1.9976, -1.9739, -1.9904, -1.9733, -1.9774, -1.9469, -1.9827,\n",
      "        -1.9858, -1.9687, -2.0002, -1.9872, -1.9709, -1.9587, -1.9777, -1.9904,\n",
      "        -1.9058, -1.9814, -1.9861, -1.9760, -1.9664, -1.9513, -2.0148, -1.9807,\n",
      "        -2.0243, -1.9588, -1.9905, -1.9729, -1.9710, -1.9523, -2.0113, -1.9725,\n",
      "        -2.0058, -1.9266, -1.9722, -1.9323, -1.9699, -1.9971, -1.9098, -1.9192,\n",
      "        -1.9186, -1.9205, -1.9583, -1.9841, -1.9770, -1.9708, -1.9659, -1.9726,\n",
      "        -1.9720, -1.9669], device='mps:0')\n",
      "mean: tensor(-1.9697, device='mps:0')\n",
      "iter_dt 1.00s; iter 46: train loss 0.36114 temperature: 7.299999999999992\n",
      "mean_logits tensor([-1.6984, -2.1480, -2.1114, -1.9773, -2.0154, -2.2068, -1.6332, -1.9700,\n",
      "        -1.8899, -2.0575, -2.0228, -2.1739, -1.7669, -2.1830, -1.6637, -1.8277,\n",
      "        -1.9908, -1.9522, -2.2136, -2.0086, -1.9402, -2.2238, -2.2636, -2.0216,\n",
      "        -2.0953, -2.1895, -1.8743, -1.6770, -1.9882, -2.4206, -2.3169, -2.1218,\n",
      "        -1.9994, -1.8220, -2.3264, -2.0747, -1.9699, -1.8709, -1.9334, -2.2094,\n",
      "        -1.7320, -1.8671, -2.1258, -1.9858, -2.2590, -2.1208, -2.2906, -2.3244,\n",
      "        -2.3103, -2.1689], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9741, -1.8644, -1.9649, -1.9775, -1.9844, -1.9173, -1.9665, -1.9738,\n",
      "        -1.9233, -1.9712, -1.9700, -1.9751, -2.0028, -1.9650, -1.9168, -1.9366,\n",
      "        -1.9601, -1.9654, -1.9670, -2.0074, -1.9959, -1.9173, -1.9923, -2.0208,\n",
      "        -1.9741, -1.9756, -1.9157, -1.9611, -1.9954, -1.9751, -1.9419, -1.9630,\n",
      "        -1.9712, -2.0049, -1.9755, -1.9676, -1.9502, -1.9968, -1.9570, -1.9840,\n",
      "        -2.0052, -1.9437, -1.9648, -1.9561, -1.9695, -1.9579, -2.0078, -1.9808,\n",
      "        -1.9534, -2.0079], device='mps:0')\n",
      "mean: tensor(-1.9673, device='mps:0')\n",
      "iter_dt 1.00s; iter 47: train loss 0.38407 temperature: 7.349999999999992\n",
      "mean_logits tensor([-2.3204, -1.9369, -2.1295, -1.6129, -2.0887, -2.0151, -2.0980, -2.0429,\n",
      "        -1.9942, -1.8976, -2.1634, -2.2027, -1.8818, -1.9001, -2.2418, -1.7374,\n",
      "        -2.1203, -1.8852, -1.8840, -2.2082, -2.0252, -2.3365, -1.7271, -2.1104,\n",
      "        -2.4600, -2.2887, -1.9305, -1.7696, -1.9904, -1.8264, -2.2530, -2.1592,\n",
      "        -1.6495, -2.0634, -1.9017, -1.9350, -1.9054, -2.0803, -2.2631, -2.1529,\n",
      "        -2.1861, -1.9558, -1.8798, -2.3440, -1.8326, -2.0884, -1.7779, -2.3761,\n",
      "        -1.8865, -2.2064], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9621, -2.0035, -1.9870, -1.9657, -1.9422, -2.0274, -1.9768, -1.9205,\n",
      "        -1.9371, -1.9763, -1.9840, -1.9991, -1.9722, -1.9764, -1.9598, -1.9651,\n",
      "        -1.9649, -1.9746, -1.9715, -1.9230, -1.9676, -1.9901, -2.0389, -1.9613,\n",
      "        -1.9674, -1.9391, -1.9687, -1.9873, -1.9390, -1.9129, -1.9701, -1.9804,\n",
      "        -1.9396, -1.9196, -1.9509, -1.9463, -1.9740, -1.9669, -1.9554, -1.9324,\n",
      "        -1.9938, -1.9570, -1.9639, -1.9431, -1.9545, -1.9819, -1.9429, -1.9815,\n",
      "        -1.9852, -1.9469], device='mps:0')\n",
      "mean: tensor(-1.9650, device='mps:0')\n",
      "iter_dt 1.02s; iter 48: train loss 0.47178 temperature: 7.3999999999999915\n",
      "mean_logits tensor([-2.0713, -2.2056, -1.6357, -2.0841, -2.0358, -1.9169, -1.9642, -2.1139,\n",
      "        -1.8315, -1.7355, -1.9422, -2.0926, -1.8653, -2.2860, -1.8373, -2.3260,\n",
      "        -1.9284, -1.9589, -2.0614, -1.9942, -2.0238, -2.0034, -1.9317, -2.1387,\n",
      "        -1.8919, -2.3904, -1.8204, -2.0273, -1.5770, -1.9659, -2.4275, -1.9119,\n",
      "        -1.7407, -1.7720, -2.3250, -1.6888, -2.3110, -2.0217, -2.0465, -2.1383,\n",
      "        -2.1528, -1.8987, -2.1193, -2.4327, -2.4309, -2.1378, -2.3805, -1.8878,\n",
      "        -2.3869, -1.9967], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9642, -1.9423, -1.9683, -1.9266, -1.9279, -1.9737, -1.9486, -1.9569,\n",
      "        -1.9548, -1.9270, -1.9742, -1.9578, -1.9173, -2.0091, -1.9768, -1.9692,\n",
      "        -1.9710, -1.9455, -1.9705, -1.9086, -2.0518, -1.9714, -1.9674, -2.0120,\n",
      "        -2.0073, -1.9441, -1.9706, -1.9787, -1.9310, -1.9915, -1.9499, -1.9077,\n",
      "        -2.0323, -1.9781, -1.9879, -1.9849, -1.9048, -1.9852, -1.9174, -1.9923,\n",
      "        -2.0161, -2.0089, -1.9901, -1.9662, -1.9707, -1.9674, -1.9539, -1.9661,\n",
      "        -1.9611, -1.9607], device='mps:0')\n",
      "mean: tensor(-1.9663, device='mps:0')\n",
      "iter_dt 1.00s; iter 49: train loss 0.43305 temperature: 7.449999999999991\n",
      "mean_logits tensor([-1.9593, -1.8246, -1.8809, -1.8514, -1.8230, -1.8869, -2.0537, -2.3449,\n",
      "        -2.2795, -1.9082, -2.0471, -2.1779, -1.9353, -1.7907, -1.7399, -1.7962,\n",
      "        -2.6393, -2.0061, -2.3705, -1.8374, -1.8869, -1.7091, -1.9468, -1.8364,\n",
      "        -1.6852, -1.8207, -2.0597, -1.8338, -1.9622, -2.0251, -2.0128, -1.9128,\n",
      "        -2.4640, -1.9618, -1.7399, -1.9257, -1.7602, -1.9929, -2.1093, -1.4322,\n",
      "        -2.0014, -2.1839, -1.7057, -1.9806, -2.0056, -2.2113, -1.8441, -2.2639,\n",
      "        -2.1319, -1.9488], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.8776, -1.9905, -1.9734, -1.9741, -1.9867, -1.9864, -1.9157, -1.8841,\n",
      "        -1.9726, -1.9741, -2.0032, -1.9611, -1.9742, -1.9776, -1.9704, -1.9714,\n",
      "        -1.9608, -1.9645, -1.9442, -1.9267, -1.9779, -1.9552, -1.9918, -1.9299,\n",
      "        -1.9878, -1.9750, -1.9620, -1.9713, -1.9777, -1.9226, -2.0127, -1.9760,\n",
      "        -1.9785, -2.0036, -1.9545, -1.9417, -1.9695, -1.9698, -2.0029, -1.9686,\n",
      "        -1.9698, -1.9734, -2.0090, -1.9824, -1.9805, -1.9642, -1.9654, -1.9543,\n",
      "        -2.0035, -1.9105], device='mps:0')\n",
      "mean: tensor(-1.9666, device='mps:0')\n",
      "iter_dt 1.00s; iter 50: train loss 0.42452 temperature: 7.499999999999991\n",
      "mean_logits tensor([-1.7152, -1.6999, -1.7556, -1.8896, -1.6553, -2.2239, -2.1288, -2.0716,\n",
      "        -1.7006, -1.6581, -1.8498, -2.1263, -2.5386, -2.2343, -1.8484, -2.1899,\n",
      "        -1.6558, -1.6583, -2.0650, -1.8059, -2.1306, -2.2772, -1.7370, -1.7729,\n",
      "        -2.0717, -2.0165, -1.8321, -1.7318, -2.2970, -1.7819, -2.1265, -1.8510,\n",
      "        -2.0785, -2.2515, -2.1365, -2.1710, -2.0602, -1.9318, -1.9929, -2.0939,\n",
      "        -1.9540, -1.9061, -2.1552, -2.1794, -2.2432, -2.4472, -2.1512, -2.2062,\n",
      "        -1.7476, -1.8157], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9082, -1.9428, -1.9508, -1.9512, -1.9031, -1.9667, -1.9514, -2.0035,\n",
      "        -2.0170, -1.9514, -1.9710, -1.9491, -1.9786, -1.9357, -1.9438, -1.9349,\n",
      "        -1.9998, -1.9863, -1.9861, -1.9766, -1.9566, -1.9662, -1.9943, -2.0013,\n",
      "        -2.0068, -1.9725, -1.9757, -1.9397, -1.9666, -1.9543, -1.8479, -1.9713,\n",
      "        -1.9809, -1.9754, -1.9737, -1.9860, -1.9441, -1.9920, -1.8830, -1.9424,\n",
      "        -1.9641, -1.9756, -1.9168, -1.9461, -1.9821, -1.9635, -1.9853, -1.9313,\n",
      "        -1.9303, -1.9353], device='mps:0')\n",
      "mean: tensor(-1.9594, device='mps:0')\n",
      "iter_dt 1.03s; iter 51: train loss 0.35504 temperature: 7.549999999999991\n",
      "mean_logits tensor([-1.8160, -2.1093, -2.1550, -2.0295, -2.0643, -1.7658, -1.8239, -1.7906,\n",
      "        -1.8278, -1.7296, -2.0782, -1.9297, -2.0370, -2.3031, -1.9857, -2.3976,\n",
      "        -2.0262, -2.0865, -1.8265, -2.1316, -1.7566, -1.9682, -2.2247, -2.1170,\n",
      "        -2.2376, -1.8895, -2.1682, -2.0381, -2.1474, -1.9435, -2.1444, -1.9185,\n",
      "        -2.2086, -2.1283, -2.4336, -2.0213, -2.2053, -1.9771, -2.3626, -1.8423,\n",
      "        -1.6700, -1.8929, -1.5187, -1.7527, -2.3290, -1.4651, -1.7451, -1.9210,\n",
      "        -2.1077, -1.8958], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.8938, -1.9288, -1.9579, -1.9254, -1.9507, -1.9509, -1.9751, -1.9098,\n",
      "        -1.9528, -1.9732, -1.9509, -1.9772, -1.9721, -1.9557, -1.9664, -1.9689,\n",
      "        -1.9245, -1.9248, -1.9701, -1.9832, -1.8729, -1.9749, -1.9805, -1.8790,\n",
      "        -2.0144, -1.9696, -1.9574, -1.9144, -1.9673, -1.9711, -1.9791, -1.9719,\n",
      "        -1.9738, -1.9817, -1.9870, -1.9412, -1.9718, -1.9833, -1.9459, -1.8957,\n",
      "        -1.9571, -1.9770, -1.9472, -1.9844, -1.9937, -1.9589, -1.9700, -2.0015,\n",
      "        -1.9124, -1.9619], device='mps:0')\n",
      "mean: tensor(-1.9562, device='mps:0')\n",
      "iter_dt 1.00s; iter 52: train loss 0.30051 temperature: 7.599999999999991\n",
      "mean_logits tensor([-2.0192, -1.8438, -2.0709, -2.3527, -1.9063, -2.2334, -2.2690, -1.7502,\n",
      "        -2.0976, -2.0067, -2.1367, -1.9677, -2.0449, -1.8812, -2.1679, -1.6555,\n",
      "        -2.1267, -1.8839, -2.1457, -2.0756, -2.0430, -2.2565, -1.7549, -1.7356,\n",
      "        -2.2172, -2.2924, -2.0223, -1.7342, -2.0484, -1.9434, -1.9218, -2.1008,\n",
      "        -2.0903, -1.9262, -1.8555, -1.5525, -1.5388, -1.7686, -1.8608, -1.7904,\n",
      "        -1.6959, -2.4040, -1.8646, -2.0990, -2.0817, -1.9106, -1.7631, -1.7958,\n",
      "        -1.8106, -2.0522], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9336, -1.9865, -1.9865, -1.9660, -1.8851, -1.9781, -1.9709, -1.9649,\n",
      "        -2.0103, -1.9679, -1.9673, -1.9814, -1.9676, -1.9869, -1.9555, -1.9760,\n",
      "        -1.9862, -1.9614, -1.9549, -1.9563, -1.9210, -1.9555, -1.9957, -1.9515,\n",
      "        -1.9460, -1.9345, -1.9817, -1.9757, -1.9824, -1.9741, -1.9221, -1.9491,\n",
      "        -1.9444, -1.9504, -1.9628, -1.9625, -1.9994, -1.9983, -1.9869, -1.9719,\n",
      "        -1.9877, -2.0331, -1.9930, -1.9700, -1.9821, -1.9582, -1.9623, -1.9843,\n",
      "        -1.9890, -1.9737], device='mps:0')\n",
      "mean: tensor(-1.9689, device='mps:0')\n",
      "iter_dt 1.01s; iter 53: train loss 0.22848 temperature: 7.649999999999991\n",
      "mean_logits tensor([-2.2125, -2.2022, -2.1202, -1.7395, -2.1357, -1.9359, -1.9767, -1.7970,\n",
      "        -1.9440, -2.1761, -1.7950, -2.1171, -1.9717, -1.9606, -1.7465, -2.0339,\n",
      "        -2.1187, -2.0053, -1.9589, -1.8415, -2.0335, -2.2808, -2.1416, -1.6680,\n",
      "        -2.1406, -2.2235, -1.9175, -2.0037, -1.7451, -2.3497, -1.8470, -2.1195,\n",
      "        -1.8853, -2.1881, -2.0826, -2.0159, -2.1539, -1.9266, -2.0606, -1.7104,\n",
      "        -2.3295, -2.0282, -2.0307, -1.8199, -1.7964, -1.9456, -2.0087, -2.0791,\n",
      "        -2.2220, -1.9288], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9601, -1.9666, -1.9705, -1.9287, -1.9465, -1.9714, -1.9438, -1.9655,\n",
      "        -1.9622, -1.9767, -1.9423, -1.9517, -1.9955, -1.9482, -1.9267, -1.9936,\n",
      "        -1.9695, -1.9520, -1.9350, -1.9562, -1.9722, -1.9461, -1.9724, -2.0147,\n",
      "        -1.9999, -1.9617, -1.9562, -2.0178, -1.9506, -1.9833, -1.9786, -1.9716,\n",
      "        -1.9440, -1.9857, -1.9850, -1.9677, -1.9826, -2.0095, -1.9586, -1.9343,\n",
      "        -1.9675, -1.9634, -2.0281, -1.9858, -1.9702, -1.9725, -1.9417, -1.9871,\n",
      "        -1.9212, -1.9694], device='mps:0')\n",
      "mean: tensor(-1.9672, device='mps:0')\n",
      "iter_dt 1.02s; iter 54: train loss 0.29340 temperature: 7.69999999999999\n",
      "mean_logits tensor([-2.1311, -2.2224, -2.2522, -1.6612, -1.8222, -1.7778, -2.2958, -1.9826,\n",
      "        -2.3080, -2.1008, -2.0657, -2.1849, -2.0013, -1.8440, -1.9305, -1.9342,\n",
      "        -2.0855, -1.9723, -2.0586, -1.8986, -2.0664, -2.1542, -1.8478, -1.9465,\n",
      "        -2.1024, -2.3143, -2.1671, -2.2145, -1.9163, -2.0429, -2.0063, -1.9412,\n",
      "        -2.2287, -1.4651, -1.6486, -1.5120, -1.9695, -1.9885, -2.1367, -2.0453,\n",
      "        -1.8548, -1.9443, -1.9004, -2.1252, -1.9619, -2.3309, -2.1635, -2.1708,\n",
      "        -2.0003, -1.9548], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9683, -1.9567, -1.9888, -1.9644, -1.9628, -1.9476, -1.9799, -1.9865,\n",
      "        -2.0440, -1.9512, -1.9465, -1.9655, -1.9586, -1.9444, -2.0174, -1.9703,\n",
      "        -1.9941, -1.9903, -1.9535, -1.9355, -1.9126, -1.9680, -1.9981, -1.9850,\n",
      "        -1.9629, -1.8733, -1.9036, -1.9470, -1.9839, -1.9705, -1.9792, -2.0188,\n",
      "        -1.9104, -1.9511, -1.9676, -1.9701, -1.9678, -1.9596, -1.9474, -1.9105,\n",
      "        -2.0054, -1.9411, -1.9190, -1.9721, -1.9151, -1.9833, -1.9770, -2.0032,\n",
      "        -1.9735, -1.9334], device='mps:0')\n",
      "mean: tensor(-1.9627, device='mps:0')\n",
      "iter_dt 1.02s; iter 55: train loss 0.36735 temperature: 7.74999999999999\n",
      "mean_logits tensor([-1.9866, -1.9810, -2.1915, -1.9537, -2.0932, -2.2043, -2.1331, -2.1009,\n",
      "        -1.8149, -1.8197, -1.8123, -2.3344, -2.3485, -2.0544, -2.2924, -1.7946,\n",
      "        -2.1874, -2.2566, -1.6994, -1.9324, -2.1665, -1.8889, -2.3932, -1.8686,\n",
      "        -1.9359, -1.9857, -1.6141, -2.2592, -1.9623, -1.8060, -1.9907, -1.8761,\n",
      "        -2.1905, -2.1890, -1.9070, -2.1705, -2.0080, -1.8398, -1.7178, -1.9611,\n",
      "        -1.7789, -2.5369, -1.9570, -2.0010, -2.2101, -2.0439, -1.9134, -2.2098,\n",
      "        -2.1200, -1.9227], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0336, -2.0169, -1.9714, -1.9772, -1.9688, -2.0054, -1.9673, -1.9805,\n",
      "        -1.9117, -1.9711, -1.9684, -1.9757, -1.9439, -1.9675, -1.9625, -1.9744,\n",
      "        -1.9808, -1.9516, -1.8771, -1.9349, -2.0279, -1.9728, -1.9895, -1.9916,\n",
      "        -1.9632, -2.0304, -1.9407, -1.9884, -1.9784, -1.9222, -1.9422, -1.9682,\n",
      "        -1.9189, -1.9531, -1.9583, -1.9550, -1.9121, -1.9863, -1.8926, -1.9905,\n",
      "        -1.9337, -1.9430, -1.9778, -1.9667, -1.9636, -1.9599, -1.9186, -2.0030,\n",
      "        -1.9117, -1.9186], device='mps:0')\n",
      "mean: tensor(-1.9624, device='mps:0')\n",
      "iter_dt 1.02s; iter 56: train loss 0.40835 temperature: 7.79999999999999\n",
      "mean_logits tensor([-1.9226, -1.8977, -2.0918, -1.6179, -2.2271, -1.7090, -1.6876, -2.1130,\n",
      "        -1.8721, -2.0749, -1.9136, -2.0074, -1.8770, -2.2510, -2.2807, -1.8669,\n",
      "        -2.1987, -1.9026, -2.1645, -2.3810, -2.0976, -2.3581, -2.2088, -1.8968,\n",
      "        -1.9050, -1.9810, -2.0354, -1.8290, -2.3504, -1.9716, -2.2160, -2.1613,\n",
      "        -1.5631, -1.9695, -1.7150, -2.0682, -2.2855, -1.9703, -1.9921, -2.0577,\n",
      "        -1.9347, -2.1024, -2.3326, -2.3636, -2.3005, -1.9991, -1.7521, -2.1655,\n",
      "        -1.9959, -2.1018], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9005, -1.8737, -1.8904, -1.9732, -1.8737, -1.9706, -1.9696, -1.9382,\n",
      "        -1.9699, -1.9652, -1.9713, -1.9681, -1.9814, -1.9975, -1.8667, -1.9982,\n",
      "        -1.9621, -1.9650, -1.9645, -1.9110, -1.9740, -1.9373, -1.9076, -1.9456,\n",
      "        -1.9696, -1.9715, -1.9868, -1.9715, -1.9748, -1.9812, -1.9707, -1.9876,\n",
      "        -1.9377, -1.9384, -1.8914, -1.9846, -1.9503, -1.9517, -1.9734, -1.9772,\n",
      "        -1.9699, -1.9883, -2.0049, -1.9577, -1.9714, -1.9654, -1.9697, -1.9594,\n",
      "        -1.9717, -1.9509], device='mps:0')\n",
      "mean: tensor(-1.9561, device='mps:0')\n",
      "iter_dt 0.99s; iter 57: train loss 0.39719 temperature: 7.84999999999999\n",
      "mean_logits tensor([-2.3404, -1.7464, -2.2006, -2.0298, -2.0019, -1.9969, -1.9869, -1.6539,\n",
      "        -2.0003, -2.0428, -1.9603, -2.3224, -1.7683, -2.1921, -2.3132, -1.8005,\n",
      "        -2.1442, -1.9516, -1.7465, -1.8421, -1.9582, -2.3323, -2.0500, -1.8687,\n",
      "        -2.3568, -1.9960, -1.8211, -2.2530, -2.0153, -2.0062, -1.9143, -2.4262,\n",
      "        -2.0895, -1.8310, -2.1184, -2.1248, -1.8698, -1.7222, -1.8813, -2.0529,\n",
      "        -1.9278, -1.9097, -2.1447, -2.0078, -1.9247, -1.7738, -2.5261, -2.0607,\n",
      "        -2.1454, -2.1193], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9493, -1.9931, -1.9704, -1.9631, -1.9755, -1.9646, -1.9726, -1.9781,\n",
      "        -1.9649, -1.9470, -1.9566, -1.9666, -1.9181, -1.9714, -1.9715, -1.9902,\n",
      "        -1.9902, -1.9782, -1.9721, -1.9011, -1.8917, -1.9636, -1.9408, -1.9472,\n",
      "        -1.8955, -1.9498, -1.9645, -1.9766, -1.9716, -1.9636, -1.9710, -1.9594,\n",
      "        -1.9527, -1.9709, -1.9608, -1.9692, -2.0528, -1.9126, -1.9918, -2.0157,\n",
      "        -1.9252, -1.9700, -1.9705, -1.9626, -1.9610, -1.9532, -1.9668, -1.9983,\n",
      "        -1.9714, -1.8717], device='mps:0')\n",
      "mean: tensor(-1.9613, device='mps:0')\n",
      "iter_dt 1.02s; iter 58: train loss 0.37009 temperature: 7.89999999999999\n",
      "mean_logits tensor([-1.9055, -1.9490, -1.8561, -2.4695, -2.1019, -1.9318, -2.0231, -1.6135,\n",
      "        -2.0286, -1.9731, -2.1623, -2.1942, -1.5970, -1.6480, -2.1666, -1.9778,\n",
      "        -1.8157, -1.6225, -2.4055, -2.0560, -1.7021, -1.9171, -1.7731, -1.6947,\n",
      "        -2.2368, -2.2079, -2.3032, -1.9889, -1.7634, -1.9240, -1.7179, -2.3114,\n",
      "        -1.5006, -1.9759, -1.9910, -2.3430, -1.8368, -2.1729, -1.9246, -1.6638,\n",
      "        -1.9690, -1.9511, -1.7236, -1.9759, -1.6969, -1.9962, -1.9011, -1.9609,\n",
      "        -1.9916, -2.0165], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9765, -1.9303, -1.9724, -1.9482, -1.9565, -1.9222, -1.9381, -1.9701,\n",
      "        -1.9689, -1.9650, -1.9730, -1.9760, -1.9498, -1.9650, -1.9489, -1.9773,\n",
      "        -1.9988, -2.0124, -1.9720, -1.9815, -1.9276, -1.9475, -1.9249, -1.9415,\n",
      "        -1.9674, -2.0003, -1.9037, -1.9243, -1.9417, -1.9728, -1.9883, -1.9519,\n",
      "        -1.9664, -1.9721, -1.9841, -1.9698, -1.9699, -1.9766, -1.9704, -1.9747,\n",
      "        -1.9956, -1.9809, -1.9677, -1.9839, -1.9136, -1.9482, -1.9173, -2.0109,\n",
      "        -1.9695, -1.9616], device='mps:0')\n",
      "mean: tensor(-1.9626, device='mps:0')\n",
      "iter_dt 0.99s; iter 59: train loss 0.29249 temperature: 7.9499999999999895\n",
      "mean_logits tensor([-2.0507, -1.9203, -2.1933, -1.8078, -2.1969, -2.0226, -2.0796, -2.2012,\n",
      "        -2.1166, -2.1488, -2.1063, -2.4009, -1.6819, -2.0950, -1.7381, -1.9454,\n",
      "        -1.9210, -1.9357, -1.9432, -1.9916, -2.0398, -1.6920, -2.0060, -1.9453,\n",
      "        -1.9293, -1.9534, -2.0540, -1.7274, -2.3377, -2.3568, -2.2458, -1.8003,\n",
      "        -2.2454, -2.0204, -2.0006, -2.1331, -1.8870, -1.8006, -2.2298, -1.9745,\n",
      "        -2.2189, -1.8738, -1.8716, -1.8826, -2.0201, -1.7999, -1.8097, -1.8677,\n",
      "        -2.1310, -2.2667], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9756, -1.9772, -1.9676, -1.9765, -1.9559, -1.9749, -1.9228, -1.9654,\n",
      "        -1.9001, -1.9460, -1.9349, -1.9741, -1.9546, -1.9730, -1.9826, -2.0188,\n",
      "        -1.9595, -1.9315, -1.9573, -1.9520, -1.9608, -2.0186, -1.9538, -2.0090,\n",
      "        -1.9102, -1.9148, -1.9335, -2.0525, -1.9640, -1.9892, -1.9737, -1.9742,\n",
      "        -1.9850, -1.9758, -1.9145, -1.9608, -1.9866, -1.9982, -1.9939, -1.9501,\n",
      "        -1.9878, -1.9134, -1.9454, -2.0038, -1.9747, -1.9123, -1.9495, -1.9877,\n",
      "        -1.9326, -1.9728], device='mps:0')\n",
      "mean: tensor(-1.9640, device='mps:0')\n",
      "iter_dt 1.00s; iter 60: train loss 0.24987 temperature: 7.999999999999989\n",
      "mean_logits tensor([-1.7445, -2.3159, -1.9822, -2.2497, -2.2083, -1.6832, -1.9069, -2.0361,\n",
      "        -1.9304, -2.0473, -2.1787, -2.2071, -1.5494, -1.8106, -1.9966, -1.9795,\n",
      "        -1.8429, -1.8957, -1.7085, -2.2125, -1.9231, -1.6849, -1.8513, -2.1300,\n",
      "        -1.9024, -1.7543, -2.1389, -2.0236, -1.8894, -2.0643, -1.8183, -1.9156,\n",
      "        -1.7976, -1.6634, -2.0583, -2.2283, -1.8351, -1.9454, -2.2313, -2.0667,\n",
      "        -1.7563, -1.7769, -1.9934, -1.9708, -1.8820, -1.9792, -2.2296, -2.2758,\n",
      "        -1.8399, -1.8059], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9564, -1.9726, -1.9685, -1.9567, -1.9826, -1.9908, -1.9823, -1.9758,\n",
      "        -1.9865, -1.9716, -1.9692, -1.9977, -1.9517, -1.9593, -1.9771, -1.9699,\n",
      "        -1.9811, -1.9637, -1.9915, -1.9500, -1.9624, -1.9695, -2.0168, -1.9689,\n",
      "        -1.9807, -1.9686, -1.9335, -1.9576, -1.9427, -1.8902, -1.9681, -1.9600,\n",
      "        -1.9672, -1.9661, -1.9714, -1.9675, -1.9524, -1.9301, -1.9582, -1.9833,\n",
      "        -1.9644, -1.9339, -1.9875, -1.9571, -1.9758, -1.9729, -1.9626, -1.9418,\n",
      "        -1.9650, -1.9656], device='mps:0')\n",
      "mean: tensor(-1.9659, device='mps:0')\n",
      "iter_dt 1.07s; iter 61: train loss 0.26192 temperature: 8.04999999999999\n",
      "mean_logits tensor([-2.1392, -1.9224, -2.2589, -1.9620, -1.9666, -1.8326, -1.5482, -1.9184,\n",
      "        -1.9907, -2.2690, -1.9438, -2.0958, -1.9719, -1.6527, -1.9266, -2.3179,\n",
      "        -1.7099, -1.9597, -2.2379, -2.2717, -1.9700, -2.1670, -2.0972, -2.2173,\n",
      "        -2.1772, -2.0720, -2.0276, -1.9200, -2.2658, -1.8251, -1.9293, -1.7721,\n",
      "        -1.8918, -1.8610, -1.9102, -1.9605, -2.2081, -1.5556, -2.1917, -1.8258,\n",
      "        -1.8237, -2.1731, -2.0899, -1.7276, -2.1413, -2.0053, -1.6785, -1.8377,\n",
      "        -1.8882, -1.8982], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9866, -1.9609, -1.9647, -1.9688, -1.9981, -1.9655, -1.9320, -1.9920,\n",
      "        -2.0178, -1.9435, -1.9567, -2.0107, -2.0185, -1.9649, -1.9758, -1.9795,\n",
      "        -1.9493, -1.9679, -1.9564, -1.9864, -1.9709, -1.9723, -1.9753, -1.9677,\n",
      "        -2.0496, -1.9702, -1.9252, -1.9527, -1.9620, -1.9791, -1.9710, -1.9712,\n",
      "        -1.9709, -1.9067, -1.9649, -1.9822, -1.9329, -1.9506, -1.9287, -1.9581,\n",
      "        -1.9593, -1.9708, -1.9018, -1.9902, -2.0673, -1.9823, -2.0386, -1.9642,\n",
      "        -1.9948, -1.9486], device='mps:0')\n",
      "mean: tensor(-1.9715, device='mps:0')\n",
      "iter_dt 1.01s; iter 62: train loss 0.30753 temperature: 8.09999999999999\n",
      "mean_logits tensor([-2.1080, -2.3339, -1.9323, -1.9429, -2.1086, -1.8651, -2.1214, -1.9254,\n",
      "        -1.9076, -2.0288, -2.1589, -1.8700, -1.9467, -1.9755, -2.0910, -2.2392,\n",
      "        -2.0846, -2.1372, -2.0375, -1.8163, -2.3171, -2.1713, -1.9683, -1.8075,\n",
      "        -2.0721, -2.1890, -1.8365, -2.3529, -1.7805, -1.8796, -2.2291, -1.9911,\n",
      "        -2.1663, -2.0993, -2.1148, -1.9938, -2.1140, -2.3963, -2.2223, -2.1436,\n",
      "        -2.0051, -1.8163, -1.9478, -2.0076, -2.1813, -2.1484, -2.3115, -1.6086,\n",
      "        -1.9924, -2.0979], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.8804, -1.9863, -1.9604, -1.9717, -1.9329, -1.9389, -1.9694, -1.9642,\n",
      "        -1.9658, -1.9606, -1.9708, -1.9765, -1.8905, -1.9874, -1.9727, -1.9120,\n",
      "        -1.9701, -1.9330, -1.9717, -1.9605, -1.9725, -1.9705, -1.9732, -1.9485,\n",
      "        -1.9710, -1.9689, -1.9778, -1.9759, -1.9556, -1.9728, -1.9768, -1.9759,\n",
      "        -1.9993, -1.9693, -1.9524, -1.8923, -1.9891, -1.9596, -1.9771, -1.9907,\n",
      "        -1.9866, -1.9490, -1.9058, -1.9283, -1.9211, -1.9502, -1.9613, -1.9632,\n",
      "        -1.9016, -1.9513], device='mps:0')\n",
      "mean: tensor(-1.9573, device='mps:0')\n",
      "iter_dt 1.01s; iter 63: train loss 0.36732 temperature: 8.149999999999991\n",
      "mean_logits tensor([-2.2016, -2.1139, -2.0646, -1.6071, -1.7528, -1.9510, -2.0036, -2.3335,\n",
      "        -1.8289, -2.0315, -1.7513, -2.0246, -1.7766, -2.1213, -2.0370, -2.0469,\n",
      "        -2.2654, -1.8272, -2.1022, -2.1882, -2.3008, -2.2468, -1.8273, -1.8647,\n",
      "        -1.9399, -1.6710, -2.0175, -2.4468, -2.1030, -2.1111, -2.0381, -2.0182,\n",
      "        -2.2415, -2.0999, -2.2074, -2.1127, -1.9753, -2.0847, -2.4209, -1.9567,\n",
      "        -1.8743, -1.9856, -1.9184, -2.0795, -2.3373, -2.0284, -2.0543, -2.3695,\n",
      "        -1.9617, -1.8861], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9813, -1.9683, -1.9403, -1.9523, -1.9998, -1.9513, -1.9403, -1.9851,\n",
      "        -1.9721, -1.9741, -1.9228, -2.0526, -1.9825, -1.9463, -1.9922, -1.9714,\n",
      "        -1.9594, -1.9160, -1.9508, -1.9950, -1.9716, -1.9604, -2.0185, -1.9436,\n",
      "        -1.9516, -1.9794, -1.9700, -1.9569, -1.9795, -1.9593, -1.9810, -1.9669,\n",
      "        -1.9402, -1.9913, -1.9828, -1.9722, -1.9556, -1.9797, -1.9737, -1.9205,\n",
      "        -1.9682, -1.9819, -2.0153, -1.9686, -1.9801, -1.9658, -1.9537, -1.9253,\n",
      "        -1.9451, -1.9596], device='mps:0')\n",
      "mean: tensor(-1.9674, device='mps:0')\n",
      "iter_dt 1.00s; iter 64: train loss 0.19231 temperature: 8.199999999999992\n",
      "mean_logits tensor([-2.0303, -2.0760, -2.1240, -2.1953, -1.8443, -1.8464, -1.8601, -1.7510,\n",
      "        -2.1701, -2.0454, -2.0423, -2.0675, -1.8531, -2.3457, -1.8970, -1.9226,\n",
      "        -1.9143, -1.9626, -2.1469, -2.2536, -2.0635, -1.9102, -1.8676, -1.7437,\n",
      "        -1.9000, -2.0990, -1.8896, -1.9927, -2.0392, -2.1046, -1.9248, -1.8336,\n",
      "        -2.0795, -1.9829, -1.9148, -2.0871, -1.8053, -1.5456, -1.8479, -1.8540,\n",
      "        -1.9153, -2.1951, -2.0370, -1.8944, -1.8729, -1.9043, -2.3482, -1.6593,\n",
      "        -1.9845, -1.9675], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0540, -1.9603, -1.9600, -2.0106, -1.9340, -1.9923, -1.9729, -1.9781,\n",
      "        -1.9743, -1.9182, -1.9703, -1.9693, -1.9616, -1.9413, -1.9392, -1.9718,\n",
      "        -1.9560, -1.9795, -1.9551, -1.9630, -1.9763, -1.9614, -1.9671, -2.0061,\n",
      "        -2.0043, -1.9702, -1.9115, -1.9513, -1.8977, -1.9677, -1.9846, -2.0031,\n",
      "        -1.9602, -1.9756, -1.9612, -1.9433, -1.8596, -1.8976, -1.9717, -1.9553,\n",
      "        -1.9585, -1.9189, -1.9730, -2.0143, -2.0072, -1.9442, -1.9876, -1.9819,\n",
      "        -1.9596, -1.9542], device='mps:0')\n",
      "mean: tensor(-1.9637, device='mps:0')\n",
      "iter_dt 1.01s; iter 65: train loss 0.31637 temperature: 8.249999999999993\n",
      "mean_logits tensor([-1.9030, -2.3805, -2.2857, -1.9593, -1.9260, -2.0886, -1.7686, -1.6960,\n",
      "        -1.8136, -2.2606, -1.7025, -1.9665, -2.1564, -2.1394, -1.9027, -2.0812,\n",
      "        -1.7848, -1.8763, -1.9848, -2.1263, -2.0464, -2.0099, -1.6076, -1.9604,\n",
      "        -2.3638, -1.7236, -2.0483, -2.0289, -2.1049, -2.1070, -2.0292, -2.1046,\n",
      "        -1.6074, -1.9446, -2.1243, -2.2134, -2.1697, -2.2162, -2.1464, -2.1459,\n",
      "        -2.0825, -1.5884, -2.0901, -1.8089, -1.9210, -1.9792, -2.2127, -2.1862,\n",
      "        -2.1624, -2.2135], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9558, -1.9450, -1.9635, -1.9069, -1.9229, -1.9519, -1.9929, -1.9471,\n",
      "        -1.9410, -1.9845, -1.9848, -1.9983, -1.9986, -1.9462, -1.9788, -1.9617,\n",
      "        -1.9933, -1.9926, -1.9344, -1.9635, -1.9791, -1.9464, -1.9680, -1.9724,\n",
      "        -1.9701, -1.9562, -1.9308, -1.9729, -1.9545, -1.9841, -1.9683, -1.9248,\n",
      "        -1.9719, -1.9729, -1.9068, -1.9578, -1.9580, -1.9524, -1.9517, -1.9662,\n",
      "        -1.9660, -1.9641, -1.9511, -1.9719, -1.9791, -1.9587, -1.9474, -1.9472,\n",
      "        -1.9898, -1.9487], device='mps:0')\n",
      "mean: tensor(-1.9611, device='mps:0')\n",
      "iter_dt 1.03s; iter 66: train loss 0.31561 temperature: 8.299999999999994\n",
      "mean_logits tensor([-2.1203, -2.0510, -2.0433, -2.0647, -2.5367, -2.1235, -2.0280, -1.8773,\n",
      "        -2.0336, -2.3236, -2.0969, -2.2025, -2.0371, -1.7355, -1.8288, -1.7277,\n",
      "        -2.2131, -1.9806, -1.8142, -2.2096, -2.3408, -2.0396, -2.0833, -1.9621,\n",
      "        -1.9863, -2.2080, -2.0338, -2.1827, -2.1025, -2.1249, -1.7489, -1.8200,\n",
      "        -1.8632, -2.0279, -1.7570, -1.9967, -1.9781, -2.1870, -1.8612, -2.1564,\n",
      "        -2.0893, -1.9332, -2.0440, -1.8133, -2.0919, -2.2281, -2.0726, -2.1484,\n",
      "        -2.1767, -1.7949], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9931, -2.0154, -2.0187, -1.9936, -1.9926, -1.9666, -1.9356, -1.9721,\n",
      "        -1.9952, -1.9654, -1.9939, -1.9371, -1.9504, -1.8676, -1.9702, -1.9048,\n",
      "        -1.8947, -1.9693, -2.0275, -1.9220, -1.9681, -1.9684, -1.9473, -1.9242,\n",
      "        -2.0267, -1.9405, -1.9717, -1.9451, -1.9332, -1.9716, -1.9627, -1.9692,\n",
      "        -1.9908, -1.8684, -1.9649, -1.9677, -1.9860, -1.9485, -1.9457, -1.9171,\n",
      "        -1.9640, -1.9396, -1.9515, -1.9139, -1.9637, -1.8944, -1.9721, -1.9560,\n",
      "        -1.9663, -1.9396], device='mps:0')\n",
      "mean: tensor(-1.9573, device='mps:0')\n",
      "iter_dt 1.02s; iter 67: train loss 0.30287 temperature: 8.349999999999994\n",
      "mean_logits tensor([-2.1721, -2.1424, -2.1965, -2.0218, -1.8231, -1.8430, -2.0042, -1.9174,\n",
      "        -2.1629, -1.8320, -2.0834, -2.1859, -1.7616, -1.7163, -1.6715, -2.2530,\n",
      "        -1.9941, -2.2612, -2.3486, -2.2029, -2.1418, -1.7020, -2.1575, -1.9474,\n",
      "        -2.2851, -1.7780, -1.8359, -1.8825, -1.9341, -1.8725, -2.3151, -2.0505,\n",
      "        -2.2027, -2.0723, -1.8271, -1.9256, -1.8401, -1.8700, -2.3800, -1.9847,\n",
      "        -1.9470, -1.9728, -2.0822, -1.8001, -1.9453, -2.1035, -2.1493, -2.0385,\n",
      "        -1.9527, -1.8433], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9634, -1.9742, -1.9749, -1.9224, -1.9981, -1.9704, -1.9412, -1.9202,\n",
      "        -1.9205, -1.9752, -1.9695, -1.9729, -1.9682, -2.0252, -1.9816, -1.9688,\n",
      "        -1.9716, -1.9008, -1.9662, -1.9452, -1.9665, -1.9599, -1.9650, -1.9539,\n",
      "        -1.9883, -2.0165, -1.9637, -1.9712, -1.9704, -2.0031, -1.9848, -1.9698,\n",
      "        -1.8760, -2.0074, -1.9367, -1.9726, -1.9565, -1.9771, -1.9666, -1.9360,\n",
      "        -1.9640, -1.9495, -1.9911, -1.9636, -1.9190, -1.9510, -1.9529, -1.9797,\n",
      "        -1.9691, -1.9721], device='mps:0')\n",
      "mean: tensor(-1.9637, device='mps:0')\n",
      "iter_dt 1.04s; iter 68: train loss 0.33001 temperature: 8.399999999999995\n",
      "mean_logits tensor([-2.2082, -2.0863, -2.3415, -1.8458, -1.9797, -2.3489, -2.0762, -2.0200,\n",
      "        -2.1317, -2.0671, -1.9643, -1.8193, -2.0774, -2.2336, -1.9283, -1.9977,\n",
      "        -2.0143, -1.9823, -1.8700, -2.1181, -1.4991, -1.9239, -1.7312, -1.7728,\n",
      "        -2.0146, -2.0301, -2.1781, -1.9893, -1.6679, -2.2348, -2.0446, -2.0740,\n",
      "        -2.1539, -2.0762, -1.9154, -1.9281, -1.9989, -2.4505, -2.3109, -1.9976,\n",
      "        -1.9086, -2.3780, -2.1734, -1.8211, -1.7794, -2.1346, -2.2531, -2.2363,\n",
      "        -2.0207, -1.8028], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9652, -1.9886, -1.9565, -2.0071, -1.9197, -2.0008, -1.9707, -1.9733,\n",
      "        -2.0210, -1.9378, -1.9109, -2.0309, -1.9712, -1.9587, -2.0042, -1.9685,\n",
      "        -1.9700, -2.0234, -1.9680, -1.9661, -1.9390, -1.9449, -1.9590, -1.9600,\n",
      "        -1.9728, -1.9791, -1.9719, -1.9066, -1.9312, -1.9674, -1.9644, -1.9711,\n",
      "        -1.9200, -1.9594, -1.9823, -1.9673, -1.9533, -1.9737, -1.9730, -1.9629,\n",
      "        -1.9220, -1.9671, -2.0206, -1.9668, -1.9616, -2.0283, -1.9720, -1.9605,\n",
      "        -1.9673, -1.9461], device='mps:0')\n",
      "mean: tensor(-1.9677, device='mps:0')\n",
      "iter_dt 1.02s; iter 69: train loss 0.32231 temperature: 8.449999999999996\n",
      "mean_logits tensor([-2.0160, -1.7902, -1.8833, -2.0961, -1.8538, -1.8980, -2.3541, -1.8056,\n",
      "        -1.8268, -2.2432, -1.8305, -1.9881, -2.3608, -1.6140, -1.8589, -1.9624,\n",
      "        -1.6307, -1.9474, -2.2592, -1.9696, -1.9538, -1.6370, -2.1167, -1.8648,\n",
      "        -1.9484, -1.9813, -2.2071, -1.9582, -2.1583, -1.8903, -2.0463, -1.9807,\n",
      "        -1.8362, -1.9346, -2.2405, -2.1177, -2.1525, -2.1466, -2.0878, -2.0363,\n",
      "        -2.1043, -1.8758, -1.9115, -2.3666, -2.4305, -2.2619, -1.9649, -1.8692,\n",
      "        -2.0734, -1.6817], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9719, -1.9313, -1.9270, -1.9518, -1.8985, -1.9984, -1.9509, -1.9653,\n",
      "        -1.9873, -2.0154, -1.9438, -1.9239, -1.9700, -1.9824, -1.9696, -1.9853,\n",
      "        -1.9403, -1.9818, -1.9749, -1.9632, -1.9411, -1.9747, -1.9714, -1.9867,\n",
      "        -1.9609, -1.9072, -1.9024, -2.0178, -1.9619, -1.9827, -1.9764, -1.9755,\n",
      "        -1.9572, -1.9439, -1.9725, -1.9629, -2.0172, -1.9616, -1.9679, -1.9612,\n",
      "        -1.9608, -1.9833, -1.9814, -1.9703, -1.9339, -1.9733, -1.9452, -1.9680,\n",
      "        -1.9717, -1.9706], device='mps:0')\n",
      "mean: tensor(-1.9639, device='mps:0')\n",
      "iter_dt 1.00s; iter 70: train loss 0.34628 temperature: 8.499999999999996\n",
      "mean_logits tensor([-2.0959, -2.2129, -1.7608, -1.8936, -1.9339, -1.9086, -2.0153, -2.0787,\n",
      "        -2.2159, -1.8555, -2.3440, -1.9723, -2.0354, -1.9161, -2.1543, -2.0966,\n",
      "        -1.9393, -2.3406, -2.2990, -2.1018, -2.2710, -1.8339, -1.7857, -2.2551,\n",
      "        -1.8308, -1.5968, -1.8920, -2.1626, -2.1572, -1.8702, -1.9267, -2.1817,\n",
      "        -1.9746, -2.1181, -2.0521, -2.3312, -2.1233, -1.9183, -2.1603, -1.7813,\n",
      "        -2.3316, -1.9179, -2.2965, -1.9942, -2.1894, -2.2290, -2.2661, -1.9013,\n",
      "        -2.1538, -2.0727], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9105, -1.9731, -1.9660, -1.9782, -1.9643, -1.9799, -1.9687, -1.9811,\n",
      "        -2.0094, -1.9726, -1.9818, -1.9049, -1.9747, -1.9606, -1.9666, -1.9872,\n",
      "        -1.9407, -1.9747, -1.8887, -1.9577, -1.9489, -1.9156, -1.9438, -1.9645,\n",
      "        -1.9607, -1.9579, -1.9376, -1.8916, -1.9539, -1.9854, -1.9427, -1.9722,\n",
      "        -1.9514, -2.0040, -1.9855, -1.9875, -1.9657, -1.9913, -1.9623, -1.9565,\n",
      "        -1.9557, -1.9052, -1.9698, -1.9833, -1.9828, -1.9667, -1.9768, -1.9469,\n",
      "        -1.9634, -1.9795], device='mps:0')\n",
      "mean: tensor(-1.9610, device='mps:0')\n",
      "iter_dt 1.01s; iter 71: train loss 0.36591 temperature: 8.549999999999997\n",
      "mean_logits tensor([-1.7362, -2.2586, -2.4082, -1.6596, -2.1545, -1.9074, -1.8969, -2.3768,\n",
      "        -1.8216, -2.0490, -1.9427, -2.0259, -2.2033, -1.6717, -1.9244, -1.9495,\n",
      "        -2.0335, -1.6489, -1.9373, -1.9501, -1.9695, -2.2030, -2.1503, -2.2802,\n",
      "        -1.9914, -2.0893, -2.0333, -1.9486, -2.1872, -2.1280, -2.0882, -2.3077,\n",
      "        -1.8833, -2.2784, -2.0177, -1.8627, -2.3186, -1.7495, -2.2090, -1.9897,\n",
      "        -1.9904, -1.9931, -2.2609, -1.9746, -2.2957, -1.9782, -1.9588, -1.7650,\n",
      "        -1.9989, -1.9854], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9790, -1.8220, -1.9345, -1.9572, -1.9271, -1.9653, -1.9755, -1.9675,\n",
      "        -1.9429, -1.9611, -1.9631, -1.9282, -1.9424, -1.9698, -1.9564, -1.9397,\n",
      "        -2.0077, -1.9993, -1.9485, -1.9685, -1.9714, -1.9292, -1.9845, -1.9301,\n",
      "        -2.0178, -1.8499, -1.9739, -1.9042, -1.9756, -1.9882, -1.8835, -1.9668,\n",
      "        -1.9826, -1.9655, -1.9708, -1.9702, -1.9727, -1.9543, -1.9582, -1.9767,\n",
      "        -1.9869, -1.9749, -1.9964, -1.9992, -1.9981, -1.9752, -1.9625, -2.0051,\n",
      "        -1.9737, -1.9592], device='mps:0')\n",
      "mean: tensor(-1.9603, device='mps:0')\n",
      "iter_dt 1.01s; iter 72: train loss 0.24430 temperature: 8.599999999999998\n",
      "mean_logits tensor([-1.9157, -1.9376, -1.8585, -1.9044, -2.1691, -2.1223, -1.9643, -1.9045,\n",
      "        -2.1393, -1.5144, -1.6885, -1.8310, -1.9462, -2.0760, -2.0258, -2.0999,\n",
      "        -1.8953, -1.8349, -1.7703, -1.5929, -1.9743, -1.7906, -2.2741, -2.0117,\n",
      "        -1.7803, -2.1860, -2.0417, -2.0936, -1.8119, -1.9908, -2.0800, -1.7635,\n",
      "        -2.0085, -2.4351, -1.8432, -1.9199, -1.9611, -1.7695, -2.0500, -2.1386,\n",
      "        -2.1205, -1.9474, -2.0554, -1.8702, -2.2281, -2.2976, -1.8330, -1.9698,\n",
      "        -1.9676, -1.8673], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9694, -1.9430, -1.9694, -1.9958, -1.9736, -1.9755, -1.9910, -1.9373,\n",
      "        -1.8787, -1.9797, -1.9710, -1.9740, -1.8890, -1.8913, -1.9528, -1.9347,\n",
      "        -1.9447, -2.0082, -2.0055, -1.9673, -1.9656, -1.9720, -1.9806, -1.9766,\n",
      "        -1.9323, -1.9505, -1.9684, -1.9703, -1.9830, -1.9466, -1.9475, -1.9587,\n",
      "        -1.9766, -1.9552, -1.9466, -1.9448, -1.9594, -1.9463, -1.9548, -1.9611,\n",
      "        -1.9686, -1.9714, -1.9426, -1.9546, -1.9353, -1.9730, -2.0014, -1.9686,\n",
      "        -1.9981, -1.9330], device='mps:0')\n",
      "mean: tensor(-1.9599, device='mps:0')\n",
      "iter_dt 1.02s; iter 73: train loss 0.31745 temperature: 8.649999999999999\n",
      "mean_logits tensor([-1.9781, -2.2591, -1.6447, -2.1379, -1.8829, -2.1332, -2.2004, -1.9104,\n",
      "        -1.9436, -1.7354, -1.7434, -2.0447, -2.0231, -2.1541, -2.0047, -1.9385,\n",
      "        -2.2934, -2.2386, -1.9928, -2.0242, -1.8216, -2.0517, -2.2397, -2.1665,\n",
      "        -1.8824, -1.9189, -2.0209, -2.0977, -2.2422, -1.9150, -1.8964, -2.6433,\n",
      "        -2.0033, -1.7814, -1.8614, -1.8971, -1.8290, -2.1822, -2.0127, -1.8331,\n",
      "        -1.9420, -2.0337, -1.9598, -2.0755, -2.0156, -1.9346, -2.1040, -1.7250,\n",
      "        -1.8960, -2.2306], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9618, -1.9774, -1.9728, -1.9709, -1.9605, -1.9612, -1.9743, -1.9695,\n",
      "        -1.9457, -1.9736, -1.9723, -1.9652, -1.9685, -1.9075, -1.9138, -1.9690,\n",
      "        -1.9830, -1.9652, -1.9933, -1.9065, -1.9546, -1.9347, -2.0108, -1.9704,\n",
      "        -1.9750, -1.9684, -1.9792, -1.9930, -1.9661, -1.9274, -1.9704, -1.9845,\n",
      "        -1.9532, -1.9425, -1.9597, -1.9659, -2.0060, -1.9582, -1.9136, -1.9759,\n",
      "        -2.0315, -1.9795, -1.9208, -1.9811, -1.9260, -1.9545, -2.0022, -2.0184,\n",
      "        -1.9384, -1.9735], device='mps:0')\n",
      "mean: tensor(-1.9649, device='mps:0')\n",
      "iter_dt 1.01s; iter 74: train loss 0.32337 temperature: 8.7\n",
      "mean_logits tensor([-2.0722, -2.0975, -2.4695, -1.7509, -2.0031, -1.9082, -2.3236, -1.8094,\n",
      "        -2.1788, -1.8813, -2.2669, -1.9948, -2.2353, -1.7744, -2.0132, -1.9836,\n",
      "        -2.2219, -1.9458, -2.0605, -1.9745, -1.9861, -2.2848, -2.0375, -2.1636,\n",
      "        -1.9788, -2.0988, -1.9208, -2.0734, -2.1452, -1.8175, -2.0844, -1.7492,\n",
      "        -2.1480, -2.0034, -1.9598, -2.1539, -2.1870, -1.7118, -1.8165, -2.1321,\n",
      "        -1.9759, -2.0974, -1.9176, -1.9141, -2.3790, -2.3387, -2.1097, -1.9603,\n",
      "        -2.0596, -2.1532], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9446, -1.9591, -1.9818, -1.8713, -1.9716, -1.9880, -1.9565, -1.9684,\n",
      "        -1.9866, -2.0206, -1.9732, -1.9884, -1.9646, -1.9922, -1.9442, -1.9433,\n",
      "        -1.9399, -2.0119, -1.9699, -1.8725, -1.9567, -1.9683, -1.9675, -1.9708,\n",
      "        -2.0327, -1.9730, -1.9904, -1.9676, -1.9540, -1.9954, -1.9565, -1.9701,\n",
      "        -1.9927, -1.9540, -1.9761, -1.9762, -1.8902, -1.9628, -1.9554, -1.9168,\n",
      "        -1.9593, -1.8823, -1.9791, -1.9615, -1.9738, -1.9788, -2.0414, -1.9013,\n",
      "        -1.9705, -1.9666], device='mps:0')\n",
      "mean: tensor(-1.9638, device='mps:0')\n",
      "iter_dt 1.02s; iter 75: train loss 0.32190 temperature: 8.75\n",
      "mean_logits tensor([-1.7965, -2.1792, -2.0364, -1.9822, -1.9726, -2.1099, -1.6805, -1.8432,\n",
      "        -2.1770, -1.9918, -2.1535, -2.1953, -1.9200, -2.3334, -2.2899, -2.2292,\n",
      "        -1.9134, -2.1532, -2.1113, -1.9505, -1.8405, -1.9641, -1.8487, -2.0757,\n",
      "        -2.1304, -1.8598, -1.7481, -1.5516, -2.0750, -2.0440, -2.1519, -2.0058,\n",
      "        -1.6581, -2.2336, -2.1421, -2.0061, -1.8482, -1.8941, -2.1993, -2.3124,\n",
      "        -1.9908, -2.2669, -2.0720, -2.0721, -2.2270, -1.7855, -2.3267, -2.2576,\n",
      "        -2.1531, -1.9899], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9751, -1.9370, -1.9804, -1.9672, -1.9944, -1.9504, -1.9382, -1.9655,\n",
      "        -1.9615, -1.9190, -1.9629, -1.9418, -1.9640, -1.9387, -1.9973, -1.9635,\n",
      "        -1.9844, -1.9547, -1.8682, -1.9618, -1.9294, -1.9730, -1.9615, -1.9701,\n",
      "        -1.9408, -2.0111, -1.9685, -1.9796, -1.9418, -1.9648, -1.9674, -2.0006,\n",
      "        -1.9699, -1.9717, -1.9764, -1.9894, -2.0492, -1.9728, -2.0180, -1.9306,\n",
      "        -1.9794, -2.0052, -2.0120, -1.9604, -1.9385, -1.9085, -1.9463, -1.9765,\n",
      "        -1.9718, -2.0278], device='mps:0')\n",
      "mean: tensor(-1.9668, device='mps:0')\n",
      "iter_dt 1.02s; iter 76: train loss 0.33366 temperature: 8.8\n",
      "mean_logits tensor([-1.9503, -1.8466, -1.9156, -1.9029, -2.1499, -1.8862, -2.0144, -1.9871,\n",
      "        -1.9179, -1.9106, -1.9641, -2.2271, -1.9460, -1.6951, -2.0118, -1.9572,\n",
      "        -1.8061, -2.4719, -2.0468, -1.8065, -2.2280, -1.8400, -2.1438, -2.1647,\n",
      "        -1.6549, -2.3293, -2.0208, -1.9491, -1.9695, -2.1549, -2.0956, -1.7515,\n",
      "        -2.1040, -1.3740, -1.8251, -2.2708, -2.0831, -2.1530, -2.2091, -2.1063,\n",
      "        -1.9677, -1.5772, -1.7997, -2.1427, -1.9423, -2.4659, -2.0089, -1.9511,\n",
      "        -1.9817, -2.2047], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9550, -1.9690, -1.9733, -1.9692, -2.0437, -1.9185, -1.9662, -1.9589,\n",
      "        -1.9854, -1.9502, -2.0237, -1.9663, -1.9767, -1.9708, -1.9903, -1.9684,\n",
      "        -2.0209, -1.9720, -1.9654, -1.9464, -1.9830, -2.0135, -1.9668, -1.9705,\n",
      "        -1.9702, -1.9743, -2.0027, -1.9352, -1.9112, -1.9573, -1.9909, -1.9888,\n",
      "        -1.9791, -1.9714, -1.9081, -1.9813, -1.9602, -1.9685, -1.9847, -1.9715,\n",
      "        -2.0120, -1.9686, -1.9492, -1.9705, -1.9560, -1.9591, -1.9086, -1.9944,\n",
      "        -1.9727, -1.9630], device='mps:0')\n",
      "mean: tensor(-1.9707, device='mps:0')\n",
      "iter_dt 1.01s; iter 77: train loss 0.17604 temperature: 8.850000000000001\n",
      "mean_logits tensor([-1.9883, -1.7886, -2.0738, -2.0983, -2.1408, -2.1476, -1.9982, -1.9839,\n",
      "        -2.1673, -2.0818, -1.9900, -2.2048, -2.1875, -1.9592, -1.8348, -1.8865,\n",
      "        -1.8845, -1.9176, -1.9797, -2.0706, -2.1840, -2.0663, -1.8162, -1.9850,\n",
      "        -1.8970, -1.9099, -1.7094, -2.0143, -1.8095, -2.0645, -2.0827, -1.9590,\n",
      "        -1.9247, -2.1008, -1.8830, -2.3371, -1.9300, -2.0724, -2.1853, -2.1761,\n",
      "        -2.1453, -1.8850, -2.1341, -2.1647, -2.0261, -1.8099, -1.6764, -2.2160,\n",
      "        -1.7440, -1.7383], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9112, -1.9695, -1.9965, -1.9638, -1.9760, -1.9649, -1.9705, -1.9619,\n",
      "        -1.9972, -1.8959, -1.9710, -1.9949, -2.0144, -1.8828, -1.9387, -1.9582,\n",
      "        -1.9819, -1.9575, -2.0303, -1.9482, -1.9729, -1.9504, -1.9821, -1.9271,\n",
      "        -1.9843, -1.9723, -1.9476, -1.9903, -1.9940, -1.9429, -1.9428, -1.9742,\n",
      "        -1.9474, -1.9970, -1.9597, -1.9739, -1.9581, -1.9608, -1.9634, -1.9791,\n",
      "        -1.9603, -1.9809, -1.9680, -2.0223, -2.0200, -1.9802, -1.9486, -1.9558,\n",
      "        -1.9820, -1.9641], device='mps:0')\n",
      "mean: tensor(-1.9678, device='mps:0')\n",
      "iter_dt 1.01s; iter 78: train loss 0.31210 temperature: 8.900000000000002\n",
      "mean_logits tensor([-1.4970, -1.8828, -1.8316, -2.1984, -2.0954, -2.1106, -1.8868, -2.3768,\n",
      "        -1.6361, -1.8967, -1.8023, -1.9496, -2.1241, -1.8607, -2.1175, -1.9895,\n",
      "        -2.3730, -2.2029, -2.0079, -1.8070, -1.9218, -2.0976, -2.0733, -2.3127,\n",
      "        -1.9915, -2.1584, -1.8666, -1.9933, -1.9723, -2.1246, -2.0407, -2.1166,\n",
      "        -1.9675, -1.8676, -1.8682, -1.9929, -1.7533, -1.7722, -2.0448, -2.1829,\n",
      "        -2.0166, -2.1411, -1.9030, -1.7145, -2.0873, -2.1381, -2.3171, -2.0159,\n",
      "        -2.3157, -2.2280], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9475, -1.9631, -1.9705, -1.9634, -1.9796, -1.9679, -1.9673, -1.8297,\n",
      "        -1.9852, -1.9691, -1.9763, -1.9658, -1.9862, -1.9315, -1.9711, -1.9500,\n",
      "        -1.9678, -1.9596, -1.9744, -1.9972, -1.9227, -1.9797, -1.9811, -1.9710,\n",
      "        -1.9733, -1.9540, -1.9575, -2.0132, -1.9777, -1.9780, -2.0006, -1.9465,\n",
      "        -1.9553, -1.9327, -1.9867, -1.9211, -1.9584, -2.0372, -2.0148, -1.9464,\n",
      "        -1.9441, -1.9655, -1.9695, -1.9507, -2.0038, -1.9996, -1.9717, -1.9870,\n",
      "        -1.9700, -1.9613], device='mps:0')\n",
      "mean: tensor(-1.9671, device='mps:0')\n",
      "iter_dt 1.01s; iter 79: train loss 0.35817 temperature: 8.950000000000003\n",
      "mean_logits tensor([-2.2115, -2.1017, -1.6421, -1.9598, -2.4070, -2.1620, -1.9862, -2.0841,\n",
      "        -1.9452, -2.0528, -1.6502, -1.8289, -2.1078, -1.9592, -2.3832, -1.6776,\n",
      "        -2.0675, -2.1584, -2.1982, -1.9181, -2.1133, -1.7680, -1.3357, -2.0284,\n",
      "        -2.1534, -2.0356, -2.2332, -2.0957, -2.2931, -1.9043, -1.7852, -1.8800,\n",
      "        -2.2018, -2.0292, -1.8152, -2.0792, -2.0065, -2.1494, -2.2980, -1.9523,\n",
      "        -2.0832, -2.0337, -1.7568, -2.2035, -2.0706, -2.0104, -2.2458, -2.3839,\n",
      "        -1.9191, -1.9948], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9714, -1.9714, -1.9884, -1.9717, -1.9496, -1.9421, -1.9768, -1.9908,\n",
      "        -1.9284, -1.9245, -1.9693, -1.9175, -1.9802, -1.9870, -1.9576, -1.9522,\n",
      "        -1.9348, -1.9548, -1.9555, -1.9573, -1.9657, -1.9544, -1.9703, -2.0053,\n",
      "        -2.0514, -1.9722, -1.9852, -1.9867, -1.9712, -1.9572, -1.9729, -2.0194,\n",
      "        -1.9623, -1.9909, -2.0143, -1.9622, -1.9301, -1.9531, -1.9726, -1.9172,\n",
      "        -1.9720, -1.9593, -1.9714, -1.9778, -1.9743, -1.9600, -1.9749, -1.9691,\n",
      "        -1.9849, -1.9869], device='mps:0')\n",
      "mean: tensor(-1.9685, device='mps:0')\n",
      "iter_dt 1.00s; iter 80: train loss 0.59051 temperature: 9.000000000000004\n",
      "mean_logits tensor([-2.6296, -2.1103, -2.2634, -1.8980, -1.7994, -2.0662, -2.4148, -1.7051,\n",
      "        -1.9953, -1.9870, -2.3648, -2.1207, -1.9227, -2.0030, -2.0843, -1.6837,\n",
      "        -1.7183, -1.9805, -2.3596, -1.9787, -2.0660, -2.0173, -2.3075, -1.9945,\n",
      "        -2.3459, -2.0193, -2.4324, -2.0259, -2.0550, -1.5907, -1.8047, -2.2131,\n",
      "        -1.9190, -2.3769, -2.2387, -2.3363, -1.7375, -1.9301, -1.8577, -2.3015,\n",
      "        -1.8587, -2.0044, -1.8360, -2.3272, -2.3006, -2.0711, -1.9331, -1.5904,\n",
      "        -1.8071, -2.0096], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9609, -1.9686, -1.9493, -1.9837, -2.0004, -1.9752, -1.9813, -1.9751,\n",
      "        -2.0160, -1.8812, -1.9679, -1.9331, -1.9841, -1.9790, -1.9279, -1.9930,\n",
      "        -1.9763, -1.9702, -1.9759, -1.9789, -2.0098, -1.9594, -1.9828, -1.9691,\n",
      "        -2.0262, -1.9568, -1.9516, -1.9778, -1.9900, -1.9697, -1.9855, -2.0309,\n",
      "        -2.0128, -1.9628, -2.0144, -1.9888, -1.9126, -2.0270, -1.9745, -1.9425,\n",
      "        -1.9973, -1.9808, -1.9856, -1.9750, -1.9545, -1.9552, -1.9320, -1.9708,\n",
      "        -1.9555, -1.9767], device='mps:0')\n",
      "mean: tensor(-1.9741, device='mps:0')\n",
      "iter_dt 1.01s; iter 81: train loss 0.26803 temperature: 9.050000000000004\n",
      "mean_logits tensor([-2.0281, -2.1327, -1.9464, -2.0244, -1.9363, -1.9709, -2.1656, -2.2515,\n",
      "        -2.0640, -2.0398, -1.7033, -2.0424, -1.8054, -2.2067, -2.3164, -1.9364,\n",
      "        -2.0949, -2.0626, -1.8957, -1.8381, -1.7452, -2.3763, -1.8763, -2.1600,\n",
      "        -2.3054, -2.1568, -1.7700, -1.8921, -1.9664, -1.8088, -1.7966, -1.8757,\n",
      "        -1.9621, -1.8503, -2.1406, -1.8762, -1.8426, -1.8727, -2.0333, -2.1537,\n",
      "        -2.0172, -2.0379, -2.4279, -2.2628, -2.1299, -1.7555, -1.8938, -2.1639,\n",
      "        -2.0227, -2.0495], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9664, -1.9579, -1.9590, -2.0121, -1.9529, -1.9796, -1.9596, -1.9997,\n",
      "        -1.9380, -1.9774, -1.9704, -1.9528, -1.9371, -2.0045, -1.9620, -1.9600,\n",
      "        -1.9588, -1.9464, -2.0489, -2.0054, -1.9228, -1.9565, -1.9929, -1.9663,\n",
      "        -1.9714, -1.9664, -1.9926, -1.9691, -1.9782, -1.9428, -1.9914, -1.9144,\n",
      "        -2.0124, -1.9726, -1.9562, -1.9160, -1.9700, -1.9704, -1.9700, -1.9868,\n",
      "        -1.9674, -1.9307, -1.9794, -1.9924, -1.9399, -1.9628, -1.9687, -1.9862,\n",
      "        -2.0081, -1.9706], device='mps:0')\n",
      "mean: tensor(-1.9695, device='mps:0')\n",
      "iter_dt 1.01s; iter 82: train loss 0.32064 temperature: 9.100000000000005\n",
      "mean_logits tensor([-1.8095, -1.9798, -2.0544, -2.0920, -2.2728, -1.9349, -2.1517, -2.0465,\n",
      "        -1.8772, -2.3580, -2.2496, -2.0407, -2.1392, -2.0303, -1.8937, -1.8416,\n",
      "        -2.0077, -1.9192, -2.4119, -1.8633, -2.1168, -1.7522, -1.8115, -1.5470,\n",
      "        -2.1355, -2.1105, -1.9663, -1.8540, -1.9364, -1.9002, -1.9360, -2.1096,\n",
      "        -2.0683, -2.0374, -1.8689, -1.9871, -2.1159, -2.1654, -2.0378, -1.9476,\n",
      "        -2.4088, -2.0464, -2.0798, -2.2332, -1.9625, -2.0421, -2.4862, -1.9834,\n",
      "        -1.9935, -1.6900], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9678, -2.0491, -1.9887, -1.9436, -1.9644, -1.9073, -1.9508, -2.0179,\n",
      "        -1.9733, -1.9726, -1.9992, -1.9492, -1.9165, -1.9600, -1.9292, -1.9372,\n",
      "        -1.9796, -1.9275, -1.9551, -1.9869, -1.9338, -1.9918, -1.9424, -1.9479,\n",
      "        -1.9759, -2.0160, -1.9790, -1.9685, -1.9496, -1.9543, -1.8913, -1.9511,\n",
      "        -1.9708, -1.9718, -2.0378, -1.9579, -1.9963, -1.9923, -1.9822, -1.9707,\n",
      "        -1.9735, -1.9359, -2.0111, -1.9595, -1.9536, -1.9673, -1.9597, -1.9912,\n",
      "        -1.9709, -1.9515], device='mps:0')\n",
      "mean: tensor(-1.9666, device='mps:0')\n",
      "iter_dt 1.00s; iter 83: train loss 0.25515 temperature: 9.150000000000006\n",
      "mean_logits tensor([-2.2861, -2.1506, -2.0227, -2.1315, -2.1893, -1.8624, -1.9073, -2.1473,\n",
      "        -1.8990, -1.9570, -1.6484, -1.8444, -1.6453, -2.2091, -1.9449, -2.0516,\n",
      "        -1.9919, -2.2277, -1.9312, -2.0807, -2.0612, -2.0403, -1.8076, -1.9261,\n",
      "        -1.6824, -2.1189, -2.2346, -1.9905, -2.1549, -1.9452, -1.9756, -1.9609,\n",
      "        -2.0638, -1.8171, -1.9442, -1.8913, -1.9501, -1.7519, -2.2601, -2.3592,\n",
      "        -1.7966, -2.2603, -1.6721, -1.7951, -1.7307, -2.2700, -2.0846, -2.0702,\n",
      "        -1.9456, -1.8754], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9653, -1.9909, -2.0148, -1.9600, -1.9455, -2.0103, -1.9773, -1.9615,\n",
      "        -1.9535, -1.9752, -2.0127, -1.9568, -1.9909, -1.9676, -2.0143, -1.9331,\n",
      "        -1.9433, -1.9935, -1.9691, -1.9704, -1.9880, -2.0055, -1.9776, -1.9522,\n",
      "        -1.9551, -1.9593, -1.9484, -2.0043, -1.9565, -2.0175, -1.9002, -1.9078,\n",
      "        -1.9506, -1.9970, -1.9028, -1.9426, -1.9439, -1.9789, -1.9627, -1.9716,\n",
      "        -1.9650, -1.9968, -1.9155, -1.9776, -1.9478, -1.9702, -1.9718, -1.9850,\n",
      "        -1.9700, -1.9915], device='mps:0')\n",
      "mean: tensor(-1.9684, device='mps:0')\n",
      "iter_dt 1.00s; iter 84: train loss 0.30436 temperature: 9.200000000000006\n",
      "mean_logits tensor([-2.0636, -2.1293, -2.2991, -1.9953, -1.9351, -2.0333, -2.1963, -2.3039,\n",
      "        -1.9009, -2.0562, -1.7536, -2.1899, -1.8424, -2.0883, -1.6524, -2.1100,\n",
      "        -1.8499, -1.8357, -2.2818, -2.0344, -2.1410, -1.4250, -2.0668, -1.7568,\n",
      "        -1.8794, -2.2126, -1.4856, -1.9328, -2.0302, -1.9741, -2.1125, -2.1339,\n",
      "        -1.7824, -1.7558, -2.3935, -2.0658, -1.8629, -1.7572, -2.2950, -1.8432,\n",
      "        -2.1416, -1.9590, -2.2916, -1.9454, -2.1970, -1.9321, -2.0417, -1.8421,\n",
      "        -1.7750, -2.1852], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9705, -1.9950, -1.9797, -1.9708, -1.9946, -2.0237, -1.9533, -1.9699,\n",
      "        -1.9619, -1.9727, -1.9629, -1.9263, -1.9740, -1.9691, -1.9829, -1.9712,\n",
      "        -1.9588, -1.9881, -1.9664, -1.9828, -1.9912, -1.9227, -2.0234, -1.9434,\n",
      "        -1.9548, -1.9726, -1.9665, -1.9850, -1.9381, -1.9365, -1.9950, -1.9962,\n",
      "        -1.9713, -1.9703, -1.9739, -1.9700, -1.9686, -1.9430, -2.0216, -1.9720,\n",
      "        -1.9501, -1.9255, -2.0031, -1.9702, -1.9220, -1.9137, -1.9706, -1.9614,\n",
      "        -1.9611, -1.9749], device='mps:0')\n",
      "mean: tensor(-1.9689, device='mps:0')\n",
      "iter_dt 1.02s; iter 85: train loss 0.20179 temperature: 9.250000000000007\n",
      "mean_logits tensor([-2.0356, -1.9674, -1.7427, -1.9038, -2.1060, -1.8988, -1.9647, -2.2379,\n",
      "        -2.0766, -1.9363, -1.9389, -1.8268, -2.1278, -1.8949, -1.7021, -2.0575,\n",
      "        -1.9438, -1.8885, -1.8978, -2.2209, -2.0656, -2.3230, -2.0006, -1.9124,\n",
      "        -1.8420, -2.3439, -2.0291, -2.0530, -2.0754, -2.1999, -1.7871, -2.1966,\n",
      "        -1.7194, -2.1225, -1.8319, -2.1106, -2.0540, -2.0531, -1.8916, -1.8768,\n",
      "        -1.9570, -1.9692, -2.0185, -1.8008, -1.9406, -2.2158, -2.0441, -2.1985,\n",
      "        -1.9510, -2.2409], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0048, -1.9921, -1.9555, -1.9752, -1.9797, -1.9523, -1.9294, -1.9698,\n",
      "        -1.9374, -1.9609, -1.9258, -2.0062, -1.9540, -1.9638, -1.9478, -2.0150,\n",
      "        -1.9727, -1.9947, -1.9717, -1.9746, -1.9855, -1.9731, -1.8866, -1.9733,\n",
      "        -1.9710, -1.9360, -1.9960, -1.9224, -1.9704, -1.9728, -1.9456, -1.9324,\n",
      "        -1.9678, -1.9770, -1.9744, -1.9916, -1.9690, -1.9641, -1.9693, -1.9673,\n",
      "        -1.9707, -1.9954, -1.9757, -1.9915, -1.9852, -2.0225, -1.9697, -1.9462,\n",
      "        -1.9863, -1.9716], device='mps:0')\n",
      "mean: tensor(-1.9689, device='mps:0')\n",
      "iter_dt 1.03s; iter 86: train loss 0.37240 temperature: 9.300000000000008\n",
      "mean_logits tensor([-2.0058, -2.0643, -1.7784, -2.0129, -1.9443, -2.2607, -1.6473, -2.1698,\n",
      "        -2.4027, -2.0360, -1.7929, -2.1583, -2.1568, -2.2436, -2.0134, -1.9827,\n",
      "        -2.1657, -2.2034, -1.7408, -1.9397, -2.3877, -1.8711, -1.7667, -2.1531,\n",
      "        -1.6853, -2.0029, -2.0252, -1.9251, -1.5906, -2.2550, -2.1651, -1.7858,\n",
      "        -2.3419, -2.0495, -1.9220, -2.0486, -2.2170, -1.8605, -1.9546, -2.0018,\n",
      "        -2.1224, -2.0326, -2.3283, -2.0300, -2.0863, -1.7085, -1.9878, -2.1747,\n",
      "        -2.4805, -1.9942], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9894, -1.9841, -1.9812, -1.9612, -1.9649, -2.0156, -1.9572, -1.9963,\n",
      "        -1.9942, -2.0072, -1.9419, -1.9655, -1.9660, -1.9705, -1.9658, -1.9709,\n",
      "        -1.9504, -1.9445, -1.9718, -1.9551, -1.9735, -1.9077, -1.9767, -2.0002,\n",
      "        -1.9378, -2.0491, -1.9691, -1.9715, -1.9809, -1.9748, -1.9704, -2.0153,\n",
      "        -1.9745, -1.9545, -1.9796, -1.9416, -1.9737, -1.9739, -1.9753, -1.8770,\n",
      "        -1.9915, -1.9067, -1.9832, -2.0091, -1.9951, -1.9753, -2.0006, -1.9673,\n",
      "        -1.9766, -1.9982], device='mps:0')\n",
      "mean: tensor(-1.9727, device='mps:0')\n",
      "iter_dt 1.04s; iter 87: train loss 0.33100 temperature: 9.350000000000009\n",
      "mean_logits tensor([-2.3428, -1.6530, -2.0461, -2.1393, -1.7820, -1.7564, -1.9115, -1.9585,\n",
      "        -2.0646, -2.1672, -1.7630, -1.9327, -1.7550, -2.1525, -1.8699, -1.9435,\n",
      "        -1.9681, -1.9815, -1.7622, -1.6255, -2.1867, -2.5620, -1.9775, -2.2802,\n",
      "        -1.9392, -1.7781, -2.0383, -2.0219, -1.8507, -2.1866, -1.6125, -2.0185,\n",
      "        -1.9381, -1.9442, -1.8813, -1.8699, -1.9157, -2.2161, -2.0739, -1.9914,\n",
      "        -2.2392, -2.3584, -1.9650, -2.0840, -1.9946, -1.8955, -2.1492, -1.8655,\n",
      "        -2.0506, -2.2229], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9791, -2.0762, -1.9731, -1.9583, -1.9741, -1.9655, -1.9814, -1.9873,\n",
      "        -1.9813, -1.9736, -2.0241, -1.9766, -1.9522, -1.9595, -1.9712, -1.9791,\n",
      "        -1.9559, -1.9706, -1.9805, -1.9410, -1.9537, -2.0056, -1.9865, -1.9539,\n",
      "        -2.0130, -1.9511, -1.9521, -2.0277, -1.9825, -1.9594, -1.9841, -1.9705,\n",
      "        -1.9050, -1.9696, -1.9901, -1.9868, -1.9599, -1.9775, -1.9634, -2.0079,\n",
      "        -2.0121, -1.9724, -1.9628, -1.9578, -1.9553, -1.9591, -1.9469, -1.9556,\n",
      "        -1.9301, -1.9674], device='mps:0')\n",
      "mean: tensor(-1.9736, device='mps:0')\n",
      "iter_dt 1.02s; iter 88: train loss 0.41521 temperature: 9.40000000000001\n",
      "mean_logits tensor([-2.3963, -1.8192, -2.0721, -2.2439, -2.2983, -2.2223, -2.0006, -2.1626,\n",
      "        -1.9339, -1.8427, -2.1626, -2.2192, -2.3266, -2.1449, -2.0719, -2.0835,\n",
      "        -1.9492, -2.0394, -1.9852, -2.3566, -1.6438, -2.0582, -2.1154, -1.9359,\n",
      "        -1.9484, -1.7690, -2.1389, -2.1397, -1.9680, -2.0481, -2.3475, -2.1864,\n",
      "        -2.0880, -2.1145, -2.3640, -2.0555, -2.1246, -2.1454, -1.8365, -1.9674,\n",
      "        -2.4187, -1.8858, -2.1011, -1.7596, -2.2023, -2.2714, -2.1146, -2.0607,\n",
      "        -1.7526, -2.0687], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.8838, -1.9729, -1.9680, -1.9741, -1.9203, -1.9719, -1.9755, -1.9713,\n",
      "        -1.9648, -1.9174, -1.9678, -1.8897, -2.0035, -1.9689, -1.9601, -1.9781,\n",
      "        -1.9440, -1.9717, -1.9415, -1.9706, -1.9055, -1.9549, -1.9707, -1.9975,\n",
      "        -1.9669, -1.9613, -1.9688, -1.9618, -1.9618, -1.8856, -1.9632, -1.9628,\n",
      "        -1.9803, -1.9707, -1.9651, -1.9481, -1.9025, -1.9735, -1.9737, -1.9664,\n",
      "        -1.9639, -1.9790, -2.0370, -1.9742, -1.9893, -1.9744, -1.9792, -1.9599,\n",
      "        -1.9123, -1.8845], device='mps:0')\n",
      "mean: tensor(-1.9582, device='mps:0')\n",
      "iter_dt 1.00s; iter 89: train loss 0.35478 temperature: 9.45000000000001\n",
      "mean_logits tensor([-2.1438, -1.8016, -1.7162, -2.5088, -1.9422, -2.0384, -2.1891, -2.1445,\n",
      "        -1.8222, -1.9996, -2.0711, -2.2555, -2.2711, -2.1694, -1.7591, -1.9944,\n",
      "        -2.1987, -1.8543, -2.0767, -1.8929, -1.9692, -2.1561, -2.1528, -1.9878,\n",
      "        -1.9960, -2.2544, -1.9753, -1.7157, -2.2547, -2.0306, -1.9769, -1.9373,\n",
      "        -2.4820, -2.0009, -2.0059, -1.8293, -1.9924, -1.9391, -2.0368, -1.8835,\n",
      "        -2.0770, -2.4020, -1.8749, -2.1856, -1.8742, -2.2442, -2.2653, -1.9784,\n",
      "        -2.0218, -1.9829], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9989, -1.9162, -1.9852, -1.9631, -1.9931, -1.9655, -1.9664, -1.9658,\n",
      "        -1.9554, -1.9778, -1.9739, -1.9429, -1.9784, -2.0182, -1.9714, -1.9170,\n",
      "        -2.0014, -1.9171, -2.0058, -1.9597, -1.9335, -1.9698, -1.9572, -1.9459,\n",
      "        -1.9412, -1.9815, -1.9369, -1.9794, -1.9921, -1.9962, -1.9462, -1.9887,\n",
      "        -1.9697, -1.9653, -1.9179, -1.9400, -2.0163, -1.9661, -1.9900, -1.9324,\n",
      "        -1.9617, -1.9696, -1.9783, -1.9739, -2.0246, -1.9420, -2.0248, -1.9692,\n",
      "        -1.9600, -1.9746], device='mps:0')\n",
      "mean: tensor(-1.9684, device='mps:0')\n",
      "iter_dt 1.02s; iter 90: train loss 0.32814 temperature: 9.50000000000001\n",
      "mean_logits tensor([-1.9912, -1.9559, -1.9868, -2.2898, -2.0760, -2.2012, -2.2649, -2.2304,\n",
      "        -1.9216, -1.9347, -2.0631, -2.0663, -2.1408, -2.2018, -1.7856, -1.9526,\n",
      "        -2.2639, -1.9343, -1.9711, -1.9007, -2.1320, -1.9216, -2.2458, -1.9160,\n",
      "        -2.0772, -1.9780, -2.2580, -2.4272, -2.0424, -1.9494, -1.6416, -2.0021,\n",
      "        -2.2504, -2.3272, -2.1825, -2.1155, -1.8471, -1.8840, -2.3274, -2.2402,\n",
      "        -2.1542, -2.0246, -1.9087, -1.9185, -2.2725, -2.0176, -2.0843, -1.7620,\n",
      "        -1.9778, -1.7629], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9697, -1.9856, -1.9652, -1.9752, -1.9062, -1.9994, -1.9979, -1.8966,\n",
      "        -1.9478, -1.9913, -1.9321, -1.9686, -1.9411, -1.9473, -1.9760, -1.9709,\n",
      "        -1.9595, -1.9681, -1.9439, -1.9602, -1.9364, -2.0106, -1.9489, -1.9155,\n",
      "        -1.9753, -1.9698, -1.9841, -1.9684, -1.9811, -1.9641, -1.9396, -2.0076,\n",
      "        -1.9612, -1.9951, -1.9895, -1.9775, -1.9740, -1.9984, -1.9739, -1.9839,\n",
      "        -1.9876, -1.9806, -1.9768, -1.9705, -1.9457, -1.9970, -2.0062, -1.9652,\n",
      "        -1.9625, -1.9598], device='mps:0')\n",
      "mean: tensor(-1.9682, device='mps:0')\n",
      "iter_dt 1.03s; iter 91: train loss 0.19556 temperature: 9.550000000000011\n",
      "mean_logits tensor([-1.7918, -2.1150, -1.9449, -2.2907, -2.2412, -2.0270, -1.7320, -2.0753,\n",
      "        -1.9285, -2.1629, -1.9632, -1.8312, -2.1044, -1.9469, -1.8898, -1.6229,\n",
      "        -2.1473, -2.4452, -1.8005, -1.9872, -2.1416, -2.0304, -1.8551, -1.7201,\n",
      "        -1.9380, -1.8565, -2.0320, -1.9418, -1.7979, -1.9785, -2.0209, -2.1572,\n",
      "        -2.0478, -1.9766, -2.2061, -1.9068, -2.1307, -1.9118, -2.1058, -2.1439,\n",
      "        -1.9733, -1.9531, -2.2218, -1.9467, -1.9480, -2.0353, -1.8505, -2.0150,\n",
      "        -2.0907, -2.0336], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9471, -1.9328, -1.9921, -1.9718, -1.9571, -1.9619, -1.9757, -1.9885,\n",
      "        -1.9640, -1.9548, -1.9704, -1.9395, -1.9672, -2.0261, -1.9734, -1.9422,\n",
      "        -2.0102, -1.9808, -1.9726, -1.9175, -1.9704, -2.0008, -1.9852, -1.9859,\n",
      "        -1.9734, -1.9716, -1.9667, -1.9816, -1.9220, -1.9823, -2.0719, -2.0045,\n",
      "        -2.0120, -1.9275, -1.9702, -1.9588, -1.9978, -1.9595, -1.9735, -1.9325,\n",
      "        -1.9847, -1.9384, -1.9891, -1.9384, -1.8596, -1.9259, -1.8770, -1.9963,\n",
      "        -1.9539, -1.9675], device='mps:0')\n",
      "mean: tensor(-1.9665, device='mps:0')\n",
      "iter_dt 1.01s; iter 92: train loss 0.25193 temperature: 9.600000000000012\n",
      "mean_logits tensor([-1.7824, -1.9949, -2.2129, -2.0798, -2.1835, -1.6614, -2.2599, -2.1578,\n",
      "        -1.8598, -1.8677, -2.1351, -2.1835, -2.0301, -1.9159, -2.2522, -1.8350,\n",
      "        -2.0361, -2.0702, -1.9429, -1.9753, -2.1607, -2.0155, -1.9120, -2.0415,\n",
      "        -2.3148, -1.8618, -2.0717, -2.1331, -1.6939, -2.2268, -1.8747, -2.3080,\n",
      "        -1.8743, -1.9841, -1.6400, -2.1421, -1.8574, -1.8790, -2.1594, -2.2352,\n",
      "        -2.0552, -1.8281, -1.8402, -2.1180, -2.1282, -2.1520, -2.1064, -1.7819,\n",
      "        -2.0495, -1.9775], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9675, -1.9683, -1.9137, -1.9599, -1.9775, -1.9794, -1.9982, -1.9450,\n",
      "        -1.9693, -2.0280, -1.9686, -1.9615, -2.0348, -1.9860, -1.9689, -1.9289,\n",
      "        -1.9887, -1.9714, -1.9957, -1.9766, -1.9356, -1.9746, -1.9817, -1.9269,\n",
      "        -1.9384, -1.9938, -2.0067, -1.9794, -1.9561, -1.9464, -2.0453, -2.0008,\n",
      "        -1.9695, -1.9376, -1.9856, -1.9668, -1.9880, -1.9645, -1.9576, -2.0128,\n",
      "        -1.9597, -1.9667, -1.9376, -2.0249, -1.9539, -1.9235, -1.9664, -1.9705,\n",
      "        -1.9675, -1.9796], device='mps:0')\n",
      "mean: tensor(-1.9721, device='mps:0')\n",
      "iter_dt 1.03s; iter 93: train loss 0.24061 temperature: 9.650000000000013\n",
      "mean_logits tensor([-2.0305, -1.9982, -1.7618, -2.0872, -2.2664, -2.1247, -1.7315, -2.0473,\n",
      "        -1.9998, -2.1818, -1.9975, -2.1105, -1.7610, -2.0992, -1.7051, -2.0415,\n",
      "        -1.9101, -1.9427, -1.8533, -1.7937, -2.0895, -1.9378, -2.0211, -1.7494,\n",
      "        -2.1193, -1.9827, -1.9666, -2.1384, -1.7050, -1.9842, -2.1436, -2.1282,\n",
      "        -1.9691, -2.3172, -1.7424, -2.3793, -2.2108, -1.7777, -2.1171, -2.1348,\n",
      "        -2.0350, -1.9268, -1.9811, -2.1961, -1.8256, -2.2261, -1.6022, -1.9252,\n",
      "        -2.1790, -1.7390], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9224, -1.9927, -1.9551, -1.9073, -1.9539, -1.9644, -1.9484, -1.9409,\n",
      "        -1.9967, -1.9736, -1.9531, -1.9607, -1.9511, -1.9642, -1.9610, -2.0054,\n",
      "        -1.9615, -1.9752, -1.9013, -2.0052, -1.9681, -1.9723, -1.9723, -1.9410,\n",
      "        -1.9840, -1.9117, -1.9365, -1.9430, -1.8948, -2.0157, -1.9822, -1.9845,\n",
      "        -1.8763, -1.9407, -1.9022, -2.0137, -1.9670, -1.8715, -1.9721, -1.9524,\n",
      "        -1.9890, -1.9490, -2.0139, -1.9463, -1.9679, -1.9198, -2.0140, -1.9817,\n",
      "        -1.9895, -1.9752], device='mps:0')\n",
      "mean: tensor(-1.9588, device='mps:0')\n",
      "iter_dt 1.16s; iter 94: train loss 0.36534 temperature: 9.700000000000014\n",
      "mean_logits tensor([-2.2845, -2.3076, -1.9829, -2.0007, -1.9847, -2.1103, -2.0914, -1.9518,\n",
      "        -2.3533, -1.5716, -1.6261, -1.9286, -2.0623, -1.7895, -2.1643, -2.2393,\n",
      "        -2.1091, -1.9646, -2.1280, -2.2091, -2.0447, -2.0104, -2.0828, -2.2187,\n",
      "        -2.5459, -1.9076, -1.9348, -1.9821, -1.9209, -2.0036, -2.2924, -1.9765,\n",
      "        -2.2005, -1.9917, -1.8426, -2.2758, -2.1079, -1.4489, -1.8557, -2.0246,\n",
      "        -2.2301, -2.1778, -2.1317, -1.9736, -2.1373, -1.8707, -1.7387, -1.7451,\n",
      "        -1.8424, -2.1213], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9888, -2.0131, -1.9678, -1.8813, -2.0247, -1.9752, -1.9628, -2.0077,\n",
      "        -1.9872, -1.9758, -1.9709, -1.9124, -1.9331, -1.9614, -1.9912, -1.9704,\n",
      "        -1.9727, -1.9995, -2.0312, -1.9729, -1.9650, -1.9718, -1.9785, -1.9838,\n",
      "        -1.9578, -1.9657, -1.9468, -1.9704, -1.9935, -1.9703, -2.0128, -1.9585,\n",
      "        -1.9721, -1.9454, -2.0030, -1.9938, -1.8384, -1.9626, -1.9727, -1.9621,\n",
      "        -1.9596, -1.9751, -1.9856, -1.9696, -1.9696, -1.9637, -1.9845, -1.9760,\n",
      "        -1.9783, -1.9850], device='mps:0')\n",
      "mean: tensor(-1.9714, device='mps:0')\n",
      "iter_dt 1.06s; iter 95: train loss 0.32375 temperature: 9.750000000000014\n",
      "mean_logits tensor([-2.1709, -1.6378, -1.9855, -2.0198, -2.1166, -1.7063, -1.9019, -1.9615,\n",
      "        -1.7676, -2.0446, -1.9161, -1.6266, -2.0687, -1.9108, -1.9675, -2.0542,\n",
      "        -2.0954, -1.7491, -1.9254, -2.1133, -1.9396, -1.6929, -2.1323, -1.9542,\n",
      "        -1.8717, -2.0957, -2.1625, -1.9370, -2.2771, -2.3137, -1.9106, -2.2604,\n",
      "        -1.7011, -1.9518, -1.8419, -1.8039, -2.1285, -1.9623, -1.8872, -2.2690,\n",
      "        -1.9817, -2.3576, -1.9574, -2.0649, -2.5610, -1.7968, -2.0240, -1.7328,\n",
      "        -2.2734, -1.7286], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9896, -1.8910, -1.9522, -1.9686, -1.9541, -1.9453, -1.9872, -1.9589,\n",
      "        -1.9782, -1.9971, -1.9959, -1.9628, -1.9687, -1.9260, -1.9577, -1.9770,\n",
      "        -1.9895, -1.9647, -1.9765, -1.9642, -1.9294, -1.9425, -1.9451, -1.9568,\n",
      "        -1.9525, -1.9872, -1.9460, -1.9556, -1.9598, -1.9608, -1.9376, -1.9470,\n",
      "        -1.9443, -1.9475, -1.9968, -1.9527, -1.9940, -2.0120, -1.9609, -1.9683,\n",
      "        -1.9411, -1.9734, -1.9711, -2.0170, -1.9673, -2.0161, -2.0019, -1.9186,\n",
      "        -1.9880, -1.9411], device='mps:0')\n",
      "mean: tensor(-1.9648, device='mps:0')\n",
      "iter_dt 1.02s; iter 96: train loss 0.30056 temperature: 9.800000000000015\n",
      "mean_logits tensor([-2.4172, -1.9218, -2.2089, -2.1567, -1.7303, -1.6390, -1.9630, -2.1137,\n",
      "        -2.1679, -1.5738, -2.0594, -2.0971, -1.8608, -2.0248, -2.0339, -2.2774,\n",
      "        -1.7549, -1.8252, -2.1648, -1.8970, -2.2765, -1.7953, -2.0177, -1.7610,\n",
      "        -2.1076, -1.9241, -2.1206, -2.1644, -2.0875, -2.1659, -2.0121, -2.0039,\n",
      "        -2.3896, -1.9799, -2.2364, -2.0706, -1.9643, -1.6906, -2.1078, -2.1251,\n",
      "        -2.0928, -2.0119, -1.6432, -2.2346, -1.8054, -1.8257, -2.0053, -1.9285,\n",
      "        -2.0933, -1.8178], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9775, -1.9652, -1.9459, -1.9737, -1.9661, -1.9676, -1.9975, -1.9657,\n",
      "        -2.0061, -1.9759, -1.9018, -1.9690, -1.9725, -1.9060, -1.9644, -1.9745,\n",
      "        -1.9622, -2.0293, -1.9877, -1.9291, -1.9803, -1.9696, -1.9572, -2.0117,\n",
      "        -1.9554, -1.9774, -1.9621, -1.9999, -1.9765, -2.0107, -1.9981, -1.9617,\n",
      "        -1.9473, -2.0077, -1.9719, -2.0227, -1.9763, -1.9709, -1.9704, -1.9254,\n",
      "        -1.9698, -1.9905, -1.9876, -2.0047, -1.9702, -1.9752, -1.9656, -1.9623,\n",
      "        -1.9680, -1.9513], device='mps:0')\n",
      "mean: tensor(-1.9727, device='mps:0')\n",
      "iter_dt 1.10s; iter 97: train loss 0.23469 temperature: 9.850000000000016\n",
      "mean_logits tensor([-1.9850, -2.1983, -1.6534, -1.9499, -2.1007, -1.9899, -2.0503, -1.7634,\n",
      "        -1.9173, -1.8145, -2.0318, -2.0303, -2.1025, -2.0591, -2.0579, -2.5191,\n",
      "        -2.0890, -2.1169, -2.1477, -1.9017, -2.0717, -1.8823, -1.7747, -2.1304,\n",
      "        -1.9954, -2.0036, -1.6624, -2.2161, -2.1931, -2.0385, -1.8021, -2.0472,\n",
      "        -1.8955, -1.5900, -1.7414, -2.0621, -2.1014, -1.7267, -1.8229, -1.9847,\n",
      "        -2.0247, -1.9405, -1.8710, -2.1535, -1.8906, -1.9823, -2.1844, -2.1637,\n",
      "        -2.0087, -1.8625], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9883, -1.9669, -1.9108, -1.9057, -1.9804, -1.9608, -1.9129, -1.9869,\n",
      "        -1.9696, -1.9561, -1.9630, -1.9864, -1.9848, -1.9601, -1.9572, -1.9523,\n",
      "        -1.9601, -1.9708, -1.9320, -2.0021, -1.9891, -1.9691, -2.0017, -2.0079,\n",
      "        -1.9914, -2.0166, -1.9563, -1.9718, -2.0017, -1.9394, -1.9843, -1.9535,\n",
      "        -2.0153, -1.9183, -1.9747, -1.9639, -1.9592, -1.9206, -2.0605, -1.9674,\n",
      "        -1.9017, -1.9785, -1.9454, -1.9563, -2.0014, -1.9915, -1.9370, -1.9588,\n",
      "        -2.0151, -1.8881], device='mps:0')\n",
      "mean: tensor(-1.9669, device='mps:0')\n",
      "iter_dt 1.03s; iter 98: train loss 0.26870 temperature: 9.900000000000016\n",
      "mean_logits tensor([-1.7094, -1.8718, -1.7973, -2.1039, -1.9465, -1.9975, -1.8335, -2.1149,\n",
      "        -2.1221, -2.1313, -1.9152, -1.8238, -2.0906, -1.7972, -1.6939, -2.0230,\n",
      "        -1.8964, -1.9214, -1.8331, -2.1690, -2.1154, -1.7185, -2.3799, -1.8777,\n",
      "        -2.0052, -1.9586, -2.0600, -2.0158, -2.2858, -1.9544, -1.7258, -1.9527,\n",
      "        -2.0743, -1.5515, -2.1629, -2.0132, -1.9201, -2.2371, -2.0223, -1.9764,\n",
      "        -1.7968, -2.3206, -1.8289, -2.3261, -1.8928, -1.8193, -2.0652, -1.5674,\n",
      "        -2.2778, -1.8423], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9470, -2.0501, -1.9784, -1.9398, -1.9204, -1.9812, -1.9781, -1.9777,\n",
      "        -1.9498, -1.9836, -1.9738, -1.9792, -1.9490, -1.9852, -1.9756, -1.9401,\n",
      "        -1.9806, -2.0137, -1.9706, -1.9646, -1.9805, -1.9227, -1.9860, -1.9704,\n",
      "        -1.9711, -1.9964, -1.9723, -1.9808, -1.9481, -1.9712, -1.9610, -1.9601,\n",
      "        -1.9644, -1.9742, -1.9632, -1.9911, -1.9936, -2.0075, -1.9952, -1.9112,\n",
      "        -1.9896, -1.9744, -2.0021, -1.9982, -1.8721, -1.9739, -1.9425, -1.9860,\n",
      "        -1.9698, -1.9775], device='mps:0')\n",
      "mean: tensor(-1.9709, device='mps:0')\n",
      "iter_dt 1.06s; iter 99: train loss 0.29011 temperature: 9.950000000000017\n",
      "mean_logits tensor([-2.1016, -1.7869, -1.7278, -1.9974, -1.7377, -2.2304, -1.8163, -1.9110,\n",
      "        -1.7297, -1.9460, -2.0189, -2.2822, -2.1835, -2.2676, -1.4418, -1.8778,\n",
      "        -2.1125, -1.8959, -2.1594, -1.8792, -1.7561, -2.2657, -1.8662, -2.2752,\n",
      "        -2.0852, -2.0478, -2.2878, -2.0728, -1.8918, -1.9479, -1.8824, -1.8430,\n",
      "        -2.3458, -1.9300, -2.0161, -2.2373, -1.8299, -2.0203, -1.9589, -2.1433,\n",
      "        -2.1668, -2.0363, -2.0799, -2.1818, -2.0595, -2.0879, -1.5620, -2.0630,\n",
      "        -2.1320, -1.8887], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9206, -1.9635, -1.9725, -2.0257, -2.0254, -1.9869, -1.9650, -1.9726,\n",
      "        -1.9781, -1.9131, -1.9142, -2.0130, -1.9807, -1.9597, -1.9795, -1.9741,\n",
      "        -2.0028, -1.9800, -1.9709, -1.9534, -2.0030, -1.9418, -1.9364, -1.9685,\n",
      "        -1.9684, -1.9730, -2.0030, -1.9703, -1.9681, -1.9713, -1.9696, -1.9715,\n",
      "        -1.9468, -1.9504, -1.9719, -1.9698, -1.9659, -2.0044, -1.9733, -1.9730,\n",
      "        -1.9677, -1.9165, -1.9649, -1.9697, -1.9237, -1.9319, -1.9371, -1.9289,\n",
      "        -1.9511, -1.9435], device='mps:0')\n",
      "mean: tensor(-1.9657, device='mps:0')\n",
      "current_prefixes: [7278 4037 5557 4534 4632]\n",
      "layer: 2 starts running\n",
      "number of parameters: 91.99M\n",
      "running on device mps\n",
      "iter_dt 0.00s; iter 0: train loss 0.75126 temperature: 5\n",
      "mean_logits tensor([-1.7837, -2.1606, -2.0511, -1.5729, -2.5480, -1.9570, -2.3454, -1.9612,\n",
      "        -1.7590, -2.6062, -2.1450, -2.6215, -2.2877, -2.4416, -1.7560, -1.9862,\n",
      "        -2.0841, -1.7271, -1.7360, -1.9265, -2.1108, -1.6777, -1.8650, -2.6126,\n",
      "        -1.7453, -1.8389, -1.8337, -1.8554, -1.5821, -2.2792, -2.0793, -1.8901,\n",
      "        -2.2478, -2.3955, -1.8560, -1.9345, -1.8310, -1.7853, -1.9555, -2.2084,\n",
      "        -1.5223, -1.8753, -1.9013, -2.0526, -1.9368, -2.4883, -1.8524, -1.6872,\n",
      "        -2.0385, -1.8855], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0847, -2.1352, -2.0930, -2.0966, -2.0856, -2.0916, -2.0882, -2.0996,\n",
      "        -2.0435, -2.0755, -2.1087, -2.1061, -2.0605, -2.0886, -1.9738, -2.0677,\n",
      "        -2.0944, -2.0863, -2.0652, -2.0892, -2.0889, -2.0874, -2.0475, -2.0866,\n",
      "        -2.0920, -2.0719, -2.1255, -2.0656, -2.0447, -2.0767, -2.0753, -2.0759,\n",
      "        -2.0234, -2.0756, -2.0862, -2.0516, -2.1095, -2.0839, -2.0554, -2.0755,\n",
      "        -2.0818, -2.1008, -2.0543, -2.0913, -2.0757, -2.0938, -2.0705, -2.0307,\n",
      "        -2.0289, -2.0603], device='mps:0')\n",
      "mean: tensor(-2.0764, device='mps:0')\n",
      "iter_dt 1695863867.54s; iter 1: train loss 0.35578 temperature: 5.05\n",
      "mean_logits tensor([-2.2308, -1.9910, -1.8639, -2.0040, -1.9586, -2.2803, -1.9637, -1.5883,\n",
      "        -2.1017, -1.9020, -2.0360, -2.1894, -1.6464, -2.1179, -2.0577, -2.1948,\n",
      "        -1.9015, -2.0067, -2.1251, -1.7106, -1.9641, -2.3455, -1.7865, -1.8549,\n",
      "        -1.6146, -2.1098, -1.8239, -2.3281, -1.8268, -1.9299, -1.9578, -2.1751,\n",
      "        -2.3786, -2.1281, -2.0144, -2.1081, -2.1052, -1.8520, -1.8467, -2.1253,\n",
      "        -1.9779, -2.0620, -1.9589, -1.8281, -1.8194, -2.3206, -1.7821, -1.5853,\n",
      "        -2.2363, -1.6351], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0812, -2.1222, -2.1279, -2.0839, -2.0853, -2.0044, -2.0940, -2.0850,\n",
      "        -2.0892, -2.0900, -2.0851, -2.0908, -2.0432, -2.0813, -2.0506, -2.0880,\n",
      "        -2.0862, -2.1088, -2.0846, -2.0557, -2.0646, -2.0669, -2.0932, -2.1021,\n",
      "        -2.0999, -2.0859, -2.0522, -2.0595, -2.1065, -2.0889, -2.0417, -2.0142,\n",
      "        -2.0951, -2.0773, -2.0884, -2.0807, -2.0925, -2.0313, -2.0675, -2.0645,\n",
      "        -2.0894, -2.0884, -2.0135, -2.0737, -2.0900, -2.0774, -2.0655, -2.0531,\n",
      "        -2.0876, -2.1227], device='mps:0')\n",
      "mean: tensor(-2.0774, device='mps:0')\n",
      "iter_dt 1.47s; iter 2: train loss 0.46862 temperature: 5.1\n",
      "mean_logits tensor([-1.4532, -2.1585, -2.2080, -1.7980, -2.2531, -1.4050, -1.8794, -1.7839,\n",
      "        -2.0859, -2.3697, -1.8292, -1.8868, -1.3187, -1.7701, -1.8231, -1.7921,\n",
      "        -2.0014, -2.1154, -2.2560, -2.2275, -1.7610, -2.0996, -1.5556, -1.8797,\n",
      "        -2.1533, -2.0497, -1.7587, -1.9744, -1.6955, -2.0642, -2.0658, -2.4626,\n",
      "        -2.1227, -1.8683, -2.1361, -1.7946, -2.1137, -1.7141, -1.9087, -2.0148,\n",
      "        -2.0448, -2.3061, -1.9964, -2.0599, -2.2620, -1.7751, -2.1037, -2.1762,\n",
      "        -2.1882, -2.1006], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1068, -2.0960, -2.1047, -2.1027, -2.0984, -2.1537, -2.0617, -2.0895,\n",
      "        -2.1072, -2.0652, -2.0739, -2.0906, -2.0231, -2.0900, -2.0809, -2.0674,\n",
      "        -2.1583, -1.9989, -2.0147, -2.0880, -2.0988, -2.0908, -2.0660, -2.0665,\n",
      "        -2.0910, -2.0905, -2.0898, -2.0163, -2.0082, -2.0976, -2.0886, -2.0507,\n",
      "        -2.0721, -2.1212, -2.0414, -2.0890, -2.0628, -2.0944, -2.0926, -2.0536,\n",
      "        -2.0840, -2.0934, -2.1190, -2.0707, -2.0703, -2.0875, -2.0914, -2.0381,\n",
      "        -2.0109, -2.0853], device='mps:0')\n",
      "mean: tensor(-2.0781, device='mps:0')\n",
      "iter_dt 1.05s; iter 3: train loss 0.37871 temperature: 5.1499999999999995\n",
      "mean_logits tensor([-1.8723, -1.7155, -2.2866, -2.1581, -1.9955, -1.9977, -1.9393, -1.8219,\n",
      "        -2.0389, -2.2457, -1.8872, -2.3080, -1.7575, -1.3282, -2.0325, -1.7958,\n",
      "        -2.1942, -2.1832, -1.9633, -1.8828, -1.7421, -1.9826, -2.4609, -1.9581,\n",
      "        -2.5137, -1.8503, -1.7362, -2.0674, -2.0370, -2.1115, -2.2309, -1.9367,\n",
      "        -1.8421, -1.9654, -1.8518, -1.9088, -1.8712, -2.2105, -1.8733, -2.1547,\n",
      "        -1.9697, -1.7192, -2.1461, -2.1125, -1.9495, -2.0797, -1.8001, -2.0756,\n",
      "        -2.1889, -1.7854], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0898, -2.0744, -2.0921, -2.0516, -2.0999, -2.0923, -2.0595, -2.1032,\n",
      "        -2.1055, -2.0767, -2.0893, -2.0599, -2.0560, -2.0420, -2.1002, -2.1017,\n",
      "        -2.0933, -2.0789, -2.0820, -2.0871, -2.0938, -2.0903, -2.1159, -2.0643,\n",
      "        -2.0760, -2.0777, -2.0371, -2.0545, -2.0643, -1.9881, -2.0397, -2.0790,\n",
      "        -2.0622, -2.1213, -2.1125, -1.9770, -2.0945, -2.0473, -2.0962, -2.0645,\n",
      "        -2.0727, -2.0951, -2.0994, -2.0902, -2.0993, -2.1059, -2.0886, -2.1225,\n",
      "        -2.0457, -2.0862], device='mps:0')\n",
      "mean: tensor(-2.0779, device='mps:0')\n",
      "iter_dt 1.07s; iter 4: train loss 0.44279 temperature: 5.199999999999999\n",
      "mean_logits tensor([-2.0037, -1.6453, -2.1091, -1.7209, -1.9389, -2.3699, -1.7488, -2.2738,\n",
      "        -1.6749, -2.1712, -2.3193, -2.0963, -1.9652, -2.2792, -1.6656, -2.0223,\n",
      "        -2.1314, -1.8150, -2.2410, -2.1136, -1.9770, -1.7517, -2.1131, -1.8952,\n",
      "        -2.0092, -1.8334, -2.0437, -2.1925, -1.6797, -2.2456, -1.7853, -2.0820,\n",
      "        -1.9420, -2.2464, -2.1773, -1.5442, -1.7337, -1.5735, -1.7335, -1.9044,\n",
      "        -2.0945, -2.3550, -2.1268, -1.8713, -2.3418, -1.9563, -1.8821, -1.9176,\n",
      "        -1.8709, -1.7003], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0940, -2.0200, -2.0908, -2.0662, -2.0783, -2.0850, -2.0082, -2.0662,\n",
      "        -2.1093, -2.0779, -2.0469, -2.0618, -2.0943, -2.0381, -2.1206, -2.0576,\n",
      "        -2.0939, -2.1031, -2.0651, -2.0083, -2.1134, -2.0934, -2.0757, -2.0893,\n",
      "        -2.0617, -2.0373, -2.0917, -1.9954, -2.0588, -2.0924, -2.0970, -2.0554,\n",
      "        -2.0978, -2.0789, -2.1232, -2.1384, -2.1183, -2.0804, -2.1130, -2.0985,\n",
      "        -2.0886, -2.1266, -2.0604, -2.1085, -2.0735, -2.0735, -2.0957, -2.1000,\n",
      "        -2.1531, -2.0901], device='mps:0')\n",
      "mean: tensor(-2.0813, device='mps:0')\n",
      "iter_dt 1.10s; iter 5: train loss 0.79315 temperature: 5.249999999999999\n",
      "mean_logits tensor([-1.7058, -2.1117, -1.7173, -1.8468, -1.5645, -1.9860, -2.5717, -2.1742,\n",
      "        -2.2800, -2.0529, -1.1703, -2.2177, -2.0793, -1.8308, -1.9813, -2.2730,\n",
      "        -2.3857, -2.2349, -2.1509, -2.3261, -2.5677, -2.1552, -2.2906, -1.9572,\n",
      "        -2.1280, -2.0177, -2.0988, -1.4158, -2.6192, -2.3710, -2.1101, -1.7488,\n",
      "        -1.8924, -2.1082, -2.0413, -1.9198, -2.3215, -2.0712, -2.2640, -2.0976,\n",
      "        -2.1082, -2.0249, -2.6386, -1.5626, -2.0425, -2.5875, -2.0555, -1.5721,\n",
      "        -1.9801, -2.0701], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0755, -2.0911, -2.0638, -2.0906, -2.0977, -2.1162, -2.0807, -2.0384,\n",
      "        -2.0812, -2.1157, -2.1121, -2.0626, -2.1385, -2.0053, -2.0946, -2.1029,\n",
      "        -2.0783, -2.0813, -2.0388, -2.0927, -2.0890, -2.0364, -2.0920, -2.0796,\n",
      "        -2.0821, -2.0957, -2.0039, -1.9981, -2.0920, -2.0484, -2.0868, -2.0916,\n",
      "        -2.0747, -2.0853, -2.0888, -2.0928, -1.9841, -2.0885, -2.0966, -2.0776,\n",
      "        -2.0624, -2.0862, -2.0862, -2.0956, -2.0891, -2.0731, -2.1070, -2.0931,\n",
      "        -2.0315, -2.1287], device='mps:0')\n",
      "mean: tensor(-2.0779, device='mps:0')\n",
      "iter_dt 1.06s; iter 6: train loss 0.40722 temperature: 5.299999999999999\n",
      "mean_logits tensor([-1.8681, -2.2635, -2.0514, -2.1911, -2.4132, -1.8551, -2.1046, -2.3763,\n",
      "        -2.0467, -1.7051, -2.0674, -2.1265, -2.3708, -1.8803, -1.8584, -2.3004,\n",
      "        -2.0827, -2.0032, -1.9728, -1.9565, -2.2607, -1.7092, -2.3946, -2.2712,\n",
      "        -2.0164, -1.9386, -2.2212, -2.0895, -1.9106, -1.8923, -1.9214, -1.9084,\n",
      "        -2.1237, -2.1693, -2.2690, -2.2149, -2.1648, -2.2218, -2.4673, -1.6367,\n",
      "        -2.1050, -2.1160, -1.9739, -2.1329, -1.8209, -2.1509, -1.6121, -1.7207,\n",
      "        -1.8579, -1.9004], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0836, -2.0710, -2.0561, -2.0753, -1.9906, -2.0921, -2.0425, -2.0450,\n",
      "        -2.1142, -2.1563, -2.0931, -2.0789, -2.0255, -2.0400, -2.0127, -2.0715,\n",
      "        -2.1034, -2.1220, -2.0860, -2.0788, -2.0330, -2.0635, -2.1466, -2.0790,\n",
      "        -2.0309, -2.0884, -2.0533, -2.0898, -2.1048, -2.0882, -2.0959, -2.1366,\n",
      "        -2.0855, -2.0938, -2.0370, -2.0659, -2.1183, -2.0288, -2.0898, -2.0905,\n",
      "        -2.0812, -2.1035, -2.0933, -2.0487, -2.0950, -2.0932, -2.0876, -2.1079,\n",
      "        -2.0721, -2.1053], device='mps:0')\n",
      "mean: tensor(-2.0789, device='mps:0')\n",
      "iter_dt 1.04s; iter 7: train loss 0.57532 temperature: 5.349999999999999\n",
      "mean_logits tensor([-1.9082, -1.8828, -1.6005, -1.8779, -1.8298, -2.0789, -1.9565, -1.7317,\n",
      "        -1.6926, -1.8138, -2.4439, -2.3268, -1.2904, -2.2354, -2.1622, -1.8786,\n",
      "        -1.8871, -1.9134, -1.9427, -1.7855, -1.9886, -2.3283, -2.0728, -2.1574,\n",
      "        -1.5178, -1.9693, -1.7493, -2.1273, -2.3874, -2.5360, -2.2073, -1.5556,\n",
      "        -1.9334, -1.7977, -2.3754, -2.1616, -1.8361, -2.2350, -2.2409, -2.1075,\n",
      "        -2.2177, -1.9748, -2.3438, -2.4444, -2.1482, -1.9545, -1.8393, -1.7592,\n",
      "        -1.8588, -2.0919], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0884, -2.0870, -2.0875, -2.0695, -2.0769, -2.1002, -2.0466, -2.0671,\n",
      "        -2.0895, -2.1053, -2.0856, -2.0909, -2.0919, -2.0891, -2.0245, -2.0868,\n",
      "        -2.1146, -2.0849, -2.0518, -2.0792, -2.0824, -2.0874, -2.0993, -2.0399,\n",
      "        -2.0839, -2.1097, -2.0936, -2.0834, -2.0528, -1.9940, -2.1018, -2.0755,\n",
      "        -2.0878, -2.0941, -2.0894, -2.0850, -2.0653, -2.0872, -2.0849, -2.0620,\n",
      "        -2.0385, -2.1155, -2.0977, -2.0405, -2.0674, -2.0845, -2.0638, -2.0120,\n",
      "        -2.0729, -2.0330], device='mps:0')\n",
      "mean: tensor(-2.0761, device='mps:0')\n",
      "iter_dt 1.03s; iter 8: train loss 0.53837 temperature: 5.399999999999999\n",
      "mean_logits tensor([-2.2663, -2.0081, -2.1478, -2.1643, -2.1443, -2.0854, -2.2687, -1.7508,\n",
      "        -1.6415, -1.9534, -2.5093, -1.6760, -2.1208, -1.9238, -1.5177, -2.0676,\n",
      "        -1.9815, -1.9913, -1.8341, -1.8477, -2.0487, -2.1792, -1.7863, -1.7225,\n",
      "        -1.9212, -1.5613, -1.7921, -2.0253, -2.2934, -1.9422, -2.0924, -2.2652,\n",
      "        -1.8264, -1.8840, -1.9680, -2.3409, -1.5482, -2.2987, -1.6550, -1.9059,\n",
      "        -1.9897, -1.9271, -2.3301, -1.6120, -1.9585, -2.0621, -1.7576, -1.5858,\n",
      "        -2.5901, -2.3604], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0821, -2.0422, -2.0275, -2.1144, -2.0990, -2.1044, -2.0534, -2.0877,\n",
      "        -2.0827, -2.0588, -2.0874, -2.0104, -2.0738, -2.0785, -2.1246, -2.0641,\n",
      "        -2.0628, -1.9999, -2.1274, -2.0368, -2.0374, -2.0819, -2.0760, -2.0973,\n",
      "        -1.9604, -2.0434, -2.0293, -2.0897, -2.0492, -2.0674, -2.0993, -2.0507,\n",
      "        -2.1060, -2.0792, -2.0608, -2.0974, -2.0850, -2.0930, -2.0902, -2.0935,\n",
      "        -2.0899, -2.0676, -2.0819, -2.0518, -2.1063, -2.0904, -2.0915, -2.0308,\n",
      "        -2.0846, -2.0557], device='mps:0')\n",
      "mean: tensor(-2.0711, device='mps:0')\n",
      "iter_dt 1.04s; iter 9: train loss 0.42394 temperature: 5.449999999999998\n",
      "mean_logits tensor([-1.7543, -2.1891, -2.0240, -1.9449, -2.1011, -2.3541, -2.1288, -1.5236,\n",
      "        -2.1342, -2.1991, -1.9711, -2.3929, -2.2140, -2.2249, -1.8802, -2.1637,\n",
      "        -1.3705, -2.2586, -2.2325, -2.3500, -1.7651, -2.0259, -2.1980, -2.0121,\n",
      "        -2.0707, -2.2797, -2.4474, -2.0433, -2.1322, -1.6896, -1.7630, -1.8627,\n",
      "        -2.1140, -2.1932, -1.6498, -1.7535, -1.8186, -1.8145, -2.0859, -1.6431,\n",
      "        -1.8530, -2.1444, -2.0911, -2.2270, -2.1378, -2.1133, -2.0413, -2.2434,\n",
      "        -1.3963, -1.9532], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0560, -2.0872, -2.0720, -2.0757, -2.1009, -2.1063, -2.0274, -2.0772,\n",
      "        -2.0721, -2.0835, -2.0892, -2.0517, -2.0400, -2.1167, -2.0864, -2.0987,\n",
      "        -2.0761, -2.1082, -2.0783, -2.0901, -2.0290, -2.0045, -2.0809, -2.0893,\n",
      "        -2.1051, -2.0727, -2.1002, -2.1130, -2.1011, -2.0682, -2.1141, -2.0854,\n",
      "        -2.0843, -2.0899, -2.1204, -2.0896, -2.0862, -2.0841, -2.0963, -2.0185,\n",
      "        -2.0876, -2.0079, -2.0720, -2.0883, -2.0853, -2.0887, -2.0768, -1.9940,\n",
      "        -2.0758, -2.0871], device='mps:0')\n",
      "mean: tensor(-2.0778, device='mps:0')\n",
      "iter_dt 1.04s; iter 10: train loss 0.38244 temperature: 5.499999999999998\n",
      "mean_logits tensor([-2.1392, -2.0708, -2.2143, -1.8162, -1.8346, -2.2336, -2.0228, -2.0601,\n",
      "        -2.4927, -1.9530, -1.9221, -1.7049, -2.2428, -1.7776, -1.8863, -2.1468,\n",
      "        -1.9675, -2.0068, -1.7604, -1.6692, -1.7543, -2.1420, -1.7514, -2.1848,\n",
      "        -2.0921, -2.1393, -2.0985, -2.3762, -2.0655, -1.8329, -2.0685, -2.1924,\n",
      "        -1.6845, -2.0783, -2.2087, -2.0959, -2.0879, -2.0966, -1.7543, -2.4090,\n",
      "        -1.8174, -1.9989, -1.8081, -1.7796, -1.7282, -1.5204, -2.0541, -1.9335,\n",
      "        -2.1655, -1.8802], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0874, -2.0398, -2.0405, -2.0492, -2.0729, -2.0910, -2.0951, -2.0882,\n",
      "        -2.0877, -2.0875, -2.0524, -2.0627, -1.9653, -2.0906, -2.1237, -2.1026,\n",
      "        -2.0787, -2.1001, -2.0880, -2.0880, -2.0758, -2.0861, -2.1116, -2.0935,\n",
      "        -2.0913, -2.0899, -2.1109, -2.0806, -2.0971, -2.1114, -2.0962, -2.0836,\n",
      "        -2.0948, -1.9965, -2.0493, -2.0891, -2.1189, -2.0887, -2.1277, -2.0876,\n",
      "        -2.0251, -2.1114, -2.0263, -2.1112, -2.0730, -2.0353, -2.0711, -2.1125,\n",
      "        -2.0598, -2.0841], device='mps:0')\n",
      "mean: tensor(-2.0796, device='mps:0')\n",
      "iter_dt 1.05s; iter 11: train loss 0.63479 temperature: 5.549999999999998\n",
      "mean_logits tensor([-2.0839, -1.7293, -1.4409, -1.9198, -2.2324, -2.3089, -1.6201, -2.2621,\n",
      "        -2.0231, -2.3418, -2.2081, -1.6976, -1.7609, -2.1141, -1.7791, -1.6346,\n",
      "        -1.9189, -1.9209, -2.2626, -2.1950, -2.0939, -1.6816, -1.9259, -1.6102,\n",
      "        -2.2233, -2.0049, -1.9136, -2.4940, -2.2043, -1.4003, -2.4591, -2.0686,\n",
      "        -1.8525, -2.2277, -1.9235, -1.9762, -1.8027, -2.3600, -1.8384, -2.0768,\n",
      "        -2.4037, -2.0105, -2.5425, -2.3722, -2.3847, -1.8113, -1.8469, -2.2733,\n",
      "        -1.6892, -2.2048], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0850, -2.0869, -2.0598, -2.0817, -2.0919, -2.0454, -2.0910, -2.1021,\n",
      "        -2.0905, -1.9915, -2.1036, -2.0982, -2.0945, -2.0931, -2.0284, -2.0950,\n",
      "        -2.0698, -2.0879, -2.1058, -2.0921, -2.0750, -2.0758, -2.0775, -2.0794,\n",
      "        -2.0130, -2.0891, -2.1097, -2.0958, -2.0863, -2.1050, -2.1196, -2.0946,\n",
      "        -2.0864, -2.0763, -2.0385, -2.0569, -2.0369, -2.0259, -2.0732, -2.0533,\n",
      "        -2.0796, -2.0915, -2.0597, -2.1091, -2.0998, -2.1122, -2.0762, -2.0309,\n",
      "        -2.0974, -2.0622], device='mps:0')\n",
      "mean: tensor(-2.0776, device='mps:0')\n",
      "iter_dt 1.05s; iter 12: train loss 0.43176 temperature: 5.599999999999998\n",
      "mean_logits tensor([-2.4362, -1.8888, -1.8913, -1.8990, -1.2067, -2.3145, -1.9654, -2.2224,\n",
      "        -2.3200, -2.2982, -1.9392, -1.7006, -1.9960, -1.7881, -2.2265, -2.2447,\n",
      "        -1.8914, -2.1019, -1.8698, -1.6589, -2.1833, -1.9670, -1.8807, -1.9925,\n",
      "        -2.4325, -1.8743, -2.1221, -2.0670, -2.2182, -2.1043, -2.0565, -2.1778,\n",
      "        -2.4765, -1.9810, -1.9564, -1.7011, -2.1828, -1.7344, -2.0018, -1.9107,\n",
      "        -2.3784, -2.2612, -1.7311, -1.8719, -1.9299, -1.6766, -1.9702, -2.1200,\n",
      "        -1.9887, -2.0340], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0836, -2.0253, -2.0942, -2.0283, -2.0769, -2.0615, -2.0592, -2.0813,\n",
      "        -2.1046, -2.1005, -2.1199, -2.0467, -2.0160, -2.1092, -2.0599, -2.0369,\n",
      "        -2.0968, -2.0973, -2.0544, -2.0863, -2.0886, -2.0266, -2.0863, -2.0805,\n",
      "        -2.0721, -2.1144, -2.0729, -2.0600, -2.1197, -2.1146, -2.0857, -2.1014,\n",
      "        -2.0886, -2.0775, -2.0978, -2.0788, -2.0821, -2.0301, -2.0869, -2.0954,\n",
      "        -2.0986, -2.0545, -2.0935, -2.1094, -2.1154, -2.0609, -2.0963, -2.0322,\n",
      "        -2.0892, -2.0873], device='mps:0')\n",
      "mean: tensor(-2.0787, device='mps:0')\n",
      "iter_dt 1.24s; iter 13: train loss 0.44799 temperature: 5.649999999999998\n",
      "mean_logits tensor([-1.4999, -1.9916, -2.3490, -2.0118, -2.2217, -1.9292, -1.9778, -1.9238,\n",
      "        -2.0219, -1.8883, -1.8864, -1.9282, -2.0901, -2.4474, -1.9490, -1.9740,\n",
      "        -2.3274, -1.9755, -1.8298, -1.8575, -2.4554, -1.6617, -2.1225, -1.9386,\n",
      "        -1.8680, -2.2416, -2.0185, -2.1378, -1.8551, -2.0473, -2.1272, -2.0399,\n",
      "        -1.9442, -1.9500, -1.7865, -1.9772, -1.7497, -2.4812, -1.8273, -2.2023,\n",
      "        -1.8346, -2.3703, -2.4266, -2.0592, -2.2611, -2.0776, -1.5795, -2.2928,\n",
      "        -1.6291, -1.7144], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0246, -2.0525, -2.0599, -2.0624, -2.0724, -2.0768, -2.0927, -2.0957,\n",
      "        -2.0895, -2.0629, -2.0428, -2.0380, -2.0734, -2.0936, -2.0727, -2.0568,\n",
      "        -2.0896, -2.0802, -2.0442, -2.1007, -2.0846, -2.1087, -2.1034, -2.0920,\n",
      "        -2.1011, -1.9753, -2.0808, -2.1059, -2.0828, -2.0848, -2.1012, -2.0893,\n",
      "        -2.0604, -2.0863, -2.0870, -2.0833, -2.1013, -2.0685, -2.0110, -2.0874,\n",
      "        -2.0785, -2.1208, -2.1006, -2.0898, -2.1128, -2.0895, -2.1037, -2.0583,\n",
      "        -2.0915, -2.0619], device='mps:0')\n",
      "mean: tensor(-2.0777, device='mps:0')\n",
      "iter_dt 1.11s; iter 14: train loss 0.36283 temperature: 5.6999999999999975\n",
      "mean_logits tensor([-2.1850, -2.0064, -1.8440, -2.0701, -2.0582, -2.0619, -2.1759, -1.8211,\n",
      "        -1.8538, -2.1875, -2.1134, -1.4573, -1.8937, -1.9619, -2.1495, -2.1400,\n",
      "        -2.4849, -1.8263, -2.2552, -2.2430, -2.3001, -2.3064, -2.1299, -1.7288,\n",
      "        -1.9842, -1.9598, -1.7961, -2.2470, -1.8946, -2.0576, -2.1421, -2.0944,\n",
      "        -2.0624, -1.9387, -2.1996, -2.1202, -1.6386, -2.3123, -1.9707, -1.9293,\n",
      "        -1.7648, -1.8835, -2.0525, -2.0192, -1.5695, -1.7422, -1.8306, -1.6781,\n",
      "        -1.7352, -1.6502], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0856, -2.1168, -2.0586, -2.1063, -2.0749, -2.0931, -2.0770, -2.0604,\n",
      "        -2.0703, -2.0829, -2.0855, -2.0695, -2.0060, -2.1048, -2.0795, -2.0812,\n",
      "        -2.0554, -2.0788, -2.1099, -2.0996, -2.1203, -2.0894, -2.0706, -2.0894,\n",
      "        -2.1152, -2.1325, -2.0872, -2.0092, -2.1170, -2.0874, -2.0834, -2.0800,\n",
      "        -2.1017, -2.0350, -2.0790, -2.1236, -2.0742, -2.1027, -2.1036, -2.0266,\n",
      "        -2.0583, -2.0601, -2.0767, -2.0859, -2.0521, -2.0219, -2.0385, -2.0871,\n",
      "        -2.0481, -2.1338], device='mps:0')\n",
      "mean: tensor(-2.0797, device='mps:0')\n",
      "iter_dt 1.04s; iter 15: train loss 0.50276 temperature: 5.749999999999997\n",
      "mean_logits tensor([-1.9906, -2.2688, -1.9275, -1.7688, -2.3998, -1.9618, -1.9565, -1.5198,\n",
      "        -1.8617, -1.9234, -1.8072, -2.3242, -2.3060, -1.7773, -2.2925, -1.6351,\n",
      "        -1.7494, -2.0741, -2.0492, -2.1757, -2.0095, -2.1813, -1.4727, -1.5323,\n",
      "        -2.3390, -2.0946, -2.3281, -1.7070, -2.4358, -2.1390, -1.8220, -1.5297,\n",
      "        -2.0825, -2.1418, -2.1186, -2.0247, -2.0896, -1.9330, -1.7523, -2.0084,\n",
      "        -1.9466, -2.3256, -2.1573, -2.0209, -2.0449, -2.0177, -2.2174, -1.6966,\n",
      "        -2.4289, -2.3334], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0925, -2.1202, -2.0891, -2.0997, -2.0893, -2.1145, -2.0557, -2.0806,\n",
      "        -2.0951, -2.0868, -2.0700, -2.0674, -2.0951, -2.0778, -2.0617, -2.1456,\n",
      "        -2.0842, -2.0887, -2.1073, -2.0529, -2.0896, -2.0956, -2.0914, -2.0720,\n",
      "        -2.0933, -2.0992, -2.0778, -2.0916, -2.1264, -2.0867, -2.0896, -2.0833,\n",
      "        -2.0999, -2.0865, -2.0711, -2.1085, -2.0821, -2.0862, -2.0963, -2.0314,\n",
      "        -2.0930, -2.1124, -2.0754, -2.0773, -2.0667, -2.0962, -2.0343, -2.0928,\n",
      "        -2.0351, -2.0506], device='mps:0')\n",
      "mean: tensor(-2.0853, device='mps:0')\n",
      "iter_dt 1.02s; iter 16: train loss 0.26277 temperature: 5.799999999999997\n",
      "mean_logits tensor([-2.1937, -2.0834, -2.0948, -2.0646, -2.2956, -2.0551, -2.1696, -1.8564,\n",
      "        -2.1217, -2.3780, -2.2841, -2.0065, -1.8911, -1.7584, -1.7872, -1.8885,\n",
      "        -1.8488, -2.0526, -1.9603, -2.2877, -2.0987, -1.8954, -2.0122, -2.1435,\n",
      "        -2.0974, -1.9297, -2.1024, -1.9110, -1.9717, -1.9564, -2.0610, -2.1571,\n",
      "        -2.1634, -1.8399, -2.2790, -2.0371, -1.9210, -1.7230, -2.0023, -2.2657,\n",
      "        -2.0071, -2.3165, -2.0956, -2.2576, -2.1723, -2.0122, -2.5388, -2.0131,\n",
      "        -2.0168, -1.9558], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0240, -2.0607, -2.0830, -2.0415, -2.0624, -2.1004, -2.1137, -2.0288,\n",
      "        -2.1187, -2.1230, -2.0736, -2.0810, -2.1096, -2.0847, -2.0764, -2.0404,\n",
      "        -2.0744, -2.0574, -2.0849, -2.0881, -2.0947, -2.0623, -2.0875, -2.0719,\n",
      "        -2.0854, -2.1157, -2.0922, -2.0518, -2.1216, -2.0576, -2.0757, -2.0891,\n",
      "        -2.0436, -2.1206, -2.0900, -2.1262, -2.0701, -2.0784, -2.0340, -2.0924,\n",
      "        -2.0544, -2.0515, -2.0609, -2.0311, -2.0818, -2.0878, -2.0675, -2.0911,\n",
      "        -2.0738, -2.0815], device='mps:0')\n",
      "mean: tensor(-2.0774, device='mps:0')\n",
      "iter_dt 1.03s; iter 17: train loss 0.35120 temperature: 5.849999999999997\n",
      "mean_logits tensor([-2.0537, -2.2623, -1.9022, -1.3239, -2.0868, -2.0798, -2.2774, -1.9835,\n",
      "        -1.8881, -1.9397, -2.3301, -1.7115, -1.7500, -2.2833, -2.3298, -1.9989,\n",
      "        -2.3858, -2.0106, -1.9043, -1.9885, -1.6186, -2.3213, -2.1064, -2.0961,\n",
      "        -2.0234, -2.2532, -1.6867, -2.0292, -2.1036, -2.1413, -2.0929, -2.1071,\n",
      "        -2.2832, -1.9912, -1.6325, -1.9010, -1.6938, -2.1963, -2.0543, -2.1380,\n",
      "        -2.0365, -2.0227, -2.3002, -1.6566, -1.9655, -1.9258, -2.0931, -2.1244,\n",
      "        -2.4073, -1.9370], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0747, -2.1006, -2.0346, -2.0946, -2.0975, -2.0597, -2.1124, -2.1094,\n",
      "        -2.0640, -2.0626, -2.1176, -2.0766, -2.0340, -2.0868, -2.0916, -2.0883,\n",
      "        -2.0645, -2.0900, -2.0691, -2.0880, -2.0986, -2.0372, -2.0310, -2.1037,\n",
      "        -2.0927, -2.0609, -2.0854, -2.0880, -2.0725, -2.0701, -2.0672, -2.0810,\n",
      "        -2.0966, -2.0420, -2.0508, -2.0598, -2.0664, -2.0803, -2.0611, -2.0664,\n",
      "        -2.0561, -2.0584, -2.0780, -2.0244, -2.0834, -2.0933, -2.0562, -2.0924,\n",
      "        -2.0700, -2.0815], device='mps:0')\n",
      "mean: tensor(-2.0744, device='mps:0')\n",
      "iter_dt 1.04s; iter 18: train loss 0.52974 temperature: 5.899999999999997\n",
      "mean_logits tensor([-2.3917, -2.1153, -1.9034, -2.2645, -2.3203, -2.0855, -1.9405, -1.9964,\n",
      "        -2.0916, -2.3353, -2.1146, -2.2854, -1.7360, -1.8086, -1.9603, -2.4303,\n",
      "        -2.3631, -2.2741, -2.0338, -1.8742, -2.0807, -1.7689, -1.9688, -2.1851,\n",
      "        -1.8431, -2.1231, -2.1756, -1.8753, -1.4345, -1.8470, -1.9829, -1.6700,\n",
      "        -1.9894, -2.2220, -2.0508, -2.3873, -1.8036, -1.9990, -1.8065, -2.5676,\n",
      "        -2.1061, -1.6202, -1.8745, -2.0728, -2.6051, -1.8047, -2.1068, -2.1519,\n",
      "        -1.8843, -2.2849], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1168, -2.0849, -2.0611, -2.1253, -2.1213, -2.0351, -2.0969, -2.0819,\n",
      "        -2.0894, -2.0412, -2.1029, -2.0901, -2.1015, -2.0900, -2.0176, -2.0777,\n",
      "        -2.0611, -2.1049, -2.0387, -2.0450, -2.0479, -2.0373, -2.0132, -2.0870,\n",
      "        -2.0939, -2.0665, -2.1001, -2.0610, -2.0941, -2.0703, -2.0297, -2.0917,\n",
      "        -2.0849, -2.0925, -2.0810, -2.0684, -2.1080, -2.0895, -2.1074, -2.0320,\n",
      "        -2.0431, -2.0949, -2.1180, -2.0199, -2.1012, -2.0839, -2.0867, -2.1109,\n",
      "        -2.0607, -2.0324], device='mps:0')\n",
      "mean: tensor(-2.0758, device='mps:0')\n",
      "iter_dt 1.03s; iter 19: train loss 0.31279 temperature: 5.949999999999997\n",
      "mean_logits tensor([-2.1561, -1.6183, -2.1137, -1.8175, -2.3098, -1.8122, -1.9199, -1.8581,\n",
      "        -2.1464, -2.1257, -1.8719, -2.1120, -1.9319, -1.6060, -1.5924, -2.0272,\n",
      "        -1.8475, -2.2501, -1.8292, -2.0886, -1.8229, -2.0816, -2.2085, -2.0295,\n",
      "        -2.2815, -1.7191, -2.2835, -1.8708, -2.1331, -1.9497, -2.3742, -2.1999,\n",
      "        -2.0446, -1.8067, -1.9773, -1.9167, -2.1353, -2.2489, -2.1662, -2.0158,\n",
      "        -1.8679, -2.1507, -1.7218, -2.2806, -2.0074, -2.0302, -2.3494, -2.2816,\n",
      "        -2.0039, -1.8467], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0604, -2.0873, -2.0918, -2.0887, -2.1056, -2.0729, -2.0853, -2.0594,\n",
      "        -2.0942, -2.0583, -2.0864, -2.1094, -2.0615, -2.0958, -2.0785, -2.0501,\n",
      "        -2.1253, -2.0875, -2.1142, -2.0913, -2.0627, -2.0563, -2.0821, -2.0842,\n",
      "        -2.0912, -2.0074, -2.0910, -2.0900, -2.0988, -2.0943, -2.1572, -2.0858,\n",
      "        -2.0959, -2.0417, -2.0897, -2.1025, -2.0906, -2.0396, -2.0479, -2.0628,\n",
      "        -2.0804, -2.0853, -2.1109, -2.0622, -2.0797, -2.1212, -2.0764, -2.1100,\n",
      "        -2.1167, -2.0470], device='mps:0')\n",
      "mean: tensor(-2.0833, device='mps:0')\n",
      "iter_dt 1.06s; iter 20: train loss 0.43087 temperature: 5.9999999999999964\n",
      "mean_logits tensor([-2.1359, -1.7168, -1.8020, -1.9358, -2.0966, -1.6737, -2.0087, -2.0739,\n",
      "        -1.4922, -2.0444, -1.9420, -2.1232, -2.4898, -2.1145, -2.1768, -2.1909,\n",
      "        -1.9606, -1.5902, -2.0089, -2.1012, -1.9885, -1.9259, -2.1425, -1.9207,\n",
      "        -1.9029, -1.5097, -2.1310, -2.3820, -2.0963, -2.2724, -1.7197, -2.1007,\n",
      "        -2.1083, -1.5550, -2.0880, -2.4196, -2.3348, -1.9132, -1.8166, -2.1104,\n",
      "        -1.8192, -2.1050, -2.0257, -1.7518, -2.1359, -2.0564, -2.1225, -2.4715,\n",
      "        -2.2342, -1.7566], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0451, -2.0934, -2.1454, -2.0126, -2.0721, -2.0443, -2.1042, -2.0731,\n",
      "        -2.0614, -2.0946, -2.0227, -2.0988, -2.0829, -2.0869, -2.0918, -2.0842,\n",
      "        -2.0565, -2.1173, -2.0844, -2.0331, -2.0848, -2.1178, -2.0979, -2.0869,\n",
      "        -2.0677, -2.1000, -2.0213, -2.0820, -2.0885, -2.1063, -2.0334, -2.1051,\n",
      "        -2.0936, -2.0313, -2.1548, -2.0861, -2.0301, -2.0740, -2.0874, -2.1106,\n",
      "        -2.0810, -2.1192, -2.0920, -2.0828, -2.0937, -2.0635, -2.0894, -2.0362,\n",
      "        -2.1071, -2.0458], device='mps:0')\n",
      "mean: tensor(-2.0795, device='mps:0')\n",
      "iter_dt 1.05s; iter 21: train loss 0.27757 temperature: 6.049999999999996\n",
      "mean_logits tensor([-1.9511, -2.3732, -2.0148, -2.3045, -2.0502, -1.8956, -2.2774, -2.1980,\n",
      "        -2.0964, -1.6827, -2.1540, -2.4619, -2.0596, -2.1078, -2.2057, -2.1166,\n",
      "        -2.0699, -1.5575, -1.8497, -1.8120, -1.9149, -1.9813, -2.0813, -2.2399,\n",
      "        -1.9202, -2.1596, -2.1767, -2.1051, -2.1474, -2.2497, -2.0048, -2.2616,\n",
      "        -2.2012, -1.7142, -2.1451, -1.9578, -1.8390, -1.8994, -1.9183, -2.3160,\n",
      "        -2.0352, -2.1123, -2.1304, -1.9885, -2.2595, -2.0762, -2.1254, -1.6429,\n",
      "        -1.8661, -2.0157], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0742, -2.0826, -2.0827, -2.0964, -2.0754, -2.0381, -2.0857, -2.0826,\n",
      "        -2.0716, -2.0792, -2.0793, -2.0659, -2.1253, -1.9915, -2.0853, -2.0334,\n",
      "        -2.0948, -2.0138, -2.0489, -2.0694, -2.1130, -2.0888, -2.1185, -2.0308,\n",
      "        -2.1275, -2.0743, -2.0979, -2.0118, -2.0781, -2.0481, -2.0893, -2.0898,\n",
      "        -2.0888, -2.0879, -2.0546, -2.0409, -2.0756, -2.0109, -2.0711, -2.0918,\n",
      "        -2.0388, -2.0602, -2.0776, -2.0682, -2.0678, -2.0917, -2.0648, -2.0938,\n",
      "        -2.0740, -2.0999], device='mps:0')\n",
      "mean: tensor(-2.0720, device='mps:0')\n",
      "iter_dt 1.04s; iter 22: train loss 0.15608 temperature: 6.099999999999996\n",
      "mean_logits tensor([-2.1312, -2.1078, -1.9359, -2.1156, -2.1110, -2.2477, -2.2850, -1.7363,\n",
      "        -1.7903, -2.2896, -2.2078, -2.0283, -1.9184, -1.8678, -2.1335, -2.0818,\n",
      "        -1.9757, -2.2859, -2.0667, -2.1209, -1.9675, -1.7978, -1.8569, -1.9433,\n",
      "        -1.9283, -2.0337, -2.0431, -1.9612, -2.0536, -1.9927, -2.2252, -2.1503,\n",
      "        -2.0748, -1.9253, -1.9231, -1.9969, -2.0035, -2.0919, -2.2176, -2.1868,\n",
      "        -2.0413, -2.1052, -2.0492, -2.1722, -2.2224, -1.9262, -2.0935, -2.0973,\n",
      "        -2.0862, -2.0088], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0066, -2.0261, -2.0909, -2.0536, -2.0523, -2.0807, -2.0877, -2.1145,\n",
      "        -2.0514, -2.0851, -2.0993, -2.0952, -2.1012, -2.0896, -2.0373, -2.0696,\n",
      "        -2.1035, -2.0828, -2.0576, -2.0742, -2.0665, -2.0946, -2.0618, -2.0871,\n",
      "        -2.1009, -2.0805, -2.0680, -2.0484, -2.0730, -2.0291, -1.9892, -2.0856,\n",
      "        -2.0923, -2.0951, -2.0742, -2.0890, -2.0904, -2.0853, -2.0907, -2.1043,\n",
      "        -2.0804, -2.0875, -2.0890, -2.0841, -2.0451, -2.0850, -2.0800, -2.1081,\n",
      "        -2.0881, -2.1164], device='mps:0')\n",
      "mean: tensor(-2.0766, device='mps:0')\n",
      "iter_dt 1.06s; iter 23: train loss 0.48992 temperature: 6.149999999999996\n",
      "mean_logits tensor([-2.2914, -2.2251, -2.4283, -1.7404, -2.1800, -2.0982, -1.9293, -2.3334,\n",
      "        -1.9995, -2.1807, -2.0640, -1.7739, -2.3013, -1.9584, -1.6645, -2.5242,\n",
      "        -1.8633, -1.9480, -2.0477, -2.1587, -2.1821, -1.9842, -2.2863, -2.3807,\n",
      "        -2.3903, -2.3190, -2.0299, -1.4279, -1.9667, -2.2639, -2.2695, -1.8235,\n",
      "        -1.9815, -1.9325, -2.0713, -1.8303, -2.3050, -2.2574, -2.2042, -2.1857,\n",
      "        -1.9749, -2.0265, -2.2021, -1.8706, -1.7937, -1.8782, -1.7588, -2.0476,\n",
      "        -2.5661, -2.4260], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0910, -2.0852, -2.1038, -2.0911, -2.0904, -2.0301, -2.0847, -2.0843,\n",
      "        -2.0737, -2.1202, -2.0873, -2.0758, -2.0940, -2.0900, -2.1187, -2.0807,\n",
      "        -2.0870, -2.0771, -2.0942, -2.0589, -2.0780, -2.0218, -2.1280, -2.0611,\n",
      "        -2.0796, -2.1088, -2.0975, -2.0393, -1.9927, -2.0480, -2.0961, -2.1054,\n",
      "        -2.0675, -2.0571, -2.0449, -2.0203, -2.0856, -2.0489, -2.0858, -2.0914,\n",
      "        -2.0873, -2.0827, -2.0960, -2.0810, -2.0964, -2.0859, -2.0820, -2.0660,\n",
      "        -2.0763, -2.0822], device='mps:0')\n",
      "mean: tensor(-2.0782, device='mps:0')\n",
      "iter_dt 1.03s; iter 24: train loss 0.48437 temperature: 6.199999999999996\n",
      "mean_logits tensor([-2.1661, -2.0675, -2.3690, -2.0760, -1.8103, -2.6493, -1.6615, -2.2574,\n",
      "        -2.2623, -2.0142, -1.7663, -1.9558, -1.6829, -2.3886, -2.3003, -2.4636,\n",
      "        -2.2590, -2.2468, -2.1428, -1.9924, -2.0121, -2.0115, -2.1248, -2.1045,\n",
      "        -1.8876, -2.3008, -2.2018, -1.8842, -1.7678, -1.8308, -2.0018, -2.2256,\n",
      "        -1.6425, -2.1687, -2.1786, -2.1092, -2.0856, -2.2266, -2.1983, -2.1072,\n",
      "        -2.1567, -2.0152, -1.8046, -2.2904, -2.5539, -2.2588, -1.9008, -2.1298,\n",
      "        -1.6574, -1.8676], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0910, -1.9526, -2.0948, -2.0633, -2.0878, -2.0929, -2.0771, -2.0306,\n",
      "        -2.0879, -2.0974, -2.0694, -2.0496, -2.0702, -2.1234, -2.0653, -2.1238,\n",
      "        -2.0563, -2.0950, -2.0416, -1.9817, -2.1006, -2.0695, -2.0162, -2.0364,\n",
      "        -2.1028, -2.0978, -2.0864, -2.0956, -2.1111, -2.0920, -2.0326, -1.9941,\n",
      "        -2.0346, -2.0952, -2.0846, -2.0845, -2.0837, -2.0801, -2.0629, -2.0818,\n",
      "        -2.0688, -2.0840, -2.0939, -2.0884, -2.0863, -2.1345, -2.0448, -2.0747,\n",
      "        -2.0847, -2.0791], device='mps:0')\n",
      "mean: tensor(-2.0727, device='mps:0')\n",
      "iter_dt 1.04s; iter 25: train loss 0.32159 temperature: 6.249999999999996\n",
      "mean_logits tensor([-1.9116, -1.8749, -2.1984, -2.3735, -1.8387, -2.2221, -1.8974, -2.0392,\n",
      "        -2.1175, -2.0631, -1.8982, -1.8049, -2.1754, -1.8314, -2.0576, -2.1372,\n",
      "        -1.7775, -1.7229, -2.0608, -1.6126, -1.6683, -1.8032, -1.9578, -2.2092,\n",
      "        -1.7909, -2.1976, -2.1294, -2.0285, -2.2422, -2.0413, -2.2823, -2.2784,\n",
      "        -1.8341, -1.9240, -2.1021, -1.9180, -2.2301, -2.3509, -2.1070, -2.1968,\n",
      "        -2.1471, -2.0338, -1.9566, -2.1564, -2.1815, -2.0843, -2.1516, -2.4785,\n",
      "        -1.8679, -1.8480], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1159, -2.0976, -2.1298, -2.0843, -2.0881, -2.1110, -2.0689, -1.9927,\n",
      "        -2.0762, -2.0797, -2.1149, -2.0826, -2.0425, -2.0766, -2.1099, -2.1091,\n",
      "        -2.0825, -2.0619, -2.1256, -2.0738, -2.1306, -2.0571, -2.0884, -2.0689,\n",
      "        -2.0668, -2.0745, -2.1424, -2.0865, -2.0392, -2.0736, -2.0597, -2.0731,\n",
      "        -2.0835, -1.9979, -2.0838, -2.0731, -2.0866, -2.0395, -2.1208, -2.0894,\n",
      "        -2.0401, -2.0862, -2.0889, -2.0878, -2.0668, -2.1140, -2.0894, -2.0558,\n",
      "        -2.0702, -2.0940], device='mps:0')\n",
      "mean: tensor(-2.0810, device='mps:0')\n",
      "iter_dt 1.07s; iter 26: train loss 0.58919 temperature: 6.299999999999995\n",
      "mean_logits tensor([-1.5891, -2.4516, -1.7483, -2.3418, -2.1846, -2.2797, -2.2384, -2.6827,\n",
      "        -2.1990, -1.7547, -1.8553, -2.3188, -2.0718, -1.9139, -1.8480, -2.0904,\n",
      "        -2.1653, -2.1491, -2.1101, -1.6757, -1.9859, -1.8953, -2.2109, -1.9765,\n",
      "        -2.0682, -1.9800, -1.5796, -1.9281, -2.0155, -1.9500, -2.2291, -2.2350,\n",
      "        -2.0399, -1.8216, -2.0542, -1.6340, -1.5951, -2.0777, -2.0987, -2.4004,\n",
      "        -1.9611, -2.1267, -2.3718, -2.1587, -1.6451, -2.1746, -1.9273, -1.8622,\n",
      "        -2.0070, -2.5850], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1308, -2.0784, -2.0847, -2.1233, -2.0451, -2.0932, -2.0899, -2.0636,\n",
      "        -2.0463, -2.0702, -2.0689, -2.0844, -2.0608, -2.0550, -2.0856, -2.0859,\n",
      "        -2.1047, -2.0827, -2.1104, -2.0857, -2.0868, -2.0502, -2.0729, -2.0828,\n",
      "        -2.1091, -2.0374, -2.1090, -2.0418, -2.0629, -2.0182, -2.0350, -2.0938,\n",
      "        -2.0738, -2.1063, -2.0562, -2.1248, -2.1052, -2.1113, -2.1281, -2.0435,\n",
      "        -2.0880, -2.0340, -2.0878, -2.0405, -2.0920, -2.0714, -2.0926, -2.0898,\n",
      "        -2.0808, -2.1030], device='mps:0')\n",
      "mean: tensor(-2.0796, device='mps:0')\n",
      "iter_dt 1.04s; iter 27: train loss 0.54484 temperature: 6.349999999999995\n",
      "mean_logits tensor([-2.5632, -1.9801, -1.8159, -1.8356, -2.3356, -2.3451, -1.9933, -2.0553,\n",
      "        -1.8964, -2.2389, -2.0618, -2.2843, -1.8406, -2.0435, -1.7126, -2.1923,\n",
      "        -1.8932, -1.9539, -1.9377, -2.3400, -1.8927, -1.8699, -1.6620, -1.7486,\n",
      "        -2.2032, -1.6223, -2.0739, -2.1488, -2.0620, -1.7453, -1.9588, -1.8383,\n",
      "        -1.9540, -2.1932, -2.3165, -2.2884, -2.4598, -2.1776, -2.1232, -1.9646,\n",
      "        -2.0820, -1.8165, -2.0153, -2.5913, -2.1616, -2.1399, -2.2072, -2.5317,\n",
      "        -2.0026, -2.0395], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-1.9927, -2.0838, -2.0713, -2.0545, -2.0706, -2.0164, -2.0891, -2.0856,\n",
      "        -2.0369, -2.0506, -2.0858, -2.0274, -2.0749, -2.1015, -2.0859, -2.0756,\n",
      "        -2.1276, -2.0673, -2.1427, -2.1066, -2.0491, -2.0795, -2.0413, -2.0485,\n",
      "        -2.0869, -2.0904, -2.0704, -2.0612, -2.0719, -2.0714, -2.1255, -2.1149,\n",
      "        -1.9871, -2.1091, -2.1219, -2.1031, -2.0962, -2.0496, -2.1156, -2.0462,\n",
      "        -2.1016, -2.0965, -2.0762, -2.0898, -2.0029, -2.0637, -2.0544, -2.0000,\n",
      "        -2.0949, -2.0762], device='mps:0')\n",
      "mean: tensor(-2.0729, device='mps:0')\n",
      "iter_dt 1.03s; iter 28: train loss 0.34821 temperature: 6.399999999999995\n",
      "mean_logits tensor([-2.2884, -1.9865, -1.8360, -1.9205, -2.0997, -2.0364, -2.2942, -2.0090,\n",
      "        -2.2653, -1.8363, -2.0398, -1.7565, -2.0466, -2.3414, -2.3764, -2.1532,\n",
      "        -2.3367, -2.1293, -2.2789, -2.0059, -2.0406, -2.1477, -2.0620, -2.4229,\n",
      "        -1.8781, -2.1800, -1.4800, -2.1264, -1.9309, -1.7668, -1.7258, -1.8018,\n",
      "        -1.7293, -2.2705, -2.0656, -1.8614, -1.9445, -2.2943, -2.1701, -2.0615,\n",
      "        -1.7821, -1.9401, -1.8154, -2.0507, -1.9775, -1.9294, -2.0155, -2.3987,\n",
      "        -1.8310, -2.0787], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0617, -2.0960, -2.0883, -2.0946, -2.0824, -2.1142, -2.0835, -2.0703,\n",
      "        -2.0741, -2.1076, -2.0983, -2.0713, -2.0930, -2.1188, -2.0762, -2.0679,\n",
      "        -2.0928, -2.0853, -2.0425, -2.0929, -2.0803, -2.0923, -2.0785, -2.0833,\n",
      "        -2.0650, -2.1104, -2.0925, -2.0127, -2.1107, -2.0425, -2.0833, -2.0818,\n",
      "        -2.0789, -2.0678, -2.1007, -2.0337, -2.0855, -2.0647, -2.0427, -2.0846,\n",
      "        -2.0564, -2.0777, -2.0857, -2.0663, -2.0893, -2.0854, -2.0995, -2.1035,\n",
      "        -2.0735, -2.0901], device='mps:0')\n",
      "mean: tensor(-2.0806, device='mps:0')\n",
      "iter_dt 1.03s; iter 29: train loss 0.27585 temperature: 6.449999999999995\n",
      "mean_logits tensor([-2.1484, -1.8828, -2.3173, -1.7822, -1.6353, -2.0801, -2.1531, -2.1415,\n",
      "        -1.5360, -2.0305, -2.1052, -2.0592, -2.0306, -2.3264, -2.0531, -2.0212,\n",
      "        -1.8331, -2.1931, -1.9255, -2.2671, -2.1469, -1.8135, -2.0367, -1.9922,\n",
      "        -2.0987, -2.0677, -2.0836, -2.0749, -1.9395, -2.2221, -2.1729, -1.7985,\n",
      "        -2.1160, -2.2210, -2.2677, -2.0716, -1.9710, -2.2849, -2.1363, -2.2097,\n",
      "        -1.9056, -2.1324, -2.2106, -2.5437, -1.6696, -2.1513, -1.9855, -2.1224,\n",
      "        -1.9892, -2.1118], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0479, -2.0657, -2.0790, -2.0834, -2.0805, -2.0944, -2.0851, -1.9684,\n",
      "        -2.0599, -2.0916, -2.0755, -2.0685, -2.0444, -2.0403, -2.0737, -2.0887,\n",
      "        -2.0880, -2.1290, -2.0907, -2.0827, -2.1360, -2.0504, -2.0511, -2.0864,\n",
      "        -2.0876, -2.0552, -2.0742, -2.0628, -2.0574, -2.0673, -2.0983, -2.0596,\n",
      "        -2.0761, -2.0475, -2.0157, -2.0465, -2.1134, -2.0994, -2.0881, -2.1256,\n",
      "        -2.0517, -2.0608, -2.0723, -2.0840, -2.0852, -2.0927, -2.0887, -2.0921,\n",
      "        -2.0940, -2.0880], device='mps:0')\n",
      "mean: tensor(-2.0749, device='mps:0')\n",
      "iter_dt 1.02s; iter 30: train loss 0.29344 temperature: 6.499999999999995\n",
      "mean_logits tensor([-1.8878, -1.7664, -1.8049, -1.8564, -2.1183, -1.8815, -2.0213, -1.5641,\n",
      "        -2.2820, -1.9861, -2.1484, -2.2708, -2.0775, -1.8961, -2.2124, -1.9010,\n",
      "        -2.0111, -2.1577, -1.7000, -1.6724, -1.9615, -1.8998, -1.8387, -2.1920,\n",
      "        -2.1743, -1.9819, -2.2074, -1.9619, -1.8302, -2.1059, -2.1810, -2.2576,\n",
      "        -2.0889, -2.0181, -2.0058, -1.9536, -1.6738, -2.1617, -1.8971, -1.7085,\n",
      "        -1.9084, -1.9137, -1.7880, -1.9850, -2.3126, -2.2263, -2.4344, -2.0010,\n",
      "        -2.1259, -2.0027], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0759, -1.9832, -2.0722, -2.0669, -2.0659, -2.0762, -2.0639, -2.0479,\n",
      "        -2.0918, -2.0892, -2.0863, -2.0605, -2.1049, -2.0835, -2.0664, -2.0977,\n",
      "        -2.0609, -2.0214, -2.0943, -2.0117, -2.1213, -2.0985, -2.0444, -2.0897,\n",
      "        -2.1219, -2.1236, -2.0335, -2.0767, -2.0341, -2.0679, -2.1316, -2.0858,\n",
      "        -2.0519, -2.1258, -2.0768, -2.0949, -2.1268, -2.0868, -2.0878, -2.1014,\n",
      "        -2.0384, -2.0768, -2.0871, -2.0396, -2.0527, -2.0729, -2.0928, -2.0810,\n",
      "        -2.0675, -2.0656], device='mps:0')\n",
      "mean: tensor(-2.0755, device='mps:0')\n",
      "iter_dt 1.04s; iter 31: train loss 0.36262 temperature: 6.5499999999999945\n",
      "mean_logits tensor([-2.0921, -2.1672, -1.8571, -2.1816, -2.1817, -2.3539, -2.2960, -2.4107,\n",
      "        -2.2509, -2.2639, -2.4201, -2.0273, -2.3126, -1.7537, -2.2934, -1.9582,\n",
      "        -2.0241, -1.9604, -1.5816, -1.7572, -2.0376, -1.8330, -2.1405, -2.0931,\n",
      "        -2.1442, -2.4142, -1.9109, -2.4951, -1.8931, -2.0150, -2.2258, -1.8781,\n",
      "        -2.2452, -2.1129, -1.9888, -1.7924, -1.9792, -2.1299, -2.2227, -2.1910,\n",
      "        -2.0440, -1.6329, -2.2614, -2.1493, -2.1696, -2.0586, -2.1048, -1.9938,\n",
      "        -1.7319, -2.0503], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0794, -2.0977, -2.0904, -2.0630, -2.0936, -2.1140, -2.1046, -2.0878,\n",
      "        -2.0846, -2.0760, -2.0543, -2.0766, -2.1234, -2.0699, -2.0523, -2.0238,\n",
      "        -2.0458, -2.0664, -2.0648, -2.1052, -2.0880, -2.0962, -2.0734, -2.0959,\n",
      "        -2.0621, -2.0516, -2.0831, -2.0702, -2.0870, -2.0415, -2.0765, -2.0959,\n",
      "        -2.0942, -2.0817, -2.0334, -2.0559, -2.0778, -2.1034, -2.0540, -2.0913,\n",
      "        -2.0299, -2.0539, -2.0905, -2.0711, -2.0770, -2.0212, -2.0558, -2.0661,\n",
      "        -2.0871, -2.0521], device='mps:0')\n",
      "mean: tensor(-2.0738, device='mps:0')\n",
      "iter_dt 1.04s; iter 32: train loss 0.46743 temperature: 6.599999999999994\n",
      "mean_logits tensor([-2.2982, -1.9574, -1.9312, -2.1256, -2.2328, -2.1591, -1.7900, -1.7300,\n",
      "        -2.3348, -1.7494, -1.8086, -2.0354, -1.7996, -1.6794, -2.1341, -2.2369,\n",
      "        -2.0580, -1.4917, -1.9849, -1.6874, -2.0569, -2.6018, -2.1086, -2.3851,\n",
      "        -1.8883, -1.7577, -2.2552, -2.2037, -2.2034, -2.1902, -1.9130, -1.9089,\n",
      "        -2.0903, -2.1378, -2.2902, -1.9796, -2.2818, -2.0314, -2.2448, -2.2968,\n",
      "        -1.8371, -2.3431, -2.4642, -1.7742, -2.2028, -1.7648, -1.6853, -1.9396,\n",
      "        -2.2022, -2.0830], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0712, -2.1047, -2.0522, -2.0887, -2.0801, -2.0984, -2.0309, -2.1084,\n",
      "        -2.0760, -2.1019, -2.0461, -2.0894, -2.0821, -2.0099, -2.0951, -2.0886,\n",
      "        -2.1436, -2.0919, -2.0045, -2.0813, -2.0574, -2.0849, -2.0853, -2.0799,\n",
      "        -2.0737, -2.0440, -2.0781, -2.0884, -2.1606, -2.0639, -2.0704, -2.0913,\n",
      "        -2.0663, -2.0888, -2.0724, -2.0987, -2.0870, -2.1565, -2.1451, -2.0771,\n",
      "        -2.0910, -2.0869, -2.0559, -2.0919, -2.0735, -2.1299, -2.0885, -2.0266,\n",
      "        -2.1017, -2.1072], device='mps:0')\n",
      "mean: tensor(-2.0834, device='mps:0')\n",
      "iter_dt 1.06s; iter 33: train loss 0.27156 temperature: 6.649999999999994\n",
      "mean_logits tensor([-1.5984, -2.1916, -1.9683, -2.0650, -2.3569, -2.0881, -2.0705, -2.0110,\n",
      "        -1.9946, -1.9565, -2.3472, -2.1183, -2.1243, -2.4538, -2.1446, -1.8669,\n",
      "        -1.8021, -2.0214, -1.8253, -2.1259, -2.0898, -1.8830, -2.0827, -1.9977,\n",
      "        -2.0596, -2.0761, -2.1286, -2.3931, -2.4310, -2.2081, -2.2387, -2.1811,\n",
      "        -2.3441, -2.0252, -1.9934, -2.0084, -2.0500, -2.0582, -2.1636, -1.9295,\n",
      "        -2.0269, -2.1839, -1.9429, -2.1853, -2.1790, -2.0626, -1.6164, -2.2878,\n",
      "        -2.2379, -1.7907], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0940, -2.1093, -2.0273, -2.0772, -2.0935, -2.0160, -2.1123, -2.0907,\n",
      "        -2.0288, -2.0379, -2.0898, -2.0887, -2.0646, -2.0885, -2.0992, -2.0653,\n",
      "        -2.0814, -2.0968, -2.0749, -2.1436, -1.9853, -2.0819, -2.1077, -2.1106,\n",
      "        -2.1127, -2.0331, -2.0960, -2.0928, -2.0954, -2.0724, -2.0868, -2.1154,\n",
      "        -2.0479, -2.0774, -2.0976, -2.0514, -2.0247, -2.0744, -2.0911, -2.0940,\n",
      "        -2.0915, -2.1081, -2.0883, -2.0875, -2.0903, -2.0788, -2.0123, -2.0616,\n",
      "        -2.1251, -2.0887], device='mps:0')\n",
      "mean: tensor(-2.0792, device='mps:0')\n",
      "iter_dt 1.06s; iter 34: train loss 0.45347 temperature: 6.699999999999994\n",
      "mean_logits tensor([-2.1053, -1.9372, -2.2312, -2.3061, -1.8926, -2.2907, -2.0940, -2.2123,\n",
      "        -1.9610, -1.9193, -2.4910, -2.2096, -2.3393, -2.0666, -2.0916, -2.1316,\n",
      "        -2.2927, -1.7202, -1.5841, -2.6642, -1.9012, -2.1928, -1.8390, -1.7647,\n",
      "        -1.8535, -2.0633, -1.9854, -2.2412, -2.1766, -1.9816, -1.9486, -2.3427,\n",
      "        -2.4948, -2.0110, -1.9919, -2.1045, -2.0260, -1.9924, -2.0334, -1.6410,\n",
      "        -2.1093, -2.0604, -2.2605, -2.0819, -2.1994, -2.3550, -2.0628, -1.8582,\n",
      "        -1.9937, -1.9551], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0663, -2.0035, -2.0910, -2.0942, -2.0722, -2.0747, -2.0886, -2.0268,\n",
      "        -2.1020, -2.0705, -2.0842, -2.0606, -2.0554, -2.0669, -2.0910, -2.0888,\n",
      "        -2.0839, -2.1516, -2.0744, -2.0881, -2.0714, -2.1047, -2.0894, -2.0854,\n",
      "        -2.0794, -2.0926, -2.0794, -2.0795, -2.1133, -2.0668, -2.1229, -2.1324,\n",
      "        -2.0662, -2.1020, -2.1124, -2.0152, -2.0392, -2.0601, -2.0886, -2.0856,\n",
      "        -2.0942, -2.0798, -2.1098, -2.1119, -2.0464, -2.0420, -2.0911, -2.0970,\n",
      "        -2.0904, -2.0274], device='mps:0')\n",
      "mean: tensor(-2.0802, device='mps:0')\n",
      "iter_dt 1.03s; iter 35: train loss 0.35884 temperature: 6.749999999999994\n",
      "mean_logits tensor([-2.1776, -2.1876, -2.0924, -2.4174, -2.2279, -1.9747, -2.3789, -1.6791,\n",
      "        -2.3121, -2.1373, -2.1111, -1.9082, -1.8313, -2.0859, -1.9701, -2.0718,\n",
      "        -2.0479, -2.3789, -2.0912, -2.0724, -2.0528, -2.5560, -2.0736, -1.8227,\n",
      "        -1.9205, -2.0251, -2.1369, -2.1586, -2.2467, -1.8209, -1.7772, -1.7775,\n",
      "        -1.9093, -2.2791, -2.1866, -1.7841, -2.0848, -2.1401, -2.3604, -1.6596,\n",
      "        -2.0913, -2.2865, -2.4036, -1.9186, -2.0372, -1.9721, -2.0152, -2.1253,\n",
      "        -2.2160, -2.2367], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0922, -2.0678, -2.1093, -2.0920, -2.0793, -2.0454, -2.0898, -2.0937,\n",
      "        -2.0841, -2.0906, -2.0679, -2.0844, -2.0925, -2.0675, -2.0888, -2.0908,\n",
      "        -2.0671, -2.0297, -2.0812, -2.0893, -2.1482, -2.0897, -2.0367, -2.0615,\n",
      "        -2.0809, -2.0897, -2.1072, -2.0992, -2.0976, -2.0494, -2.0671, -2.0472,\n",
      "        -2.0719, -2.0802, -2.0684, -2.0772, -2.0642, -2.1074, -2.0683, -2.1071,\n",
      "        -2.1032, -2.0748, -2.0899, -2.0867, -2.0834, -2.0658, -2.0528, -2.1102,\n",
      "        -2.0647, -2.0888], device='mps:0')\n",
      "mean: tensor(-2.0809, device='mps:0')\n",
      "iter_dt 1.03s; iter 36: train loss 0.36629 temperature: 6.799999999999994\n",
      "mean_logits tensor([-1.8902, -2.3479, -1.9602, -1.8230, -2.5031, -1.9231, -2.3976, -2.3380,\n",
      "        -2.2698, -1.9744, -1.7387, -2.0636, -1.7762, -2.0354, -2.0524, -2.3609,\n",
      "        -2.1963, -2.1174, -1.9605, -2.0836, -1.9929, -2.1184, -2.1392, -2.1395,\n",
      "        -1.8235, -1.9183, -2.2368, -2.1072, -2.4886, -2.0549, -2.3013, -2.0748,\n",
      "        -1.8407, -2.0470, -2.3102, -2.3248, -2.0450, -1.9288, -2.2388, -1.8055,\n",
      "        -1.8688, -1.8350, -2.1571, -2.0972, -1.9142, -1.9536, -2.2159, -2.2756,\n",
      "        -2.1704, -2.2908], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0444, -2.0745, -2.0704, -2.0995, -2.0960, -2.0982, -2.0942, -2.0920,\n",
      "        -2.0973, -2.0856, -2.0484, -2.0233, -2.1101, -2.0934, -2.0776, -2.0684,\n",
      "        -2.0766, -2.0888, -2.0810, -2.0599, -2.1093, -2.0196, -2.0906, -2.0804,\n",
      "        -2.1002, -2.0983, -2.0924, -2.0893, -2.0935, -2.0873, -2.0516, -2.0980,\n",
      "        -2.0881, -2.0962, -2.0328, -2.0961, -2.0964, -2.0619, -2.0288, -2.0924,\n",
      "        -2.0773, -2.1263, -2.0751, -2.0376, -2.1037, -2.0600, -2.0756, -2.0938,\n",
      "        -2.1105, -2.0906], device='mps:0')\n",
      "mean: tensor(-2.0807, device='mps:0')\n",
      "iter_dt 1.09s; iter 37: train loss 0.43794 temperature: 6.849999999999993\n",
      "mean_logits tensor([-2.0119, -2.1350, -1.9564, -2.2136, -2.5791, -1.9953, -2.0234, -1.8920,\n",
      "        -1.9899, -1.9847, -2.0246, -2.1866, -1.7636, -2.3761, -2.1694, -2.0892,\n",
      "        -1.8280, -2.2784, -2.5842, -2.2531, -1.8254, -2.1566, -2.3614, -2.0230,\n",
      "        -1.9269, -2.0728, -2.1244, -1.9559, -1.5174, -2.1042, -2.0935, -2.3893,\n",
      "        -1.9233, -2.0646, -2.2157, -2.0699, -1.8343, -2.0036, -2.2271, -2.1577,\n",
      "        -2.0933, -1.9237, -1.9560, -2.2504, -2.2228, -2.3489, -2.1640, -2.6179,\n",
      "        -2.0131, -1.7566], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0616, -2.0761, -2.1016, -2.0894, -2.1061, -2.0418, -2.0399, -2.1042,\n",
      "        -2.0862, -2.0839, -2.0821, -2.0931, -2.1011, -2.0794, -2.1187, -2.0763,\n",
      "        -2.0589, -2.0780, -2.1036, -2.0729, -2.0827, -2.0697, -2.0870, -2.0663,\n",
      "        -2.0436, -2.0661, -2.0920, -2.0377, -2.0457, -2.0797, -2.0456, -2.0945,\n",
      "        -2.0426, -2.0746, -2.0752, -2.1177, -2.0916, -2.1099, -2.0720, -2.1055,\n",
      "        -2.0905, -2.0892, -2.0886, -2.1221, -2.0625, -2.0938, -2.0976, -2.1173,\n",
      "        -2.0849, -2.0436], device='mps:0')\n",
      "mean: tensor(-2.0809, device='mps:0')\n",
      "iter_dt 1.06s; iter 38: train loss 0.50902 temperature: 6.899999999999993\n",
      "mean_logits tensor([-1.7855, -2.0375, -1.9146, -2.3670, -2.1485, -2.2596, -1.5591, -1.9441,\n",
      "        -2.1292, -2.2231, -1.5687, -1.7010, -1.9027, -1.9627, -1.8398, -2.2228,\n",
      "        -1.7633, -1.9236, -1.9233, -2.4589, -1.9876, -2.0717, -1.9370, -2.0050,\n",
      "        -2.3616, -1.8971, -1.8617, -1.7133, -2.1567, -2.1367, -2.0490, -2.1975,\n",
      "        -1.9034, -2.2194, -2.4832, -2.3049, -1.7837, -2.2064, -2.0170, -2.0264,\n",
      "        -2.4610, -1.9818, -1.8827, -2.1664, -2.3761, -2.4857, -2.5683, -2.0211,\n",
      "        -1.9469, -1.9708], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0549, -2.0832, -2.0831, -2.0895, -2.1003, -2.1031, -2.0123, -2.0844,\n",
      "        -2.0939, -2.0832, -2.0925, -2.0820, -2.0774, -2.0950, -2.0038, -2.0366,\n",
      "        -2.0889, -2.0827, -2.1091, -2.0967, -2.0953, -2.0892, -2.0772, -2.0571,\n",
      "        -2.0925, -2.0997, -2.0908, -2.0952, -2.0875, -2.0343, -2.0825, -2.0951,\n",
      "        -2.0431, -2.1036, -2.0732, -2.0786, -2.1316, -2.0646, -2.0866, -2.0446,\n",
      "        -2.0713, -2.0812, -2.0748, -2.0950, -2.0975, -2.0897, -2.0680, -2.0803,\n",
      "        -2.0708, -2.0664], device='mps:0')\n",
      "mean: tensor(-2.0794, device='mps:0')\n",
      "iter_dt 1.07s; iter 39: train loss 0.27023 temperature: 6.949999999999993\n",
      "mean_logits tensor([-2.0771, -2.2576, -2.0468, -2.3397, -2.1891, -1.9534, -2.0001, -1.9234,\n",
      "        -1.7106, -1.5782, -2.1879, -1.9856, -1.8134, -1.6841, -2.3318, -2.0666,\n",
      "        -2.2784, -2.1349, -2.0880, -2.2430, -1.6730, -1.9093, -2.0131, -2.1414,\n",
      "        -2.3038, -1.8576, -2.1851, -2.1274, -1.9765, -1.9526, -1.9112, -2.2590,\n",
      "        -2.1190, -2.1435, -2.2782, -2.2701, -2.1966, -2.2828, -1.8484, -2.0201,\n",
      "        -1.9558, -1.6342, -1.9923, -2.2935, -2.0749, -2.0985, -1.9142, -2.0449,\n",
      "        -1.9208, -2.0660], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0879, -2.0740, -2.0919, -2.1289, -2.0841, -2.0418, -2.0759, -2.0666,\n",
      "        -2.1034, -2.0766, -2.0940, -2.0907, -2.0922, -2.0647, -2.0866, -2.0851,\n",
      "        -2.0724, -2.0850, -1.9819, -2.1399, -2.0884, -2.0069, -2.0320, -2.0981,\n",
      "        -2.0886, -2.0539, -2.0366, -2.0688, -2.1275, -2.0324, -2.0812, -2.0676,\n",
      "        -2.0249, -2.1040, -2.1032, -2.0762, -2.1225, -2.0984, -2.0814, -2.0995,\n",
      "        -2.1049, -2.0908, -2.0742, -2.0732, -2.0838, -2.0906, -2.0932, -2.1384,\n",
      "        -2.0903, -2.0803], device='mps:0')\n",
      "mean: tensor(-2.0807, device='mps:0')\n",
      "iter_dt 1.04s; iter 40: train loss 0.41750 temperature: 6.999999999999993\n",
      "mean_logits tensor([-2.0893, -2.2106, -1.9832, -1.9425, -2.4108, -2.4265, -1.9663, -1.9272,\n",
      "        -2.1723, -2.3247, -2.3592, -2.2991, -1.8916, -2.2700, -1.8177, -2.4502,\n",
      "        -1.7190, -2.0608, -2.1598, -2.1467, -2.0759, -2.2267, -2.0612, -2.2553,\n",
      "        -2.2147, -2.1175, -2.2976, -2.0759, -2.3106, -2.3434, -1.8024, -1.7494,\n",
      "        -2.4046, -2.1025, -2.2351, -2.1603, -2.2879, -1.9261, -1.9097, -2.1410,\n",
      "        -2.2874, -1.5904, -1.6708, -1.8964, -1.5072, -2.0585, -2.1673, -2.1676,\n",
      "        -2.0743, -1.7885], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0931, -2.0457, -2.0896, -2.0348, -2.0951, -2.0514, -2.1012, -2.1100,\n",
      "        -2.0888, -2.0845, -2.1011, -2.1030, -2.0750, -2.0513, -2.0659, -2.0427,\n",
      "        -2.0795, -2.1340, -2.0581, -2.0858, -2.0934, -2.0736, -2.1244, -2.0508,\n",
      "        -2.0960, -2.1097, -2.0896, -2.0296, -2.0319, -2.0246, -2.0268, -2.0382,\n",
      "        -2.0869, -2.0954, -2.0555, -2.0836, -2.0912, -2.0987, -2.0821, -2.0691,\n",
      "        -2.0831, -2.0650, -2.0193, -2.0455, -2.0424, -2.0923, -2.0606, -2.1127,\n",
      "        -2.0083, -2.0589], device='mps:0')\n",
      "mean: tensor(-2.0726, device='mps:0')\n",
      "iter_dt 1.05s; iter 41: train loss 0.23862 temperature: 7.049999999999993\n",
      "mean_logits tensor([-2.4486, -2.0535, -2.4490, -2.1914, -2.0199, -2.1841, -2.0584, -2.2111,\n",
      "        -1.9657, -1.9987, -2.2506, -1.9662, -2.1997, -2.3967, -2.0916, -2.1558,\n",
      "        -2.0475, -2.1941, -2.0870, -2.0523, -2.0315, -1.8949, -1.7960, -1.9533,\n",
      "        -2.2162, -2.3880, -1.9594, -2.1072, -2.0615, -1.9967, -2.2510, -2.0539,\n",
      "        -2.0111, -2.3067, -2.1351, -2.2118, -2.0387, -1.8845, -2.1218, -2.0996,\n",
      "        -2.0443, -2.0702, -1.8315, -2.1419, -2.2019, -2.1431, -2.0030, -2.4731,\n",
      "        -2.2039, -2.1828], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0576, -2.0911, -2.1083, -2.0857, -2.0483, -2.0918, -2.0817, -2.0664,\n",
      "        -2.1079, -2.0772, -2.0987, -2.0273, -2.1948, -2.1330, -2.1106, -2.0091,\n",
      "        -2.0652, -2.0635, -2.0845, -2.0593, -2.1152, -2.0872, -2.0722, -2.0639,\n",
      "        -2.1172, -2.0836, -2.0277, -2.1091, -2.1153, -2.0581, -2.1043, -2.0493,\n",
      "        -2.1016, -2.0494, -2.0855, -2.1005, -2.1494, -2.0372, -2.0754, -2.0926,\n",
      "        -2.0818, -2.0911, -1.9827, -2.0809, -2.0693, -2.0930, -2.0935, -2.1048,\n",
      "        -2.0222, -2.0464], device='mps:0')\n",
      "mean: tensor(-2.0804, device='mps:0')\n",
      "iter_dt 1.05s; iter 42: train loss 0.37427 temperature: 7.0999999999999925\n",
      "mean_logits tensor([-2.0636, -2.1881, -2.3103, -1.7822, -2.0649, -1.9807, -2.4896, -2.1926,\n",
      "        -2.3187, -1.9517, -2.0449, -2.2969, -1.8972, -2.0266, -1.9704, -1.9049,\n",
      "        -2.2594, -2.1295, -1.9682, -2.2040, -2.4288, -2.0131, -2.3504, -1.9420,\n",
      "        -2.1010, -1.8608, -1.8327, -2.2174, -1.8064, -2.0965, -1.7797, -2.3084,\n",
      "        -2.2867, -2.0140, -1.9861, -2.0231, -2.1099, -2.3577, -2.0743, -2.3191,\n",
      "        -2.0138, -2.5167, -1.8088, -1.9487, -2.0541, -1.8740, -2.1280, -2.4459,\n",
      "        -1.9509, -2.1256], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0475, -2.0952, -2.0881, -2.0713, -2.0013, -2.0996, -2.0886, -2.0933,\n",
      "        -2.0924, -2.1138, -2.1048, -2.0413, -2.0931, -2.0814, -2.0419, -2.0511,\n",
      "        -2.0497, -2.1128, -2.0594, -2.0685, -2.0772, -2.0919, -2.0780, -2.0619,\n",
      "        -2.0897, -2.0064, -2.0840, -2.0902, -2.0772, -2.0839, -2.0953, -2.0967,\n",
      "        -2.0694, -2.1064, -2.0720, -2.0458, -2.1308, -2.0718, -2.1038, -2.0925,\n",
      "        -2.0587, -2.0553, -2.0620, -2.0832, -2.0685, -2.0237, -2.0502, -2.0957,\n",
      "        -2.1039, -2.0556], device='mps:0')\n",
      "mean: tensor(-2.0755, device='mps:0')\n",
      "iter_dt 1.04s; iter 43: train loss 0.47620 temperature: 7.149999999999992\n",
      "mean_logits tensor([-2.1066, -1.9509, -1.8703, -2.1706, -2.1176, -2.0952, -1.8206, -2.1609,\n",
      "        -2.1980, -2.0172, -2.3115, -2.1959, -1.9167, -2.4122, -2.2998, -2.2332,\n",
      "        -1.6007, -2.0874, -1.8827, -1.9599, -2.2808, -2.3860, -1.8142, -2.0772,\n",
      "        -1.8797, -1.5535, -1.8883, -2.0010, -1.8852, -2.1720, -2.2349, -2.3054,\n",
      "        -2.5899, -2.3759, -2.0114, -1.8897, -2.1787, -1.7593, -1.9677, -2.5498,\n",
      "        -1.8512, -2.4078, -2.0491, -2.1179, -1.7919, -2.1540, -2.3741, -1.9149,\n",
      "        -2.0524, -1.8090], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0763, -2.0924, -2.0705, -2.0728, -2.0905, -2.0392, -2.0954, -2.0696,\n",
      "        -2.1457, -2.0821, -2.0446, -2.1101, -2.0349, -2.1026, -2.0806, -2.0939,\n",
      "        -2.0909, -2.0637, -2.1014, -2.0933, -2.0848, -2.0565, -2.0749, -2.0755,\n",
      "        -2.0995, -2.0395, -2.0843, -2.0879, -2.0889, -2.1014, -2.1175, -2.0857,\n",
      "        -2.0800, -2.0915, -2.1230, -2.1156, -2.0877, -2.1125, -2.0626, -2.1298,\n",
      "        -2.0907, -2.0824, -2.0423, -2.0758, -2.1011, -2.0663, -2.1047, -2.0851,\n",
      "        -2.1081, -2.0851], device='mps:0')\n",
      "mean: tensor(-2.0858, device='mps:0')\n",
      "iter_dt 1.03s; iter 44: train loss 0.28301 temperature: 7.199999999999992\n",
      "mean_logits tensor([-1.4756, -2.0274, -2.1256, -2.0521, -2.1646, -2.0701, -1.8598, -1.8850,\n",
      "        -2.1138, -2.0765, -1.8345, -2.1903, -1.9546, -1.7421, -1.9179, -2.2110,\n",
      "        -1.9319, -2.0644, -2.1481, -1.9528, -1.8290, -1.9151, -2.0500, -2.0788,\n",
      "        -2.0377, -2.0302, -1.6744, -2.1677, -2.0391, -1.7581, -2.0081, -2.2825,\n",
      "        -1.7690, -1.9869, -2.3406, -2.2071, -2.2544, -2.1525, -2.0717, -1.7671,\n",
      "        -1.8205, -2.0960, -2.1457, -2.0246, -1.8609, -2.0857, -2.1678, -1.7904,\n",
      "        -2.4407, -2.3839], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0775, -2.0709, -2.0400, -2.0893, -2.0931, -2.0980, -2.0369, -2.0986,\n",
      "        -2.0922, -2.1018, -2.0952, -2.0630, -2.0832, -2.0916, -2.0745, -2.0957,\n",
      "        -2.1159, -2.0757, -2.1032, -2.0895, -2.0749, -2.0790, -2.0857, -2.0559,\n",
      "        -2.1175, -2.0843, -2.0163, -2.0766, -2.0996, -2.0590, -2.0555, -2.0867,\n",
      "        -2.0210, -2.0233, -2.1154, -2.1057, -2.1048, -2.1033, -2.0931, -2.1177,\n",
      "        -2.1132, -2.0621, -2.0836, -2.1570, -2.0902, -2.0674, -2.0685, -2.0628,\n",
      "        -2.0299, -2.0882], device='mps:0')\n",
      "mean: tensor(-2.0817, device='mps:0')\n",
      "iter_dt 1.02s; iter 45: train loss 0.52535 temperature: 7.249999999999992\n",
      "mean_logits tensor([-2.1402, -2.1514, -2.0316, -2.1269, -2.1601, -2.3667, -2.2173, -2.1184,\n",
      "        -2.1394, -2.4247, -2.2824, -2.4262, -2.0066, -2.1017, -2.0792, -1.7994,\n",
      "        -1.8526, -2.2817, -2.2083, -2.5256, -2.0826, -2.0592, -2.0170, -2.0782,\n",
      "        -2.1065, -1.9281, -1.9556, -2.2838, -2.4093, -2.0093, -2.3462, -2.1044,\n",
      "        -2.1232, -1.6267, -2.0861, -1.6979, -2.0416, -2.4494, -1.9711, -2.4590,\n",
      "        -2.4211, -2.5784, -2.1773, -2.0481, -2.1926, -1.9348, -2.1098, -2.3063,\n",
      "        -2.0930, -2.1493], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0667, -2.0879, -2.0996, -2.0679, -2.0618, -2.0944, -2.1193, -2.0838,\n",
      "        -2.0885, -1.9403, -2.0275, -2.0576, -2.0290, -2.0909, -2.0653, -2.0412,\n",
      "        -2.0790, -2.0946, -2.0746, -2.0776, -2.0747, -1.9889, -2.0379, -2.0932,\n",
      "        -2.0919, -2.0881, -2.0860, -2.0801, -2.0702, -2.0381, -2.1627, -2.1094,\n",
      "        -2.0567, -2.1191, -2.1032, -2.1065, -2.1063, -2.0805, -2.0948, -2.0764,\n",
      "        -2.0731, -1.9883, -2.0865, -2.1206, -2.0514, -2.0722, -2.0659, -2.0763,\n",
      "        -2.0479, -2.0797], device='mps:0')\n",
      "mean: tensor(-2.0735, device='mps:0')\n",
      "iter_dt 1.03s; iter 46: train loss 0.24359 temperature: 7.299999999999992\n",
      "mean_logits tensor([-2.0796, -2.0264, -1.8700, -2.2382, -2.2259, -2.3239, -1.9599, -2.2341,\n",
      "        -2.0588, -1.8173, -2.0305, -2.2987, -1.9995, -2.2789, -1.9072, -2.3208,\n",
      "        -2.1091, -2.0546, -1.7674, -2.3237, -2.1498, -2.2520, -1.7793, -2.0782,\n",
      "        -2.1721, -2.1295, -2.1345, -2.2038, -2.1715, -2.0410, -1.6137, -1.9999,\n",
      "        -2.0032, -2.2144, -1.7652, -1.9986, -1.9336, -2.1162, -1.9214, -2.1956,\n",
      "        -2.2379, -2.1168, -1.9762, -1.9937, -2.1524, -1.8315, -2.3199, -1.7712,\n",
      "        -1.9841, -1.9540], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0622, -2.0417, -2.0739, -2.0811, -2.0954, -2.0006, -2.0256, -2.1060,\n",
      "        -2.1094, -2.0888, -2.0585, -2.0633, -2.0584, -2.0493, -2.0803, -2.1300,\n",
      "        -2.0863, -2.0687, -2.0654, -2.0962, -2.0864, -2.0859, -2.0520, -2.0859,\n",
      "        -2.0683, -2.0274, -2.0611, -2.0366, -2.1080, -2.1065, -2.0931, -2.0997,\n",
      "        -2.0839, -2.0696, -2.1037, -2.1224, -2.0695, -2.0807, -2.0781, -2.0839,\n",
      "        -2.0758, -2.1162, -2.0828, -2.0722, -2.0648, -2.0845, -2.0871, -2.0904,\n",
      "        -2.0757, -2.0806], device='mps:0')\n",
      "mean: tensor(-2.0775, device='mps:0')\n",
      "iter_dt 1.03s; iter 47: train loss 0.41647 temperature: 7.349999999999992\n",
      "mean_logits tensor([-1.9949, -2.0992, -2.2719, -2.4277, -2.1513, -2.2802, -2.2333, -2.3479,\n",
      "        -1.8870, -1.7564, -2.0465, -1.8856, -2.3389, -1.8150, -1.7688, -2.4017,\n",
      "        -2.3441, -2.1398, -2.2373, -1.6245, -2.2243, -2.1534, -1.8854, -1.9536,\n",
      "        -2.0536, -2.1569, -1.6175, -2.1315, -2.1009, -2.1334, -1.9125, -2.3835,\n",
      "        -1.8584, -2.2930, -1.7751, -2.0382, -2.2436, -2.1999, -2.4695, -2.2459,\n",
      "        -2.4026, -2.1376, -2.0963, -2.2283, -2.1814, -1.9713, -2.2292, -1.8539,\n",
      "        -1.7791, -2.2042], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0997, -2.1703, -2.0862, -2.0790, -2.0855, -2.0419, -2.0891, -2.0896,\n",
      "        -2.0881, -2.0035, -2.1345, -2.0843, -2.0456, -2.1198, -2.1101, -2.0886,\n",
      "        -1.9911, -2.0356, -2.0959, -2.0718, -2.0745, -2.1080, -2.0869, -2.0814,\n",
      "        -2.0829, -2.0659, -2.0069, -2.0853, -2.0600, -2.0922, -2.1100, -2.0542,\n",
      "        -2.0916, -2.0822, -2.0487, -2.0756, -2.0595, -2.1081, -2.0841, -2.0645,\n",
      "        -2.1425, -2.0925, -2.1165, -2.1008, -2.0969, -2.1159, -2.0511, -2.1103,\n",
      "        -2.0823, -2.0960], device='mps:0')\n",
      "mean: tensor(-2.0828, device='mps:0')\n",
      "iter_dt 1.00s; iter 48: train loss 0.20946 temperature: 7.3999999999999915\n",
      "mean_logits tensor([-1.8565, -1.8047, -2.2995, -2.1654, -1.9295, -2.2084, -1.8355, -2.3283,\n",
      "        -2.1428, -2.1610, -2.0589, -1.9196, -1.8864, -1.8913, -2.0101, -2.0868,\n",
      "        -1.8673, -2.2421, -1.8652, -2.0662, -2.1762, -1.8646, -1.6642, -2.0878,\n",
      "        -1.8842, -1.9154, -2.0121, -1.8514, -2.0010, -2.0109, -2.0124, -2.0323,\n",
      "        -2.0253, -2.1456, -2.1105, -2.0407, -2.1074, -2.3588, -2.0126, -1.9368,\n",
      "        -1.9580, -2.0872, -1.8794, -1.8910, -2.1248, -1.9734, -2.0183, -1.9922,\n",
      "        -1.7696, -2.2741], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0610, -2.1086, -2.0962, -2.0950, -2.1012, -2.0622, -2.0917, -2.0989,\n",
      "        -2.0966, -2.0755, -2.0582, -2.0962, -2.0895, -2.0282, -2.0211, -2.0699,\n",
      "        -2.0618, -2.1018, -2.0991, -2.0953, -2.1416, -2.0759, -2.1111, -2.0712,\n",
      "        -2.0899, -2.0919, -2.1159, -2.0710, -2.0853, -2.1122, -2.1005, -2.0884,\n",
      "        -2.0917, -2.0948, -2.0882, -2.1278, -2.0805, -2.0636, -2.0884, -2.1147,\n",
      "        -2.0901, -2.0868, -2.0604, -2.1004, -2.0911, -2.0822, -2.0543, -2.0948,\n",
      "        -2.0542, -2.0742], device='mps:0')\n",
      "mean: tensor(-2.0860, device='mps:0')\n",
      "iter_dt 1.03s; iter 49: train loss 0.48198 temperature: 7.449999999999991\n",
      "mean_logits tensor([-2.3165, -1.9704, -2.3730, -2.4063, -1.7334, -2.0581, -2.5399, -1.9860,\n",
      "        -2.1633, -2.0879, -2.1795, -1.8608, -2.1036, -2.1175, -1.9570, -1.9669,\n",
      "        -1.9936, -2.1833, -2.4205, -2.3120, -2.1002, -1.8721, -2.2265, -1.9234,\n",
      "        -2.0249, -2.1388, -2.0174, -1.8826, -1.8823, -1.7469, -2.2883, -2.1376,\n",
      "        -1.7451, -1.8686, -2.4533, -2.4605, -1.7646, -2.0779, -2.0930, -2.0254,\n",
      "        -1.7447, -2.0269, -2.2683, -2.2028, -2.0949, -1.6595, -1.7628, -1.6505,\n",
      "        -2.4042, -2.3091], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0683, -2.0921, -2.1062, -2.0472, -2.0780, -2.0858, -2.0332, -2.0930,\n",
      "        -2.1302, -2.0743, -2.0956, -2.0681, -2.1000, -2.0885, -2.0896, -2.1006,\n",
      "        -2.1101, -2.1111, -2.0805, -2.0546, -2.0789, -2.0434, -2.0913, -2.0611,\n",
      "        -2.0873, -2.1171, -2.0606, -2.0894, -2.0563, -2.0922, -2.0683, -2.0500,\n",
      "        -2.0428, -2.0915, -2.1295, -2.0543, -2.1002, -2.0626, -2.0687, -2.1133,\n",
      "        -2.0990, -2.0745, -2.0668, -2.0588, -2.0722, -2.0777, -2.0910, -2.0952,\n",
      "        -2.0988, -2.0607], device='mps:0')\n",
      "mean: tensor(-2.0812, device='mps:0')\n",
      "iter_dt 1.03s; iter 50: train loss 0.36749 temperature: 7.499999999999991\n",
      "mean_logits tensor([-1.6791, -2.1252, -2.2947, -2.0398, -2.3597, -2.5287, -1.9839, -2.1795,\n",
      "        -2.2854, -2.1906, -1.9105, -1.9906, -1.9648, -1.8960, -2.1587, -2.3284,\n",
      "        -2.0956, -2.0738, -2.2094, -2.0408, -2.2709, -2.0344, -2.0918, -1.9388,\n",
      "        -2.0277, -2.0549, -2.1100, -2.1665, -1.8044, -1.9219, -2.2247, -2.0451,\n",
      "        -1.9236, -2.1332, -1.6266, -2.4073, -2.1232, -1.9553, -1.7560, -2.2166,\n",
      "        -2.4442, -1.9082, -1.8207, -1.9978, -1.9922, -2.1221, -2.2541, -2.3641,\n",
      "        -2.2842, -2.3784], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0948, -2.0846, -2.0138, -2.0672, -2.0637, -2.1293, -2.0851, -2.1214,\n",
      "        -2.1186, -2.0357, -2.1055, -2.1311, -2.1400, -2.0742, -2.0941, -2.0850,\n",
      "        -2.0898, -2.0824, -2.0951, -2.0876, -2.0817, -2.0380, -2.0523, -2.0836,\n",
      "        -2.0714, -2.0333, -2.0689, -2.0984, -2.0876, -2.0930, -2.0828, -2.1052,\n",
      "        -2.0649, -2.1059, -2.1009, -2.0356, -2.1199, -2.0865, -1.9965, -2.0611,\n",
      "        -2.0615, -2.0915, -2.0532, -2.0833, -2.1157, -2.0596, -2.0868, -2.1366,\n",
      "        -2.0531, -2.0407], device='mps:0')\n",
      "mean: tensor(-2.0810, device='mps:0')\n",
      "iter_dt 1.03s; iter 51: train loss 0.22987 temperature: 7.549999999999991\n",
      "mean_logits tensor([-2.1472, -2.0725, -2.1781, -1.3903, -1.5755, -2.0156, -2.0125, -1.7912,\n",
      "        -1.8934, -2.0827, -2.1118, -2.3178, -2.1616, -2.0543, -1.8866, -2.1502,\n",
      "        -2.0993, -1.8413, -2.0817, -2.2506, -2.0004, -2.1687, -2.2574, -2.2006,\n",
      "        -2.1450, -1.9070, -2.1218, -2.1939, -2.3187, -2.0702, -2.0968, -1.8788,\n",
      "        -1.9899, -2.1649, -1.9544, -1.9165, -2.3967, -2.1010, -2.2893, -2.0803,\n",
      "        -2.0709, -1.7478, -1.9083, -2.0032, -2.2846, -2.0853, -1.9948, -2.0932,\n",
      "        -2.1840, -2.0585], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0931, -2.0521, -2.0589, -2.0430, -2.0747, -1.9457, -2.0576, -2.0804,\n",
      "        -2.0506, -2.0585, -2.0874, -2.1000, -2.1070, -2.0727, -2.0633, -2.0896,\n",
      "        -2.0908, -2.0895, -2.0920, -2.0716, -2.1303, -2.0463, -2.0773, -2.0947,\n",
      "        -2.0856, -2.0881, -2.0886, -2.0721, -2.0523, -2.0926, -2.1070, -2.0879,\n",
      "        -2.1018, -2.0067, -2.0840, -2.0711, -2.0972, -2.0966, -2.0795, -2.0866,\n",
      "        -2.0366, -2.0822, -2.0703, -2.0583, -2.1316, -2.0915, -2.0911, -2.0892,\n",
      "        -2.0874, -2.0887], device='mps:0')\n",
      "mean: tensor(-2.0770, device='mps:0')\n",
      "iter_dt 1.03s; iter 52: train loss 0.27130 temperature: 7.599999999999991\n",
      "mean_logits tensor([-1.9623, -2.2794, -1.9511, -1.9356, -2.1545, -2.3267, -1.6998, -2.1635,\n",
      "        -2.2864, -2.1177, -1.9824, -1.9401, -2.1091, -1.8749, -2.0889, -2.3119,\n",
      "        -2.1717, -1.8947, -2.2232, -1.9418, -2.1493, -2.0246, -1.8179, -2.1625,\n",
      "        -1.9620, -2.3788, -1.9459, -2.0808, -2.2648, -2.1374, -2.0053, -1.9565,\n",
      "        -1.9292, -1.8776, -2.3032, -2.0674, -1.9214, -2.0784, -2.0420, -1.6945,\n",
      "        -2.2513, -1.9596, -2.3652, -1.9255, -2.1267, -2.0981, -2.2103, -1.7437,\n",
      "        -1.7372, -2.1600], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0858, -2.0487, -2.0625, -2.0907, -2.0337, -2.0868, -2.0803, -2.0974,\n",
      "        -2.0764, -2.0674, -2.0950, -2.0965, -2.1049, -2.0857, -2.0646, -2.0739,\n",
      "        -2.0876, -2.0917, -2.0913, -2.0909, -2.0890, -2.0602, -2.1124, -2.0709,\n",
      "        -2.0862, -2.0419, -2.0516, -2.0426, -2.0783, -2.0937, -2.0819, -2.0865,\n",
      "        -2.0615, -2.0890, -2.0752, -2.0914, -2.0772, -2.0929, -2.0752, -2.1023,\n",
      "        -2.1037, -2.0841, -2.1285, -2.0918, -2.0588, -2.0729, -2.0698, -2.1430,\n",
      "        -2.1011, -2.0471], device='mps:0')\n",
      "mean: tensor(-2.0814, device='mps:0')\n",
      "iter_dt 1.01s; iter 53: train loss 0.36114 temperature: 7.649999999999991\n",
      "mean_logits tensor([-2.1222, -2.2157, -2.0347, -2.4692, -2.0601, -1.9772, -1.9011, -2.5491,\n",
      "        -2.1483, -2.3120, -2.1706, -1.7842, -2.0367, -1.9592, -2.0496, -2.2880,\n",
      "        -2.1460, -2.1583, -1.8739, -1.9864, -2.0843, -2.0829, -2.1711, -1.6835,\n",
      "        -2.3225, -1.8882, -2.0322, -2.0821, -2.1840, -2.0984, -2.0098, -1.9344,\n",
      "        -2.2211, -1.9008, -2.0841, -2.1714, -2.5627, -2.2131, -2.3828, -2.3295,\n",
      "        -1.8158, -2.2186, -2.3664, -1.9581, -1.9514, -2.2116, -2.2629, -1.7739,\n",
      "        -2.0642, -2.0473], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1096, -2.1227, -2.1053, -2.0889, -2.0599, -2.0632, -2.0981, -2.1225,\n",
      "        -2.1019, -2.0360, -2.0817, -2.0670, -2.0714, -2.1333, -2.0820, -2.1024,\n",
      "        -2.0928, -2.0565, -2.0778, -2.0845, -2.1218, -2.1105, -2.0566, -2.0568,\n",
      "        -2.0960, -2.0515, -2.0674, -2.0865, -2.0939, -2.0553, -2.1043, -2.0521,\n",
      "        -2.0338, -2.0777, -2.0712, -2.0893, -2.0869, -2.0920, -2.0853, -2.0535,\n",
      "        -2.0656, -2.0806, -2.1154, -2.0735, -2.0606, -2.1167, -2.0936, -2.0786,\n",
      "        -2.0534, -2.0894], device='mps:0')\n",
      "mean: tensor(-2.0825, device='mps:0')\n",
      "iter_dt 1.03s; iter 54: train loss 0.31429 temperature: 7.69999999999999\n",
      "mean_logits tensor([-2.1494, -1.9248, -2.4033, -2.2030, -2.1570, -2.0940, -2.3385, -2.0345,\n",
      "        -1.7627, -2.0858, -2.1355, -2.2900, -1.8921, -2.0930, -2.1842, -2.1306,\n",
      "        -2.2130, -1.8808, -2.3779, -2.0578, -2.1313, -2.0824, -2.0456, -2.1156,\n",
      "        -2.1787, -2.3293, -2.3215, -2.0849, -2.0616, -1.9251, -2.2963, -1.7840,\n",
      "        -2.2335, -1.9285, -2.1702, -2.4313, -2.1851, -2.0590, -2.2717, -2.0760,\n",
      "        -2.1948, -1.7329, -2.1387, -2.3982, -2.3098, -1.8380, -1.9757, -2.4539,\n",
      "        -2.1109, -2.2287], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0895, -2.0890, -2.0367, -2.0971, -2.1492, -2.0879, -2.1066, -2.1249,\n",
      "        -2.0860, -2.0769, -2.0384, -2.1069, -2.0187, -2.0869, -2.0945, -2.0566,\n",
      "        -2.0834, -2.0871, -2.0732, -2.0854, -2.0955, -2.0884, -2.1115, -2.0914,\n",
      "        -2.0102, -2.0751, -2.0976, -2.0781, -2.0809, -2.0801, -2.0839, -2.0728,\n",
      "        -2.1428, -2.0980, -2.1309, -2.1171, -2.0820, -2.0864, -2.0774, -2.1036,\n",
      "        -2.0455, -2.0826, -2.0902, -2.0760, -2.0776, -2.0524, -2.0681, -2.0871,\n",
      "        -2.1084, -2.0368], device='mps:0')\n",
      "mean: tensor(-2.0841, device='mps:0')\n",
      "iter_dt 1.04s; iter 55: train loss 0.30931 temperature: 7.74999999999999\n",
      "mean_logits tensor([-2.2417, -2.2518, -2.3970, -2.1399, -2.4319, -2.0106, -1.9904, -1.8955,\n",
      "        -2.0889, -2.0901, -1.8672, -2.4261, -2.0395, -2.2121, -2.0237, -2.2708,\n",
      "        -2.1283, -2.4765, -1.9992, -2.3484, -2.2068, -1.9922, -2.3105, -1.9605,\n",
      "        -2.1244, -2.1345, -2.1436, -1.9528, -1.9813, -2.1676, -1.8907, -2.1700,\n",
      "        -1.9959, -2.0623, -2.1167, -2.1055, -2.2498, -1.8379, -2.1122, -2.0622,\n",
      "        -1.6899, -2.1954, -2.2281, -2.4094, -2.1790, -2.1800, -2.3150, -1.9409,\n",
      "        -1.9466, -2.1220], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0939, -2.1062, -2.1084, -2.0628, -2.0874, -2.0570, -2.0023, -2.0752,\n",
      "        -2.0442, -2.0336, -2.0619, -2.0367, -2.0974, -2.0878, -2.0905, -2.1015,\n",
      "        -2.0857, -2.0741, -2.0991, -2.1278, -2.1107, -2.1126, -2.0800, -2.0609,\n",
      "        -2.0255, -2.0442, -2.1169, -2.1144, -2.0677, -2.0425, -2.0942, -2.0777,\n",
      "        -2.0870, -2.0853, -2.1295, -2.0919, -2.0640, -2.1108, -2.0637, -2.0841,\n",
      "        -2.1208, -2.0494, -2.0891, -2.0984, -2.0644, -2.0621, -2.0967, -2.0849,\n",
      "        -2.1302, -2.0847], device='mps:0')\n",
      "mean: tensor(-2.0816, device='mps:0')\n",
      "iter_dt 1.05s; iter 56: train loss 0.37467 temperature: 7.79999999999999\n",
      "mean_logits tensor([-2.1986, -1.7433, -1.8823, -2.0842, -2.0615, -2.0889, -1.8605, -2.2535,\n",
      "        -2.5282, -1.9287, -1.9924, -1.9080, -2.2875, -2.0864, -1.7300, -1.6741,\n",
      "        -2.0832, -2.1999, -1.9861, -2.2409, -2.0530, -2.0300, -2.2617, -2.1425,\n",
      "        -1.5896, -1.9830, -2.0463, -1.9852, -2.1649, -2.5104, -1.9170, -1.6618,\n",
      "        -1.6931, -2.0594, -1.5175, -2.2200, -2.1464, -1.9408, -2.0992, -2.0361,\n",
      "        -2.0696, -1.7733, -2.1013, -1.9789, -1.9249, -2.2102, -2.3246, -2.1943,\n",
      "        -1.9955, -2.2403], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0892, -2.0618, -2.0585, -2.0947, -2.0283, -2.1148, -2.1086, -2.0858,\n",
      "        -2.0778, -2.0517, -2.0819, -2.0596, -2.0117, -2.1057, -2.1214, -2.0710,\n",
      "        -2.0960, -2.0770, -2.0851, -2.1085, -2.0782, -2.0537, -2.0844, -2.0881,\n",
      "        -2.0835, -2.0934, -2.0060, -2.0999, -2.1095, -2.0626, -2.0796, -2.0910,\n",
      "        -2.0363, -2.0803, -2.0911, -2.0779, -2.0645, -2.0901, -2.1252, -2.0109,\n",
      "        -2.0875, -2.0845, -2.0417, -2.0744, -2.0712, -2.0669, -2.0867, -2.0766,\n",
      "        -2.0642, -2.0920], device='mps:0')\n",
      "mean: tensor(-2.0768, device='mps:0')\n",
      "iter_dt 1.04s; iter 57: train loss 0.24166 temperature: 7.84999999999999\n",
      "mean_logits tensor([-1.3956, -2.0756, -2.2427, -2.0015, -2.1852, -2.1071, -2.0974, -2.1327,\n",
      "        -2.0025, -1.9288, -1.8297, -2.0358, -2.3642, -1.6823, -2.1339, -1.9806,\n",
      "        -1.8783, -2.2687, -2.1847, -2.1012, -2.1114, -1.8738, -2.0922, -2.1912,\n",
      "        -2.0503, -1.9379, -1.9454, -1.7252, -1.9747, -1.8512, -1.9590, -2.1602,\n",
      "        -1.9877, -1.9798, -1.9190, -2.2704, -2.0516, -1.8954, -1.7692, -1.7249,\n",
      "        -1.9591, -2.0346, -1.9868, -2.0978, -2.1490, -1.8873, -2.2699, -2.1300,\n",
      "        -2.1165, -2.3896], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0648, -2.0968, -2.0523, -2.0930, -2.1011, -2.0700, -2.0981, -2.0677,\n",
      "        -2.1239, -2.1047, -2.0623, -2.0597, -2.0967, -2.0757, -2.1308, -2.0358,\n",
      "        -2.0448, -2.0811, -2.1250, -2.0823, -2.0660, -2.0748, -2.0815, -2.0892,\n",
      "        -2.0598, -2.0959, -2.1090, -2.0889, -2.0735, -2.0532, -2.1362, -2.0707,\n",
      "        -2.0919, -2.0750, -2.0747, -2.0846, -2.0893, -2.0736, -2.0416, -2.0932,\n",
      "        -2.1211, -2.0493, -2.0678, -2.0674, -2.0953, -2.0841, -2.1366, -2.0793,\n",
      "        -2.0777, -2.0927], device='mps:0')\n",
      "mean: tensor(-2.0832, device='mps:0')\n",
      "iter_dt 1.05s; iter 58: train loss 0.38287 temperature: 7.89999999999999\n",
      "mean_logits tensor([-1.9783, -2.3426, -1.9343, -2.1887, -2.0973, -2.0251, -2.2684, -2.3298,\n",
      "        -2.1438, -2.2812, -2.2466, -1.9722, -2.2929, -1.8976, -1.7871, -2.3969,\n",
      "        -2.0391, -1.8340, -2.3508, -1.9224, -2.1714, -1.7062, -2.3429, -2.1047,\n",
      "        -2.1861, -2.2703, -2.2001, -2.0058, -2.1302, -2.2076, -2.0009, -1.9774,\n",
      "        -2.3997, -1.8835, -2.2745, -2.1140, -1.9040, -2.2789, -2.2075, -2.3901,\n",
      "        -2.2001, -2.1929, -2.0131, -1.9630, -2.2643, -2.5003, -1.9578, -2.3704,\n",
      "        -1.9552, -2.3411], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0603, -2.0375, -2.0609, -2.0471, -2.0927, -1.9584, -2.0945, -2.0557,\n",
      "        -2.0672, -2.0525, -2.1172, -2.0584, -2.0920, -2.0739, -2.0886, -2.0722,\n",
      "        -2.0997, -2.0956, -2.0833, -2.0915, -2.0570, -2.0316, -2.0983, -2.0370,\n",
      "        -2.0924, -2.0855, -2.0060, -2.0491, -2.0798, -2.1242, -2.0486, -2.0328,\n",
      "        -2.0462, -2.0806, -2.0793, -2.1159, -2.0716, -2.0899, -1.9949, -2.1161,\n",
      "        -2.1473, -2.0592, -2.1074, -2.0361, -2.0930, -2.0680, -2.1349, -2.0790,\n",
      "        -2.0897, -2.0817], device='mps:0')\n",
      "mean: tensor(-2.0726, device='mps:0')\n",
      "iter_dt 1.07s; iter 59: train loss 0.36624 temperature: 7.9499999999999895\n",
      "mean_logits tensor([-2.4357, -2.0379, -1.9671, -2.1006, -2.1601, -2.0857, -2.2294, -2.2232,\n",
      "        -2.4561, -1.9291, -1.8314, -2.2464, -2.1613, -2.0638, -1.9966, -2.0559,\n",
      "        -1.8395, -2.1793, -2.2869, -2.3178, -2.1789, -1.9507, -2.0819, -2.2549,\n",
      "        -2.3651, -2.1178, -1.7645, -2.1297, -1.9228, -1.8294, -2.5059, -2.4397,\n",
      "        -1.9816, -2.0863, -2.1739, -2.0922, -2.3058, -2.2215, -2.0886, -2.0030,\n",
      "        -2.3003, -2.0603, -1.9337, -1.8077, -2.0150, -2.2803, -2.3870, -1.7592,\n",
      "        -1.9215, -2.1526], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0696, -2.0599, -2.0406, -2.1038, -2.0346, -2.0972, -2.0910, -2.0889,\n",
      "        -2.0739, -2.0825, -2.0680, -2.0834, -2.1052, -2.0006, -2.1238, -2.0651,\n",
      "        -2.0503, -2.1372, -2.1071, -2.0081, -2.0771, -2.0891, -2.0796, -2.0898,\n",
      "        -2.0633, -2.0327, -2.0383, -2.0603, -2.0404, -2.1196, -2.0756, -2.0742,\n",
      "        -2.0951, -2.0620, -2.0379, -2.0730, -2.1059, -2.0813, -2.0904, -2.0561,\n",
      "        -2.0735, -2.0897, -2.0720, -2.0578, -2.0959, -2.0830, -2.0763, -2.0703,\n",
      "        -2.0727, -2.0355], device='mps:0')\n",
      "mean: tensor(-2.0732, device='mps:0')\n",
      "iter_dt 1.03s; iter 60: train loss 0.29602 temperature: 7.999999999999989\n",
      "mean_logits tensor([-2.0562, -2.3883, -2.2166, -2.2108, -2.0312, -2.0351, -2.3601, -1.6102,\n",
      "        -1.7946, -2.0997, -2.2743, -2.1722, -1.5974, -2.0039, -2.3620, -1.8239,\n",
      "        -1.9923, -2.0785, -2.2155, -1.6929, -2.1129, -1.9768, -2.2525, -2.1866,\n",
      "        -2.0224, -1.8339, -1.9874, -2.0869, -2.2966, -2.0815, -2.3139, -2.2357,\n",
      "        -1.8783, -1.9684, -2.2598, -2.2362, -2.2676, -2.0257, -2.3260, -2.2202,\n",
      "        -1.9965, -2.3492, -2.1352, -2.1708, -2.0745, -2.1598, -2.1830, -2.0964,\n",
      "        -2.0982, -2.3433], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0823, -2.0775, -2.0582, -2.0671, -2.0415, -2.0352, -2.0934, -2.0896,\n",
      "        -2.1060, -2.0747, -2.1305, -2.0901, -2.0578, -2.0858, -2.0839, -2.0890,\n",
      "        -2.0595, -2.0494, -2.0774, -2.0998, -2.1003, -2.1003, -2.0829, -2.0804,\n",
      "        -2.1071, -2.0811, -2.0997, -2.0879, -2.0800, -2.0747, -2.1396, -2.0331,\n",
      "        -2.0894, -2.0807, -2.0769, -2.0653, -2.0905, -2.0874, -2.1158, -2.1231,\n",
      "        -2.0832, -2.0590, -2.0722, -2.1136, -2.0496, -2.0794, -2.0938, -2.0734,\n",
      "        -2.1121, -2.0939], device='mps:0')\n",
      "mean: tensor(-2.0835, device='mps:0')\n",
      "iter_dt 1.05s; iter 61: train loss 0.26574 temperature: 8.04999999999999\n",
      "mean_logits tensor([-2.0228, -2.0058, -2.0556, -1.9790, -1.9979, -2.1440, -2.3724, -2.3728,\n",
      "        -2.0006, -1.9390, -2.1770, -2.0940, -2.0011, -2.1765, -1.9908, -2.0985,\n",
      "        -2.1941, -2.1717, -1.9175, -2.0844, -1.8584, -1.9974, -1.9727, -1.8475,\n",
      "        -2.1665, -1.8895, -2.2260, -1.9842, -2.0169, -2.0297, -2.3962, -2.4571,\n",
      "        -1.9917, -1.8796, -1.9086, -2.3037, -2.2445, -2.1340, -2.0372, -1.9063,\n",
      "        -2.0102, -2.2816, -1.8850, -2.2619, -2.1898, -1.9555, -2.3323, -2.1604,\n",
      "        -2.1935, -2.3805], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0554, -2.0953, -2.1214, -2.0204, -2.0730, -2.0900, -2.0917, -2.0489,\n",
      "        -2.0740, -2.0917, -2.0943, -2.0991, -2.0409, -2.0859, -2.0627, -2.0780,\n",
      "        -2.0763, -2.0885, -2.0881, -2.0543, -2.0971, -2.0838, -2.0909, -2.0854,\n",
      "        -2.0840, -2.0511, -2.0730, -2.0795, -2.1329, -2.0334, -2.0666, -2.0842,\n",
      "        -2.0402, -2.0480, -2.0812, -2.0839, -2.0485, -2.0662, -2.0916, -2.0867,\n",
      "        -2.0431, -2.0388, -2.0828, -2.0512, -2.0247, -2.1460, -2.0791, -2.0745,\n",
      "        -2.0880, -2.0953], device='mps:0')\n",
      "mean: tensor(-2.0752, device='mps:0')\n",
      "iter_dt 1.07s; iter 62: train loss 0.26990 temperature: 8.09999999999999\n",
      "mean_logits tensor([-2.1623, -1.7859, -1.9989, -2.0647, -2.0459, -2.1612, -1.9718, -1.8503,\n",
      "        -2.1259, -2.0214, -2.0774, -2.2919, -2.1655, -1.8686, -1.9839, -2.2200,\n",
      "        -1.8793, -2.0280, -2.1311, -2.0771, -2.1606, -2.3307, -1.9259, -2.3194,\n",
      "        -2.0272, -1.5853, -2.1284, -2.1480, -2.0759, -1.9146, -1.9746, -2.2658,\n",
      "        -2.1533, -1.6844, -2.1089, -2.1163, -2.1571, -2.0489, -1.9529, -2.0438,\n",
      "        -1.7670, -1.7498, -1.9425, -2.4033, -1.6420, -1.8131, -2.2771, -2.0336,\n",
      "        -2.2968, -2.3318], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0731, -2.1052, -2.0727, -2.0483, -2.1065, -2.1043, -2.0628, -2.1073,\n",
      "        -2.1067, -2.0687, -2.0875, -2.0798, -2.0571, -2.1121, -2.0869, -2.0557,\n",
      "        -2.0695, -2.0832, -2.1087, -2.0619, -2.0923, -2.0673, -2.0580, -2.1000,\n",
      "        -2.0209, -2.0656, -2.0910, -2.1197, -2.0715, -2.0989, -2.0814, -2.0904,\n",
      "        -2.1290, -2.0663, -2.0874, -2.0602, -2.0715, -2.0800, -2.0358, -2.0670,\n",
      "        -2.0942, -2.0926, -2.0801, -2.0747, -2.0999, -2.0996, -2.1775, -2.0880,\n",
      "        -2.0809, -2.0841], device='mps:0')\n",
      "mean: tensor(-2.0837, device='mps:0')\n",
      "iter_dt 1.04s; iter 63: train loss 0.27625 temperature: 8.149999999999991\n",
      "mean_logits tensor([-2.0455, -1.9235, -2.4446, -2.2861, -1.8405, -1.9524, -2.1461, -2.1430,\n",
      "        -2.0318, -2.1907, -1.7452, -1.8222, -2.1141, -1.6522, -2.2099, -1.9752,\n",
      "        -2.0796, -2.3709, -2.1592, -2.1656, -2.0910, -2.3031, -2.3502, -2.0729,\n",
      "        -2.1333, -2.1563, -2.3481, -2.0260, -2.1107, -2.1728, -2.0741, -1.8502,\n",
      "        -2.3024, -1.9028, -1.8175, -1.9948, -1.9391, -2.0554, -2.3779, -2.0455,\n",
      "        -2.0106, -2.1109, -2.0820, -1.9847, -2.1385, -1.9689, -2.1116, -2.1949,\n",
      "        -2.2067, -1.9238], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0924, -2.0968, -1.9986, -2.0869, -2.0595, -2.0864, -2.0402, -2.1015,\n",
      "        -2.0826, -2.0271, -2.0901, -2.0908, -2.0812, -2.0833, -2.0790, -2.0397,\n",
      "        -2.0750, -2.0976, -2.0433, -2.0827, -2.0514, -2.0866, -2.0895, -2.0787,\n",
      "        -2.0793, -2.1036, -2.0886, -2.0847, -2.0425, -2.0892, -2.0936, -2.0908,\n",
      "        -2.1126, -2.1119, -2.0880, -1.9938, -2.0682, -2.0878, -2.0146, -2.0670,\n",
      "        -2.0941, -2.0851, -2.0833, -2.0946, -2.0954, -2.0691, -2.1515, -2.0457,\n",
      "        -2.0751, -2.0911], device='mps:0')\n",
      "mean: tensor(-2.0768, device='mps:0')\n",
      "iter_dt 1.06s; iter 64: train loss 0.33920 temperature: 8.199999999999992\n",
      "mean_logits tensor([-2.2990, -2.5035, -2.3448, -1.9851, -2.0483, -2.1018, -1.7737, -1.9946,\n",
      "        -2.1685, -2.0197, -2.0041, -1.9983, -1.9441, -2.0534, -2.2720, -2.0385,\n",
      "        -1.8442, -1.8391, -2.4066, -2.0324, -2.2303, -2.0562, -1.7711, -2.0285,\n",
      "        -2.3244, -2.0215, -2.2521, -1.8329, -2.3267, -2.1531, -2.0986, -2.1746,\n",
      "        -2.4612, -2.1237, -2.1696, -2.2641, -1.9680, -2.1003, -1.6687, -2.3662,\n",
      "        -1.9029, -1.8160, -2.0227, -1.7589, -1.8876, -2.2056, -2.2601, -1.7484,\n",
      "        -2.0842, -2.0907], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1024, -2.1223, -2.0868, -2.1054, -2.0680, -2.1260, -2.0448, -2.0857,\n",
      "        -2.0845, -2.0196, -2.0883, -2.0903, -2.0989, -2.0436, -2.0966, -2.0523,\n",
      "        -2.0283, -2.0925, -2.0604, -2.0564, -2.0967, -2.0866, -2.0925, -2.1033,\n",
      "        -2.0892, -2.0898, -2.0295, -2.0819, -2.1187, -2.1352, -2.0846, -2.1122,\n",
      "        -2.0826, -2.0754, -2.0882, -2.0998, -2.1144, -2.0839, -2.1009, -2.0878,\n",
      "        -2.1037, -2.0695, -2.0889, -2.0911, -2.0815, -2.0691, -2.0941, -2.0630,\n",
      "        -2.0344, -2.0862], device='mps:0')\n",
      "mean: tensor(-2.0838, device='mps:0')\n",
      "iter_dt 1.25s; iter 65: train loss 0.42774 temperature: 8.249999999999993\n",
      "mean_logits tensor([-2.3148, -2.0909, -1.9380, -1.9739, -2.2279, -2.1834, -2.5065, -2.2921,\n",
      "        -2.1401, -2.0191, -1.8897, -2.1275, -2.2280, -2.2949, -2.3719, -2.4923,\n",
      "        -2.2868, -2.0027, -1.8942, -2.0475, -1.9041, -2.3154, -2.0442, -2.2911,\n",
      "        -1.9405, -1.7956, -2.2512, -2.0610, -1.9999, -2.2144, -2.0758, -1.9886,\n",
      "        -1.9272, -2.4926, -1.8323, -2.3059, -2.4068, -2.2113, -2.1099, -1.9323,\n",
      "        -2.2696, -2.0017, -2.2328, -2.4045, -1.8823, -2.0898, -2.3484, -2.1717,\n",
      "        -2.5202, -2.2332], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0397, -2.0743, -2.1133, -2.0974, -2.1145, -2.0852, -2.0877, -2.1300,\n",
      "        -2.1318, -2.0369, -2.0929, -2.1146, -2.0420, -2.0894, -2.0789, -2.0844,\n",
      "        -2.0920, -2.0900, -2.0927, -2.0407, -2.0823, -2.0519, -2.0618, -2.1043,\n",
      "        -2.1006, -2.0091, -2.0835, -2.0780, -2.0538, -2.0824, -2.0935, -2.0547,\n",
      "        -2.0953, -2.0971, -2.0349, -2.0901, -2.0910, -2.0795, -2.0936, -2.0265,\n",
      "        -2.0774, -2.0884, -2.0873, -2.0766, -2.0747, -2.0733, -2.0900, -2.1085,\n",
      "        -2.1359, -2.1187], device='mps:0')\n",
      "mean: tensor(-2.0825, device='mps:0')\n",
      "iter_dt 1.08s; iter 66: train loss 0.29325 temperature: 8.299999999999994\n",
      "mean_logits tensor([-2.1901, -2.0682, -1.9481, -1.9859, -1.9343, -2.0716, -2.0052, -2.1045,\n",
      "        -1.9783, -2.2377, -2.2546, -2.1004, -2.4598, -1.8991, -1.9128, -2.1092,\n",
      "        -2.2652, -1.4045, -2.1663, -2.1041, -1.9032, -2.1317, -1.9744, -2.0452,\n",
      "        -1.8188, -1.9787, -2.3862, -1.8973, -1.9486, -2.1863, -1.7029, -1.9686,\n",
      "        -2.1491, -2.0789, -2.1796, -2.1367, -2.1380, -2.3792, -2.3381, -2.0695,\n",
      "        -1.8018, -1.9941, -1.9200, -2.0405, -2.1033, -2.0162, -2.3839, -2.2399,\n",
      "        -2.0534, -1.7194], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0862, -2.0900, -2.0621, -2.0715, -2.0389, -2.0981, -2.0593, -2.0829,\n",
      "        -2.0835, -2.0961, -2.0513, -2.0465, -2.0939, -2.0826, -2.1247, -2.1007,\n",
      "        -2.0868, -2.0873, -2.0876, -2.1249, -2.0256, -2.0904, -2.0953, -2.0397,\n",
      "        -2.0668, -2.0927, -2.0546, -2.0670, -2.0930, -2.0789, -2.1223, -2.1282,\n",
      "        -2.0809, -2.1282, -2.1148, -2.0112, -2.1058, -2.0891, -2.1036, -2.0829,\n",
      "        -2.0860, -2.0943, -2.1267, -2.1225, -2.0848, -2.0941, -2.0841, -2.0896,\n",
      "        -2.0935, -2.0373], device='mps:0')\n",
      "mean: tensor(-2.0848, device='mps:0')\n",
      "iter_dt 1.11s; iter 67: train loss 0.42421 temperature: 8.349999999999994\n",
      "mean_logits tensor([-2.0860, -1.8267, -2.2694, -2.0342, -1.7603, -2.1271, -2.1450, -2.1503,\n",
      "        -1.9875, -2.1737, -2.1489, -2.3515, -2.2062, -2.3225, -2.2176, -2.4682,\n",
      "        -1.9681, -2.1475, -2.0760, -2.0915, -2.0377, -2.2503, -1.8708, -2.0675,\n",
      "        -1.9833, -2.4692, -1.9996, -2.3028, -1.9045, -2.2938, -2.2915, -2.0685,\n",
      "        -2.3125, -2.4622, -2.3505, -2.4310, -1.8940, -2.2703, -1.7636, -2.3147,\n",
      "        -1.9372, -2.0214, -2.0244, -2.1666, -2.0463, -2.0584, -2.4961, -1.9349,\n",
      "        -2.4490, -1.9332], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0914, -2.1079, -2.0977, -2.0799, -2.1047, -2.0880, -2.0887, -2.0893,\n",
      "        -2.1187, -2.0783, -2.0533, -2.0980, -2.0848, -2.0825, -2.0517, -2.0680,\n",
      "        -2.0516, -2.0898, -2.0927, -2.1256, -2.1008, -2.0862, -2.0626, -2.1087,\n",
      "        -2.0463, -2.0777, -2.0711, -2.0740, -2.0910, -2.1014, -2.1226, -2.1110,\n",
      "        -2.0657, -2.0617, -2.1058, -2.0934, -2.0892, -2.1009, -2.0521, -2.0729,\n",
      "        -2.0880, -2.1396, -2.0891, -2.0931, -2.0425, -2.0893, -2.0949, -2.0909,\n",
      "        -2.0973, -2.0511], device='mps:0')\n",
      "mean: tensor(-2.0863, device='mps:0')\n",
      "iter_dt 1.16s; iter 68: train loss 0.24318 temperature: 8.399999999999995\n",
      "mean_logits tensor([-2.1261, -2.1838, -2.2630, -2.1166, -2.1034, -2.0136, -2.2524, -1.8376,\n",
      "        -1.9299, -2.2379, -2.0652, -2.1975, -2.1359, -2.1414, -2.3058, -2.3010,\n",
      "        -2.1002, -1.9985, -2.2192, -1.9098, -1.7911, -1.8602, -2.2141, -2.1307,\n",
      "        -2.2258, -2.5016, -2.2092, -2.1486, -1.7655, -2.1319, -2.0681, -2.1182,\n",
      "        -2.2396, -2.0936, -2.1141, -2.3166, -2.3094, -1.8436, -1.9889, -2.3117,\n",
      "        -2.1089, -1.9838, -2.0146, -2.0427, -2.0663, -2.0730, -2.4109, -1.9630,\n",
      "        -2.0221, -2.0257], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1094, -2.1103, -2.0860, -2.0557, -2.0558, -2.0638, -2.1077, -2.0214,\n",
      "        -2.0724, -2.0953, -2.0465, -2.0765, -2.0998, -2.1092, -2.0721, -2.0508,\n",
      "        -2.0655, -2.0914, -2.0900, -2.0872, -2.0916, -2.0231, -2.1044, -2.0304,\n",
      "        -2.1093, -2.1023, -2.0846, -2.0445, -2.0565, -2.0497, -2.0929, -2.0792,\n",
      "        -2.0342, -2.0696, -2.0818, -2.0288, -2.0643, -2.0883, -2.1003, -2.0774,\n",
      "        -2.0584, -2.1086, -2.1038, -2.0377, -2.0840, -2.1066, -2.0881, -2.1082,\n",
      "        -2.0701, -2.1235], device='mps:0')\n",
      "mean: tensor(-2.0774, device='mps:0')\n",
      "iter_dt 1.10s; iter 69: train loss 0.32862 temperature: 8.449999999999996\n",
      "mean_logits tensor([-1.8423, -1.9837, -2.0374, -2.0751, -1.5827, -2.1298, -2.2006, -2.2772,\n",
      "        -2.1679, -2.4582, -2.2278, -2.3311, -1.7939, -2.3397, -1.9868, -2.3092,\n",
      "        -2.0215, -2.3251, -2.0470, -2.3047, -2.0757, -1.9185, -2.0791, -2.1045,\n",
      "        -1.8750, -2.3401, -2.1214, -2.1186, -1.7891, -2.1258, -2.2209, -2.0154,\n",
      "        -2.3577, -2.0621, -2.2692, -2.1361, -1.9665, -1.9937, -2.4056, -1.8441,\n",
      "        -2.1270, -2.1713, -2.1833, -2.3327, -2.1470, -2.0772, -2.0106, -1.9599,\n",
      "        -2.1371, -2.4113], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0733, -2.1038, -2.0923, -2.0950, -2.0844, -2.1091, -2.0111, -2.0670,\n",
      "        -2.1018, -2.0891, -2.0696, -2.0489, -2.0661, -2.1159, -1.9975, -2.0448,\n",
      "        -2.0224, -2.1159, -2.0937, -2.0885, -2.0950, -2.0974, -2.0945, -2.0748,\n",
      "        -2.0715, -2.0842, -2.0949, -2.0552, -2.0879, -2.0719, -2.0874, -2.0405,\n",
      "        -2.0413, -2.0742, -2.0448, -2.0628, -2.0365, -2.0926, -2.0509, -2.1018,\n",
      "        -2.0951, -2.0905, -2.0734, -2.0838, -2.0942, -2.1173, -2.1102, -2.0848,\n",
      "        -2.0886, -2.1310], device='mps:0')\n",
      "mean: tensor(-2.0784, device='mps:0')\n",
      "iter_dt 1.02s; iter 70: train loss 0.27671 temperature: 8.499999999999996\n",
      "mean_logits tensor([-2.1887, -2.0138, -2.1567, -1.9795, -2.3198, -2.1930, -2.1335, -2.2811,\n",
      "        -1.7520, -2.2334, -1.7983, -1.8683, -2.1888, -2.0938, -1.9967, -1.7937,\n",
      "        -1.9745, -2.0455, -1.9627, -2.2927, -2.2582, -2.1415, -2.2991, -2.2199,\n",
      "        -2.3299, -1.9481, -2.1325, -2.0846, -2.2855, -1.8955, -2.1244, -2.1077,\n",
      "        -2.3178, -1.9050, -2.1369, -2.0915, -1.8739, -1.7494, -2.0984, -2.0691,\n",
      "        -1.9188, -2.2103, -1.8742, -2.4351, -1.9627, -1.5942, -2.1763, -2.1280,\n",
      "        -2.0764, -1.9931], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0949, -2.1221, -2.0698, -2.0993, -2.1029, -2.0714, -2.1195, -2.0749,\n",
      "        -2.1044, -2.0353, -2.1096, -2.0680, -2.1145, -2.0843, -2.1122, -2.0717,\n",
      "        -2.0429, -2.1296, -2.0937, -2.1295, -2.0945, -2.1073, -2.0393, -2.0911,\n",
      "        -2.0912, -2.0949, -2.0637, -2.0699, -2.0666, -2.1584, -2.0937, -2.0807,\n",
      "        -2.0994, -2.0932, -2.1346, -2.1268, -2.0844, -2.0836, -2.0868, -2.0825,\n",
      "        -2.0116, -2.1354, -2.1314, -2.0962, -2.0761, -2.1394, -2.0940, -2.1062,\n",
      "        -2.1110, -2.1168], device='mps:0')\n",
      "mean: tensor(-2.0942, device='mps:0')\n",
      "iter_dt 1.04s; iter 71: train loss 0.43046 temperature: 8.549999999999997\n",
      "mean_logits tensor([-1.8631, -1.8502, -2.3685, -1.6849, -2.2332, -2.3707, -2.3006, -2.3346,\n",
      "        -2.3695, -2.2893, -2.1642, -2.1115, -1.9989, -2.0495, -1.9226, -2.0117,\n",
      "        -2.2025, -1.8690, -2.3179, -2.3371, -1.8591, -2.1397, -1.8493, -1.9316,\n",
      "        -1.9575, -2.3803, -1.8279, -1.9938, -2.2984, -2.1140, -2.2179, -2.0640,\n",
      "        -1.8833, -2.5523, -2.4658, -2.0598, -2.2494, -2.1823, -2.3065, -1.9707,\n",
      "        -2.0927, -1.9995, -1.7780, -1.8627, -2.0573, -2.3514, -1.9015, -1.8782,\n",
      "        -2.0317, -2.2140], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0393, -2.0902, -2.0892, -2.0965, -2.0851, -2.0683, -2.0904, -2.0788,\n",
      "        -2.0667, -2.0889, -2.0905, -2.0224, -2.1115, -2.1164, -2.0894, -2.0953,\n",
      "        -2.1025, -2.0855, -2.0615, -2.0874, -2.0945, -2.1065, -2.0808, -2.0852,\n",
      "        -2.0861, -2.0824, -2.0723, -2.0522, -2.0535, -2.0687, -2.0808, -2.0736,\n",
      "        -2.0695, -2.0920, -2.0763, -2.0868, -2.0608, -2.0953, -2.0239, -2.0546,\n",
      "        -2.0950, -2.0857, -2.0925, -2.0805, -2.1119, -2.0675, -2.1070, -2.0666,\n",
      "        -2.0867, -2.1222], device='mps:0')\n",
      "mean: tensor(-2.0813, device='mps:0')\n",
      "iter_dt 1.05s; iter 72: train loss 0.38818 temperature: 8.599999999999998\n",
      "mean_logits tensor([-2.0470, -2.2678, -1.9774, -2.1174, -1.9634, -1.9781, -1.8877, -1.9876,\n",
      "        -2.2374, -1.9975, -2.1897, -1.7423, -2.3622, -2.2632, -2.3435, -2.4025,\n",
      "        -2.3759, -1.9052, -2.0931, -2.0729, -2.0629, -2.0409, -2.2013, -1.8995,\n",
      "        -2.3000, -1.8972, -2.1392, -2.0041, -2.0127, -1.7761, -1.6215, -2.1452,\n",
      "        -2.0000, -2.0871, -2.3326, -1.9855, -2.6023, -1.9349, -1.6579, -2.2285,\n",
      "        -2.0439, -2.3988, -2.1681, -1.9842, -2.2463, -1.8853, -2.0364, -2.3792,\n",
      "        -1.7326, -2.1389], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0885, -2.1020, -2.0868, -2.0908, -2.0608, -2.1107, -2.0792, -2.0542,\n",
      "        -2.0999, -2.0589, -2.0866, -2.0893, -2.0781, -2.0909, -2.0896, -2.0948,\n",
      "        -2.1200, -2.0693, -2.0873, -2.0544, -2.0767, -2.0995, -2.0846, -2.1029,\n",
      "        -2.0974, -2.0600, -2.0870, -2.0847, -2.0941, -2.0567, -2.0804, -2.0865,\n",
      "        -2.1163, -2.0997, -2.0400, -2.1684, -2.0884, -2.0858, -2.1084, -2.0883,\n",
      "        -2.0335, -2.0892, -2.0895, -2.0738, -2.0885, -2.0522, -2.0242, -2.0931,\n",
      "        -2.0678, -2.0893], device='mps:0')\n",
      "mean: tensor(-2.0840, device='mps:0')\n",
      "iter_dt 1.04s; iter 73: train loss 0.22871 temperature: 8.649999999999999\n",
      "mean_logits tensor([-2.1869, -1.9985, -1.8166, -2.2308, -2.2431, -2.2304, -2.2573, -2.0224,\n",
      "        -2.2287, -2.2741, -2.0050, -2.0246, -1.9988, -1.8383, -1.8542, -2.0227,\n",
      "        -2.0059, -1.8944, -2.0367, -2.0049, -2.2798, -1.8190, -2.0013, -2.1573,\n",
      "        -1.9512, -2.2364, -1.7726, -1.8242, -1.5194, -1.9945, -1.8705, -2.2161,\n",
      "        -1.8808, -2.1267, -1.9415, -2.3274, -2.3065, -2.2080, -1.9276, -2.0771,\n",
      "        -1.9942, -2.0602, -2.1758, -2.2638, -1.9303, -2.2177, -1.9821, -2.1147,\n",
      "        -2.2535, -1.9459], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0891, -2.0561, -2.1094, -2.0902, -2.0393, -2.0877, -2.0973, -2.1159,\n",
      "        -2.0856, -2.0844, -2.0915, -2.0927, -2.0391, -2.0937, -2.1151, -2.1072,\n",
      "        -2.0691, -2.0730, -2.0990, -2.0645, -2.0960, -2.0786, -2.0899, -2.0783,\n",
      "        -2.0899, -2.1117, -2.0770, -2.0428, -2.0155, -2.0791, -2.1054, -2.1000,\n",
      "        -2.0648, -2.0823, -2.1355, -2.0903, -2.0867, -2.0997, -2.0896, -2.0945,\n",
      "        -2.0939, -2.0937, -2.0438, -2.0948, -2.0570, -2.1453, -2.1214, -2.0711,\n",
      "        -2.0271, -2.0968], device='mps:0')\n",
      "mean: tensor(-2.0850, device='mps:0')\n",
      "iter_dt 1.04s; iter 74: train loss 0.37963 temperature: 8.7\n",
      "mean_logits tensor([-1.8083, -2.1095, -1.9537, -2.3414, -2.0854, -2.3392, -2.4430, -2.1608,\n",
      "        -2.3265, -2.0384, -2.1433, -2.0648, -1.9397, -2.1544, -1.9480, -2.1164,\n",
      "        -2.0267, -2.0203, -2.3492, -2.2635, -2.3234, -2.1445, -1.9244, -2.3217,\n",
      "        -1.6889, -2.2338, -2.1311, -2.0429, -1.9721, -1.9292, -1.8419, -2.4205,\n",
      "        -1.8987, -2.1566, -1.9550, -2.0951, -2.3880, -2.1425, -2.1256, -2.4162,\n",
      "        -2.4192, -2.3202, -2.0613, -2.2063, -2.0757, -2.0244, -2.4049, -2.2621,\n",
      "        -2.2082, -2.2954], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1015, -2.0055, -2.0925, -2.1107, -2.1114, -2.0552, -2.1025, -2.0896,\n",
      "        -2.0960, -2.0950, -2.0606, -2.0748, -2.0923, -2.0805, -2.0732, -2.0890,\n",
      "        -2.0926, -2.0671, -2.0741, -2.0744, -2.0432, -2.1073, -2.0891, -2.0800,\n",
      "        -2.0730, -2.0986, -2.0975, -2.0844, -2.0126, -2.0894, -2.1178, -2.0916,\n",
      "        -2.0793, -2.0940, -2.1254, -2.0985, -2.0756, -2.0779, -2.0851, -2.0539,\n",
      "        -2.0720, -2.0661, -2.0381, -2.1067, -2.0682, -2.0792, -2.0699, -2.0927,\n",
      "        -2.0772, -2.0865], device='mps:0')\n",
      "mean: tensor(-2.0814, device='mps:0')\n",
      "iter_dt 1.05s; iter 75: train loss 0.48504 temperature: 8.75\n",
      "mean_logits tensor([-1.7377, -1.8657, -1.9288, -2.0343, -1.8694, -2.3681, -1.6412, -2.0864,\n",
      "        -2.4393, -2.1992, -2.0014, -2.0252, -2.1447, -1.9861, -2.1443, -2.1946,\n",
      "        -2.1017, -2.2051, -1.9987, -1.9044, -2.1406, -2.4101, -2.3683, -1.9180,\n",
      "        -1.9589, -2.1205, -1.8842, -2.1230, -2.3909, -1.6234, -2.2452, -2.4835,\n",
      "        -2.0320, -2.5103, -1.9932, -1.7846, -2.4844, -2.0814, -2.3021, -2.1287,\n",
      "        -2.0022, -1.8454, -2.2748, -2.1828, -2.1041, -2.4716, -2.1268, -2.0217,\n",
      "        -1.7051, -2.0830], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0951, -2.0733, -2.1097, -2.0878, -2.0611, -2.0923, -2.0906, -2.0648,\n",
      "        -2.0665, -2.0895, -2.1198, -2.0547, -2.0861, -2.0997, -2.0508, -2.0922,\n",
      "        -2.0814, -2.0569, -2.0974, -2.0851, -2.0565, -2.0396, -2.0620, -2.0410,\n",
      "        -2.0908, -2.0964, -2.1058, -2.0499, -2.1074, -2.0638, -2.0904, -2.1509,\n",
      "        -2.0602, -2.0376, -2.1129, -2.0884, -2.0813, -2.0188, -2.0351, -2.1037,\n",
      "        -2.0655, -2.0526, -2.0971, -2.0502, -2.0740, -2.0735, -2.0788, -2.0254,\n",
      "        -2.1088, -2.0528], device='mps:0')\n",
      "mean: tensor(-2.0765, device='mps:0')\n",
      "iter_dt 1.08s; iter 76: train loss 0.36850 temperature: 8.8\n",
      "mean_logits tensor([-2.0816, -1.8769, -1.8601, -2.2852, -1.9933, -2.1694, -2.0251, -1.7303,\n",
      "        -1.7565, -2.3216, -2.0236, -2.3028, -2.0215, -2.3336, -2.1917, -2.5895,\n",
      "        -2.0642, -2.2474, -2.1470, -1.8496, -1.8570, -2.4201, -2.2681, -1.7667,\n",
      "        -2.1153, -1.8951, -1.7988, -2.1418, -2.2730, -2.0081, -2.0087, -2.0216,\n",
      "        -2.1872, -1.9746, -2.0461, -2.4041, -2.0591, -2.0553, -1.9752, -2.0594,\n",
      "        -2.0045, -2.3028, -2.0320, -1.9324, -2.3888, -2.3144, -2.1551, -2.3177,\n",
      "        -2.2161, -1.8124], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1027, -2.0854, -2.0780, -2.0875, -2.1177, -2.0643, -2.0656, -2.0755,\n",
      "        -2.1032, -2.1192, -2.0895, -2.1006, -2.0834, -2.0844, -2.0824, -2.0913,\n",
      "        -2.0955, -2.1074, -2.0614, -2.0804, -2.0905, -2.0977, -2.0639, -2.0971,\n",
      "        -2.0885, -2.0835, -2.1105, -2.0322, -2.0876, -2.1013, -2.0956, -2.0502,\n",
      "        -2.0932, -2.0449, -2.0458, -2.0989, -2.0443, -2.0820, -2.0764, -2.0885,\n",
      "        -2.0831, -2.0870, -2.0747, -2.0792, -2.0910, -2.0611, -2.0503, -2.1043,\n",
      "        -2.1407, -2.0958], device='mps:0')\n",
      "mean: tensor(-2.0843, device='mps:0')\n",
      "iter_dt 1.04s; iter 77: train loss 0.33222 temperature: 8.850000000000001\n",
      "mean_logits tensor([-2.2625, -2.3006, -1.7171, -1.9190, -2.1649, -1.7116, -2.1818, -1.9891,\n",
      "        -1.9523, -2.2766, -2.2153, -1.9256, -2.2178, -2.0232, -2.1805, -1.8596,\n",
      "        -2.0167, -2.0042, -1.8997, -2.1426, -2.1031, -2.3334, -2.2074, -2.2198,\n",
      "        -2.3924, -1.7884, -2.2614, -2.5389, -2.3155, -1.8500, -2.0693, -2.2644,\n",
      "        -2.0800, -2.1841, -1.6830, -2.2412, -2.2204, -2.0445, -2.0979, -2.2176,\n",
      "        -2.0510, -1.8569, -2.1949, -1.6639, -2.2508, -2.1257, -2.1634, -1.9390,\n",
      "        -1.7619, -2.1431], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0841, -2.0827, -2.0887, -2.0894, -2.0975, -2.0872, -2.0816, -2.0742,\n",
      "        -2.1057, -2.0590, -2.0783, -2.0271, -2.0859, -2.0641, -2.0991, -2.1096,\n",
      "        -2.0048, -2.0892, -2.0892, -2.0446, -2.0847, -2.0166, -2.1082, -2.0376,\n",
      "        -2.0675, -2.0733, -2.1078, -2.1146, -2.0980, -2.0703, -2.0983, -2.0791,\n",
      "        -2.0910, -2.0872, -2.1186, -2.0758, -2.0587, -2.0926, -2.0822, -2.1009,\n",
      "        -2.1096, -2.1135, -2.1031, -1.9834, -2.1068, -2.0346, -2.0634, -2.1005,\n",
      "        -2.0628, -2.0890], device='mps:0')\n",
      "mean: tensor(-2.0794, device='mps:0')\n",
      "iter_dt 1.09s; iter 78: train loss 0.31872 temperature: 8.900000000000002\n",
      "mean_logits tensor([-1.5782, -2.4692, -2.2796, -1.9928, -2.1564, -2.2661, -2.4211, -2.0099,\n",
      "        -2.0482, -2.0023, -1.8613, -1.9042, -1.7467, -2.1650, -1.5882, -2.0377,\n",
      "        -1.9823, -2.0266, -2.1015, -1.8402, -2.2310, -1.8542, -2.0980, -1.8350,\n",
      "        -2.0998, -2.1059, -2.1035, -2.1744, -2.2646, -1.9867, -2.0191, -2.2624,\n",
      "        -2.1693, -1.7580, -2.1278, -2.1396, -2.1218, -2.0309, -1.8144, -2.0657,\n",
      "        -2.2696, -1.9249, -2.1772, -2.4579, -1.8585, -2.3045, -2.2737, -1.9175,\n",
      "        -2.0103, -2.1605], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0908, -2.0996, -2.0877, -2.0913, -2.0926, -2.0629, -2.1037, -2.0448,\n",
      "        -2.0746, -2.0914, -2.0872, -2.0576, -2.0770, -2.1496, -2.0925, -2.0884,\n",
      "        -2.0615, -2.0973, -2.0894, -2.0820, -2.1024, -2.0834, -2.1285, -2.0718,\n",
      "        -2.0245, -2.0932, -2.0725, -2.0860, -2.0786, -2.0651, -2.0881, -2.0936,\n",
      "        -2.0383, -2.1082, -2.0904, -2.0889, -2.0983, -1.9927, -2.0944, -2.0725,\n",
      "        -2.1079, -2.0837, -2.0917, -2.0861, -2.0928, -2.0687, -2.1148, -2.0866,\n",
      "        -2.0901, -2.0547], device='mps:0')\n",
      "mean: tensor(-2.0834, device='mps:0')\n",
      "iter_dt 1.04s; iter 79: train loss 0.26711 temperature: 8.950000000000003\n",
      "mean_logits tensor([-1.9277, -1.9150, -1.5880, -1.9962, -2.2508, -2.1472, -2.2687, -2.0553,\n",
      "        -1.9640, -2.0637, -2.4060, -1.7490, -1.8775, -2.1451, -2.2218, -2.0490,\n",
      "        -1.9248, -2.2251, -1.9332, -1.9473, -1.9932, -1.9464, -2.0894, -2.2002,\n",
      "        -2.1663, -2.3608, -2.0601, -1.9941, -1.9705, -1.9118, -2.0239, -2.1710,\n",
      "        -1.8953, -2.4218, -1.8473, -2.0481, -1.9966, -2.1214, -2.1560, -1.9409,\n",
      "        -2.1230, -2.0418, -2.4505, -2.0586, -2.3704, -2.0788, -1.8499, -1.9470,\n",
      "        -1.9096, -2.0771], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0935, -2.0884, -2.0687, -2.0755, -2.0989, -2.0332, -2.0904, -2.0495,\n",
      "        -2.0847, -2.0639, -2.0753, -2.0942, -2.0819, -2.0341, -2.1001, -2.0983,\n",
      "        -2.0882, -2.0778, -2.0810, -2.1246, -2.0345, -2.1000, -2.1085, -2.0824,\n",
      "        -2.1252, -2.1115, -2.1207, -2.1238, -2.0859, -2.0289, -2.0953, -2.0301,\n",
      "        -2.1223, -2.0886, -2.0903, -2.0718, -2.0909, -2.0692, -2.0060, -2.0661,\n",
      "        -2.1062, -2.0476, -2.1127, -2.0940, -2.0823, -2.0960, -2.0695, -2.0539,\n",
      "        -2.0558, -2.0420], device='mps:0')\n",
      "mean: tensor(-2.0803, device='mps:0')\n",
      "iter_dt 1.05s; iter 80: train loss 0.35203 temperature: 9.000000000000004\n",
      "mean_logits tensor([-1.9824, -1.8219, -2.3079, -2.0735, -2.4029, -2.3105, -2.2976, -2.4253,\n",
      "        -2.0269, -1.9925, -1.9855, -1.9427, -1.6303, -2.1981, -2.1193, -2.3081,\n",
      "        -2.2540, -1.9746, -2.0175, -2.0705, -2.1968, -2.0081, -2.2420, -2.0858,\n",
      "        -2.2859, -2.1227, -2.3793, -1.9630, -1.9458, -1.7130, -2.1609, -2.5232,\n",
      "        -2.0007, -2.0702, -1.8664, -1.9961, -2.3192, -2.1919, -2.0429, -2.1112,\n",
      "        -2.3420, -2.0511, -2.1142, -2.3767, -2.1643, -2.0923, -2.3563, -2.0336,\n",
      "        -1.9674, -2.1791], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1031, -2.0878, -2.0851, -2.0886, -2.0920, -2.1312, -2.0761, -2.0934,\n",
      "        -2.1120, -2.1097, -2.0805, -2.0750, -2.0865, -2.1178, -2.1160, -2.0654,\n",
      "        -2.0191, -2.0603, -2.1009, -2.0731, -2.0442, -2.0656, -2.0912, -2.0490,\n",
      "        -2.0818, -2.0865, -2.0863, -2.0430, -2.0951, -2.0914, -2.0641, -2.1142,\n",
      "        -2.1092, -1.9911, -2.1017, -2.0470, -2.0969, -2.0837, -2.0731, -2.0426,\n",
      "        -2.0917, -2.0918, -2.0917, -2.0708, -2.1153, -2.0804, -2.0261, -2.1247,\n",
      "        -2.0893, -2.1100], device='mps:0')\n",
      "mean: tensor(-2.0825, device='mps:0')\n",
      "iter_dt 1.04s; iter 81: train loss 0.39796 temperature: 9.050000000000004\n",
      "mean_logits tensor([-1.9988, -2.3667, -1.8004, -2.0713, -2.0345, -1.8127, -1.9353, -1.9934,\n",
      "        -1.9389, -2.0315, -2.0436, -2.0002, -2.2701, -2.1632, -2.3736, -1.9621,\n",
      "        -1.9514, -1.9899, -1.9276, -1.8577, -1.8780, -2.1884, -2.4552, -1.8537,\n",
      "        -2.4838, -2.1023, -2.0593, -2.1791, -2.3863, -1.5816, -1.9871, -2.5432,\n",
      "        -1.8063, -2.0050, -1.9874, -2.3449, -1.5517, -1.9556, -1.9296, -2.0104,\n",
      "        -2.2125, -2.0177, -2.1003, -1.8105, -1.7649, -2.1313, -2.1529, -2.0543,\n",
      "        -2.1198, -2.1097], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0445, -2.0744, -2.0988, -2.0895, -2.0800, -2.0742, -2.0838, -2.0888,\n",
      "        -2.0704, -2.0905, -2.0651, -2.0598, -2.0713, -2.1251, -2.0905, -2.1365,\n",
      "        -2.0868, -2.0072, -2.0852, -2.0523, -2.0545, -2.0431, -2.0716, -2.0675,\n",
      "        -2.0919, -2.0816, -2.0726, -2.0861, -2.1065, -2.0345, -2.1204, -2.0437,\n",
      "        -2.0975, -2.1080, -2.0347, -2.0737, -2.1084, -2.1310, -2.0776, -2.0730,\n",
      "        -2.0826, -2.0725, -2.0921, -2.0814, -2.0552, -2.0804, -2.1290, -2.0828,\n",
      "        -2.0411, -2.1276], device='mps:0')\n",
      "mean: tensor(-2.0800, device='mps:0')\n",
      "iter_dt 1.04s; iter 82: train loss 0.23867 temperature: 9.100000000000005\n",
      "mean_logits tensor([-2.3003, -2.0174, -2.0348, -1.9914, -1.8687, -2.1724, -2.1410, -2.1932,\n",
      "        -1.9347, -2.1220, -2.1479, -1.6793, -2.0361, -1.9258, -2.2525, -2.0243,\n",
      "        -2.0861, -2.0552, -2.1583, -2.2709, -2.2516, -1.6341, -2.0698, -2.1441,\n",
      "        -2.1330, -2.3500, -2.3654, -2.0201, -2.0409, -1.9349, -2.0820, -2.1009,\n",
      "        -1.9233, -2.1008, -1.6978, -2.1327, -2.2769, -1.8766, -1.9131, -2.0993,\n",
      "        -2.0631, -2.3118, -2.3479, -2.1635, -1.7939, -2.1320, -2.0609, -2.0402,\n",
      "        -2.1673, -2.2004], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0999, -2.0960, -2.0603, -2.1194, -2.1063, -2.0875, -2.1254, -2.0317,\n",
      "        -2.0657, -2.0567, -2.1016, -2.0558, -2.0808, -2.0700, -2.0147, -2.0463,\n",
      "        -2.0262, -2.0492, -2.0605, -2.0304, -2.0876, -2.0724, -2.0214, -2.0819,\n",
      "        -2.0968, -2.1431, -2.0799, -2.0746, -2.0888, -2.1109, -2.0864, -2.0566,\n",
      "        -2.0883, -2.0917, -2.1113, -2.0982, -2.0404, -2.0726, -2.0762, -2.0874,\n",
      "        -2.0341, -2.0913, -2.0383, -2.0746, -2.1047, -2.0373, -2.0904, -2.0448,\n",
      "        -2.1219, -2.0456], device='mps:0')\n",
      "mean: tensor(-2.0747, device='mps:0')\n",
      "iter_dt 1.04s; iter 83: train loss 0.31905 temperature: 9.150000000000006\n",
      "mean_logits tensor([-2.2161, -2.0914, -2.1437, -1.9587, -2.0784, -2.1826, -1.8926, -1.9364,\n",
      "        -2.1255, -2.2931, -1.9307, -1.9498, -2.0753, -1.7403, -2.0749, -1.9072,\n",
      "        -2.1876, -2.0138, -1.8697, -1.9791, -1.9986, -2.0171, -1.8020, -2.3744,\n",
      "        -1.8337, -2.1365, -2.1024, -2.1304, -2.2064, -2.5321, -2.1703, -2.1146,\n",
      "        -2.4193, -2.1390, -2.2878, -2.3715, -1.7301, -2.0978, -2.0546, -2.3437,\n",
      "        -1.9482, -2.1782, -2.0565, -2.1714, -1.9386, -2.0329, -1.8930, -1.6878,\n",
      "        -1.9555, -2.2898], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0912, -2.1341, -2.0757, -2.0507, -2.0717, -2.0829, -2.0574, -2.0994,\n",
      "        -2.1008, -2.0883, -2.0884, -2.0597, -2.0927, -2.0747, -2.0838, -2.0928,\n",
      "        -2.0384, -2.0922, -2.0417, -2.0846, -2.0901, -2.0346, -2.0735, -2.0892,\n",
      "        -2.0836, -2.0721, -2.0978, -2.0719, -2.0088, -2.0060, -2.1190, -2.0247,\n",
      "        -2.0939, -2.0994, -2.0542, -2.1470, -2.0705, -2.0508, -2.0122, -2.0465,\n",
      "        -2.1522, -2.1000, -2.0775, -2.0410, -2.0929, -2.0726, -2.0934, -2.0972,\n",
      "        -2.0752, -2.0786], device='mps:0')\n",
      "mean: tensor(-2.0766, device='mps:0')\n",
      "iter_dt 1.04s; iter 84: train loss 0.40782 temperature: 9.200000000000006\n",
      "mean_logits tensor([-2.0990, -2.0011, -2.2838, -1.6849, -2.1507, -2.0049, -2.1242, -2.1052,\n",
      "        -2.1454, -2.6445, -2.1172, -2.5227, -2.3762, -1.7512, -2.2285, -2.1398,\n",
      "        -2.3002, -2.0556, -1.8899, -2.1102, -1.9199, -2.0305, -2.0988, -2.1744,\n",
      "        -2.0552, -2.1868, -2.0310, -2.1981, -1.8271, -2.3548, -1.9935, -1.8799,\n",
      "        -1.9968, -1.8648, -2.3393, -2.2498, -2.2007, -1.7701, -1.8165, -1.9117,\n",
      "        -2.0596, -1.8888, -2.0099, -2.0273, -2.2859, -2.2075, -2.3786, -2.0733,\n",
      "        -2.2425, -1.7762], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0889, -2.0934, -2.0968, -2.0940, -2.0952, -2.0913, -2.0876, -2.1057,\n",
      "        -2.0863, -2.0883, -2.0575, -2.0858, -2.0643, -2.0829, -2.0877, -2.0781,\n",
      "        -2.1102, -2.1476, -2.0989, -2.0180, -2.0736, -2.0926, -2.0734, -2.0982,\n",
      "        -2.0344, -2.1118, -2.0725, -2.0696, -2.0886, -2.0594, -2.1019, -2.0663,\n",
      "        -2.0604, -2.0720, -2.0911, -2.1461, -2.0803, -2.0931, -2.0877, -2.1133,\n",
      "        -2.0596, -2.0492, -2.0074, -2.1180, -2.0427, -2.1089, -2.0100, -2.0823,\n",
      "        -2.1091, -2.0845], device='mps:0')\n",
      "mean: tensor(-2.0823, device='mps:0')\n",
      "iter_dt 1.07s; iter 85: train loss 0.33327 temperature: 9.250000000000007\n",
      "mean_logits tensor([-1.8849, -1.9839, -2.2105, -1.9679, -1.9286, -2.1443, -2.0583, -1.9128,\n",
      "        -1.7927, -1.9472, -1.8991, -2.1223, -2.1704, -2.1595, -2.0243, -2.0996,\n",
      "        -1.6712, -2.2528, -2.0469, -1.8793, -2.1444, -2.2541, -2.3048, -2.1945,\n",
      "        -2.4675, -1.8674, -2.0912, -2.3150, -2.3405, -2.0788, -2.2009, -2.1878,\n",
      "        -1.8582, -2.2274, -1.9046, -2.2107, -2.1093, -1.9487, -2.0545, -2.3019,\n",
      "        -1.8733, -2.1823, -1.7545, -2.3010, -1.7757, -2.4759, -2.2109, -2.3023,\n",
      "        -2.4049, -2.0084], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0933, -2.0874, -2.0919, -2.0660, -2.0858, -2.1014, -2.0561, -2.1315,\n",
      "        -2.0877, -2.0950, -2.0886, -2.0689, -2.0961, -2.0891, -2.0875, -2.0211,\n",
      "        -2.0266, -2.1135, -2.1031, -2.0838, -2.0453, -2.0674, -2.0844, -2.0671,\n",
      "        -2.0715, -2.0775, -2.0667, -2.0642, -2.0193, -2.0836, -2.0846, -2.0861,\n",
      "        -2.1190, -2.1056, -2.0919, -2.0692, -2.0395, -2.0914, -2.0778, -2.0911,\n",
      "        -2.0816, -2.0796, -2.0891, -2.0941, -2.0765, -2.1318, -2.1206, -2.0605,\n",
      "        -2.0926, -2.0914], device='mps:0')\n",
      "mean: tensor(-2.0819, device='mps:0')\n",
      "iter_dt 1.03s; iter 86: train loss 0.25690 temperature: 9.300000000000008\n",
      "mean_logits tensor([-2.1995, -2.0525, -2.0544, -2.3570, -2.3508, -2.1481, -2.2120, -1.8986,\n",
      "        -1.7643, -2.3522, -2.4007, -2.0259, -2.2076, -2.3711, -1.9813, -2.4091,\n",
      "        -1.8778, -2.1292, -2.0001, -1.8244, -2.0788, -1.9682, -2.1599, -1.9521,\n",
      "        -2.1057, -2.3726, -2.0479, -2.1453, -1.8726, -2.1418, -2.0658, -2.1268,\n",
      "        -2.0014, -1.8933, -2.0358, -1.8550, -1.9056, -2.1880, -2.0974, -1.9930,\n",
      "        -2.2134, -1.9279, -2.1507, -2.0962, -2.1580, -1.9653, -1.8177, -1.8599,\n",
      "        -2.2009, -2.1819], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1303, -2.1353, -2.0952, -2.0753, -2.0854, -2.0479, -2.0665, -2.0504,\n",
      "        -2.1320, -2.0646, -2.0508, -2.0473, -2.0845, -2.0916, -2.0750, -2.1232,\n",
      "        -2.0944, -2.0646, -2.0539, -2.0905, -2.0882, -2.0883, -2.0950, -2.0926,\n",
      "        -2.1384, -2.0971, -2.1312, -2.1140, -2.0236, -2.0410, -2.0751, -2.0818,\n",
      "        -2.0360, -2.0900, -2.0917, -2.0884, -2.0847, -2.0787, -2.0852, -2.0873,\n",
      "        -2.1009, -2.0997, -2.0886, -2.0928, -2.0949, -2.0899, -2.0864, -2.0228,\n",
      "        -2.0897, -2.0379], device='mps:0')\n",
      "mean: tensor(-2.0834, device='mps:0')\n",
      "iter_dt 1.05s; iter 87: train loss 0.31233 temperature: 9.350000000000009\n",
      "mean_logits tensor([-2.0961, -2.3028, -2.1969, -2.3642, -1.8902, -1.9310, -2.0976, -1.9491,\n",
      "        -2.0931, -2.2636, -2.0864, -1.9401, -1.9848, -2.1025, -1.7274, -1.8415,\n",
      "        -1.9256, -2.0735, -2.1713, -1.8605, -2.2929, -1.8816, -2.0230, -2.3675,\n",
      "        -1.4199, -1.7200, -2.2627, -2.0238, -2.2396, -2.1191, -2.4247, -2.3586,\n",
      "        -1.8869, -2.3182, -2.0504, -1.9130, -2.3634, -2.2427, -2.1742, -1.9898,\n",
      "        -2.2098, -2.0493, -1.9701, -2.0987, -2.1421, -1.8767, -2.1844, -2.0132,\n",
      "        -1.7993, -2.1222], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0769, -2.0304, -2.0691, -2.1386, -2.0968, -1.9808, -2.1198, -2.1586,\n",
      "        -1.9760, -2.0972, -2.0402, -2.0401, -2.0928, -2.0611, -2.0851, -2.0743,\n",
      "        -2.0866, -2.0705, -2.0617, -2.0641, -2.0735, -2.0681, -2.0607, -2.0523,\n",
      "        -2.0926, -2.0855, -2.0521, -2.1067, -2.0504, -2.0467, -2.1243, -2.1346,\n",
      "        -2.0592, -2.1213, -2.0383, -2.0601, -2.0630, -2.0902, -2.0678, -2.0708,\n",
      "        -2.0367, -2.0932, -2.0421, -2.1021, -2.0813, -2.0514, -2.0857, -1.9987,\n",
      "        -2.0829, -2.0681], device='mps:0')\n",
      "mean: tensor(-2.0716, device='mps:0')\n",
      "iter_dt 1.05s; iter 88: train loss 0.22080 temperature: 9.40000000000001\n",
      "mean_logits tensor([-2.1415, -1.9022, -2.2123, -2.1141, -2.2065, -2.1324, -2.1150, -2.2576,\n",
      "        -2.3225, -2.1141, -2.1377, -2.0448, -2.3112, -2.0338, -2.2057, -1.9408,\n",
      "        -2.2730, -2.3701, -2.2883, -1.8229, -1.9312, -2.2201, -2.0215, -1.8742,\n",
      "        -2.0531, -2.3958, -2.2572, -1.9790, -1.9094, -2.2211, -1.8447, -1.8760,\n",
      "        -2.1678, -2.1449, -2.0915, -1.9554, -2.1767, -2.2074, -2.2626, -1.8631,\n",
      "        -1.9005, -2.1697, -2.0423, -2.2733, -2.1345, -2.1973, -2.1666, -2.2642,\n",
      "        -2.1874, -2.0557], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0726, -2.0884, -2.1146, -2.0423, -2.0844, -2.0675, -2.1228, -2.1100,\n",
      "        -2.0751, -2.0689, -2.0552, -2.0968, -2.0945, -2.0877, -2.0907, -2.0213,\n",
      "        -2.0833, -2.0970, -2.0896, -2.0890, -2.1468, -2.1084, -2.0318, -2.0868,\n",
      "        -2.0630, -2.0636, -2.0360, -2.0670, -2.0747, -2.0869, -2.0911, -2.0922,\n",
      "        -2.0899, -2.1003, -2.0876, -2.0571, -2.1418, -2.1355, -2.0656, -2.0521,\n",
      "        -2.0661, -2.0901, -2.0816, -2.0897, -2.0519, -2.0076, -2.0507, -2.0302,\n",
      "        -2.0768, -2.1042], device='mps:0')\n",
      "mean: tensor(-2.0796, device='mps:0')\n",
      "iter_dt 1.05s; iter 89: train loss 0.37447 temperature: 9.45000000000001\n",
      "mean_logits tensor([-2.0666, -2.1418, -2.3551, -2.1016, -2.0351, -1.9920, -1.9884, -1.8893,\n",
      "        -1.8644, -2.1676, -1.8812, -1.6401, -2.2042, -2.2747, -1.9511, -2.2003,\n",
      "        -2.0985, -2.2238, -2.1074, -1.8932, -2.2697, -2.0367, -1.7690, -2.4165,\n",
      "        -1.8607, -2.0553, -2.1447, -2.0610, -2.1719, -2.2103, -2.2864, -2.3233,\n",
      "        -2.3705, -1.9598, -1.9305, -2.0047, -2.5749, -2.0927, -1.7973, -2.3206,\n",
      "        -2.2252, -2.1535, -2.4211, -2.1013, -1.8446, -2.0943, -1.9528, -2.2702,\n",
      "        -2.2508, -1.7786], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0713, -2.0566, -2.0934, -2.0968, -2.0413, -2.1001, -2.0929, -2.1307,\n",
      "        -2.0820, -2.0633, -2.0469, -2.0932, -2.0141, -2.0891, -2.0397, -2.0536,\n",
      "        -2.0994, -2.0867, -2.0857, -2.0798, -2.0485, -2.0973, -2.0587, -2.0620,\n",
      "        -2.0662, -2.1022, -2.1192, -2.1074, -2.1076, -2.1016, -2.0974, -2.0819,\n",
      "        -2.0799, -2.0663, -2.0668, -2.0411, -2.0564, -2.1040, -2.0865, -2.0548,\n",
      "        -2.1046, -2.0326, -2.0419, -2.1041, -2.0761, -2.0894, -2.0794, -2.0923,\n",
      "        -2.0882, -2.0529], device='mps:0')\n",
      "mean: tensor(-2.0777, device='mps:0')\n",
      "iter_dt 1.04s; iter 90: train loss 0.12797 temperature: 9.50000000000001\n",
      "mean_logits tensor([-1.9464, -2.0201, -2.1547, -2.0626, -2.0347, -2.1796, -2.0683, -2.0501,\n",
      "        -1.8621, -2.0187, -2.1372, -2.1677, -2.2054, -1.8020, -2.1182, -1.9368,\n",
      "        -2.2277, -1.8655, -2.1475, -1.8121, -2.3059, -2.1193, -2.0010, -2.1776,\n",
      "        -1.9688, -2.0276, -2.1170, -1.9502, -2.0427, -2.2520, -2.1236, -2.0790,\n",
      "        -2.0636, -2.0929, -1.8740, -2.1596, -1.9946, -2.3313, -2.0894, -2.1045,\n",
      "        -2.0529, -1.9344, -1.9995, -2.1323, -2.0092, -2.2091, -2.0961, -1.8688,\n",
      "        -1.9147, -2.1692], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0918, -2.0756, -2.1403, -2.0735, -2.0875, -2.0385, -2.1159, -2.0869,\n",
      "        -2.0791, -2.0882, -2.0632, -2.0808, -2.1168, -2.0429, -2.0844, -2.0558,\n",
      "        -2.1226, -2.0491, -2.0966, -2.0326, -2.0714, -2.0259, -2.0783, -2.0305,\n",
      "        -2.0470, -2.0891, -2.0586, -2.0926, -2.0972, -2.1026, -2.0221, -2.0589,\n",
      "        -2.0848, -2.1120, -2.0966, -2.0686, -2.0931, -2.0295, -2.0593, -2.0643,\n",
      "        -2.0532, -2.0410, -2.0914, -1.9940, -2.0808, -2.0997, -2.1291, -2.1046,\n",
      "        -2.0435, -2.0237], device='mps:0')\n",
      "mean: tensor(-2.0733, device='mps:0')\n",
      "iter_dt 1.07s; iter 91: train loss 0.32311 temperature: 9.550000000000011\n",
      "mean_logits tensor([-2.0765, -2.1913, -2.0914, -2.2047, -1.8879, -2.1507, -2.3743, -1.9584,\n",
      "        -2.0521, -1.8288, -1.8073, -2.0021, -2.1463, -2.0819, -2.0384, -1.8879,\n",
      "        -1.9824, -2.2756, -2.3421, -2.1782, -1.8896, -2.1294, -2.0441, -2.2355,\n",
      "        -2.2044, -2.1264, -2.1742, -1.8477, -2.4489, -2.0559, -2.2147, -2.4171,\n",
      "        -2.2046, -2.3310, -2.1100, -1.8989, -2.0751, -1.6235, -2.2706, -2.4342,\n",
      "        -2.1995, -2.1468, -2.0208, -2.3042, -2.1853, -1.8026, -2.2704, -2.1241,\n",
      "        -2.4786, -2.1407], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0775, -2.0889, -2.0772, -2.1096, -2.0910, -2.1080, -2.1026, -2.0312,\n",
      "        -2.1269, -2.0729, -2.0647, -2.1112, -2.0845, -2.1220, -2.1174, -2.0176,\n",
      "        -2.0666, -2.1174, -2.1173, -2.0844, -2.0641, -2.1182, -2.0710, -2.0807,\n",
      "        -2.0802, -2.0896, -2.0412, -2.0453, -2.1037, -2.0661, -2.0714, -2.0614,\n",
      "        -2.0834, -2.1053, -2.0643, -2.1191, -2.0911, -2.0421, -2.0438, -2.0603,\n",
      "        -2.0699, -2.0467, -2.1226, -2.0717, -2.0989, -2.0677, -2.0720, -2.0909,\n",
      "        -2.0933, -2.0683], device='mps:0')\n",
      "mean: tensor(-2.0819, device='mps:0')\n",
      "iter_dt 1.05s; iter 92: train loss 0.19452 temperature: 9.600000000000012\n",
      "mean_logits tensor([-2.1628, -2.0294, -1.9364, -1.9087, -2.1032, -2.1847, -1.8779, -2.0721,\n",
      "        -2.2267, -2.2373, -2.0069, -2.1327, -2.3141, -1.8518, -2.2061, -2.3321,\n",
      "        -2.1272, -2.1576, -1.8237, -2.1337, -2.2702, -2.1904, -2.3062, -2.1229,\n",
      "        -1.9774, -1.9880, -2.4226, -2.0955, -2.2936, -2.0659, -2.2670, -2.3204,\n",
      "        -2.2634, -1.8040, -1.8531, -2.1312, -2.1351, -2.0476, -2.2103, -1.9958,\n",
      "        -1.7617, -1.9840, -2.0902, -2.0740, -2.1069, -2.0788, -2.1951, -2.0290,\n",
      "        -2.1498, -1.9812], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1088, -2.0433, -2.0874, -2.0675, -2.1043, -2.1222, -2.0183, -2.0958,\n",
      "        -2.1390, -2.0963, -2.1018, -2.1210, -2.0235, -2.0612, -2.0631, -2.0972,\n",
      "        -2.0943, -2.0673, -2.0772, -2.0709, -2.1130, -2.0722, -2.0967, -2.1387,\n",
      "        -2.0929, -2.0521, -2.0904, -2.0753, -2.0955, -2.0906, -2.0849, -2.0474,\n",
      "        -2.0766, -2.0783, -2.1086, -2.1422, -2.0892, -2.0915, -2.1058, -2.0255,\n",
      "        -2.0414, -2.0905, -2.0737, -2.0934, -2.1164, -2.0559, -2.0953, -2.1048,\n",
      "        -2.1046, -2.0346], device='mps:0')\n",
      "mean: tensor(-2.0848, device='mps:0')\n",
      "iter_dt 1.05s; iter 93: train loss 0.28167 temperature: 9.650000000000013\n",
      "mean_logits tensor([-1.9736, -2.0622, -2.0959, -2.0889, -2.0817, -1.9748, -2.2251, -2.1835,\n",
      "        -2.0481, -2.1682, -2.2589, -2.1892, -2.4629, -1.9074, -2.1267, -1.9048,\n",
      "        -1.9792, -1.9303, -2.1344, -2.1811, -2.5734, -2.2450, -2.0256, -1.9133,\n",
      "        -1.9158, -2.0528, -2.3334, -2.1920, -1.8394, -2.0112, -2.1836, -2.2553,\n",
      "        -2.3872, -2.2796, -2.0308, -2.0250, -2.0407, -2.0798, -2.2276, -2.0432,\n",
      "        -2.2362, -1.9122, -2.2212, -2.1869, -1.6815, -1.9696, -2.0443, -1.8598,\n",
      "        -1.7795, -1.9654], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0924, -2.0882, -2.0931, -2.0852, -2.1127, -2.1331, -2.1270, -2.0930,\n",
      "        -2.1053, -2.0880, -2.0322, -2.0945, -2.0807, -2.1049, -2.0965, -2.1277,\n",
      "        -2.0692, -2.0070, -2.1218, -2.1021, -2.0982, -2.1119, -2.0838, -2.0407,\n",
      "        -2.0098, -2.0876, -2.1154, -2.0914, -2.0714, -2.0895, -2.0853, -2.0890,\n",
      "        -2.0880, -2.0036, -2.0839, -2.1045, -2.0941, -2.0586, -2.0947, -2.0668,\n",
      "        -2.0726, -2.0947, -2.0869, -2.1158, -2.0940, -2.0900, -2.0699, -2.0731,\n",
      "        -2.0808, -2.0604], device='mps:0')\n",
      "mean: tensor(-2.0852, device='mps:0')\n",
      "iter_dt 1.04s; iter 94: train loss 0.28048 temperature: 9.700000000000014\n",
      "mean_logits tensor([-2.0042, -1.9963, -2.1750, -2.1874, -2.3508, -2.1347, -2.1680, -2.1243,\n",
      "        -2.4861, -2.0343, -2.2461, -2.1975, -2.1037, -1.8223, -2.1895, -2.4369,\n",
      "        -2.2563, -2.0669, -1.9449, -2.3267, -2.3243, -2.2753, -2.0066, -2.1006,\n",
      "        -2.1487, -2.2310, -2.2908, -2.1181, -1.7392, -2.1040, -2.1397, -1.9379,\n",
      "        -2.1082, -1.9894, -2.0319, -2.2244, -1.7331, -2.1685, -1.8961, -1.9773,\n",
      "        -2.1007, -2.2855, -2.0653, -1.9636, -2.2739, -1.7800, -2.0384, -2.2484,\n",
      "        -1.6967, -2.2865], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1143, -1.9865, -2.0761, -2.0942, -2.1109, -2.0863, -2.0730, -2.0991,\n",
      "        -2.0886, -2.0881, -2.1333, -2.0517, -2.0966, -2.0657, -2.0890, -2.1070,\n",
      "        -2.0395, -2.0472, -2.0910, -2.0870, -2.0824, -2.1057, -2.0812, -2.1072,\n",
      "        -2.1175, -2.0942, -2.1193, -2.0875, -2.0860, -2.0830, -2.0961, -2.1053,\n",
      "        -2.0741, -2.0834, -2.0947, -2.0504, -2.0740, -2.1682, -2.0874, -2.1221,\n",
      "        -2.0482, -2.0634, -2.0914, -2.0849, -2.0746, -2.0727, -2.0896, -2.0833,\n",
      "        -2.0658, -2.0739], device='mps:0')\n",
      "mean: tensor(-2.0858, device='mps:0')\n",
      "iter_dt 1.03s; iter 95: train loss 0.27349 temperature: 9.750000000000014\n",
      "mean_logits tensor([-2.2334, -2.1937, -2.2273, -1.7899, -1.9933, -1.9059, -1.9357, -2.2370,\n",
      "        -1.8165, -2.3382, -1.9703, -2.0093, -2.1994, -2.1484, -1.9069, -2.2901,\n",
      "        -2.3542, -1.9564, -2.0913, -1.9791, -1.7702, -2.0904, -2.0130, -1.9888,\n",
      "        -2.1435, -2.0951, -2.0198, -2.0261, -2.0220, -2.4759, -2.1962, -2.1653,\n",
      "        -2.3030, -2.5014, -1.8224, -2.0527, -2.0026, -2.0281, -2.3021, -2.1821,\n",
      "        -2.1394, -2.0684, -2.0901, -2.0493, -1.9661, -1.9721, -2.1129, -1.8254,\n",
      "        -1.7482, -2.1544], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0668, -2.0942, -2.0728, -2.0619, -2.0058, -2.0769, -2.0683, -2.1038,\n",
      "        -2.1093, -2.0926, -2.0898, -2.0570, -2.0871, -2.0476, -2.0407, -2.1136,\n",
      "        -2.1168, -2.0995, -2.0657, -2.0895, -2.1136, -2.0443, -2.0811, -2.0905,\n",
      "        -2.1171, -2.0785, -2.1007, -2.1142, -2.0870, -2.0876, -2.0935, -2.0804,\n",
      "        -2.0692, -2.0862, -2.0507, -2.0865, -2.0963, -2.0925, -2.0616, -2.0826,\n",
      "        -2.0789, -2.0423, -2.0979, -2.0836, -2.1098, -2.0942, -2.0330, -2.1096,\n",
      "        -2.0760, -2.0613], device='mps:0')\n",
      "mean: tensor(-2.0812, device='mps:0')\n",
      "iter_dt 1.06s; iter 96: train loss 0.36320 temperature: 9.800000000000015\n",
      "mean_logits tensor([-2.1173, -2.1073, -1.7494, -2.0193, -1.8346, -2.0422, -2.2907, -1.5593,\n",
      "        -2.4652, -2.0312, -1.8523, -2.2581, -2.1433, -2.2275, -2.3043, -2.2453,\n",
      "        -1.9825, -2.0198, -2.0854, -1.9880, -2.0416, -1.8592, -2.1356, -2.0986,\n",
      "        -1.9423, -2.1643, -1.8907, -2.2493, -2.3688, -1.9994, -1.8165, -2.1326,\n",
      "        -1.9831, -2.0426, -1.9198, -1.8769, -1.9044, -2.1874, -2.2076, -2.1808,\n",
      "        -2.0634, -2.0611, -1.6399, -2.1100, -1.9181, -2.3455, -1.9415, -2.0612,\n",
      "        -2.5839, -2.3135], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0962, -2.0729, -2.0779, -2.0923, -2.0776, -2.0972, -2.0876, -2.1301,\n",
      "        -2.0834, -2.0313, -2.0789, -2.0731, -2.0969, -2.0589, -2.0934, -2.0936,\n",
      "        -2.0041, -2.1264, -2.0735, -2.0422, -2.0982, -2.0836, -2.0810, -2.1216,\n",
      "        -2.1033, -2.0996, -2.0762, -2.0377, -2.0605, -2.0909, -2.0823, -2.1058,\n",
      "        -2.0858, -2.0722, -2.0856, -2.1033, -2.0680, -2.0896, -2.0893, -2.0863,\n",
      "        -2.1130, -2.0873, -2.0814, -2.0378, -2.0926, -2.0955, -2.0961, -2.0603,\n",
      "        -2.0593, -2.0898], device='mps:0')\n",
      "mean: tensor(-2.0824, device='mps:0')\n",
      "iter_dt 1.07s; iter 97: train loss 0.29098 temperature: 9.850000000000016\n",
      "mean_logits tensor([-2.1018, -2.2450, -1.9104, -2.1544, -2.2928, -2.1256, -1.9205, -1.9477,\n",
      "        -2.1262, -1.9177, -2.1841, -1.8655, -2.1821, -2.3171, -2.1852, -2.1022,\n",
      "        -1.8580, -2.0182, -2.0249, -1.7732, -2.4175, -2.1893, -2.0280, -1.7021,\n",
      "        -2.2808, -2.1135, -1.8970, -2.0802, -2.1376, -2.1638, -2.2251, -2.1794,\n",
      "        -1.8462, -2.2644, -2.1944, -2.0812, -2.0621, -1.9755, -2.2436, -1.9943,\n",
      "        -2.1145, -2.2499, -1.5861, -2.1165, -2.0729, -2.4285, -2.1882, -2.4189,\n",
      "        -1.6999, -1.9751], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0916, -2.1182, -2.1152, -2.1461, -2.0749, -2.1058, -2.0659, -2.1010,\n",
      "        -2.0968, -2.1064, -2.0855, -2.1377, -2.0852, -2.0889, -2.0994, -2.0986,\n",
      "        -2.1202, -2.1277, -2.0584, -2.1079, -2.1089, -2.0999, -2.1038, -2.0743,\n",
      "        -2.0983, -2.0584, -2.0484, -2.1129, -2.1080, -2.1300, -2.1029, -2.0989,\n",
      "        -2.0608, -2.0872, -2.0916, -2.0915, -2.0520, -2.0919, -2.1074, -2.0597,\n",
      "        -2.1040, -2.0353, -2.0978, -2.0522, -2.0448, -2.0670, -2.0826, -2.0630,\n",
      "        -2.0952, -2.0252], device='mps:0')\n",
      "mean: tensor(-2.0897, device='mps:0')\n",
      "iter_dt 1.06s; iter 98: train loss 0.33711 temperature: 9.900000000000016\n",
      "mean_logits tensor([-2.1734, -1.9831, -2.0233, -2.4090, -2.1268, -1.6797, -2.0792, -1.9003,\n",
      "        -2.0500, -1.7100, -1.9531, -2.2008, -1.8144, -2.1139, -2.2633, -1.9587,\n",
      "        -1.8914, -2.2899, -2.0712, -2.1642, -2.0611, -2.5614, -1.9170, -1.9203,\n",
      "        -2.0403, -2.1056, -2.2509, -2.0980, -2.4098, -2.0787, -2.2829, -2.1073,\n",
      "        -2.0910, -2.2166, -2.0514, -1.9315, -1.8968, -1.7864, -2.0724, -2.2552,\n",
      "        -2.0325, -1.7904, -2.1202, -2.3138, -1.8972, -1.7565, -2.2776, -2.0248,\n",
      "        -2.1193, -1.9006], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0952, -2.0938, -2.1152, -2.0897, -2.1053, -2.1092, -2.0864, -2.0798,\n",
      "        -2.0233, -2.0678, -2.0939, -2.0900, -2.0731, -2.0611, -2.0891, -2.1289,\n",
      "        -2.0080, -2.1039, -2.0779, -2.0757, -2.0414, -2.0172, -2.1173, -2.0896,\n",
      "        -2.1000, -2.0495, -2.1017, -2.0815, -2.1139, -2.0844, -2.0731, -2.1089,\n",
      "        -2.0210, -2.0799, -2.1043, -2.0817, -2.0402, -2.0920, -2.0892, -2.0739,\n",
      "        -2.0783, -2.0991, -2.0720, -2.0687, -2.1091, -2.1119, -2.0205, -2.0516,\n",
      "        -2.1033, -2.1121], device='mps:0')\n",
      "mean: tensor(-2.0811, device='mps:0')\n",
      "iter_dt 1.05s; iter 99: train loss 0.31942 temperature: 9.950000000000017\n",
      "mean_logits tensor([-2.1689, -2.0997, -2.0503, -2.0503, -2.0069, -2.2499, -2.2818, -1.9501,\n",
      "        -2.3438, -2.1016, -1.9987, -2.3927, -2.4154, -2.2619, -2.2033, -2.0300,\n",
      "        -2.1846, -2.0535, -2.5185, -2.2588, -1.9858, -1.8303, -2.1043, -1.8426,\n",
      "        -1.9100, -2.0376, -2.2853, -1.8818, -1.7285, -1.9603, -2.1434, -2.4054,\n",
      "        -1.9281, -1.9237, -2.3065, -1.9018, -2.3134, -1.8284, -2.0886, -2.1984,\n",
      "        -2.0036, -2.0575, -2.2263, -1.9962, -2.0710, -1.8980, -1.9794, -2.2691,\n",
      "        -1.9442, -2.2235], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.0543, -2.0538, -2.1281, -2.1085, -2.0775, -2.1246, -2.0914, -2.0880,\n",
      "        -2.0666, -2.0201, -2.0877, -2.0958, -2.1014, -2.0903, -2.0700, -2.1011,\n",
      "        -2.1021, -2.0849, -2.0937, -2.0409, -2.0930, -2.0792, -2.0864, -2.0869,\n",
      "        -2.0825, -2.0986, -2.0671, -2.0308, -2.1048, -2.0467, -2.0590, -2.0825,\n",
      "        -2.0810, -2.0820, -2.0553, -2.0359, -2.0785, -2.0893, -2.0807, -2.0925,\n",
      "        -2.0489, -2.0852, -2.0345, -2.1697, -2.0975, -2.0627, -2.0919, -2.0598,\n",
      "        -2.0958, -2.1145], device='mps:0')\n",
      "mean: tensor(-2.0811, device='mps:0')\n",
      "current_prefixes: [7278 4037 5557 4534 4632 6985  380 4805 4101 4404]\n",
      "layer: 3 starts running\n",
      "number of parameters: 91.99M\n",
      "running on device mps\n",
      "iter_dt 0.00s; iter 0: train loss 0.75444 temperature: 5\n",
      "mean_logits tensor([-2.1701, -1.6379, -1.8242, -2.2044, -2.2128, -2.0123, -1.5228, -1.9391,\n",
      "        -1.6574, -1.7613, -1.9753, -1.9355, -1.7975, -2.3889, -2.0770, -1.3299,\n",
      "        -1.9751, -2.0892, -1.7869, -1.6944, -2.3472, -1.5798, -1.8675, -2.3846,\n",
      "        -2.0543, -1.8171, -1.9019, -1.5603, -2.3064, -1.9454, -1.8092, -1.9150,\n",
      "        -1.9125, -2.3336, -1.9747, -2.0336, -2.1011, -2.3420, -2.0830, -2.0068,\n",
      "        -2.0511, -1.9832, -1.7941, -1.8888, -1.7227, -1.9339, -2.3612, -2.0179,\n",
      "        -1.8539, -2.0005], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2195, -2.1400, -2.1940, -2.1925, -2.1929, -2.1944, -2.2292, -2.1751,\n",
      "        -2.1932, -2.1037, -2.1917, -2.1960, -2.1760, -2.2343, -2.2122, -2.2297,\n",
      "        -2.1885, -2.2021, -2.1523, -2.1812, -2.1957, -2.1940, -2.1595, -2.1860,\n",
      "        -2.1809, -2.1984, -2.1905, -2.1932, -2.1700, -2.1942, -2.2370, -2.1780,\n",
      "        -2.1674, -2.1884, -2.1912, -2.2032, -2.1900, -2.2064, -2.1927, -2.2128,\n",
      "        -2.1841, -2.1803, -2.1868, -2.1003, -2.2029, -2.1982, -2.1927, -2.1704,\n",
      "        -2.1851, -2.1867], device='mps:0')\n",
      "mean: tensor(-2.1883, device='mps:0')\n",
      "iter_dt 1695863975.57s; iter 1: train loss 0.57327 temperature: 5.05\n",
      "mean_logits tensor([-2.1317, -2.0416, -1.9207, -2.3216, -1.8763, -2.1719, -2.1191, -2.0586,\n",
      "        -2.1516, -1.8938, -1.8576, -1.7851, -2.1240, -1.9489, -1.8256, -2.2862,\n",
      "        -2.2446, -1.8404, -1.8364, -1.9838, -1.9684, -2.3118, -1.9274, -1.9045,\n",
      "        -2.5027, -1.9841, -1.9009, -2.1132, -2.1947, -1.9159, -1.7342, -2.4595,\n",
      "        -1.9133, -2.0474, -2.1895, -2.5535, -1.7941, -1.9841, -1.8668, -1.9563,\n",
      "        -2.0210, -1.9365, -1.7208, -2.1250, -2.2124, -1.6462, -2.1775, -1.9893,\n",
      "        -2.1176, -1.6234], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1716, -2.2010, -2.1981, -2.1899, -2.1708, -2.1689, -2.1890, -2.1971,\n",
      "        -2.1924, -2.1798, -2.1315, -2.1947, -2.1601, -2.1952, -2.1701, -2.1488,\n",
      "        -2.1905, -2.1684, -2.1790, -2.1909, -2.1926, -2.1917, -2.2010, -2.2142,\n",
      "        -2.2003, -2.2031, -2.1608, -2.1950, -2.1435, -2.1959, -2.1944, -2.1913,\n",
      "        -2.1440, -2.1633, -2.1597, -2.1302, -2.1935, -2.1895, -2.1392, -2.2055,\n",
      "        -2.1586, -2.1953, -2.2149, -2.1656, -2.1581, -2.1909, -2.1761, -2.1940,\n",
      "        -2.1979, -2.1960], device='mps:0')\n",
      "mean: tensor(-2.1809, device='mps:0')\n",
      "iter_dt 1.07s; iter 2: train loss 0.67967 temperature: 5.1\n",
      "mean_logits tensor([-1.6459, -2.1539, -1.8492, -2.3135, -2.3203, -1.8821, -2.4948, -2.3021,\n",
      "        -1.5260, -2.3106, -2.0523, -2.0745, -2.1516, -2.1284, -1.8427, -2.2520,\n",
      "        -2.6558, -2.3633, -1.9633, -2.0101, -2.6074, -2.3025, -2.2819, -2.1146,\n",
      "        -1.9174, -2.0367, -2.5180, -2.1355, -2.2671, -2.2280, -1.8950, -2.1521,\n",
      "        -1.7774, -1.7288, -2.2627, -1.8000, -1.7907, -1.7789, -1.8969, -2.5715,\n",
      "        -1.9690, -2.2790, -2.2532, -1.6619, -2.2671, -2.1000, -2.4740, -2.0497,\n",
      "        -1.9964, -2.1369], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2039, -2.1958, -2.1475, -2.1961, -2.1592, -2.2191, -2.1904, -2.2524,\n",
      "        -2.1481, -2.1960, -2.2014, -2.1906, -2.1957, -2.1798, -2.1425, -2.1591,\n",
      "        -2.1939, -2.1816, -2.1922, -2.1968, -2.1917, -2.1877, -2.1938, -2.2087,\n",
      "        -2.1812, -2.1865, -2.1944, -2.1919, -2.1963, -2.1946, -2.1933, -2.1937,\n",
      "        -2.1420, -2.2030, -2.2038, -2.1607, -2.1933, -2.2023, -2.1780, -2.1885,\n",
      "        -2.1958, -2.2180, -2.1732, -2.1892, -2.1716, -2.1922, -2.1464, -2.1850,\n",
      "        -2.2084, -2.1903], device='mps:0')\n",
      "mean: tensor(-2.1880, device='mps:0')\n",
      "iter_dt 1.01s; iter 3: train loss 0.63736 temperature: 5.1499999999999995\n",
      "mean_logits tensor([-2.0346, -1.6806, -2.3473, -1.6643, -2.0463, -2.0278, -1.9948, -2.1239,\n",
      "        -2.2029, -1.6664, -2.2334, -2.1517, -2.0687, -2.4132, -2.6999, -2.3301,\n",
      "        -1.9551, -2.2267, -2.2380, -2.2780, -1.9798, -2.4654, -1.7433, -1.9084,\n",
      "        -2.1882, -1.5978, -2.0462, -2.1835, -2.5281, -2.1362, -1.7740, -2.6059,\n",
      "        -1.9619, -2.1496, -1.7932, -1.5067, -2.2781, -2.1457, -1.9617, -1.7998,\n",
      "        -2.2086, -2.3151, -2.3920, -2.2007, -2.0549, -2.2085, -1.9491, -2.1631,\n",
      "        -2.2253, -2.3512], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1919, -2.1506, -2.1902, -2.1910, -2.1987, -2.1850, -2.2096, -2.1623,\n",
      "        -2.1875, -2.1654, -2.1898, -2.2064, -2.1270, -2.2081, -2.2040, -2.1319,\n",
      "        -2.1721, -2.1499, -2.1947, -2.1729, -2.1941, -2.1968, -2.1635, -2.1637,\n",
      "        -2.1781, -2.1975, -2.1928, -2.1933, -2.1781, -2.1742, -2.2632, -2.1506,\n",
      "        -2.1456, -2.1662, -2.1452, -2.1445, -2.1981, -2.1946, -2.1482, -2.1788,\n",
      "        -2.1770, -2.1274, -2.1870, -2.1668, -2.1635, -2.2070, -2.1532, -2.1846,\n",
      "        -2.1353, -2.1874], device='mps:0')\n",
      "mean: tensor(-2.1769, device='mps:0')\n",
      "iter_dt 1.04s; iter 4: train loss 0.53301 temperature: 5.199999999999999\n",
      "mean_logits tensor([-1.4708, -2.0035, -1.4010, -1.9870, -2.1641, -2.3072, -2.2856, -1.9862,\n",
      "        -2.2571, -1.9899, -2.2660, -2.2226, -2.1976, -1.9905, -2.0813, -1.7889,\n",
      "        -1.5683, -2.1061, -2.0940, -1.7067, -2.0956, -2.3214, -2.0728, -1.9524,\n",
      "        -2.0443, -2.0628, -1.6115, -2.2515, -2.1485, -2.2601, -2.0463, -1.9512,\n",
      "        -1.9948, -2.3067, -1.9771, -2.1839, -2.1875, -2.1491, -2.2235, -1.9773,\n",
      "        -2.3559, -2.3950, -1.7922, -1.9666, -2.5410, -1.7082, -2.0539, -2.4462,\n",
      "        -2.1085, -2.1454], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1934, -2.1627, -2.1929, -2.1564, -2.1889, -2.1984, -2.1946, -2.1429,\n",
      "        -2.1771, -2.1886, -2.1513, -2.1904, -2.2020, -2.1552, -2.2127, -2.2214,\n",
      "        -2.1924, -2.1928, -2.1725, -2.1284, -2.2018, -2.1955, -2.2095, -2.2024,\n",
      "        -2.1773, -2.1928, -2.1951, -2.2539, -2.1807, -2.1345, -2.1663, -2.1972,\n",
      "        -2.2109, -2.1863, -2.1594, -2.1899, -2.1593, -2.1956, -2.1814, -2.0992,\n",
      "        -2.1747, -2.1221, -2.1940, -2.1971, -2.1920, -2.1391, -2.1961, -2.0751,\n",
      "        -2.1949, -2.2476], device='mps:0')\n",
      "mean: tensor(-2.1807, device='mps:0')\n",
      "iter_dt 1.04s; iter 5: train loss 0.56487 temperature: 5.249999999999999\n",
      "mean_logits tensor([-2.0594, -1.9594, -1.5955, -2.0895, -2.1777, -2.0512, -2.6246, -2.0252,\n",
      "        -2.1698, -2.0699, -2.1088, -1.7941, -2.4146, -2.1971, -1.7561, -2.4206,\n",
      "        -2.0173, -2.4154, -1.9808, -2.1397, -2.1396, -2.0643, -2.3531, -2.4449,\n",
      "        -2.0299, -2.2130, -1.9842, -1.9961, -2.1648, -1.8011, -2.5584, -1.9278,\n",
      "        -2.1848, -2.2009, -1.5676, -2.3230, -1.9301, -1.7972, -2.2607, -2.5326,\n",
      "        -2.0706, -2.0539, -2.4928, -2.2792, -2.1099, -2.3274, -1.8199, -2.1910,\n",
      "        -2.1579, -2.0190], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1922, -2.1967, -2.1904, -2.1847, -2.1853, -2.1982, -2.1973, -2.1924,\n",
      "        -2.1523, -2.2328, -2.1889, -2.1538, -2.1876, -2.2000, -2.1789, -2.1642,\n",
      "        -2.1356, -2.1934, -2.1337, -2.1892, -2.0819, -2.1720, -2.1437, -2.1591,\n",
      "        -2.1469, -2.1317, -2.1674, -2.1985, -2.1990, -2.2035, -2.1833, -2.1595,\n",
      "        -2.1195, -2.1694, -2.1852, -2.1851, -2.1858, -2.1936, -2.1709, -2.1925,\n",
      "        -2.2272, -2.1788, -2.1373, -2.1959, -2.1547, -2.2033, -2.2227, -2.1888,\n",
      "        -2.1303, -2.1896], device='mps:0')\n",
      "mean: tensor(-2.1765, device='mps:0')\n",
      "iter_dt 1.01s; iter 6: train loss 0.52752 temperature: 5.299999999999999\n",
      "mean_logits tensor([-1.9972, -2.1251, -2.3019, -1.8880, -1.4705, -1.8079, -2.0698, -2.1893,\n",
      "        -2.0824, -1.5940, -2.1732, -2.0508, -1.9801, -1.9607, -2.2229, -1.9609,\n",
      "        -2.4633, -2.3667, -2.2247, -2.1328, -1.9398, -1.9986, -1.7810, -1.8822,\n",
      "        -1.7757, -2.0189, -1.4209, -2.0053, -2.3807, -1.9654, -2.3739, -2.0558,\n",
      "        -2.1503, -1.8840, -2.4197, -2.1229, -1.8253, -2.2844, -2.1706, -2.3061,\n",
      "        -2.3511, -2.1523, -2.2210, -1.8469, -2.4311, -2.0969, -2.1168, -1.9458,\n",
      "        -1.9508, -2.0132], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2059, -2.1960, -2.1939, -2.1714, -2.1404, -2.1838, -2.2523, -2.1935,\n",
      "        -2.2024, -2.1652, -2.2159, -2.2198, -2.1487, -2.2070, -2.1946, -2.2109,\n",
      "        -2.1862, -2.1308, -2.1925, -2.2166, -2.1981, -2.1654, -2.1917, -2.1930,\n",
      "        -2.1858, -2.1825, -2.1735, -2.1515, -2.1905, -2.2157, -2.2546, -2.2113,\n",
      "        -2.2581, -2.2119, -2.1570, -2.1753, -2.1937, -2.1944, -2.1702, -2.1876,\n",
      "        -2.1850, -2.1675, -2.1940, -2.1807, -2.1617, -2.1670, -2.1422, -2.2108,\n",
      "        -2.2036, -2.2085], device='mps:0')\n",
      "mean: tensor(-2.1902, device='mps:0')\n",
      "iter_dt 1.04s; iter 7: train loss 0.33158 temperature: 5.349999999999999\n",
      "mean_logits tensor([-2.2248, -2.1090, -2.2610, -2.2785, -2.0812, -2.0465, -1.9476, -1.9554,\n",
      "        -2.0060, -2.2133, -2.1867, -2.1453, -1.9719, -2.2251, -1.8540, -1.9980,\n",
      "        -2.2242, -1.8966, -2.1820, -2.1545, -1.7542, -2.2842, -1.9188, -1.7993,\n",
      "        -2.0575, -2.4614, -2.3755, -2.1843, -2.3190, -2.1496, -1.8707, -2.0811,\n",
      "        -2.1236, -2.4627, -1.9115, -2.1781, -2.0294, -2.1987, -2.1634, -2.0816,\n",
      "        -2.4462, -2.1868, -1.8651, -2.2897, -2.0448, -2.1656, -2.0719, -2.5645,\n",
      "        -2.0599, -2.0184], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1932, -2.1419, -2.1371, -2.1685, -2.1857, -2.1569, -2.1799, -2.2252,\n",
      "        -2.1437, -2.1918, -2.1894, -2.1476, -2.0934, -2.2016, -2.1804, -2.1935,\n",
      "        -2.1961, -2.1481, -2.1798, -2.1996, -2.2003, -2.2439, -2.1318, -2.1566,\n",
      "        -2.1197, -2.1972, -2.1963, -2.1936, -2.2023, -2.1821, -2.2065, -2.1777,\n",
      "        -2.1973, -2.1488, -2.2243, -2.1964, -2.2555, -2.1808, -2.2146, -2.1882,\n",
      "        -2.1821, -2.1827, -2.1795, -2.1729, -2.1483, -2.0959, -2.1870, -2.1944,\n",
      "        -2.1650, -2.1831], device='mps:0')\n",
      "mean: tensor(-2.1792, device='mps:0')\n",
      "iter_dt 1.04s; iter 8: train loss 0.39194 temperature: 5.399999999999999\n",
      "mean_logits tensor([-2.1945, -2.1755, -1.8903, -2.1175, -2.0124, -2.0089, -2.4585, -2.2438,\n",
      "        -1.9039, -2.0372, -1.6935, -2.2559, -2.3642, -1.9581, -2.3036, -2.2098,\n",
      "        -1.8505, -2.0989, -2.1346, -2.2327, -2.1037, -2.0686, -2.2779, -2.2032,\n",
      "        -2.0807, -1.7673, -2.1281, -1.6901, -2.0226, -2.0018, -1.9610, -2.0875,\n",
      "        -2.2983, -1.5436, -1.9858, -1.9672, -1.9810, -2.1512, -1.8185, -2.1518,\n",
      "        -1.9701, -2.0403, -2.2030, -1.8734, -2.0027, -2.0631, -1.7306, -2.1557,\n",
      "        -2.3961, -2.3159], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2081, -2.1568, -2.1761, -2.1923, -2.1569, -2.1939, -2.1826, -2.1951,\n",
      "        -2.2012, -2.1371, -2.1544, -2.1761, -2.1627, -2.1934, -2.1779, -2.1501,\n",
      "        -2.1889, -2.2029, -2.1392, -2.1948, -2.1481, -2.1565, -2.1946, -2.1641,\n",
      "        -2.1983, -2.1793, -2.1399, -2.1936, -2.1799, -2.1492, -2.1562, -2.1924,\n",
      "        -2.1425, -2.1770, -2.2022, -2.1326, -2.1931, -2.1952, -2.2087, -2.1866,\n",
      "        -2.1888, -2.2037, -2.1933, -2.1369, -2.1931, -2.1694, -2.1925, -2.1358,\n",
      "        -2.1878, -2.1889], device='mps:0')\n",
      "mean: tensor(-2.1764, device='mps:0')\n",
      "iter_dt 1.01s; iter 9: train loss 0.50033 temperature: 5.449999999999998\n",
      "mean_logits tensor([-2.1370, -1.8578, -2.4907, -2.3694, -2.2226, -2.0021, -2.1562, -2.1673,\n",
      "        -1.9170, -2.3287, -1.8089, -1.9371, -1.8032, -1.8722, -2.0958, -2.4234,\n",
      "        -2.0591, -2.5503, -2.3346, -1.9967, -2.3601, -2.3101, -2.3464, -2.0642,\n",
      "        -2.1018, -2.1796, -2.2350, -2.0932, -1.6215, -2.2016, -2.1613, -2.1580,\n",
      "        -2.2500, -2.3173, -2.4249, -2.2413, -1.9255, -1.9424, -2.0558, -1.8139,\n",
      "        -2.5234, -1.7936, -1.8497, -2.1219, -2.0598, -2.4419, -2.3802, -1.8102,\n",
      "        -1.7258, -2.2535], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1472, -2.1417, -2.1919, -2.1943, -2.1378, -2.1738, -2.1803, -2.2024,\n",
      "        -2.2046, -2.1968, -2.1956, -2.1904, -2.1329, -2.1952, -2.2112, -2.1943,\n",
      "        -2.1898, -2.2178, -2.1932, -2.1693, -2.1059, -2.2049, -2.1733, -2.1706,\n",
      "        -2.1587, -2.2030, -2.2618, -2.1925, -2.1833, -2.1976, -2.1902, -2.1948,\n",
      "        -2.2093, -2.1880, -2.1936, -2.1691, -2.1939, -2.1793, -2.1952, -2.1999,\n",
      "        -2.1910, -2.1666, -2.2113, -2.1897, -2.1912, -2.1794, -2.1955, -2.1808,\n",
      "        -2.1940, -2.1749], device='mps:0')\n",
      "mean: tensor(-2.1860, device='mps:0')\n",
      "iter_dt 1.00s; iter 10: train loss 0.60664 temperature: 5.499999999999998\n",
      "mean_logits tensor([-1.9917, -2.1673, -2.0326, -1.9071, -2.3099, -1.9614, -2.0142, -2.3303,\n",
      "        -2.0896, -1.8715, -1.9019, -2.0313, -2.7508, -1.7757, -2.4660, -2.1915,\n",
      "        -2.2644, -1.6636, -2.1304, -2.1738, -2.1010, -2.1635, -2.4653, -2.1107,\n",
      "        -2.1054, -2.3447, -1.5891, -2.0432, -2.0366, -2.4011, -2.3221, -1.9975,\n",
      "        -1.9669, -2.4294, -2.3846, -2.1424, -2.2502, -2.2309, -1.9058, -2.0928,\n",
      "        -1.5434, -2.4263, -2.1247, -2.1085, -1.9221, -2.3184, -2.4494, -2.5714,\n",
      "        -2.1541, -1.9336], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1985, -2.1900, -2.1936, -2.2048, -2.1982, -2.1939, -2.1814, -2.1385,\n",
      "        -2.1182, -2.1964, -2.2074, -2.2197, -2.2119, -2.1778, -2.1970, -2.1859,\n",
      "        -2.1952, -2.1996, -2.1944, -2.1665, -2.1219, -2.1940, -2.1879, -2.2489,\n",
      "        -2.1853, -2.1950, -2.1807, -2.1924, -2.1755, -2.1909, -2.1296, -2.2223,\n",
      "        -2.1729, -2.1921, -2.1478, -2.2081, -2.1926, -2.1391, -2.1437, -2.1642,\n",
      "        -2.1668, -2.2286, -2.2170, -2.1949, -2.1956, -2.1657, -2.2154, -2.1907,\n",
      "        -2.2011, -2.1975], device='mps:0')\n",
      "mean: tensor(-2.1865, device='mps:0')\n",
      "iter_dt 1.01s; iter 11: train loss 0.56877 temperature: 5.549999999999998\n",
      "mean_logits tensor([-2.1907, -1.7634, -1.8377, -2.2477, -1.4658, -1.8657, -2.2412, -1.6394,\n",
      "        -2.3495, -2.5389, -2.3110, -2.2923, -2.4412, -2.4752, -2.2642, -2.1560,\n",
      "        -1.8785, -2.2753, -2.5671, -1.4920, -1.7725, -2.1175, -2.0229, -1.9639,\n",
      "        -2.4023, -2.1348, -1.9050, -2.2196, -1.9861, -2.0478, -2.3699, -1.7124,\n",
      "        -1.9888, -2.2435, -2.2234, -2.0202, -1.7893, -2.1002, -2.2468, -2.3097,\n",
      "        -1.8817, -2.4220, -2.4061, -2.0775, -1.9664, -2.1215, -2.1378, -2.0611,\n",
      "        -2.0049, -2.2754], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1836, -2.1783, -2.1749, -2.1915, -2.2304, -2.1906, -2.2005, -2.1995,\n",
      "        -2.2081, -2.2317, -2.2031, -2.1912, -2.2738, -2.1385, -2.1669, -2.2017,\n",
      "        -2.2287, -2.1950, -2.1621, -2.1499, -2.1942, -2.1634, -2.2016, -2.2112,\n",
      "        -2.1919, -2.2092, -2.1929, -2.1933, -2.1776, -2.1781, -2.2059, -2.1976,\n",
      "        -2.1707, -2.1903, -2.2095, -2.1752, -2.0627, -2.1949, -2.1934, -2.1989,\n",
      "        -2.0881, -2.2120, -2.1627, -2.1184, -2.1960, -2.1512, -2.1908, -2.1672,\n",
      "        -2.1813, -2.1585], device='mps:0')\n",
      "mean: tensor(-2.1848, device='mps:0')\n",
      "iter_dt 1.04s; iter 12: train loss 0.32885 temperature: 5.599999999999998\n",
      "mean_logits tensor([-2.1823, -2.1648, -2.1884, -2.0136, -2.0778, -2.4537, -2.0042, -2.1774,\n",
      "        -2.0960, -1.7677, -1.7900, -1.8715, -1.7930, -1.9012, -2.3823, -1.9127,\n",
      "        -2.0640, -2.2478, -2.0677, -1.7398, -1.8360, -1.9355, -2.2092, -2.0873,\n",
      "        -2.2528, -2.3754, -2.4248, -2.0827, -2.3139, -2.3131, -2.0423, -2.1344,\n",
      "        -2.0476, -2.0880, -2.2084, -2.2372, -2.1601, -2.1288, -1.9558, -1.9907,\n",
      "        -2.2065, -2.1384, -2.2633, -2.4045, -1.9058, -2.2844, -2.1246, -2.2934,\n",
      "        -2.3553, -1.9878], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1955, -2.1881, -2.1460, -2.0860, -2.1853, -2.1855, -2.2020, -2.1598,\n",
      "        -2.2118, -2.1417, -2.1886, -2.1932, -2.1877, -2.1854, -2.1947, -2.1516,\n",
      "        -2.1979, -2.2613, -2.1927, -2.1765, -2.1786, -2.1890, -2.1800, -2.1953,\n",
      "        -2.1924, -2.1892, -2.1920, -2.1740, -2.1353, -2.1857, -2.1989, -2.1633,\n",
      "        -2.1879, -2.1636, -2.1980, -2.1913, -2.1341, -2.2189, -2.1968, -2.1966,\n",
      "        -2.1620, -2.2249, -2.1443, -2.1844, -2.1892, -2.1740, -2.1488, -2.1904,\n",
      "        -2.1935, -2.1907], device='mps:0')\n",
      "mean: tensor(-2.1819, device='mps:0')\n",
      "iter_dt 1.00s; iter 13: train loss 0.28332 temperature: 5.649999999999998\n",
      "mean_logits tensor([-2.2968, -2.2483, -1.8109, -2.0726, -2.1308, -1.9195, -2.1219, -1.9575,\n",
      "        -2.0134, -2.3357, -2.1679, -2.0027, -2.1401, -2.2947, -1.7778, -1.9544,\n",
      "        -2.3029, -2.2507, -2.1489, -2.1500, -2.0522, -2.1980, -2.3422, -2.2138,\n",
      "        -2.0640, -2.4311, -2.2878, -2.0139, -2.1457, -2.1632, -2.0455, -2.1282,\n",
      "        -2.1030, -1.9774, -1.9258, -2.0813, -2.3280, -2.5706, -2.2424, -2.2546,\n",
      "        -2.0854, -1.8218, -2.1427, -2.0894, -2.3148, -1.8609, -2.0995, -2.1708,\n",
      "        -1.9685, -1.8007], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1767, -2.1891, -2.2129, -2.1929, -2.1628, -2.1971, -2.1950, -2.1499,\n",
      "        -2.1935, -2.2601, -2.1882, -2.1854, -2.1961, -2.2364, -2.1741, -2.1883,\n",
      "        -2.2102, -2.1829, -2.1693, -2.1131, -2.1895, -2.1857, -2.1890, -2.1880,\n",
      "        -2.1978, -2.1886, -2.1894, -2.1547, -2.1936, -2.2264, -2.1388, -2.1703,\n",
      "        -2.1968, -2.1942, -2.1712, -2.1597, -2.1958, -2.1929, -2.2384, -2.1781,\n",
      "        -2.1944, -2.1173, -2.1933, -2.1959, -2.2132, -2.1761, -2.1932, -2.1782,\n",
      "        -2.2008, -2.1976], device='mps:0')\n",
      "mean: tensor(-2.1875, device='mps:0')\n",
      "iter_dt 1.01s; iter 14: train loss 0.40859 temperature: 5.6999999999999975\n",
      "mean_logits tensor([-1.7652, -2.3118, -2.0330, -2.1458, -2.4396, -2.1758, -1.6531, -2.0147,\n",
      "        -2.0746, -2.5848, -1.8950, -1.6468, -1.9821, -2.1401, -2.3600, -1.8351,\n",
      "        -1.9487, -2.1145, -2.3685, -2.0257, -2.1315, -1.9207, -2.1047, -2.1987,\n",
      "        -1.9806, -2.0090, -1.9435, -2.3381, -2.2643, -1.9960, -2.1063, -2.1827,\n",
      "        -2.2898, -2.1718, -2.1469, -2.2116, -2.1683, -2.1965, -2.2626, -1.9620,\n",
      "        -2.3977, -2.1864, -2.3297, -1.9411, -1.9161, -2.3881, -2.4181, -2.2254,\n",
      "        -2.2832, -1.9543], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1939, -2.1965, -2.1956, -2.2065, -2.1574, -2.1748, -2.1739, -2.2165,\n",
      "        -2.1929, -2.1852, -2.1273, -2.1865, -2.1147, -2.1952, -2.1849, -2.1495,\n",
      "        -2.1729, -2.1830, -2.2039, -2.1938, -2.2565, -2.2154, -2.1468, -2.2193,\n",
      "        -2.1885, -2.1674, -2.1968, -2.1433, -2.1732, -2.1771, -2.1589, -2.1507,\n",
      "        -2.1895, -2.1902, -2.1921, -2.1821, -2.1909, -2.2206, -2.2048, -2.1932,\n",
      "        -2.1739, -2.1922, -2.1960, -2.1679, -2.1858, -2.1352, -2.1026, -2.2055,\n",
      "        -2.1706, -2.1647], device='mps:0')\n",
      "mean: tensor(-2.1811, device='mps:0')\n",
      "iter_dt 1.01s; iter 15: train loss 0.48290 temperature: 5.749999999999997\n",
      "mean_logits tensor([-2.2224, -2.2878, -2.1008, -1.6552, -2.3207, -2.2770, -1.9110, -1.8297,\n",
      "        -1.9121, -2.2399, -2.1497, -2.2789, -2.0521, -2.1328, -2.0907, -1.7450,\n",
      "        -2.3343, -2.0004, -1.7294, -2.2237, -2.4032, -2.3082, -1.9153, -1.9536,\n",
      "        -2.2925, -2.1395, -1.8243, -2.1298, -1.5302, -2.1841, -2.2719, -1.9134,\n",
      "        -2.1880, -2.0711, -2.3600, -1.6914, -2.1495, -2.3383, -2.0600, -1.8404,\n",
      "        -1.9254, -1.7569, -2.3313, -1.8393, -2.4650, -2.4168, -2.2576, -2.3200,\n",
      "        -2.2983, -1.9942], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2051, -2.1961, -2.1999, -2.1812, -2.1837, -2.1806, -2.2076, -2.2045,\n",
      "        -2.1803, -2.1573, -2.0761, -2.1474, -2.1907, -2.1848, -2.1934, -2.1886,\n",
      "        -2.2227, -2.2013, -2.2227, -2.1987, -2.2162, -2.1305, -2.2088, -2.1976,\n",
      "        -2.2036, -2.2144, -2.2029, -2.1274, -2.1821, -2.1660, -2.1864, -2.1892,\n",
      "        -2.1724, -2.1757, -2.1923, -2.2060, -2.1923, -2.1967, -2.1318, -2.1468,\n",
      "        -2.1904, -2.1671, -2.1887, -2.1913, -2.1947, -2.2326, -2.1754, -2.1604,\n",
      "        -2.1979, -2.1900], device='mps:0')\n",
      "mean: tensor(-2.1850, device='mps:0')\n",
      "iter_dt 1.01s; iter 16: train loss 0.33484 temperature: 5.799999999999997\n",
      "mean_logits tensor([-2.2695, -2.2861, -2.3452, -2.4549, -2.2633, -2.0971, -2.2534, -2.4321,\n",
      "        -2.0289, -2.0025, -1.9710, -1.9141, -2.1954, -2.1841, -1.9110, -2.0560,\n",
      "        -2.1780, -2.3385, -2.2425, -1.8402, -1.9896, -1.9650, -2.0755, -2.1161,\n",
      "        -2.0401, -2.2258, -2.2207, -1.7000, -2.2895, -2.0512, -2.3598, -2.3967,\n",
      "        -2.1478, -1.9251, -2.1391, -2.4480, -2.1174, -1.8275, -2.1885, -2.0751,\n",
      "        -2.3448, -2.0190, -2.3285, -1.9749, -2.1003, -1.8368, -2.0666, -2.3874,\n",
      "        -1.8011, -2.0665], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1908, -2.2063, -2.2013, -2.2011, -2.1948, -2.2007, -2.2566, -2.1361,\n",
      "        -2.2101, -2.1810, -2.1791, -2.1422, -2.2140, -2.2004, -2.1464, -2.1921,\n",
      "        -2.1897, -2.1893, -2.2034, -2.1723, -2.1307, -2.1482, -2.1615, -2.1834,\n",
      "        -2.1957, -2.2140, -2.1585, -2.1825, -2.2590, -2.2017, -2.1997, -2.1539,\n",
      "        -2.1796, -2.1826, -2.1944, -2.1902, -2.1768, -2.1909, -2.1746, -2.1960,\n",
      "        -2.1531, -2.1995, -2.1373, -2.2461, -2.1201, -2.1751, -2.1883, -2.2003,\n",
      "        -2.1778, -2.2009], device='mps:0')\n",
      "mean: tensor(-2.1856, device='mps:0')\n",
      "iter_dt 1.02s; iter 17: train loss 0.41019 temperature: 5.849999999999997\n",
      "mean_logits tensor([-2.1751, -2.0034, -2.0068, -2.3283, -2.2293, -1.9505, -1.6882, -2.2685,\n",
      "        -2.2530, -2.2560, -2.3252, -2.1894, -2.0928, -1.5941, -1.8260, -1.7431,\n",
      "        -2.3110, -2.1638, -2.1677, -2.3521, -2.2162, -2.3086, -2.2258, -1.9956,\n",
      "        -2.3223, -2.2933, -2.3709, -2.2647, -2.2316, -2.0449, -2.2696, -2.2904,\n",
      "        -2.3590, -2.3551, -1.9707, -2.4906, -2.1422, -2.0144, -1.9235, -2.1413,\n",
      "        -2.4291, -2.3195, -2.1901, -1.8423, -2.0867, -2.1253, -1.8571, -1.9639,\n",
      "        -2.5515, -2.3169], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1439, -2.1859, -2.2307, -2.1947, -2.1943, -2.1684, -2.1510, -2.1418,\n",
      "        -2.1963, -2.1946, -2.1890, -2.1804, -2.1856, -2.1987, -2.2156, -2.2038,\n",
      "        -2.1746, -2.1889, -2.2008, -2.1796, -2.1893, -2.1782, -2.1900, -2.1971,\n",
      "        -2.1415, -2.1982, -2.2122, -2.1941, -2.1020, -2.2131, -2.1850, -2.1516,\n",
      "        -2.1965, -2.1977, -2.1983, -2.1666, -2.0846, -2.1831, -2.1564, -2.1865,\n",
      "        -2.1822, -2.1443, -2.2597, -2.1745, -2.1758, -2.1887, -2.1978, -2.2019,\n",
      "        -2.1811, -2.1821], device='mps:0')\n",
      "mean: tensor(-2.1826, device='mps:0')\n",
      "iter_dt 1.00s; iter 18: train loss 0.56902 temperature: 5.899999999999997\n",
      "mean_logits tensor([-2.0803, -1.6325, -2.1348, -2.2135, -2.1712, -1.5678, -1.7418, -2.3821,\n",
      "        -2.1206, -1.9307, -2.1453, -2.1266, -2.3046, -1.8966, -1.9078, -2.2857,\n",
      "        -2.2331, -2.1510, -2.0456, -2.1808, -2.0529, -2.1641, -2.4963, -2.4291,\n",
      "        -2.1426, -2.2809, -2.0419, -1.8555, -2.3867, -2.3175, -1.7942, -2.0718,\n",
      "        -2.3057, -2.2366, -2.0634, -2.5254, -2.1716, -2.4253, -2.3977, -2.0032,\n",
      "        -2.4409, -2.2069, -2.4783, -2.4545, -2.4520, -2.3085, -2.5923, -2.2994,\n",
      "        -2.3202, -1.8331], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1799, -2.1882, -2.1953, -2.1687, -2.1884, -2.2011, -2.2003, -2.1925,\n",
      "        -2.1779, -2.2065, -2.2018, -2.1918, -2.1751, -2.2058, -2.2018, -2.2049,\n",
      "        -2.1911, -2.1426, -2.1915, -2.1835, -2.1977, -2.2045, -2.1933, -2.1946,\n",
      "        -2.1904, -2.1935, -2.1641, -2.1941, -2.1925, -2.1400, -2.2089, -2.1965,\n",
      "        -2.1950, -2.1319, -2.2850, -2.1515, -2.1484, -2.1861, -2.1976, -2.1942,\n",
      "        -2.1964, -2.2038, -2.1586, -2.1613, -2.1941, -2.1860, -2.1596, -2.1866,\n",
      "        -2.1738, -2.1779], device='mps:0')\n",
      "mean: tensor(-2.1869, device='mps:0')\n",
      "iter_dt 1.00s; iter 19: train loss 0.45475 temperature: 5.949999999999997\n",
      "mean_logits tensor([-1.9642, -2.1705, -2.0369, -2.3157, -1.9860, -1.8803, -2.3923, -1.6975,\n",
      "        -2.4059, -1.8267, -2.2245, -2.0932, -2.1846, -2.1305, -2.0611, -2.1497,\n",
      "        -2.0732, -2.3614, -2.1650, -2.1827, -2.2483, -1.9138, -1.9679, -2.3570,\n",
      "        -2.0106, -2.0186, -2.4584, -2.2126, -2.0115, -2.5329, -2.0535, -2.4142,\n",
      "        -2.0095, -2.1412, -2.1222, -2.1245, -1.9225, -2.3394, -1.9507, -2.0044,\n",
      "        -1.5480, -2.5353, -2.2014, -2.0364, -1.8780, -1.8906, -2.5376, -1.9812,\n",
      "        -2.3177, -2.3091], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1772, -2.1590, -2.2195, -2.1714, -2.2036, -2.1593, -2.1922, -2.1691,\n",
      "        -2.1931, -2.2089, -2.1894, -2.1925, -2.1733, -2.1743, -2.2128, -2.1739,\n",
      "        -2.1706, -2.2201, -2.2029, -2.1871, -2.2187, -2.1362, -2.1699, -2.1678,\n",
      "        -2.1930, -2.1627, -2.1806, -2.1489, -2.1242, -2.1831, -2.1657, -2.1898,\n",
      "        -2.1994, -2.1642, -2.2013, -2.1669, -2.2007, -2.2068, -2.1554, -2.1902,\n",
      "        -2.1920, -2.1813, -2.1993, -2.1957, -2.1897, -2.1918, -2.2048, -2.2077,\n",
      "        -2.1606, -2.1983], device='mps:0')\n",
      "mean: tensor(-2.1839, device='mps:0')\n",
      "iter_dt 1.03s; iter 20: train loss 0.40778 temperature: 5.9999999999999964\n",
      "mean_logits tensor([-1.7731, -2.2086, -2.2354, -1.9921, -2.6729, -2.4001, -2.1599, -2.1854,\n",
      "        -2.1917, -2.2680, -2.3228, -2.0589, -1.9456, -2.0665, -2.0275, -2.5085,\n",
      "        -2.1270, -2.3877, -2.3024, -2.3095, -2.1658, -2.3517, -2.0177, -2.2723,\n",
      "        -2.2402, -2.1858, -2.1617, -2.3653, -2.2434, -2.1099, -2.2995, -2.2690,\n",
      "        -2.6171, -2.2194, -2.3244, -2.2582, -2.2461, -2.1258, -2.0576, -1.8682,\n",
      "        -2.2032, -2.3489, -2.0214, -2.0750, -2.1776, -1.8956, -2.2106, -1.7953,\n",
      "        -2.2456, -2.3037], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1527, -2.1332, -2.1851, -2.1877, -2.1847, -2.1704, -2.1713, -2.2322,\n",
      "        -2.2092, -2.1846, -2.1537, -2.1961, -2.1965, -2.1954, -2.2217, -2.1213,\n",
      "        -2.1982, -2.1934, -2.1966, -2.1943, -2.1518, -2.2031, -2.1841, -2.1882,\n",
      "        -2.2004, -2.2066, -2.2068, -2.1972, -2.2356, -2.1819, -2.1924, -2.1937,\n",
      "        -2.1162, -2.1937, -2.1656, -2.2088, -2.1715, -2.2351, -2.1652, -2.1864,\n",
      "        -2.1639, -2.1704, -2.1984, -2.1671, -2.1867, -2.1875, -2.1678, -2.1436,\n",
      "        -2.1953, -2.1285], device='mps:0')\n",
      "mean: tensor(-2.1834, device='mps:0')\n",
      "iter_dt 1.00s; iter 21: train loss 0.45840 temperature: 6.049999999999996\n",
      "mean_logits tensor([-2.3361, -2.3608, -1.7896, -2.1468, -2.0873, -2.0171, -2.2737, -2.2275,\n",
      "        -2.1147, -2.3177, -1.8892, -2.1793, -2.5576, -2.2408, -2.0422, -2.2723,\n",
      "        -2.1407, -1.9918, -2.1278, -2.1299, -2.5558, -2.2287, -2.1204, -1.7991,\n",
      "        -2.0516, -1.4839, -1.6625, -2.3211, -2.3132, -2.1166, -2.0011, -2.1074,\n",
      "        -1.7687, -2.5506, -2.2039, -1.8749, -2.3119, -2.2903, -2.1387, -1.9837,\n",
      "        -2.0043, -2.1857, -1.8794, -1.9224, -2.1421, -2.3861, -2.1156, -2.0394,\n",
      "        -2.3113, -1.9599], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1553, -2.1978, -2.1890, -2.1309, -2.1970, -2.1531, -2.2055, -2.1819,\n",
      "        -2.2238, -2.1859, -2.2065, -2.1680, -2.1748, -2.1373, -2.1777, -2.1993,\n",
      "        -2.1920, -2.1894, -2.1922, -2.1933, -2.1889, -2.1956, -2.1984, -2.1956,\n",
      "        -2.1953, -2.1667, -2.2417, -2.1941, -2.1903, -2.1896, -2.1746, -2.1857,\n",
      "        -2.1953, -2.2021, -2.2003, -2.1577, -2.2004, -2.1716, -2.1180, -2.1937,\n",
      "        -2.1378, -2.2060, -2.1904, -2.1520, -2.1326, -2.1774, -2.1962, -2.1332,\n",
      "        -2.2182, -2.1982], device='mps:0')\n",
      "mean: tensor(-2.1830, device='mps:0')\n",
      "iter_dt 1.01s; iter 22: train loss 0.64139 temperature: 6.099999999999996\n",
      "mean_logits tensor([-2.0242, -2.1230, -2.0351, -1.6199, -1.9842, -1.8484, -1.9604, -2.1373,\n",
      "        -2.4983, -2.0880, -2.3881, -2.6599, -2.1950, -2.2863, -2.5548, -1.8340,\n",
      "        -1.8140, -2.4171, -2.4515, -1.6577, -1.9284, -2.2046, -2.1317, -2.2570,\n",
      "        -2.4742, -1.8524, -2.1263, -2.4487, -2.1130, -2.5076, -2.2983, -2.3599,\n",
      "        -2.2005, -2.4426, -2.0615, -1.6341, -2.4553, -2.0331, -2.0230, -1.9257,\n",
      "        -1.9563, -2.0720, -2.0370, -2.5395, -2.1758, -2.0277, -2.0205, -1.9937,\n",
      "        -2.0164, -2.2695], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1496, -2.1892, -2.2377, -2.1673, -2.2056, -2.1934, -2.1823, -2.1737,\n",
      "        -2.2257, -2.1562, -2.1946, -2.1938, -2.1776, -2.2003, -2.1926, -2.1986,\n",
      "        -2.1269, -2.1917, -2.1974, -2.1933, -2.1599, -2.1539, -2.1196, -2.1400,\n",
      "        -2.1885, -2.1986, -2.2044, -2.2052, -2.1884, -2.1997, -2.1361, -2.2480,\n",
      "        -2.1625, -2.1956, -2.1941, -2.1952, -2.1878, -2.1926, -2.1978, -2.1936,\n",
      "        -2.1741, -2.1233, -2.2203, -2.1475, -2.1809, -2.1660, -2.1931, -2.1665,\n",
      "        -2.2110, -2.1765], device='mps:0')\n",
      "mean: tensor(-2.1834, device='mps:0')\n",
      "iter_dt 1.04s; iter 23: train loss 0.62420 temperature: 6.149999999999996\n",
      "mean_logits tensor([-1.7262, -1.8504, -2.4782, -1.8776, -2.3616, -2.6464, -2.2781, -2.3341,\n",
      "        -1.7883, -2.1818, -2.3570, -2.0737, -2.1707, -1.9276, -2.0348, -2.1604,\n",
      "        -2.1097, -2.1484, -2.1948, -2.3980, -2.2497, -2.1091, -2.2320, -1.5708,\n",
      "        -2.5559, -2.2020, -2.1562, -1.7231, -2.1271, -2.1083, -2.2248, -2.4067,\n",
      "        -2.2052, -2.0421, -1.7862, -2.0651, -2.2391, -1.9395, -2.3276, -2.1987,\n",
      "        -1.8604, -2.2904, -2.6058, -1.9147, -1.6329, -2.6016, -2.1656, -1.8916,\n",
      "        -2.2955, -2.3090], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1980, -2.2078, -2.1766, -2.1619, -2.1910, -2.2309, -2.2339, -2.1949,\n",
      "        -2.1945, -2.1687, -2.1789, -2.1795, -2.1954, -2.1947, -2.1430, -2.1627,\n",
      "        -2.1582, -2.1971, -2.2239, -2.2161, -2.1443, -2.1611, -2.2140, -2.1672,\n",
      "        -2.2143, -2.2081, -2.1881, -2.1848, -2.1991, -2.2109, -2.1279, -2.1762,\n",
      "        -2.2285, -2.1662, -2.1951, -2.2047, -2.1985, -2.1916, -2.1872, -2.2145,\n",
      "        -2.2034, -2.1953, -2.1886, -2.1680, -2.1970, -2.1281, -2.1804, -2.2048,\n",
      "        -2.1959, -2.1865], device='mps:0')\n",
      "mean: tensor(-2.1888, device='mps:0')\n",
      "iter_dt 1.01s; iter 24: train loss 0.47875 temperature: 6.199999999999996\n",
      "mean_logits tensor([-2.0284, -2.0410, -2.4026, -1.9430, -2.4595, -2.2211, -2.0555, -2.4276,\n",
      "        -1.9708, -2.2415, -2.0993, -2.4232, -2.1767, -2.0753, -2.2987, -2.5132,\n",
      "        -2.2606, -1.9590, -2.2209, -2.1843, -2.1863, -2.2281, -2.4419, -2.4462,\n",
      "        -2.3630, -2.1293, -2.1078, -1.9232, -1.9790, -1.7445, -2.7040, -1.9415,\n",
      "        -2.0561, -2.1213, -1.9429, -2.1487, -2.1214, -2.1875, -2.0791, -1.7607,\n",
      "        -2.3556, -2.4176, -2.0808, -2.1588, -2.2778, -2.4819, -2.0275, -2.3870,\n",
      "        -2.2562, -2.4479], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1981, -2.2253, -2.1899, -2.1835, -2.1922, -2.1626, -2.1811, -2.1907,\n",
      "        -2.1928, -2.1878, -2.2034, -2.2040, -2.2248, -2.2141, -2.1906, -2.1942,\n",
      "        -2.1194, -2.0888, -2.1984, -2.1805, -2.1682, -2.1454, -2.1908, -2.1896,\n",
      "        -2.2209, -2.2474, -2.1299, -2.1854, -2.1441, -2.2053, -2.1558, -2.1779,\n",
      "        -2.1616, -2.2002, -2.1785, -2.1826, -2.1989, -2.1605, -2.1527, -2.2404,\n",
      "        -2.1759, -2.2637, -2.1603, -2.1919, -2.1867, -2.1937, -2.1703, -2.1806,\n",
      "        -2.1883, -2.1978], device='mps:0')\n",
      "mean: tensor(-2.1854, device='mps:0')\n",
      "iter_dt 1.01s; iter 25: train loss 0.52192 temperature: 6.249999999999996\n",
      "mean_logits tensor([-2.2262, -2.2297, -2.2689, -2.1229, -2.0895, -2.1625, -2.3473, -2.3143,\n",
      "        -2.2246, -2.5153, -2.1954, -2.1709, -2.6554, -2.1448, -2.4512, -1.9500,\n",
      "        -2.5068, -2.1778, -1.9164, -1.8029, -2.0139, -2.3345, -2.1589, -1.5095,\n",
      "        -2.4197, -1.8975, -2.1198, -2.0384, -2.1538, -1.7731, -2.0908, -2.0961,\n",
      "        -2.5675, -2.1334, -2.1147, -2.0124, -2.3203, -2.2727, -1.4073, -2.3613,\n",
      "        -2.0646, -2.3072, -2.3000, -2.0414, -2.4010, -2.2212, -2.0763, -2.2857,\n",
      "        -2.3695, -2.1492], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1974, -2.1831, -2.1753, -2.2042, -2.1904, -2.2281, -2.1180, -2.1947,\n",
      "        -2.1814, -2.1915, -2.2000, -2.1601, -2.1714, -2.2015, -2.1907, -2.2017,\n",
      "        -2.1916, -2.1704, -2.2013, -2.1927, -2.2047, -2.1828, -2.1939, -2.1960,\n",
      "        -2.1914, -2.1203, -2.2020, -2.1901, -2.1981, -2.1597, -2.1846, -2.1874,\n",
      "        -2.1933, -2.1948, -2.1856, -2.2010, -2.1786, -2.1903, -2.1778, -2.1659,\n",
      "        -2.1696, -2.1450, -2.1990, -2.2082, -2.1965, -2.1998, -2.1044, -2.1799,\n",
      "        -2.1707, -2.1964], device='mps:0')\n",
      "mean: tensor(-2.1843, device='mps:0')\n",
      "iter_dt 1.04s; iter 26: train loss 0.48358 temperature: 6.299999999999995\n",
      "mean_logits tensor([-2.1342, -2.2955, -2.0195, -1.9553, -2.1155, -2.1644, -2.1348, -2.3710,\n",
      "        -2.1330, -2.0569, -2.1652, -1.9104, -1.9308, -1.9156, -2.5299, -2.4671,\n",
      "        -2.0337, -2.4231, -2.5159, -2.3309, -2.2497, -1.8740, -2.4941, -1.9152,\n",
      "        -2.3696, -2.1426, -2.4241, -2.0005, -1.8170, -2.2418, -2.1130, -2.4548,\n",
      "        -1.9744, -2.4035, -2.2157, -2.1541, -2.0160, -2.1602, -2.1011, -2.1728,\n",
      "        -1.9047, -2.3463, -2.1165, -2.2045, -1.9044, -2.0415, -2.6169, -2.0482,\n",
      "        -1.6637, -2.2214], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1927, -2.1940, -2.2059, -2.1223, -2.1937, -2.1937, -2.1940, -2.1537,\n",
      "        -2.1768, -2.1863, -2.1576, -2.1994, -2.1933, -2.2004, -2.1536, -2.2086,\n",
      "        -2.1314, -2.1877, -2.1856, -2.1913, -2.1857, -2.2284, -2.1950, -2.2025,\n",
      "        -2.2429, -2.2076, -2.1777, -2.1931, -2.1932, -2.2455, -2.1967, -2.1966,\n",
      "        -2.2084, -2.1961, -2.2067, -2.1998, -2.1761, -2.1796, -2.2142, -2.1980,\n",
      "        -2.1654, -2.1851, -2.1984, -2.1889, -2.1984, -2.1936, -2.1979, -2.1961,\n",
      "        -2.1803, -2.2248], device='mps:0')\n",
      "mean: tensor(-2.1919, device='mps:0')\n",
      "iter_dt 1.01s; iter 27: train loss 0.39242 temperature: 6.349999999999995\n",
      "mean_logits tensor([-2.2967, -1.9776, -2.0428, -2.3305, -2.1143, -1.9885, -2.4148, -2.1588,\n",
      "        -2.0127, -2.0719, -2.3265, -1.9552, -2.1805, -2.2929, -1.8614, -1.9079,\n",
      "        -2.1701, -2.0834, -2.4563, -2.2958, -2.2089, -2.2155, -2.1790, -1.9210,\n",
      "        -2.4227, -2.2824, -2.1292, -1.9444, -2.2210, -2.4454, -1.8883, -2.0733,\n",
      "        -2.1577, -2.4334, -2.4051, -2.1656, -2.2696, -1.6913, -2.3088, -2.0551,\n",
      "        -2.5611, -2.3538, -2.5041, -2.1713, -2.4827, -2.1588, -2.0991, -1.9527,\n",
      "        -2.1745, -2.0402], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1985, -2.1936, -2.1949, -2.1985, -2.2268, -2.1947, -2.2014, -2.1733,\n",
      "        -2.0875, -2.2013, -2.1767, -2.1929, -2.2158, -2.1942, -2.1849, -2.1992,\n",
      "        -2.1904, -2.1843, -2.1936, -2.1844, -2.1920, -2.1074, -2.1927, -2.1378,\n",
      "        -2.1908, -2.1934, -2.1933, -2.1726, -2.2397, -2.1693, -2.1982, -2.2555,\n",
      "        -2.1907, -2.1919, -2.1707, -2.1442, -2.2040, -2.2078, -2.0837, -2.1715,\n",
      "        -2.1966, -2.1971, -2.1958, -2.1739, -2.2219, -2.1239, -2.1350, -2.1977,\n",
      "        -2.1918, -2.1715], device='mps:0')\n",
      "mean: tensor(-2.1840, device='mps:0')\n",
      "iter_dt 1.02s; iter 28: train loss 0.39191 temperature: 6.399999999999995\n",
      "mean_logits tensor([-2.2092, -1.9383, -2.1104, -1.8991, -2.3265, -2.0166, -1.9759, -2.3474,\n",
      "        -1.9112, -1.9374, -2.1421, -2.2258, -1.9810, -2.6108, -2.0439, -2.1861,\n",
      "        -2.0033, -2.2473, -2.2691, -2.1635, -2.1510, -2.2777, -2.1091, -2.3516,\n",
      "        -2.0414, -2.3356, -2.5719, -2.1685, -2.3615, -2.0337, -2.0245, -1.9205,\n",
      "        -2.2126, -1.9486, -2.0611, -2.5889, -2.3313, -1.9260, -2.2085, -2.0875,\n",
      "        -1.9147, -2.3374, -2.0112, -2.1463, -2.3558, -2.0097, -2.3922, -2.2122,\n",
      "        -2.0292, -2.1507], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1938, -2.1317, -2.2657, -2.1613, -2.1647, -2.1906, -2.1936, -2.1938,\n",
      "        -2.1937, -2.2066, -2.1715, -2.1553, -2.1636, -2.1979, -2.1605, -2.1935,\n",
      "        -2.1954, -2.2087, -2.1689, -2.1944, -2.1778, -2.2144, -2.2495, -2.2009,\n",
      "        -2.2192, -2.1378, -2.2045, -2.1237, -2.1987, -2.1629, -2.2027, -2.1937,\n",
      "        -2.1810, -2.2042, -2.1905, -2.1898, -2.1252, -2.1898, -2.2120, -2.1261,\n",
      "        -2.2048, -2.1826, -2.1985, -2.1874, -2.1929, -2.1485, -2.1886, -2.1780,\n",
      "        -2.2048, -2.1803], device='mps:0')\n",
      "mean: tensor(-2.1855, device='mps:0')\n",
      "iter_dt 1.04s; iter 29: train loss 0.46261 temperature: 6.449999999999995\n",
      "mean_logits tensor([-1.9639, -1.9457, -2.4131, -1.9851, -2.0225, -2.1179, -2.1337, -2.1318,\n",
      "        -2.0141, -1.9307, -1.8204, -1.7430, -2.0130, -1.7731, -2.6400, -2.2234,\n",
      "        -2.3816, -1.9049, -2.0762, -2.1531, -2.1265, -2.0065, -2.2196, -1.9692,\n",
      "        -2.1869, -1.7332, -1.9115, -1.8614, -2.3992, -2.2817, -2.3236, -2.4853,\n",
      "        -2.1614, -2.3392, -2.0938, -2.2487, -2.1864, -2.1669, -2.1478, -2.1755,\n",
      "        -2.0767, -1.9806, -2.2134, -2.6577, -2.3345, -2.1968, -2.1669, -2.0980,\n",
      "        -2.0518, -2.1701], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1911, -2.1925, -2.1657, -2.1235, -2.2212, -2.1785, -2.2450, -2.1955,\n",
      "        -2.1918, -2.1918, -2.1605, -2.1823, -2.1644, -2.1726, -2.1769, -2.1999,\n",
      "        -2.1368, -2.1933, -2.1331, -2.2202, -2.1639, -2.1988, -2.1988, -2.1992,\n",
      "        -2.1949, -2.1949, -2.1988, -2.1653, -2.1914, -2.1812, -2.1650, -2.2016,\n",
      "        -2.1675, -2.1964, -2.2625, -2.2148, -2.2316, -2.1950, -2.1872, -2.1796,\n",
      "        -2.1990, -2.1515, -2.1716, -2.2029, -2.1965, -2.1937, -2.1439, -2.1706,\n",
      "        -2.1816, -2.1866], device='mps:0')\n",
      "mean: tensor(-2.1865, device='mps:0')\n",
      "iter_dt 1.00s; iter 30: train loss 0.31155 temperature: 6.499999999999995\n",
      "mean_logits tensor([-2.0178, -2.0577, -2.1156, -2.0813, -2.0896, -1.8121, -2.2293, -2.1895,\n",
      "        -2.3879, -1.8093, -2.1545, -2.2401, -2.3952, -2.0156, -2.0776, -2.1754,\n",
      "        -2.0612, -2.3110, -2.1615, -2.2990, -2.2095, -2.1382, -2.4048, -2.2780,\n",
      "        -2.1753, -2.2152, -2.0406, -1.8835, -2.0333, -2.1037, -2.3566, -1.7558,\n",
      "        -2.2021, -1.9064, -2.1199, -1.8003, -2.4002, -2.2201, -2.1898, -2.2626,\n",
      "        -2.2568, -1.7081, -2.1861, -2.3542, -2.0884, -1.9276, -2.1578, -2.2340,\n",
      "        -2.3764, -1.6826], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1603, -2.1889, -2.1903, -2.2096, -2.1455, -2.1736, -2.1936, -2.1858,\n",
      "        -2.1896, -2.1828, -2.1959, -2.2148, -2.1953, -2.1560, -2.1621, -2.2059,\n",
      "        -2.2102, -2.2592, -2.1745, -2.1943, -2.1925, -2.1489, -2.2009, -2.1947,\n",
      "        -2.1969, -2.1914, -2.1925, -2.2448, -2.1833, -2.1904, -2.1908, -2.1714,\n",
      "        -2.2101, -2.1883, -2.1655, -2.1342, -2.2053, -2.1835, -2.1286, -2.2062,\n",
      "        -2.1541, -2.1697, -2.2072, -2.1267, -2.1974, -2.1333, -2.1763, -2.1921,\n",
      "        -2.2141, -2.2600], device='mps:0')\n",
      "mean: tensor(-2.1868, device='mps:0')\n",
      "iter_dt 1.01s; iter 31: train loss 0.32012 temperature: 6.5499999999999945\n",
      "mean_logits tensor([-2.0602, -2.1746, -2.4432, -2.2907, -1.9873, -2.1881, -2.0057, -2.2114,\n",
      "        -2.0576, -2.1095, -2.1638, -2.2650, -2.0856, -2.1361, -2.1520, -2.1047,\n",
      "        -2.2233, -1.9197, -1.7505, -2.3541, -2.1413, -2.4528, -1.7433, -1.9538,\n",
      "        -2.0449, -2.3814, -2.0860, -2.1033, -2.0879, -2.3127, -2.3509, -2.3558,\n",
      "        -2.2108, -1.9594, -1.8591, -1.9380, -1.8825, -2.0264, -2.2785, -2.0300,\n",
      "        -2.2265, -1.8653, -1.9938, -1.9512, -2.2317, -2.1964, -2.2818, -2.2606,\n",
      "        -2.0479, -1.8678], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1902, -2.1639, -2.1915, -2.1925, -2.1755, -2.2588, -2.2442, -2.1745,\n",
      "        -2.1986, -2.1907, -2.1279, -2.1452, -2.1308, -2.1981, -2.1303, -2.2370,\n",
      "        -2.2269, -2.1969, -2.1716, -2.2443, -2.1549, -2.1957, -2.1813, -2.1839,\n",
      "        -2.1940, -2.1692, -2.2251, -2.1791, -2.2193, -2.1931, -2.1175, -2.1723,\n",
      "        -2.1839, -2.1988, -2.1960, -2.1210, -2.1860, -2.1812, -2.1846, -2.1934,\n",
      "        -2.1860, -2.2255, -2.1951, -2.1330, -2.2057, -2.1985, -2.2222, -2.1925,\n",
      "        -2.2382, -2.2004], device='mps:0')\n",
      "mean: tensor(-2.1883, device='mps:0')\n",
      "iter_dt 1.01s; iter 32: train loss 0.44089 temperature: 6.599999999999994\n",
      "mean_logits tensor([-1.9967, -2.1356, -2.4232, -2.2032, -2.0644, -1.9736, -2.2814, -2.2262,\n",
      "        -2.2624, -2.2348, -2.1184, -2.0818, -2.1786, -2.3411, -2.3406, -2.2331,\n",
      "        -2.2852, -1.9963, -2.5409, -1.8097, -1.4683, -2.0335, -2.3197, -1.9709,\n",
      "        -2.0890, -2.1532, -2.3614, -2.3345, -2.2707, -2.0038, -2.1472, -2.2974,\n",
      "        -2.7715, -2.2578, -2.2195, -2.1465, -2.4362, -1.8733, -1.9906, -2.0683,\n",
      "        -2.2345, -2.2527, -2.1503, -2.2294, -1.9228, -2.0694, -1.9462, -2.2593,\n",
      "        -2.1028, -1.9937], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1990, -2.1912, -2.1538, -2.1725, -2.1700, -2.2261, -2.1878, -2.1799,\n",
      "        -2.2037, -2.2023, -2.1434, -2.0890, -2.2174, -2.1948, -2.1664, -2.1894,\n",
      "        -2.1461, -2.1708, -2.1830, -2.1703, -2.1761, -2.1901, -2.2336, -2.1920,\n",
      "        -2.1523, -2.2213, -2.2045, -2.1936, -2.2675, -2.1920, -2.1665, -2.1470,\n",
      "        -2.1896, -2.1639, -2.1812, -2.0834, -2.1809, -2.1989, -2.1895, -2.1947,\n",
      "        -2.1392, -2.1927, -2.1935, -2.2127, -2.1970, -2.1556, -2.2396, -2.1929,\n",
      "        -2.1574, -2.1351], device='mps:0')\n",
      "mean: tensor(-2.1818, device='mps:0')\n",
      "iter_dt 1.01s; iter 33: train loss 0.37577 temperature: 6.649999999999994\n",
      "mean_logits tensor([-2.2794, -2.4551, -1.9189, -2.2382, -1.9608, -2.2703, -2.1382, -2.2169,\n",
      "        -2.1809, -2.1253, -1.8684, -2.3083, -1.7662, -1.8798, -2.2977, -1.9239,\n",
      "        -2.2523, -2.2120, -2.0975, -2.1224, -2.4120, -2.2825, -1.9548, -2.1827,\n",
      "        -2.2328, -1.8804, -2.4321, -2.2338, -2.2650, -2.0623, -1.9243, -2.1221,\n",
      "        -2.0918, -2.0550, -2.0881, -1.7315, -2.4496, -1.5334, -1.8986, -2.3065,\n",
      "        -2.1008, -2.1068, -2.2111, -2.4235, -1.6730, -2.2275, -1.9362, -2.1129,\n",
      "        -2.3407, -2.1604], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2141, -2.1310, -2.2211, -2.1765, -2.1421, -2.2059, -2.1823, -2.2119,\n",
      "        -2.2123, -2.1475, -2.1943, -2.2239, -2.1748, -2.1932, -2.1952, -2.1900,\n",
      "        -2.1718, -2.1262, -2.1112, -2.1919, -2.2542, -2.1818, -2.1601, -2.1755,\n",
      "        -2.1739, -2.1977, -2.1979, -2.1919, -2.2030, -2.1039, -2.2635, -2.1512,\n",
      "        -2.1939, -2.1829, -2.1934, -2.1658, -2.2613, -2.1776, -2.1842, -2.1873,\n",
      "        -2.2416, -2.1938, -2.1687, -2.2355, -2.2091, -2.2522, -2.1512, -2.1896,\n",
      "        -2.2199, -2.1919], device='mps:0')\n",
      "mean: tensor(-2.1894, device='mps:0')\n",
      "iter_dt 1.01s; iter 34: train loss 0.43538 temperature: 6.699999999999994\n",
      "mean_logits tensor([-2.2906, -2.3302, -2.0602, -2.3007, -2.1494, -2.1188, -2.1099, -2.2408,\n",
      "        -2.5546, -2.0101, -2.0121, -2.0645, -2.2918, -2.0891, -1.6804, -2.2880,\n",
      "        -2.4395, -1.9959, -2.2353, -1.5949, -2.3208, -2.1055, -2.2706, -2.3619,\n",
      "        -2.0345, -1.9590, -2.4043, -2.0927, -2.1115, -2.4224, -2.0365, -1.8929,\n",
      "        -2.2807, -2.4652, -2.2601, -2.6022, -2.1573, -2.1634, -2.0095, -2.4157,\n",
      "        -1.9432, -2.2827, -1.8909, -1.9954, -2.4761, -2.1199, -2.0545, -2.5134,\n",
      "        -2.1124, -2.0033], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2132, -2.1805, -2.1751, -2.2042, -2.2427, -2.1781, -2.2115, -2.2213,\n",
      "        -2.1932, -2.1920, -2.1380, -2.2256, -2.1871, -2.1913, -2.2201, -2.2054,\n",
      "        -2.1454, -2.1702, -2.1947, -2.1409, -2.1938, -2.2058, -2.1891, -2.1711,\n",
      "        -2.1655, -2.1849, -2.2128, -2.1933, -2.1767, -2.1925, -2.1631, -2.1248,\n",
      "        -2.2138, -2.1875, -2.1802, -2.1870, -2.1414, -2.1918, -2.1903, -2.1971,\n",
      "        -2.1329, -2.1796, -2.1411, -2.1914, -2.1974, -2.1363, -2.1803, -2.1903,\n",
      "        -2.1290, -2.1617], device='mps:0')\n",
      "mean: tensor(-2.1827, device='mps:0')\n",
      "iter_dt 1.03s; iter 35: train loss 0.42501 temperature: 6.749999999999994\n",
      "mean_logits tensor([-2.3840, -2.4653, -2.1782, -2.2653, -2.3793, -2.4126, -1.7782, -2.0000,\n",
      "        -2.3349, -2.0803, -1.9835, -2.0879, -2.3042, -2.4059, -2.0229, -2.2293,\n",
      "        -2.5278, -2.4318, -2.1766, -2.2756, -2.3540, -2.1661, -2.2486, -2.2585,\n",
      "        -1.8250, -2.3028, -2.2255, -2.6336, -2.2118, -2.2406, -1.7780, -1.8652,\n",
      "        -2.0448, -2.2517, -2.1026, -2.3558, -1.7349, -2.3898, -1.8585, -2.3147,\n",
      "        -2.2413, -2.0105, -2.3315, -2.2303, -2.2134, -2.0027, -2.2408, -1.9964,\n",
      "        -1.9602, -2.0587], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1403, -2.1929, -2.1462, -2.1860, -2.1503, -2.1937, -2.1958, -2.1149,\n",
      "        -2.1474, -2.2238, -2.1697, -2.1947, -2.1837, -2.1473, -2.1693, -2.1807,\n",
      "        -2.1992, -2.1678, -2.2210, -2.1952, -2.1935, -2.1599, -2.1951, -2.1961,\n",
      "        -2.1990, -2.1916, -2.2024, -2.2279, -2.1869, -2.2114, -2.1435, -2.1888,\n",
      "        -2.1872, -2.2024, -2.2066, -2.2169, -2.1778, -2.1729, -2.1894, -2.1711,\n",
      "        -2.2109, -2.1416, -2.1873, -2.1930, -2.1556, -2.1849, -2.1936, -2.2009,\n",
      "        -2.1955, -2.1287], device='mps:0')\n",
      "mean: tensor(-2.1827, device='mps:0')\n",
      "iter_dt 1.00s; iter 36: train loss 0.52270 temperature: 6.799999999999994\n",
      "mean_logits tensor([-2.3656, -1.8780, -1.9200, -2.1178, -2.4768, -2.2457, -1.9288, -2.1895,\n",
      "        -2.5740, -2.2252, -1.6283, -2.2087, -2.2207, -1.9919, -2.5580, -2.2296,\n",
      "        -2.3172, -2.5504, -2.3119, -1.7573, -1.7186, -2.0031, -2.2366, -1.8715,\n",
      "        -2.4455, -2.0533, -2.3112, -2.4532, -2.4562, -2.1401, -1.8640, -2.1851,\n",
      "        -2.2955, -2.0372, -2.1424, -2.0483, -1.8813, -2.0800, -2.1855, -2.3965,\n",
      "        -2.2341, -1.8381, -2.1422, -2.2588, -2.0906, -1.8077, -2.1759, -2.3714,\n",
      "        -2.0920, -1.9421], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1964, -2.2003, -2.1711, -2.1947, -2.1786, -2.1973, -2.2021, -2.1925,\n",
      "        -2.1777, -2.1934, -2.1656, -2.1003, -2.1933, -2.1739, -2.2268, -2.1852,\n",
      "        -2.1935, -2.2171, -2.2035, -2.1878, -2.1728, -2.2070, -2.1971, -2.1894,\n",
      "        -2.1135, -2.1831, -2.1692, -2.1847, -2.1863, -2.1898, -2.1985, -2.1918,\n",
      "        -2.1871, -2.2179, -2.1382, -2.1922, -2.2087, -2.2180, -2.1530, -2.2276,\n",
      "        -2.2127, -2.1516, -2.2129, -2.1826, -2.1505, -2.1921, -2.1714, -2.2129,\n",
      "        -2.1927, -2.1945], device='mps:0')\n",
      "mean: tensor(-2.1870, device='mps:0')\n",
      "iter_dt 1.01s; iter 37: train loss 0.45779 temperature: 6.849999999999993\n",
      "mean_logits tensor([-2.4472, -2.0880, -2.2173, -2.2289, -2.0005, -2.5912, -2.3777, -1.9499,\n",
      "        -2.2052, -2.2901, -2.5883, -2.2165, -2.5487, -2.1640, -2.2481, -2.3557,\n",
      "        -1.9578, -2.4573, -2.4499, -2.5360, -2.1129, -2.0858, -2.0319, -2.0584,\n",
      "        -2.2695, -2.0375, -2.0069, -2.1956, -2.2344, -2.1357, -2.3448, -2.1159,\n",
      "        -2.0907, -2.4256, -2.0827, -2.1567, -2.4624, -1.8838, -2.1034, -2.0239,\n",
      "        -2.2147, -2.0311, -2.2863, -2.1587, -2.2868, -2.4148, -1.8480, -2.2771,\n",
      "        -2.1877, -2.0931], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1925, -2.1912, -2.2176, -2.2059, -2.1937, -2.1970, -2.1149, -2.1922,\n",
      "        -2.1367, -2.2280, -2.1964, -2.2054, -2.1221, -2.1828, -2.1839, -2.1955,\n",
      "        -2.1776, -2.1971, -2.1363, -2.1891, -2.2010, -2.1822, -2.1397, -2.2271,\n",
      "        -2.1680, -2.1842, -2.2369, -2.1909, -2.1268, -2.2278, -2.1949, -2.1890,\n",
      "        -2.0902, -2.1840, -2.1677, -2.1940, -2.1716, -2.1980, -2.2041, -2.2292,\n",
      "        -2.1920, -2.1264, -2.1750, -2.2032, -2.1336, -2.2024, -2.1725, -2.1949,\n",
      "        -2.1618, -2.1911], device='mps:0')\n",
      "mean: tensor(-2.1823, device='mps:0')\n",
      "iter_dt 1.04s; iter 38: train loss 0.28324 temperature: 6.899999999999993\n",
      "mean_logits tensor([-2.1275, -2.2829, -1.9350, -2.0731, -2.2979, -1.8701, -1.8821, -2.1332,\n",
      "        -2.1830, -2.2484, -2.3558, -1.9883, -1.9870, -2.0903, -2.1040, -2.1484,\n",
      "        -2.0307, -2.0910, -2.0323, -2.1964, -2.2207, -2.3777, -2.4104, -2.1395,\n",
      "        -1.9995, -2.4197, -2.2292, -1.9625, -2.4063, -2.1619, -2.2615, -2.2156,\n",
      "        -2.0062, -2.2360, -2.0534, -2.1475, -1.9860, -2.2734, -2.4603, -2.0118,\n",
      "        -1.7292, -2.1224, -2.2421, -2.2643, -1.7551, -2.2685, -2.4153, -2.2947,\n",
      "        -2.1118, -1.9881], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2027, -2.2218, -2.1959, -2.2005, -2.2242, -2.1637, -2.2077, -2.1281,\n",
      "        -2.1646, -2.1800, -2.2103, -2.2284, -2.1956, -2.1929, -2.1934, -2.1576,\n",
      "        -2.1193, -2.1972, -2.2134, -2.1900, -2.1949, -2.2065, -2.1665, -2.1949,\n",
      "        -2.1963, -2.1802, -2.1888, -2.1853, -2.2033, -2.1224, -2.1777, -2.1108,\n",
      "        -2.1567, -2.1976, -2.2338, -2.1952, -2.1630, -2.1970, -2.1671, -2.1955,\n",
      "        -2.2052, -2.1634, -2.1938, -2.1937, -2.1331, -2.1633, -2.2250, -2.1860,\n",
      "        -2.1898, -2.1869], device='mps:0')\n",
      "mean: tensor(-2.1852, device='mps:0')\n",
      "iter_dt 1.03s; iter 39: train loss 0.36981 temperature: 6.949999999999993\n",
      "mean_logits tensor([-1.9177, -1.9592, -1.9630, -2.2121, -2.1456, -2.3431, -1.9293, -1.9921,\n",
      "        -2.4488, -2.4253, -2.2456, -2.2163, -1.9267, -2.3806, -2.0554, -2.4683,\n",
      "        -2.0580, -1.9800, -2.2092, -1.7592, -2.1509, -2.1545, -2.4609, -1.8792,\n",
      "        -2.5293, -2.0248, -2.1110, -2.0405, -2.0891, -2.2196, -2.3177, -2.4883,\n",
      "        -2.2025, -2.1254, -2.2214, -2.2813, -2.1548, -2.3911, -2.5025, -2.0662,\n",
      "        -2.1779, -2.1417, -2.1058, -2.0447, -2.0767, -2.1628, -2.2732, -2.2053,\n",
      "        -2.2514, -2.4040], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1932, -2.1968, -2.1622, -2.0284, -2.1964, -2.1924, -2.2173, -2.1465,\n",
      "        -2.1549, -2.2083, -2.1983, -2.1652, -2.1900, -2.1878, -2.1242, -2.1904,\n",
      "        -2.1524, -2.1904, -2.1551, -2.2160, -2.2018, -2.1545, -2.1807, -2.1772,\n",
      "        -2.1778, -2.1648, -2.1898, -2.1963, -2.1914, -2.1543, -2.2167, -2.2157,\n",
      "        -2.1602, -2.1192, -2.1732, -2.1778, -2.1805, -2.1955, -2.1775, -2.2221,\n",
      "        -2.2116, -2.2358, -2.2121, -2.1831, -2.2308, -2.1756, -2.1939, -2.1714,\n",
      "        -2.1971, -2.2053], device='mps:0')\n",
      "mean: tensor(-2.1822, device='mps:0')\n",
      "iter_dt 1.01s; iter 40: train loss 0.30432 temperature: 6.999999999999993\n",
      "mean_logits tensor([-2.1009, -1.9768, -1.9479, -1.9509, -2.1832, -2.1522, -2.3179, -2.1695,\n",
      "        -1.7788, -2.1797, -2.0221, -2.2649, -2.4071, -2.1718, -2.1700, -2.0699,\n",
      "        -1.9172, -2.3604, -1.8663, -2.1318, -2.1502, -1.8654, -1.8983, -2.2226,\n",
      "        -2.3123, -2.0201, -2.2962, -2.1348, -1.9322, -2.1918, -1.7596, -2.2749,\n",
      "        -2.3085, -1.9389, -2.1766, -2.2650, -1.9807, -2.1964, -2.0513, -2.2227,\n",
      "        -2.0328, -1.9578, -1.8128, -2.1127, -1.8137, -2.2978, -1.9410, -2.4036,\n",
      "        -2.3304, -2.1433], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1695, -2.1479, -2.2107, -2.1814, -2.2046, -2.1935, -2.1990, -2.1857,\n",
      "        -2.1904, -2.1784, -2.1980, -2.1775, -2.1932, -2.1958, -2.1888, -2.1435,\n",
      "        -2.1913, -2.2238, -2.1805, -2.2156, -2.1542, -2.1924, -2.2112, -2.0944,\n",
      "        -2.1878, -2.1891, -2.1445, -2.1967, -2.1222, -2.1960, -2.1484, -2.2075,\n",
      "        -2.1373, -2.1821, -2.1953, -2.1848, -2.1798, -2.1166, -2.2503, -2.1931,\n",
      "        -2.2010, -2.1999, -2.1573, -2.1958, -2.1876, -2.2019, -2.1626, -2.2245,\n",
      "        -2.1860, -2.1941], device='mps:0')\n",
      "mean: tensor(-2.1833, device='mps:0')\n",
      "iter_dt 1.03s; iter 41: train loss 0.34858 temperature: 7.049999999999993\n",
      "mean_logits tensor([-2.1728, -2.2224, -2.3064, -1.9432, -2.5649, -2.4420, -2.0783, -1.9949,\n",
      "        -2.0978, -2.1782, -2.3350, -2.0980, -1.9860, -2.1740, -2.2032, -1.9753,\n",
      "        -2.0209, -1.9578, -2.2258, -2.3245, -2.3218, -1.7977, -1.9305, -2.1622,\n",
      "        -1.9329, -2.4398, -2.1124, -1.8907, -1.9188, -2.0914, -2.3675, -2.3320,\n",
      "        -2.0364, -2.2499, -2.2135, -2.1716, -2.2851, -1.9171, -1.7871, -2.1391,\n",
      "        -1.9158, -2.3325, -2.3494, -2.2875, -2.3747, -1.9550, -2.3406, -2.1907,\n",
      "        -1.9521, -2.3153], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2703, -2.1955, -2.2011, -2.1836, -2.1800, -2.1694, -2.2030, -2.1842,\n",
      "        -2.1691, -2.1916, -2.1923, -2.2105, -2.1576, -2.1454, -2.1685, -2.1574,\n",
      "        -2.1998, -2.1004, -2.1955, -2.2259, -2.1656, -2.2050, -2.2005, -2.1579,\n",
      "        -2.1942, -2.2102, -2.1575, -2.1760, -2.1708, -2.1942, -2.1915, -2.1924,\n",
      "        -2.1979, -2.1971, -2.1870, -2.2009, -2.2084, -2.1794, -2.2137, -2.1583,\n",
      "        -2.2121, -2.1342, -2.1961, -2.1600, -2.1927, -2.2111, -2.1947, -2.1938,\n",
      "        -2.1759, -2.1951], device='mps:0')\n",
      "mean: tensor(-2.1865, device='mps:0')\n",
      "iter_dt 1.00s; iter 42: train loss 0.49977 temperature: 7.0999999999999925\n",
      "mean_logits tensor([-2.1634, -2.1313, -2.0468, -1.9304, -2.2133, -2.1593, -2.2448, -2.2454,\n",
      "        -1.9824, -2.1651, -2.0229, -2.0270, -2.1152, -2.1789, -2.3423, -1.9320,\n",
      "        -2.0824, -2.2992, -1.5469, -2.1025, -1.7636, -1.8532, -2.4927, -2.2374,\n",
      "        -2.1179, -2.3446, -2.6825, -1.8630, -2.2370, -2.3116, -1.9180, -2.4502,\n",
      "        -2.2349, -2.2650, -1.6732, -1.7074, -2.4500, -2.2122, -2.3451, -2.1189,\n",
      "        -2.3506, -2.0976, -2.5474, -1.8005, -2.2657, -2.2415, -2.0433, -1.9932,\n",
      "        -2.1844, -2.0586], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1882, -2.1571, -2.1498, -2.1919, -2.1180, -2.1766, -2.1451, -2.2382,\n",
      "        -2.1788, -2.2359, -2.1932, -2.1571, -2.2024, -2.1339, -2.2171, -2.1722,\n",
      "        -2.1640, -2.1925, -2.1962, -2.1993, -2.1949, -2.1649, -2.1892, -2.1284,\n",
      "        -2.1957, -2.1983, -2.1802, -2.1977, -2.1340, -2.1586, -2.1443, -2.1911,\n",
      "        -2.1959, -2.2413, -2.2067, -2.1823, -2.2087, -2.1802, -2.1958, -2.1494,\n",
      "        -2.1922, -2.1264, -2.2168, -2.1968, -2.1931, -2.1793, -2.2039, -2.1885,\n",
      "        -2.2267, -2.1786], device='mps:0')\n",
      "mean: tensor(-2.1829, device='mps:0')\n",
      "iter_dt 1.01s; iter 43: train loss 0.50263 temperature: 7.149999999999992\n",
      "mean_logits tensor([-2.2669, -2.1224, -2.2497, -2.2577, -2.4293, -2.1231, -2.0641, -2.4448,\n",
      "        -2.3412, -2.5002, -2.2412, -2.3424, -1.9244, -2.3101, -1.7169, -2.1360,\n",
      "        -1.9200, -2.1326, -2.5130, -1.8933, -1.7163, -2.4683, -2.0038, -2.2547,\n",
      "        -2.4574, -2.1211, -2.0161, -2.2507, -2.3591, -2.1924, -2.2453, -2.0010,\n",
      "        -1.8368, -1.6721, -2.2233, -2.2754, -2.2511, -2.2263, -2.1675, -2.4790,\n",
      "        -2.1886, -2.2449, -1.7255, -2.2190, -2.1347, -2.0881, -2.6822, -2.3476,\n",
      "        -2.0713, -2.0513], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2031, -2.1923, -2.1875, -2.2576, -2.1955, -2.1853, -2.1776, -2.1767,\n",
      "        -2.1659, -2.1696, -2.1951, -2.2007, -2.1816, -2.0712, -2.1990, -2.1695,\n",
      "        -2.1428, -2.2448, -2.2365, -2.2003, -2.1827, -2.1997, -2.1957, -2.2122,\n",
      "        -2.1452, -2.2080, -2.1834, -2.2086, -2.1896, -2.1210, -2.1890, -2.1869,\n",
      "        -2.1959, -2.2057, -2.1423, -2.1327, -2.2153, -2.2117, -2.1506, -2.1673,\n",
      "        -2.1689, -2.2410, -2.1823, -2.1968, -2.1040, -2.1390, -2.2618, -2.1749,\n",
      "        -2.1972, -2.1990], device='mps:0')\n",
      "mean: tensor(-2.1852, device='mps:0')\n",
      "iter_dt 1.04s; iter 44: train loss 0.36370 temperature: 7.199999999999992\n",
      "mean_logits tensor([-2.0734, -2.0563, -2.0046, -2.3335, -1.9435, -2.2588, -2.5790, -2.0497,\n",
      "        -2.1650, -2.4513, -2.3471, -2.3280, -2.2599, -2.3725, -2.3311, -2.0917,\n",
      "        -2.2521, -1.8408, -2.1193, -2.0295, -2.1182, -2.3229, -2.1273, -2.2733,\n",
      "        -1.9757, -2.1649, -2.1161, -1.9986, -1.7955, -2.4558, -2.3627, -2.2497,\n",
      "        -1.8102, -2.4119, -1.9465, -2.0988, -2.2254, -2.3123, -1.8167, -1.9301,\n",
      "        -2.4709, -2.0646, -2.0219, -1.9423, -2.0176, -2.4065, -2.1808, -2.2088,\n",
      "        -2.2302, -2.4487], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1660, -2.1506, -2.1796, -2.1366, -2.1598, -2.2280, -2.2239, -2.1806,\n",
      "        -2.1908, -2.2137, -2.1994, -2.1805, -2.2047, -2.2035, -2.1865, -2.1726,\n",
      "        -2.1991, -2.2186, -2.1566, -2.1797, -2.1909, -2.1946, -2.2024, -2.1693,\n",
      "        -2.2290, -2.2016, -2.1958, -2.1920, -2.1900, -2.1828, -2.1866, -2.1969,\n",
      "        -2.1834, -2.1325, -2.1890, -2.1995, -2.2240, -2.2306, -2.1493, -2.1936,\n",
      "        -2.2806, -2.1987, -2.1540, -2.1999, -2.1868, -2.2408, -2.1861, -2.2039,\n",
      "        -2.1964, -2.2050], device='mps:0')\n",
      "mean: tensor(-2.1923, device='mps:0')\n",
      "iter_dt 1.00s; iter 45: train loss 0.35215 temperature: 7.249999999999992\n",
      "mean_logits tensor([-2.4505, -2.1087, -1.9047, -2.4580, -2.3751, -2.2002, -2.3426, -1.7764,\n",
      "        -1.7472, -2.1305, -1.9482, -2.2430, -2.4345, -1.8962, -2.1850, -2.2059,\n",
      "        -2.2578, -2.0718, -1.9355, -2.1637, -2.3857, -2.1643, -1.9688, -2.1416,\n",
      "        -1.8646, -2.1396, -2.0692, -2.4534, -2.4645, -2.0969, -2.3472, -2.2069,\n",
      "        -1.9984, -2.3159, -2.1645, -2.1905, -2.2085, -2.1641, -1.8037, -2.1849,\n",
      "        -1.9478, -1.8620, -2.1350, -2.3864, -2.1165, -2.0693, -1.9814, -2.1110,\n",
      "        -2.1600, -2.1389], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1987, -2.2033, -2.1860, -2.2002, -2.1586, -2.1913, -2.2034, -2.1166,\n",
      "        -2.1327, -2.1797, -2.1845, -2.1935, -2.2497, -2.2086, -2.2605, -2.1929,\n",
      "        -2.2497, -2.1902, -2.1915, -2.1314, -2.1391, -2.1738, -2.2018, -2.2078,\n",
      "        -2.1460, -2.2281, -2.1982, -2.1646, -2.1214, -2.1910, -2.1934, -2.1456,\n",
      "        -2.1942, -2.1590, -2.1809, -2.1363, -2.1192, -2.1957, -2.1933, -2.0806,\n",
      "        -2.1909, -2.2055, -2.1580, -2.1921, -2.1757, -2.1674, -2.1826, -2.1825,\n",
      "        -2.2009, -2.1937], device='mps:0')\n",
      "mean: tensor(-2.1808, device='mps:0')\n",
      "iter_dt 0.99s; iter 46: train loss 0.48846 temperature: 7.299999999999992\n",
      "mean_logits tensor([-1.6703, -2.1933, -1.8249, -2.0676, -2.2823, -2.2519, -2.0606, -2.0871,\n",
      "        -2.3308, -2.2069, -2.0594, -2.2573, -1.8582, -2.5548, -1.9381, -1.9039,\n",
      "        -2.0051, -1.8978, -2.4319, -2.3865, -1.9240, -1.9984, -2.1044, -2.0830,\n",
      "        -2.0469, -2.5975, -2.0352, -2.4357, -2.1857, -2.3317, -1.9959, -2.1657,\n",
      "        -2.0413, -2.3970, -2.6049, -1.9443, -1.9431, -1.9182, -2.1390, -1.7305,\n",
      "        -2.2587, -2.2605, -1.9775, -2.2465, -2.4110, -2.1577, -2.0154, -2.0132,\n",
      "        -2.0814, -2.2714], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1383, -2.1777, -2.2258, -2.1708, -2.2023, -2.1827, -2.1941, -2.1714,\n",
      "        -2.1955, -2.1362, -2.1392, -2.1088, -2.1931, -2.1380, -2.1858, -2.1948,\n",
      "        -2.1292, -2.1941, -2.1927, -2.1953, -2.1752, -2.1799, -2.1850, -2.1931,\n",
      "        -2.1555, -2.1870, -2.1814, -2.1320, -2.2287, -2.2165, -2.1944, -2.1820,\n",
      "        -2.1027, -2.2651, -2.1999, -2.1337, -2.1957, -2.1990, -2.2022, -2.1874,\n",
      "        -2.1608, -2.2119, -2.1612, -2.1583, -2.2072, -2.1934, -2.2625, -2.1480,\n",
      "        -2.2168, -2.1950], device='mps:0')\n",
      "mean: tensor(-2.1815, device='mps:0')\n",
      "iter_dt 1.04s; iter 47: train loss 0.48192 temperature: 7.349999999999992\n",
      "mean_logits tensor([-2.2556, -2.1851, -2.1087, -2.3024, -2.4631, -1.9878, -2.1476, -2.1854,\n",
      "        -2.1504, -2.2101, -2.3234, -1.7148, -1.6860, -2.3428, -2.1578, -2.6679,\n",
      "        -2.0164, -1.8339, -2.0567, -2.0929, -1.9686, -2.1653, -2.0678, -2.6046,\n",
      "        -1.9400, -2.2149, -2.3292, -2.2344, -2.1618, -2.1220, -1.8956, -2.1282,\n",
      "        -1.9603, -2.1246, -2.3689, -2.3200, -2.2740, -1.9381, -2.3638, -1.9375,\n",
      "        -2.3121, -1.7929, -2.1453, -1.9414, -2.2775, -2.2112, -2.5539, -2.3405,\n",
      "        -2.3010, -1.8988], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1240, -2.1522, -2.2057, -2.2333, -2.2134, -2.2052, -2.2158, -2.2246,\n",
      "        -2.1886, -2.1371, -2.1927, -2.2321, -2.2042, -2.2069, -2.1773, -2.1611,\n",
      "        -2.1836, -2.1510, -2.1641, -2.1955, -2.1617, -2.1611, -2.1863, -2.2667,\n",
      "        -2.1976, -2.1739, -2.1770, -2.2251, -2.2293, -2.1149, -2.2108, -2.1941,\n",
      "        -2.2131, -2.2204, -2.1787, -2.1672, -2.1399, -2.1916, -2.1885, -2.1827,\n",
      "        -2.2127, -2.1979, -2.1861, -2.1616, -2.1471, -2.1527, -2.1977, -2.1809,\n",
      "        -2.1860, -2.1812], device='mps:0')\n",
      "mean: tensor(-2.1871, device='mps:0')\n",
      "iter_dt 0.99s; iter 48: train loss 0.33886 temperature: 7.3999999999999915\n",
      "mean_logits tensor([-2.0797, -2.3585, -2.3157, -1.9581, -2.2548, -2.1707, -2.2098, -1.6141,\n",
      "        -2.2958, -2.2096, -2.3879, -1.8750, -2.1564, -2.1850, -2.5407, -1.8999,\n",
      "        -1.9365, -2.3213, -2.2082, -2.0892, -2.3012, -2.1092, -2.1988, -2.1682,\n",
      "        -2.2184, -2.0406, -2.1805, -2.2597, -2.3714, -2.2194, -1.7852, -1.9996,\n",
      "        -1.8998, -2.0341, -2.2191, -2.2593, -2.1685, -1.9191, -1.9497, -2.0567,\n",
      "        -2.0966, -2.1583, -2.4769, -2.4568, -2.0416, -1.9226, -1.8510, -2.1868,\n",
      "        -2.2793, -2.2871], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1543, -2.2528, -2.1906, -2.2076, -2.1741, -2.1463, -2.1679, -2.1495,\n",
      "        -2.1979, -2.1930, -2.1847, -2.1893, -2.1953, -2.1963, -2.1706, -2.1386,\n",
      "        -2.1895, -2.1571, -2.1879, -2.2399, -2.1966, -2.1583, -2.2243, -2.1686,\n",
      "        -2.1938, -2.1676, -2.2004, -2.1953, -2.1689, -2.2191, -2.1615, -2.1426,\n",
      "        -2.1733, -2.2031, -2.1907, -2.1966, -2.1548, -2.1824, -2.1961, -2.1394,\n",
      "        -2.2206, -2.1775, -2.1611, -2.1926, -2.2614, -2.1929, -2.1990, -2.1937,\n",
      "        -2.1884, -2.1387], device='mps:0')\n",
      "mean: tensor(-2.1849, device='mps:0')\n",
      "iter_dt 1.01s; iter 49: train loss 0.32611 temperature: 7.449999999999991\n",
      "mean_logits tensor([-2.2538, -2.0847, -2.3400, -1.8342, -2.3571, -2.0707, -2.2034, -2.0193,\n",
      "        -2.0408, -2.3057, -2.0434, -1.8747, -2.2012, -2.0696, -1.8802, -2.6117,\n",
      "        -2.3939, -2.0925, -2.3746, -1.9602, -2.1345, -2.4056, -2.4055, -1.8720,\n",
      "        -2.1104, -2.1036, -2.2699, -2.0549, -2.4294, -2.1424, -2.3382, -2.1204,\n",
      "        -2.3908, -2.1381, -1.9231, -2.0076, -2.1538, -2.1343, -2.2583, -2.1280,\n",
      "        -2.0393, -2.2191, -2.3865, -2.1138, -2.0590, -2.1981, -2.3048, -1.9975,\n",
      "        -2.0345, -2.1454], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1973, -2.1652, -2.1758, -2.2307, -2.1821, -2.1916, -2.1674, -2.1865,\n",
      "        -2.1629, -2.2089, -2.1686, -2.2211, -2.2004, -2.1944, -2.2338, -2.1532,\n",
      "        -2.2097, -2.2100, -2.2040, -2.2601, -2.1909, -2.1984, -2.3067, -2.1776,\n",
      "        -2.2030, -2.1845, -2.1955, -2.1829, -2.2057, -2.2074, -2.1952, -2.1731,\n",
      "        -2.1971, -2.1732, -2.1550, -2.1689, -2.1907, -2.2649, -2.2139, -2.1659,\n",
      "        -2.1708, -2.1883, -2.1776, -2.2252, -2.1752, -2.2073, -2.1755, -2.1835,\n",
      "        -2.1814, -2.1917], device='mps:0')\n",
      "mean: tensor(-2.1950, device='mps:0')\n",
      "iter_dt 1.03s; iter 50: train loss 0.27514 temperature: 7.499999999999991\n",
      "mean_logits tensor([-2.1778, -2.2722, -1.8635, -1.9366, -1.8453, -2.0415, -2.1714, -1.9362,\n",
      "        -2.5121, -2.1702, -1.9755, -2.0189, -2.3562, -2.1266, -2.1867, -2.0661,\n",
      "        -2.0626, -2.3591, -1.8529, -2.0857, -2.3605, -2.1852, -2.1758, -2.3603,\n",
      "        -2.3220, -2.1895, -2.0120, -2.3123, -2.1360, -2.0552, -2.1484, -2.0753,\n",
      "        -2.1763, -2.2739, -2.1197, -2.0192, -2.2190, -2.2774, -2.1582, -2.1994,\n",
      "        -2.3998, -2.1228, -2.0592, -2.2033, -1.9167, -2.1776, -2.5012, -1.9940,\n",
      "        -2.2044, -2.1840], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1620, -2.2700, -2.1766, -2.2449, -2.1893, -2.1210, -2.1751, -2.1974,\n",
      "        -2.1805, -2.0305, -2.1660, -2.1978, -2.1447, -2.1632, -2.1864, -2.1772,\n",
      "        -2.1843, -2.1657, -2.1933, -2.2034, -2.1655, -2.1444, -2.1846, -2.1952,\n",
      "        -2.1382, -2.1950, -2.1760, -2.1992, -2.1965, -2.2110, -2.1747, -2.1295,\n",
      "        -2.2074, -2.1798, -2.2329, -2.2042, -2.1841, -2.1027, -2.1953, -2.1550,\n",
      "        -2.1841, -2.1930, -2.1121, -2.1949, -2.1956, -2.1959, -2.2070, -2.1792,\n",
      "        -2.1946, -2.1886], device='mps:0')\n",
      "mean: tensor(-2.1789, device='mps:0')\n",
      "iter_dt 1.01s; iter 51: train loss 0.28897 temperature: 7.549999999999991\n",
      "mean_logits tensor([-2.0080, -2.1333, -2.0487, -2.2003, -2.3679, -1.8070, -2.3197, -2.0724,\n",
      "        -1.9988, -1.9019, -2.2641, -2.0250, -2.2416, -2.3448, -1.9670, -2.5366,\n",
      "        -2.3213, -1.8761, -2.0953, -2.1569, -1.8501, -1.9950, -1.8223, -2.2172,\n",
      "        -2.2789, -2.2694, -2.0916, -2.2238, -2.1597, -2.0717, -2.2725, -2.3634,\n",
      "        -2.2720, -2.4161, -1.9510, -2.3668, -2.2808, -2.1683, -2.3351, -2.0330,\n",
      "        -2.2177, -2.3687, -2.1340, -2.0784, -2.1415, -2.2191, -2.2656, -2.1713,\n",
      "        -2.2342, -1.9765], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1976, -2.1818, -2.1849, -2.1928, -2.1383, -2.1423, -2.1703, -2.2080,\n",
      "        -2.2716, -2.1339, -2.1288, -2.1918, -2.1970, -2.1920, -2.2098, -2.1928,\n",
      "        -2.2108, -2.1583, -2.1562, -2.1699, -2.2111, -2.2154, -2.1930, -2.1036,\n",
      "        -2.1624, -2.2014, -2.2485, -2.1999, -2.1476, -2.1921, -2.1839, -2.1882,\n",
      "        -2.1940, -2.1911, -2.1678, -2.1942, -2.1954, -2.2049, -2.2114, -2.1767,\n",
      "        -2.2001, -2.1753, -2.1355, -2.2022, -2.2149, -2.1922, -2.2407, -2.1793,\n",
      "        -2.1715, -2.1971], device='mps:0')\n",
      "mean: tensor(-2.1864, device='mps:0')\n",
      "iter_dt 1.02s; iter 52: train loss 0.40694 temperature: 7.599999999999991\n",
      "mean_logits tensor([-1.6713, -2.0573, -2.3864, -2.5463, -1.9807, -2.0047, -2.2089, -2.1818,\n",
      "        -2.2490, -2.3293, -2.1304, -2.1001, -2.2207, -2.3534, -2.2085, -2.1126,\n",
      "        -2.0574, -2.2148, -1.9770, -2.2974, -2.2367, -2.3145, -2.0101, -2.0612,\n",
      "        -2.3816, -2.1433, -2.5303, -2.4777, -2.3542, -2.2604, -1.9733, -2.1713,\n",
      "        -1.9201, -2.3848, -2.0944, -2.2466, -1.9950, -2.0820, -2.3136, -2.2073,\n",
      "        -2.0014, -2.3441, -2.4015, -2.0261, -2.4982, -2.1504, -2.1255, -2.6866,\n",
      "        -2.1506, -2.2481], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1918, -2.2087, -2.2324, -2.2355, -2.1766, -2.1933, -2.1624, -2.1990,\n",
      "        -2.1906, -2.1964, -2.1909, -2.1294, -2.1964, -2.1950, -2.1724, -2.1680,\n",
      "        -2.1895, -2.1891, -2.1920, -2.1904, -2.2223, -2.2371, -2.1223, -2.2033,\n",
      "        -2.1728, -2.2123, -2.1902, -2.1961, -2.1464, -2.1861, -2.2047, -2.2035,\n",
      "        -2.1900, -2.1643, -2.1930, -2.1380, -2.2254, -2.1434, -2.1883, -2.2120,\n",
      "        -2.1923, -2.1767, -2.2041, -2.1576, -2.2017, -2.1862, -2.1941, -2.1982,\n",
      "        -2.2339, -2.2026], device='mps:0')\n",
      "mean: tensor(-2.1900, device='mps:0')\n",
      "iter_dt 1.01s; iter 53: train loss 0.27039 temperature: 7.649999999999991\n",
      "mean_logits tensor([-2.0755, -2.2333, -2.3678, -2.2222, -2.2464, -1.9929, -2.3007, -1.9031,\n",
      "        -1.9920, -2.1125, -2.0630, -2.2870, -2.0604, -2.2688, -1.9999, -2.0899,\n",
      "        -2.1745, -2.1502, -2.0036, -2.0552, -2.4933, -2.1940, -2.2052, -1.9893,\n",
      "        -2.2509, -2.0400, -2.0203, -2.3522, -1.8934, -2.4077, -2.2120, -2.1469,\n",
      "        -2.0122, -2.1349, -2.0525, -2.3665, -1.9614, -2.0370, -2.0867, -2.4918,\n",
      "        -2.4534, -2.1223, -2.2856, -2.4685, -2.2501, -2.1100, -2.3282, -2.2425,\n",
      "        -2.0884, -2.1794], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1980, -2.1883, -2.1675, -2.1945, -2.1863, -2.1836, -2.1814, -2.1698,\n",
      "        -2.1721, -2.2000, -2.1792, -2.1716, -2.1971, -2.1734, -2.1366, -2.1925,\n",
      "        -2.1648, -2.1974, -2.1679, -2.1291, -2.1681, -2.1708, -2.1569, -2.1638,\n",
      "        -2.1899, -2.1939, -2.1901, -2.1994, -2.1761, -2.1414, -2.2039, -2.1892,\n",
      "        -2.1464, -2.1669, -2.1852, -2.1921, -2.1920, -2.1872, -2.1910, -2.1241,\n",
      "        -2.1413, -2.1285, -2.1715, -2.2399, -2.1725, -2.1806, -2.2460, -2.1827,\n",
      "        -2.2075, -2.1964], device='mps:0')\n",
      "mean: tensor(-2.1789, device='mps:0')\n",
      "iter_dt 1.02s; iter 54: train loss 0.29423 temperature: 7.69999999999999\n",
      "mean_logits tensor([-2.2438, -2.3023, -2.0088, -2.1168, -1.9457, -2.0257, -2.1219, -2.1110,\n",
      "        -2.1374, -2.4207, -2.1544, -2.1933, -2.4046, -2.0303, -2.3278, -2.2639,\n",
      "        -2.2558, -2.4289, -2.2114, -2.0829, -2.3037, -2.4204, -2.2224, -2.0962,\n",
      "        -1.9633, -2.1144, -2.3285, -2.0550, -1.8941, -1.9396, -2.3981, -2.2564,\n",
      "        -2.0960, -2.5350, -2.0778, -2.3080, -2.0180, -2.2320, -2.2309, -2.4028,\n",
      "        -2.2890, -2.4256, -2.0413, -2.3093, -2.1849, -1.9867, -2.1092, -1.9939,\n",
      "        -2.3020, -2.3715], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1704, -2.1681, -2.1934, -2.1315, -2.1882, -2.1938, -2.1865, -2.2429,\n",
      "        -2.1891, -2.2144, -2.1905, -2.2033, -2.1949, -2.1562, -2.1916, -2.2093,\n",
      "        -2.1651, -2.2791, -2.1956, -2.2111, -2.1503, -2.1605, -2.2687, -2.1920,\n",
      "        -2.1925, -2.1723, -2.1579, -2.1997, -2.1370, -2.1795, -2.1245, -2.1385,\n",
      "        -2.1989, -2.1788, -2.1969, -2.1816, -2.1867, -2.1826, -2.1819, -2.1456,\n",
      "        -2.1959, -2.1907, -2.1830, -2.1347, -2.1995, -2.1902, -2.1969, -2.2080,\n",
      "        -2.1758, -2.1594], device='mps:0')\n",
      "mean: tensor(-2.1847, device='mps:0')\n",
      "iter_dt 1.01s; iter 55: train loss 0.32325 temperature: 7.74999999999999\n",
      "mean_logits tensor([-2.1075, -2.2292, -1.6881, -2.0728, -1.9279, -2.2499, -2.3317, -2.2098,\n",
      "        -2.1475, -2.2397, -2.3159, -2.0545, -1.9535, -2.2340, -2.0149, -1.9624,\n",
      "        -2.2088, -2.2858, -2.1083, -2.1924, -2.1840, -1.5496, -2.1841, -2.4118,\n",
      "        -2.2322, -2.0968, -2.3124, -2.4053, -2.0719, -2.0004, -2.3214, -1.9522,\n",
      "        -2.0808, -2.2802, -1.8884, -2.1527, -2.2904, -2.1169, -2.0047, -1.9530,\n",
      "        -2.3541, -1.9021, -2.3968, -2.3329, -2.2610, -2.0785, -2.1084, -2.4242,\n",
      "        -1.9867, -1.9819], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1687, -2.1938, -2.2013, -2.1909, -2.1563, -2.1510, -2.1906, -2.1951,\n",
      "        -2.1744, -2.1693, -2.1937, -2.1937, -2.1967, -2.1810, -2.1936, -2.1997,\n",
      "        -2.1800, -2.1640, -2.2001, -2.1901, -2.1749, -2.1748, -2.1894, -2.1392,\n",
      "        -2.1600, -2.1924, -2.1062, -2.1531, -2.2091, -2.1910, -2.2048, -2.1398,\n",
      "        -2.1955, -2.1912, -2.1859, -2.2300, -2.2092, -2.1808, -2.1913, -2.1893,\n",
      "        -2.1944, -2.1752, -2.1401, -2.2346, -2.2337, -2.1471, -2.1956, -2.1564,\n",
      "        -2.1940, -2.2148], device='mps:0')\n",
      "mean: tensor(-2.1836, device='mps:0')\n",
      "iter_dt 1.01s; iter 56: train loss 0.32387 temperature: 7.79999999999999\n",
      "mean_logits tensor([-2.4112, -2.0975, -1.9457, -1.9644, -2.1991, -2.2195, -2.4685, -2.2810,\n",
      "        -2.0592, -1.8370, -2.2000, -2.1081, -2.3258, -1.8809, -2.2339, -2.1085,\n",
      "        -2.5744, -2.4058, -2.2347, -2.1591, -1.9546, -2.1571, -2.4631, -2.1254,\n",
      "        -2.3821, -2.3112, -2.5472, -2.1941, -2.0448, -2.2525, -2.3567, -1.9884,\n",
      "        -1.9836, -2.1555, -2.2274, -2.0060, -2.1849, -2.2935, -2.1301, -2.1486,\n",
      "        -2.1347, -2.0652, -2.0470, -2.1191, -2.0947, -2.3995, -2.2373, -2.1657,\n",
      "        -2.0605, -2.0883], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2375, -2.1701, -2.1823, -2.2126, -2.2064, -2.1856, -2.1412, -2.2125,\n",
      "        -2.1992, -2.1889, -2.1062, -2.1944, -2.1927, -2.1727, -2.1817, -2.1949,\n",
      "        -2.1949, -2.1709, -2.1904, -2.1912, -2.1351, -2.1865, -2.1624, -2.1941,\n",
      "        -2.1787, -2.2137, -2.1968, -2.1558, -2.1997, -2.1824, -2.1980, -2.1857,\n",
      "        -2.2057, -2.1898, -2.2077, -2.1865, -2.1939, -2.1700, -2.1687, -2.1898,\n",
      "        -2.2072, -2.2583, -2.1396, -2.1867, -2.1680, -2.1603, -2.1978, -2.1930,\n",
      "        -2.2085, -2.1849], device='mps:0')\n",
      "mean: tensor(-2.1866, device='mps:0')\n",
      "iter_dt 1.00s; iter 57: train loss 0.37676 temperature: 7.84999999999999\n",
      "mean_logits tensor([-2.0761, -2.3976, -2.1451, -2.0377, -2.0946, -2.1326, -2.3226, -2.2848,\n",
      "        -2.2099, -2.3203, -1.9752, -1.8953, -1.8368, -2.2737, -2.0399, -2.1510,\n",
      "        -1.9950, -2.2475, -2.1673, -2.3009, -2.4410, -2.0996, -2.2905, -2.2412,\n",
      "        -2.3751, -2.3884, -2.4822, -2.3218, -1.9786, -2.3200, -2.3767, -2.3448,\n",
      "        -2.1236, -2.0090, -2.4331, -2.0415, -2.1885, -2.0684, -1.9920, -2.1514,\n",
      "        -2.2609, -2.2006, -1.9926, -2.2130, -2.6511, -2.0439, -2.0651, -2.0933,\n",
      "        -1.9288, -2.4182], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1882, -2.1964, -2.2137, -2.1952, -2.1345, -2.1966, -2.1233, -2.2449,\n",
      "        -2.1714, -2.1466, -2.1912, -2.1399, -2.1986, -2.2420, -2.1912, -2.1779,\n",
      "        -2.1748, -2.1939, -2.1963, -2.2578, -2.1707, -2.1855, -2.1757, -2.1539,\n",
      "        -2.1187, -2.2225, -2.1751, -2.1798, -2.2108, -2.1618, -2.1838, -2.1940,\n",
      "        -2.1533, -2.2482, -2.1821, -2.1797, -2.1992, -2.1659, -2.1641, -2.2035,\n",
      "        -2.1831, -2.1432, -2.1919, -2.2013, -2.1421, -2.1973, -2.1802, -2.1908,\n",
      "        -2.1736, -2.1133], device='mps:0')\n",
      "mean: tensor(-2.1824, device='mps:0')\n",
      "iter_dt 1.01s; iter 58: train loss 0.54733 temperature: 7.89999999999999\n",
      "mean_logits tensor([-2.1403, -1.9466, -1.9976, -2.2338, -2.2335, -2.7058, -2.0855, -2.5669,\n",
      "        -1.9539, -2.0370, -2.2109, -2.2558, -2.1635, -2.1117, -2.1421, -2.6169,\n",
      "        -2.2530, -2.1432, -2.0477, -2.1797, -2.3556, -1.8980, -1.8842, -2.0423,\n",
      "        -2.2374, -2.4473, -2.1688, -2.1095, -2.2350, -1.8799, -1.9382, -2.1876,\n",
      "        -2.2316, -2.1364, -2.5363, -2.0899, -2.1367, -2.1409, -2.3711, -2.0138,\n",
      "        -2.5872, -1.9070, -2.4166, -2.0550, -2.2936, -2.4813, -2.3350, -2.0536,\n",
      "        -2.3995, -2.2935], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2346, -2.1451, -2.1675, -2.2267, -2.1743, -2.1903, -2.1815, -2.1708,\n",
      "        -2.1838, -2.1881, -2.1749, -2.1288, -2.1501, -2.1813, -2.1913, -2.1946,\n",
      "        -2.1976, -2.2629, -2.2039, -2.1949, -2.1623, -2.1832, -2.1932, -2.1870,\n",
      "        -2.1877, -2.2020, -2.1832, -2.2037, -2.1905, -2.2078, -2.1515, -2.1950,\n",
      "        -2.1939, -2.1898, -2.1766, -2.1945, -2.2345, -2.1921, -2.1275, -2.1989,\n",
      "        -2.1235, -2.1812, -2.1556, -2.1400, -2.2348, -2.1952, -2.1893, -2.1591,\n",
      "        -2.1845, -2.1938], device='mps:0')\n",
      "mean: tensor(-2.1851, device='mps:0')\n",
      "iter_dt 1.02s; iter 59: train loss 0.26518 temperature: 7.9499999999999895\n",
      "mean_logits tensor([-2.2861, -2.2767, -1.9453, -2.1116, -2.5974, -1.9922, -2.0094, -1.8229,\n",
      "        -2.2554, -2.1194, -2.2143, -2.3545, -2.1133, -2.2055, -2.2855, -2.3171,\n",
      "        -2.1989, -2.1497, -2.1427, -2.3039, -2.3692, -2.0979, -2.4195, -2.3554,\n",
      "        -2.2472, -2.1353, -2.4499, -2.2532, -2.1262, -1.9937, -2.2062, -2.1431,\n",
      "        -1.8882, -2.0883, -2.0935, -2.1102, -2.2251, -2.2635, -2.0266, -2.2242,\n",
      "        -2.0333, -2.1439, -1.8741, -2.2690, -2.2565, -2.1753, -1.9705, -2.3147,\n",
      "        -1.8567, -1.9906], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2712, -2.1946, -2.2088, -2.1535, -2.2012, -2.1854, -2.1471, -2.1708,\n",
      "        -2.1587, -2.2267, -2.1929, -2.2267, -2.1562, -2.1204, -2.2030, -2.2171,\n",
      "        -2.1992, -2.1534, -2.2235, -2.1932, -2.1761, -2.2139, -2.1985, -2.1781,\n",
      "        -2.1278, -2.1998, -2.1665, -2.1795, -2.1982, -2.1860, -2.1880, -2.1634,\n",
      "        -2.1435, -2.1968, -2.1965, -2.1946, -2.1292, -2.1439, -2.1921, -2.1776,\n",
      "        -2.1824, -2.2107, -2.1950, -2.2275, -2.1943, -2.1785, -2.1782, -2.1743,\n",
      "        -2.1614, -2.1957], device='mps:0')\n",
      "mean: tensor(-2.1850, device='mps:0')\n",
      "iter_dt 1.01s; iter 60: train loss 0.35671 temperature: 7.999999999999989\n",
      "mean_logits tensor([-2.3563, -2.0787, -2.2512, -2.4551, -2.0269, -2.3123, -2.2671, -2.1082,\n",
      "        -2.1622, -2.1086, -1.7156, -2.2130, -2.3761, -1.9383, -2.2538, -1.7734,\n",
      "        -2.3462, -2.5444, -2.1020, -2.2897, -2.5350, -2.2131, -1.9382, -2.0694,\n",
      "        -2.1566, -2.0866, -2.3144, -2.2528, -2.1595, -2.3650, -2.4112, -2.1843,\n",
      "        -2.0704, -2.1251, -2.4284, -2.4185, -1.8990, -2.0452, -2.0743, -1.8661,\n",
      "        -2.3750, -2.2786, -2.0582, -1.9632, -2.0426, -1.9620, -2.1919, -1.9020,\n",
      "        -2.0964, -2.2755], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1993, -2.2002, -2.1935, -2.2636, -2.1907, -2.1726, -2.1393, -2.1824,\n",
      "        -2.2110, -2.1967, -2.1780, -2.1837, -2.1954, -2.1772, -2.2051, -2.1690,\n",
      "        -2.1898, -2.1695, -2.2371, -2.1994, -2.1723, -2.1310, -2.1929, -2.1817,\n",
      "        -2.1896, -2.1738, -2.2059, -2.1855, -2.1978, -2.2216, -2.2692, -2.1482,\n",
      "        -2.2023, -2.2034, -2.2061, -2.1964, -2.1677, -2.1957, -2.1812, -2.1723,\n",
      "        -2.1929, -2.2433, -2.2213, -2.2202, -2.1707, -2.1944, -2.2044, -2.2018,\n",
      "        -2.1940, -2.1698], device='mps:0')\n",
      "mean: tensor(-2.1932, device='mps:0')\n",
      "iter_dt 1.02s; iter 61: train loss 0.26194 temperature: 8.04999999999999\n",
      "mean_logits tensor([-2.1639, -2.1906, -2.2481, -2.1044, -2.2250, -2.0470, -2.0128, -2.0502,\n",
      "        -2.2518, -2.1689, -2.0887, -2.3475, -1.9600, -2.2239, -2.0374, -2.0709,\n",
      "        -2.4329, -1.6679, -2.3310, -2.3392, -2.3639, -2.3346, -2.2034, -2.0308,\n",
      "        -2.2966, -2.0726, -2.2369, -2.2249, -2.0555, -2.0893, -1.9574, -2.0202,\n",
      "        -2.0425, -2.4729, -2.0963, -1.8407, -2.1597, -2.0572, -2.0937, -2.1830,\n",
      "        -2.1110, -2.3044, -2.1017, -2.2139, -2.5212, -2.3028, -2.0008, -2.2220,\n",
      "        -2.4044, -2.1994], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1793, -2.1874, -2.1706, -2.2263, -2.1967, -2.1949, -2.2446, -2.1909,\n",
      "        -2.1924, -2.1980, -2.1619, -2.1426, -2.1423, -2.1711, -2.2412, -2.1603,\n",
      "        -2.1920, -2.1832, -2.2618, -2.2154, -2.1481, -2.2328, -2.1746, -2.1928,\n",
      "        -2.1791, -2.1781, -2.2336, -2.1933, -2.1637, -2.1675, -2.1894, -2.1929,\n",
      "        -2.1853, -2.1940, -2.1773, -2.1390, -2.1991, -2.1998, -2.1945, -2.2248,\n",
      "        -2.1930, -2.2068, -2.1921, -2.1921, -2.1699, -2.1541, -2.1850, -2.1985,\n",
      "        -2.1991, -2.2337], device='mps:0')\n",
      "mean: tensor(-2.1907, device='mps:0')\n",
      "iter_dt 1.03s; iter 62: train loss 0.24710 temperature: 8.09999999999999\n",
      "mean_logits tensor([-2.1202, -1.9972, -2.0109, -2.2741, -2.1828, -2.2920, -2.0374, -2.3126,\n",
      "        -2.1074, -2.1626, -2.1806, -2.4620, -2.3572, -2.3014, -2.2579, -2.4805,\n",
      "        -2.1984, -2.1144, -2.2491, -2.2232, -2.3103, -2.3281, -2.0322, -1.9942,\n",
      "        -1.9302, -2.3920, -2.3232, -2.2666, -2.0393, -2.0877, -2.0579, -2.3083,\n",
      "        -1.9994, -1.9988, -2.3118, -2.0941, -2.4364, -2.2368, -2.0086, -2.1214,\n",
      "        -2.2069, -2.1605, -2.0314, -2.1707, -2.3608, -2.0382, -2.1425, -2.4239,\n",
      "        -2.0941, -1.8584], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1511, -2.1916, -2.2096, -2.1921, -2.2047, -2.2385, -2.1838, -2.1825,\n",
      "        -2.2151, -2.1220, -2.1595, -2.1977, -2.2119, -2.1797, -2.1743, -2.1634,\n",
      "        -2.2005, -2.1962, -2.2626, -2.2414, -2.2348, -2.1804, -2.1910, -2.2090,\n",
      "        -2.1964, -2.1957, -2.2063, -2.2015, -2.1954, -2.1775, -2.1955, -2.1358,\n",
      "        -2.1815, -2.2080, -2.2085, -2.2127, -2.2031, -2.1868, -2.1926, -2.1955,\n",
      "        -2.1589, -2.1849, -2.1919, -2.1936, -2.1726, -2.1399, -2.1822, -2.1988,\n",
      "        -2.1996, -2.2147], device='mps:0')\n",
      "mean: tensor(-2.1925, device='mps:0')\n",
      "iter_dt 1.04s; iter 63: train loss 0.22056 temperature: 8.149999999999991\n",
      "mean_logits tensor([-1.8177, -2.1897, -2.0404, -2.4145, -1.9812, -2.2188, -2.1507, -2.1692,\n",
      "        -2.2388, -1.8973, -2.2563, -2.3535, -2.4204, -2.3297, -2.0834, -2.3529,\n",
      "        -1.9971, -2.2563, -2.1409, -2.0971, -1.9279, -2.0845, -1.8803, -2.1740,\n",
      "        -2.3357, -2.2212, -2.0734, -2.0987, -2.1457, -2.1272, -2.1740, -2.3075,\n",
      "        -2.1172, -2.1703, -2.2522, -2.2752, -2.2549, -2.0788, -2.2148, -2.4202,\n",
      "        -2.1854, -2.2730, -2.2275, -2.1290, -2.2206, -2.3098, -2.0502, -2.2770,\n",
      "        -2.2305, -1.9382], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1900, -2.1923, -2.1946, -2.1880, -2.2668, -2.1884, -2.1905, -2.1979,\n",
      "        -2.1949, -2.2019, -2.1961, -2.1269, -2.1981, -2.2094, -2.2080, -2.1873,\n",
      "        -2.1948, -2.1862, -2.2676, -2.1967, -2.1950, -2.1853, -2.1961, -2.1941,\n",
      "        -2.2187, -2.2326, -2.1909, -2.1968, -2.2591, -2.2032, -2.1689, -2.1715,\n",
      "        -2.1668, -2.1736, -2.1942, -2.1829, -2.1761, -2.1902, -2.1974, -2.2269,\n",
      "        -2.1926, -2.1807, -2.1802, -2.1636, -2.2262, -2.1323, -2.2133, -2.1283,\n",
      "        -2.1701, -2.1818], device='mps:0')\n",
      "mean: tensor(-2.1933, device='mps:0')\n",
      "iter_dt 1.03s; iter 64: train loss 0.28153 temperature: 8.199999999999992\n",
      "mean_logits tensor([-2.0189, -2.2878, -2.0227, -2.1633, -2.1345, -2.2114, -2.0440, -2.1218,\n",
      "        -2.1656, -2.2409, -2.0945, -2.3539, -2.2217, -2.2500, -2.2797, -2.0566,\n",
      "        -2.3189, -2.1312, -2.0782, -2.0373, -2.1098, -2.1259, -2.5978, -2.4794,\n",
      "        -2.5278, -2.2441, -2.2777, -1.8446, -2.1250, -2.1905, -2.1571, -2.1351,\n",
      "        -2.2403, -1.9859, -1.9546, -2.0276, -2.1274, -2.2965, -2.3074, -2.1349,\n",
      "        -2.0665, -2.3607, -2.1067, -2.2666, -2.0173, -2.2671, -2.2584, -1.9226,\n",
      "        -1.8609, -2.3106], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1904, -2.1629, -2.1924, -2.1678, -2.1914, -2.1931, -2.1850, -2.1636,\n",
      "        -2.1961, -2.2581, -2.1955, -2.1448, -2.1921, -2.1959, -2.1846, -2.1945,\n",
      "        -2.1312, -2.2021, -2.1968, -2.1472, -2.1737, -2.1765, -2.1966, -2.1950,\n",
      "        -2.1287, -2.2146, -2.1967, -2.1452, -2.1775, -2.1985, -2.2093, -2.2043,\n",
      "        -2.1879, -2.1377, -2.1961, -2.1960, -2.1965, -2.1926, -2.1899, -2.1916,\n",
      "        -2.1988, -2.1307, -2.1942, -2.2059, -2.1916, -2.1755, -2.1493, -2.1691,\n",
      "        -2.1911, -2.1808], device='mps:0')\n",
      "mean: tensor(-2.1835, device='mps:0')\n",
      "iter_dt 1.02s; iter 65: train loss 0.26523 temperature: 8.249999999999993\n",
      "mean_logits tensor([-2.0391, -1.9666, -2.3073, -2.2382, -2.2282, -2.2187, -2.3869, -2.2123,\n",
      "        -2.0400, -2.0736, -1.9503, -2.2039, -2.1386, -2.0916, -2.2546, -2.3307,\n",
      "        -2.1101, -2.0074, -2.3876, -2.4250, -1.8897, -2.4270, -2.1413, -2.1579,\n",
      "        -2.0999, -2.2309, -2.4416, -2.2321, -2.3269, -1.9815, -2.1960, -2.2934,\n",
      "        -1.9017, -2.1950, -2.2157, -2.3034, -1.9799, -2.2005, -2.2454, -2.3723,\n",
      "        -2.2356, -2.4397, -2.2498, -2.4232, -2.3648, -2.0149, -2.1934, -2.1264,\n",
      "        -1.9873, -2.3346], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1620, -2.1803, -2.1864, -2.1652, -2.1631, -2.1999, -2.1481, -2.2051,\n",
      "        -2.1830, -2.2037, -2.2004, -2.1598, -2.1994, -2.1913, -2.1876, -2.1412,\n",
      "        -2.1963, -2.1939, -2.2356, -2.1366, -2.1926, -2.1925, -2.1956, -2.2131,\n",
      "        -2.1919, -2.2072, -2.1929, -2.2533, -2.1924, -2.2614, -2.1727, -2.2032,\n",
      "        -2.1886, -2.1932, -2.2029, -2.1807, -2.2432, -2.1959, -2.1683, -2.1935,\n",
      "        -2.1681, -2.2034, -2.2084, -2.1933, -2.2041, -2.1718, -2.1650, -2.1983,\n",
      "        -2.1867, -2.1884], device='mps:0')\n",
      "mean: tensor(-2.1912, device='mps:0')\n",
      "iter_dt 1.01s; iter 66: train loss 0.29442 temperature: 8.299999999999994\n",
      "mean_logits tensor([-2.0673, -2.1170, -1.9454, -1.9799, -2.2923, -2.0487, -2.0513, -2.0419,\n",
      "        -2.3621, -1.9841, -1.7914, -2.2117, -2.1033, -2.0027, -2.3398, -2.1069,\n",
      "        -1.8578, -2.1855, -2.2787, -2.0952, -2.3777, -2.4146, -2.3273, -2.0714,\n",
      "        -2.3623, -2.2025, -2.0883, -2.1610, -2.4282, -2.2041, -2.1614, -2.4639,\n",
      "        -1.9736, -2.0660, -1.9546, -1.7769, -2.2060, -2.0329, -2.2246, -2.3180,\n",
      "        -2.1911, -2.2179, -2.0904, -2.4121, -2.3538, -2.0516, -2.2445, -1.8255,\n",
      "        -2.1694, -1.9808], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1961, -2.2034, -2.1939, -2.1383, -2.2172, -2.1791, -2.1979, -2.1972,\n",
      "        -2.2099, -2.2063, -2.1989, -2.2191, -2.1917, -2.2203, -2.1929, -2.1936,\n",
      "        -2.1835, -2.2211, -2.1940, -2.1900, -2.1915, -2.2122, -2.1606, -2.2493,\n",
      "        -2.2130, -2.1990, -2.1920, -2.1977, -2.2617, -2.1353, -2.2554, -2.1910,\n",
      "        -2.1752, -2.1928, -2.1951, -2.1900, -2.3294, -2.2002, -2.1492, -2.1965,\n",
      "        -2.1822, -2.1969, -2.2062, -2.1967, -2.2037, -2.1832, -2.1947, -2.1863,\n",
      "        -2.1463, -2.1774], device='mps:0')\n",
      "mean: tensor(-2.1981, device='mps:0')\n",
      "iter_dt 1.03s; iter 67: train loss 0.23415 temperature: 8.349999999999994\n",
      "mean_logits tensor([-2.4493, -2.1626, -2.2024, -2.1004, -1.9754, -2.1167, -2.1248, -2.2512,\n",
      "        -2.1949, -2.0322, -2.0869, -2.4653, -2.1267, -2.2299, -2.3904, -2.2885,\n",
      "        -2.3630, -2.0811, -2.2122, -1.9273, -2.2194, -1.9998, -2.3623, -1.9260,\n",
      "        -2.1535, -2.0652, -2.2953, -2.2099, -2.0991, -2.1923, -2.0152, -1.9812,\n",
      "        -2.1187, -2.0918, -2.0493, -2.1878, -2.4292, -2.2998, -2.1797, -2.4820,\n",
      "        -2.1433, -1.9805, -2.2455, -2.0656, -2.4168, -2.1067, -2.2852, -2.3126,\n",
      "        -2.4305, -1.9487], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1379, -2.1892, -2.1959, -2.1842, -2.1005, -2.1956, -2.1896, -2.2025,\n",
      "        -2.1227, -2.1509, -2.1953, -2.1940, -2.1947, -2.1061, -2.1882, -2.2012,\n",
      "        -2.1925, -2.1990, -2.1948, -2.1956, -2.1946, -2.1952, -2.2046, -2.1985,\n",
      "        -2.1956, -2.1935, -2.1633, -2.1817, -2.1956, -2.1497, -2.1714, -2.1924,\n",
      "        -2.1932, -2.1886, -2.1912, -2.1901, -2.1924, -2.1937, -2.2594, -2.2627,\n",
      "        -2.1656, -2.1533, -2.1594, -2.1887, -2.2784, -2.1678, -2.1982, -2.1901,\n",
      "        -2.2277, -2.2131], device='mps:0')\n",
      "mean: tensor(-2.1876, device='mps:0')\n",
      "iter_dt 1.01s; iter 68: train loss 0.36484 temperature: 8.399999999999995\n",
      "mean_logits tensor([-2.1293, -2.0909, -2.0817, -2.4843, -2.2074, -2.1743, -2.0342, -2.1064,\n",
      "        -2.1884, -2.3205, -2.1957, -2.1432, -2.0843, -2.1953, -2.4064, -2.1386,\n",
      "        -1.9565, -2.2769, -1.7038, -2.3757, -2.1706, -2.1022, -1.9402, -2.4032,\n",
      "        -2.0854, -2.0835, -1.7958, -1.9317, -2.3877, -2.0640, -2.3465, -2.0461,\n",
      "        -2.1812, -2.2372, -2.0447, -1.9942, -2.2075, -1.5080, -2.4119, -1.9978,\n",
      "        -2.2498, -2.3588, -1.9753, -2.2369, -1.9141, -2.4129, -2.1526, -2.4271,\n",
      "        -2.1659, -2.4924], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2585, -2.1845, -2.2046, -2.1994, -2.2374, -2.1980, -2.1977, -2.1895,\n",
      "        -2.2058, -2.1712, -2.2052, -2.1626, -2.1265, -2.1833, -2.1800, -2.2112,\n",
      "        -2.1644, -2.2052, -2.1474, -2.2054, -2.1380, -2.1589, -2.1936, -2.1938,\n",
      "        -2.1990, -2.1988, -2.2320, -2.2384, -2.1951, -2.2159, -2.1732, -2.1833,\n",
      "        -2.1725, -2.1711, -2.1877, -2.1963, -2.1908, -2.1317, -2.1811, -2.1922,\n",
      "        -2.1925, -2.2054, -2.1946, -2.1513, -2.1835, -2.1626, -2.2344, -2.1958,\n",
      "        -2.2550, -2.1998], device='mps:0')\n",
      "mean: tensor(-2.1911, device='mps:0')\n",
      "iter_dt 1.00s; iter 69: train loss 0.24796 temperature: 8.449999999999996\n",
      "mean_logits tensor([-1.9694, -2.1243, -2.0192, -2.2520, -2.4728, -2.1648, -2.1507, -2.3460,\n",
      "        -2.3979, -2.1831, -1.9581, -2.1660, -1.9894, -2.2559, -2.2836, -2.3923,\n",
      "        -1.9558, -2.3036, -2.2333, -2.2597, -1.8643, -2.3751, -2.1571, -1.8956,\n",
      "        -1.9617, -2.2923, -1.9064, -2.2880, -2.0526, -2.3552, -2.2055, -2.1379,\n",
      "        -2.2916, -2.3308, -2.0321, -2.3147, -2.4757, -2.2870, -2.1647, -1.9631,\n",
      "        -2.1245, -2.1359, -2.0222, -2.1254, -2.3640, -2.2758, -2.2387, -2.2333,\n",
      "        -2.1301, -2.1740], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1639, -2.1928, -2.2477, -2.1881, -2.2172, -2.1834, -2.2053, -2.1880,\n",
      "        -2.1962, -2.2103, -2.1946, -2.1928, -2.1989, -2.1812, -2.1853, -2.2441,\n",
      "        -2.1959, -2.1389, -2.1935, -2.1583, -2.1719, -2.1732, -2.1450, -2.1421,\n",
      "        -2.1624, -2.1750, -2.2033, -2.2887, -2.1491, -2.1791, -2.1929, -2.1959,\n",
      "        -2.1963, -2.1647, -2.1694, -2.1718, -2.1501, -2.1903, -2.2066, -2.1495,\n",
      "        -2.1347, -2.1954, -2.1812, -2.1867, -2.1574, -2.1710, -2.1902, -2.1594,\n",
      "        -2.1644, -2.1824], device='mps:0')\n",
      "mean: tensor(-2.1835, device='mps:0')\n",
      "iter_dt 1.00s; iter 70: train loss 0.28386 temperature: 8.499999999999996\n",
      "mean_logits tensor([-2.1610, -2.0850, -1.9038, -2.3991, -2.0530, -2.1860, -2.3311, -2.3823,\n",
      "        -2.3732, -1.9796, -2.1206, -2.4419, -2.2928, -1.8555, -1.8942, -2.2608,\n",
      "        -2.1960, -2.4475, -2.2708, -1.9418, -2.3516, -2.3416, -2.1024, -2.2706,\n",
      "        -1.8461, -2.4090, -2.2642, -2.1915, -2.0358, -2.0926, -2.3236, -2.3187,\n",
      "        -2.2199, -1.9571, -1.9464, -2.1833, -2.3730, -1.9228, -1.9247, -2.1463,\n",
      "        -2.3049, -2.3957, -2.1517, -2.2122, -2.1650, -2.1357, -2.2715, -2.3327,\n",
      "        -2.1795, -2.2335], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1955, -2.1978, -2.1982, -2.1967, -2.2706, -2.1788, -2.2242, -2.1682,\n",
      "        -2.2164, -2.1941, -2.1804, -2.1346, -2.1918, -2.1809, -2.1815, -2.1672,\n",
      "        -2.2008, -2.2062, -2.1950, -2.2050, -2.1809, -2.2025, -2.1915, -2.1910,\n",
      "        -2.1921, -2.1697, -2.1965, -2.1272, -2.1528, -2.1960, -2.1995, -2.2471,\n",
      "        -2.1957, -2.1936, -2.1622, -2.1907, -2.1742, -2.1310, -2.1883, -2.2057,\n",
      "        -2.2161, -2.1993, -2.1861, -2.1900, -2.2007, -2.1965, -2.2597, -2.1922,\n",
      "        -2.1967, -2.1761], device='mps:0')\n",
      "mean: tensor(-2.1917, device='mps:0')\n",
      "iter_dt 1.02s; iter 71: train loss 0.25468 temperature: 8.549999999999997\n",
      "mean_logits tensor([-2.0379, -2.2280, -2.0174, -2.2524, -2.2525, -2.1331, -2.0214, -2.0869,\n",
      "        -1.9866, -2.1241, -2.1754, -2.1956, -2.1736, -2.2586, -1.9228, -2.1642,\n",
      "        -1.8664, -2.2639, -1.8876, -1.9722, -2.1235, -2.2455, -2.2001, -2.0918,\n",
      "        -2.1526, -2.0789, -2.1858, -2.2184, -2.1612, -2.1707, -2.2196, -2.1032,\n",
      "        -2.4960, -2.2637, -2.5027, -2.1857, -2.0436, -2.0357, -1.9118, -2.2009,\n",
      "        -2.4549, -2.3470, -2.1704, -2.3045, -2.2888, -2.2282, -2.3001, -2.4875,\n",
      "        -2.1966, -1.9150], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1212, -2.1967, -2.2193, -2.1962, -2.1963, -2.1960, -2.1903, -2.1259,\n",
      "        -2.1070, -2.1979, -2.1730, -2.1734, -2.1551, -2.1932, -2.1897, -2.1938,\n",
      "        -2.2633, -2.2699, -2.1803, -2.2606, -2.1942, -2.1663, -2.1998, -2.1717,\n",
      "        -2.1930, -2.2107, -2.1955, -2.2408, -2.1656, -2.1902, -2.2014, -2.1873,\n",
      "        -2.2043, -2.1895, -2.1893, -2.1644, -2.1914, -2.1873, -2.1683, -2.1900,\n",
      "        -2.2098, -2.1855, -2.1951, -2.1941, -2.2064, -2.1989, -2.1680, -2.1329,\n",
      "        -2.2003, -2.1940], device='mps:0')\n",
      "mean: tensor(-2.1897, device='mps:0')\n",
      "iter_dt 1.01s; iter 72: train loss 0.19437 temperature: 8.599999999999998\n",
      "mean_logits tensor([-2.1816, -2.2478, -2.0302, -2.1973, -2.1933, -2.1777, -2.0338, -2.1306,\n",
      "        -2.0703, -2.2843, -2.0838, -1.9286, -2.1245, -2.0224, -2.0359, -2.2991,\n",
      "        -2.1488, -2.1322, -2.2841, -1.8353, -2.2993, -2.2490, -2.0820, -2.2486,\n",
      "        -1.9332, -1.9159, -2.1517, -2.2712, -2.3071, -2.3317, -2.0783, -2.2187,\n",
      "        -2.0134, -2.2187, -1.9429, -2.3404, -2.2884, -2.0772, -2.3919, -2.2177,\n",
      "        -2.1628, -2.1025, -2.2224, -1.9598, -2.0033, -2.0402, -2.2493, -2.0285,\n",
      "        -2.0180, -2.3272], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2249, -2.1955, -2.1422, -2.1177, -2.2032, -2.1687, -2.1845, -2.2212,\n",
      "        -2.1696, -2.2273, -2.1729, -2.2484, -2.1752, -2.2026, -2.1945, -2.1385,\n",
      "        -2.1854, -2.1835, -2.1915, -2.1771, -2.2238, -2.2042, -2.1987, -2.1917,\n",
      "        -2.2634, -2.1838, -2.2560, -2.1968, -2.2578, -2.1621, -2.2506, -2.1430,\n",
      "        -2.1130, -2.1629, -2.2120, -2.2506, -2.1898, -2.1954, -2.1881, -2.1738,\n",
      "        -2.1396, -2.1920, -2.1444, -2.1796, -2.1801, -2.1492, -2.1970, -2.1965,\n",
      "        -2.1947, -2.1959], device='mps:0')\n",
      "mean: tensor(-2.1902, device='mps:0')\n",
      "iter_dt 1.02s; iter 73: train loss 0.33157 temperature: 8.649999999999999\n",
      "mean_logits tensor([-2.3069, -2.0608, -2.3802, -2.4724, -2.1789, -2.3394, -2.3399, -2.0613,\n",
      "        -2.1797, -2.3245, -2.2420, -2.1145, -2.1495, -1.9819, -1.8150, -2.3296,\n",
      "        -2.1507, -2.1149, -2.0661, -2.3051, -2.4303, -2.0155, -2.1799, -2.0777,\n",
      "        -2.1927, -1.9561, -2.0966, -1.9111, -2.1741, -2.1238, -2.1382, -2.1992,\n",
      "        -2.2897, -2.2539, -2.3059, -2.3863, -2.0540, -2.1362, -2.3294, -1.7494,\n",
      "        -2.2209, -2.2652, -1.8026, -2.2397, -2.3258, -2.1976, -2.3074, -1.8273,\n",
      "        -2.6086, -2.0592], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1815, -2.2097, -2.1631, -2.1705, -2.2044, -2.2244, -2.1321, -2.1924,\n",
      "        -2.2099, -2.2063, -2.2761, -2.2068, -2.1886, -2.1898, -2.1937, -2.1978,\n",
      "        -2.2584, -2.2171, -2.2058, -2.1770, -2.2455, -2.1888, -2.1857, -2.1913,\n",
      "        -2.2015, -2.1778, -2.1775, -2.1977, -2.1901, -2.2136, -2.2598, -2.2812,\n",
      "        -2.2002, -2.1815, -2.1902, -2.2795, -2.1741, -2.1951, -2.1921, -2.1579,\n",
      "        -2.2009, -2.1956, -2.1922, -2.1527, -2.1853, -2.1636, -2.2354, -2.2009,\n",
      "        -2.1307, -2.1784], device='mps:0')\n",
      "mean: tensor(-2.1984, device='mps:0')\n",
      "iter_dt 1.03s; iter 74: train loss 0.36125 temperature: 8.7\n",
      "mean_logits tensor([-2.1621, -2.0117, -2.0512, -2.3771, -2.1427, -2.0850, -2.4819, -1.9812,\n",
      "        -2.2996, -2.4261, -1.9927, -2.1705, -1.9386, -2.1486, -2.4898, -2.1959,\n",
      "        -2.1818, -2.2197, -2.2499, -2.3973, -2.2676, -2.3171, -2.1381, -2.4048,\n",
      "        -2.1400, -2.0408, -2.4011, -2.0829, -2.2745, -1.9190, -2.0701, -1.9095,\n",
      "        -2.0859, -2.3015, -2.4020, -2.1283, -2.0167, -2.1923, -2.2108, -1.9793,\n",
      "        -2.5875, -2.1971, -2.3736, -2.3908, -2.5266, -2.2479, -2.5033, -2.1696,\n",
      "        -1.9888, -2.2986], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1888, -2.1257, -2.1956, -2.1709, -2.1793, -2.1569, -2.1922, -2.2547,\n",
      "        -2.2547, -2.1854, -2.1907, -2.1976, -2.1857, -2.1894, -2.2600, -2.2564,\n",
      "        -2.1486, -2.2049, -2.1865, -2.2105, -2.1865, -2.1912, -2.2110, -2.2624,\n",
      "        -2.2023, -2.2125, -2.1852, -2.1695, -2.2008, -2.1598, -2.1293, -2.2043,\n",
      "        -2.1898, -2.1324, -2.2629, -2.1769, -2.2142, -2.1939, -2.1950, -2.2087,\n",
      "        -2.1923, -2.2496, -2.1899, -2.1529, -2.1859, -2.1895, -2.1853, -2.1615,\n",
      "        -2.1745, -2.1512], device='mps:0')\n",
      "mean: tensor(-2.1931, device='mps:0')\n",
      "iter_dt 1.00s; iter 75: train loss 0.28289 temperature: 8.75\n",
      "mean_logits tensor([-2.1330, -2.1411, -2.0361, -2.0034, -1.5652, -1.9590, -1.9257, -2.3939,\n",
      "        -2.2390, -2.1035, -1.9981, -2.4082, -1.9527, -2.2959, -2.3085, -2.2547,\n",
      "        -2.0565, -2.1887, -2.1832, -2.2864, -2.4334, -2.3630, -2.3093, -1.9720,\n",
      "        -2.1060, -2.2122, -2.1341, -2.3833, -1.9027, -1.9355, -1.8621, -2.0644,\n",
      "        -2.2374, -2.0191, -2.2357, -2.3419, -2.3107, -2.2817, -2.3450, -2.4847,\n",
      "        -2.3965, -1.9065, -2.2982, -2.2411, -2.3631, -2.2611, -2.2603, -2.1468,\n",
      "        -2.2268, -2.2104], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1976, -2.1806, -2.1489, -2.1958, -2.1716, -2.1513, -2.1790, -2.1976,\n",
      "        -2.1929, -2.1936, -2.1792, -2.1938, -2.2060, -2.1233, -2.2638, -2.2014,\n",
      "        -2.1869, -2.1420, -2.2033, -2.1921, -2.2024, -2.2020, -2.1970, -2.1723,\n",
      "        -2.1694, -2.1937, -2.1991, -2.2144, -2.1995, -2.2182, -2.1577, -2.2093,\n",
      "        -2.1952, -2.1447, -2.1567, -2.1970, -2.2031, -2.1371, -2.1962, -2.2598,\n",
      "        -2.2286, -2.1780, -2.2610, -2.1483, -2.1979, -2.1882, -2.1911, -2.1640,\n",
      "        -2.1953, -2.2154], device='mps:0')\n",
      "mean: tensor(-2.1899, device='mps:0')\n",
      "iter_dt 1.01s; iter 76: train loss 0.27498 temperature: 8.8\n",
      "mean_logits tensor([-2.1674, -2.1974, -2.2038, -2.3027, -2.2126, -2.4756, -2.2077, -1.7691,\n",
      "        -1.8928, -2.1918, -2.2285, -2.3235, -2.1255, -1.9527, -2.1900, -2.0155,\n",
      "        -2.2078, -2.4331, -2.3086, -2.2616, -2.1992, -2.1759, -2.0908, -1.8836,\n",
      "        -2.1892, -2.0307, -2.3038, -2.1375, -2.2783, -2.1588, -2.2021, -2.1729,\n",
      "        -1.9830, -1.8731, -2.1417, -2.1142, -1.7483, -2.1139, -2.1748, -2.0434,\n",
      "        -2.5013, -2.4149, -2.2104, -2.1072, -2.3365, -2.4727, -2.0608, -1.9104,\n",
      "        -2.2994, -2.1582], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2012, -2.1977, -2.2097, -2.2186, -2.2589, -2.1915, -2.2598, -2.1629,\n",
      "        -2.2065, -2.1967, -2.1880, -2.1834, -2.1967, -2.2057, -2.1937, -2.1936,\n",
      "        -2.2670, -2.2259, -2.2714, -2.1912, -2.2057, -2.1884, -2.1946, -2.2131,\n",
      "        -2.1946, -2.1553, -2.1886, -2.1536, -2.1937, -2.1942, -2.2249, -2.2036,\n",
      "        -2.1409, -2.1955, -2.1963, -2.1910, -2.1415, -2.1990, -2.1952, -2.1364,\n",
      "        -2.1580, -2.1894, -2.1701, -2.1432, -2.1948, -2.1900, -2.1952, -2.2036,\n",
      "        -2.2008, -2.2356], device='mps:0')\n",
      "mean: tensor(-2.1961, device='mps:0')\n",
      "iter_dt 1.05s; iter 77: train loss 0.28693 temperature: 8.850000000000001\n",
      "mean_logits tensor([-2.0868, -1.8972, -2.2699, -2.3321, -2.1513, -2.0923, -2.0580, -2.4641,\n",
      "        -2.3476, -2.0339, -2.0169, -2.0117, -2.4062, -2.0319, -2.0852, -2.2066,\n",
      "        -2.2464, -2.2138, -2.3351, -2.1342, -2.3040, -2.2462, -2.0024, -2.2613,\n",
      "        -2.3505, -2.3024, -2.0510, -1.8014, -2.0729, -2.3588, -2.4195, -2.2653,\n",
      "        -2.0464, -1.9733, -2.3606, -2.1050, -2.2415, -2.2467, -1.9634, -2.1770,\n",
      "        -2.0651, -1.9345, -2.2192, -2.1672, -2.1055, -2.2727, -2.3159, -2.5081,\n",
      "        -2.2631, -2.2192], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1736, -2.1781, -2.1970, -2.1239, -2.2124, -2.2617, -2.1928, -2.1515,\n",
      "        -2.2139, -2.1917, -2.1890, -2.1159, -2.1966, -2.1712, -2.1946, -2.1979,\n",
      "        -2.2618, -2.1983, -2.1826, -2.1817, -2.1497, -2.1680, -2.2599, -2.1444,\n",
      "        -2.0897, -2.1664, -2.1972, -2.1892, -2.1939, -2.2072, -2.1272, -2.1943,\n",
      "        -2.1284, -2.2500, -2.1898, -2.1928, -2.2111, -2.1868, -2.2420, -2.1543,\n",
      "        -2.2039, -2.1529, -2.1928, -2.1306, -2.2019, -2.1703, -2.1826, -2.2485,\n",
      "        -2.2043, -2.2316], device='mps:0')\n",
      "mean: tensor(-2.1870, device='mps:0')\n",
      "iter_dt 1.02s; iter 78: train loss 0.23808 temperature: 8.900000000000002\n",
      "mean_logits tensor([-1.7532, -2.0577, -2.0156, -2.1348, -2.2954, -2.0873, -2.1746, -2.1827,\n",
      "        -2.3949, -2.1497, -2.0156, -2.0903, -2.2002, -2.2362, -2.0745, -2.1432,\n",
      "        -2.1226, -2.2062, -2.3786, -2.0346, -2.0717, -2.2313, -2.0463, -2.2328,\n",
      "        -2.2768, -2.1793, -2.1331, -2.1056, -1.9689, -2.2143, -2.0768, -2.0333,\n",
      "        -1.9983, -1.7892, -2.0541, -2.3395, -1.9709, -2.1643, -1.8319, -1.9116,\n",
      "        -2.2359, -2.2090, -2.4254, -2.2028, -2.1280, -2.0418, -2.2297, -2.1336,\n",
      "        -2.2769, -2.0023], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1923, -2.1957, -2.1983, -2.1573, -2.1993, -2.1835, -2.2165, -2.2149,\n",
      "        -2.1267, -2.2270, -2.2499, -2.2266, -2.1705, -2.2264, -2.1807, -2.2034,\n",
      "        -2.2100, -2.1945, -2.1932, -2.1649, -2.1348, -2.2419, -2.2240, -2.1545,\n",
      "        -2.1962, -2.1934, -2.1900, -2.1575, -2.1838, -2.1750, -2.1826, -2.2002,\n",
      "        -2.1636, -2.2196, -2.1923, -2.1978, -2.2000, -2.2027, -2.1885, -2.2007,\n",
      "        -2.1982, -2.1693, -2.1599, -2.1465, -2.1024, -2.2021, -2.2529, -2.1955,\n",
      "        -2.1998, -2.2010], device='mps:0')\n",
      "mean: tensor(-2.1912, device='mps:0')\n",
      "iter_dt 1.02s; iter 79: train loss 0.23175 temperature: 8.950000000000003\n",
      "mean_logits tensor([-2.2723, -2.2588, -2.1419, -2.0198, -2.3252, -2.1360, -2.0441, -1.8503,\n",
      "        -2.3348, -2.0645, -2.2070, -2.0631, -2.1421, -2.0800, -2.0487, -2.2574,\n",
      "        -2.3111, -2.3102, -1.8204, -2.2301, -2.0539, -2.1179, -2.3216, -2.1449,\n",
      "        -2.4954, -2.3591, -1.9658, -2.0768, -2.2788, -2.1962, -2.1395, -2.2046,\n",
      "        -2.1597, -2.2589, -2.2418, -2.0107, -2.3246, -2.2303, -1.9929, -2.3449,\n",
      "        -2.0200, -2.4105, -2.3644, -2.0345, -2.4031, -2.3263, -2.1932, -1.9917,\n",
      "        -1.8472, -2.1053], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1924, -2.1964, -2.1502, -2.1902, -2.1561, -2.1742, -2.1900, -2.1900,\n",
      "        -2.2022, -2.1883, -2.1405, -2.2001, -2.1460, -2.2155, -2.2205, -2.2153,\n",
      "        -2.1920, -2.2224, -2.1536, -2.1857, -2.1801, -2.2502, -2.1920, -2.1853,\n",
      "        -2.2040, -2.1770, -2.1945, -2.1216, -2.1686, -2.1853, -2.1977, -2.1808,\n",
      "        -2.1472, -2.1923, -2.2056, -2.1990, -2.1700, -2.1949, -2.2207, -2.1986,\n",
      "        -2.1956, -2.2380, -2.1747, -2.1676, -2.2752, -2.1976, -2.1976, -2.1919,\n",
      "        -2.2032, -2.1986], device='mps:0')\n",
      "mean: tensor(-2.1905, device='mps:0')\n",
      "iter_dt 1.04s; iter 80: train loss 0.21127 temperature: 9.000000000000004\n",
      "mean_logits tensor([-2.0297, -2.0195, -2.1725, -2.2159, -2.2047, -2.1590, -2.2870, -1.8826,\n",
      "        -2.3608, -2.0367, -2.2414, -2.2025, -2.2319, -2.1446, -1.9769, -2.1040,\n",
      "        -2.2786, -2.3295, -2.2049, -2.1096, -2.3943, -2.4172, -2.2435, -2.1848,\n",
      "        -1.8120, -1.9771, -2.0501, -2.4869, -2.2665, -2.1299, -2.0646, -2.1251,\n",
      "        -2.0033, -1.9542, -1.9852, -2.3162, -2.2199, -2.1285, -1.9782, -2.1378,\n",
      "        -2.2055, -2.2390, -2.1065, -2.1949, -2.0053, -2.0368, -2.0021, -2.2268,\n",
      "        -2.1312, -2.4447], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1416, -2.1942, -2.1955, -2.1644, -2.2472, -2.1628, -2.2583, -2.1940,\n",
      "        -2.1324, -2.1862, -2.2003, -2.1968, -2.1649, -2.1675, -2.1980, -2.1785,\n",
      "        -2.1839, -2.1888, -2.1920, -2.1790, -2.1709, -2.1774, -2.1961, -2.1412,\n",
      "        -2.1649, -2.2069, -2.1381, -2.2453, -2.1950, -2.1561, -2.2055, -2.1811,\n",
      "        -2.1927, -2.1956, -2.1938, -2.1799, -2.1495, -2.1511, -2.1965, -2.1628,\n",
      "        -2.1704, -2.2715, -2.1898, -2.1869, -2.1981, -2.1950, -2.1895, -2.2597,\n",
      "        -2.1482, -2.2636], device='mps:0')\n",
      "mean: tensor(-2.1880, device='mps:0')\n",
      "iter_dt 1.00s; iter 81: train loss 0.29859 temperature: 9.050000000000004\n",
      "mean_logits tensor([-2.0322, -2.1336, -2.1137, -2.1337, -2.0248, -2.4728, -2.2940, -1.9740,\n",
      "        -1.8227, -2.4161, -2.1666, -2.3257, -2.4143, -1.8989, -2.2169, -1.9524,\n",
      "        -2.1073, -1.8925, -2.3277, -2.3136, -2.3729, -2.3817, -1.9558, -2.0721,\n",
      "        -2.3199, -2.0782, -2.1335, -2.2145, -2.0025, -1.9866, -2.4077, -2.3268,\n",
      "        -2.2832, -2.0818, -2.2812, -2.1243, -2.1545, -2.2080, -2.0135, -2.2846,\n",
      "        -2.2836, -2.1447, -2.2352, -2.2736, -1.9832, -2.2710, -2.0797, -2.4528,\n",
      "        -2.2208, -2.5165], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1831, -2.1918, -2.2003, -2.1895, -2.1839, -2.2103, -2.2099, -2.1899,\n",
      "        -2.1716, -2.1504, -2.1394, -2.1165, -2.1465, -2.1109, -2.1900, -2.1845,\n",
      "        -2.2344, -2.1960, -2.1586, -2.1952, -2.2487, -2.1923, -2.1895, -2.2230,\n",
      "        -2.1129, -2.1936, -2.1331, -2.2091, -2.2567, -2.2089, -2.2431, -2.1520,\n",
      "        -2.1827, -2.2001, -2.1108, -2.1945, -2.1518, -2.2155, -2.1811, -2.2441,\n",
      "        -2.1868, -2.1715, -2.1890, -2.1993, -2.1666, -2.2591, -2.1968, -2.2580,\n",
      "        -2.1883, -2.2163], device='mps:0')\n",
      "mean: tensor(-2.1886, device='mps:0')\n",
      "iter_dt 1.03s; iter 82: train loss 0.26246 temperature: 9.100000000000005\n",
      "mean_logits tensor([-2.1675, -2.3873, -2.1511, -2.2298, -2.0005, -2.2394, -2.0174, -2.4765,\n",
      "        -2.2948, -2.0259, -2.1022, -2.1893, -1.8746, -2.3141, -2.2599, -2.1939,\n",
      "        -2.1856, -2.3959, -2.0961, -2.2147, -2.3039, -1.8261, -2.2610, -2.0177,\n",
      "        -2.2098, -2.3454, -1.9720, -1.9382, -2.3077, -2.3808, -2.2706, -2.4301,\n",
      "        -1.8992, -2.2504, -2.1840, -2.2003, -2.2897, -2.1528, -2.0815, -2.4283,\n",
      "        -2.4232, -2.3589, -2.2040, -2.1472, -2.4593, -1.9706, -2.2091, -2.1826,\n",
      "        -2.3113, -2.3466], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1941, -2.1855, -2.1355, -2.2343, -2.2228, -2.1645, -2.1486, -2.1899,\n",
      "        -2.2152, -2.1625, -2.2160, -2.1877, -2.1658, -2.2061, -2.1949, -2.1932,\n",
      "        -2.1337, -2.2196, -2.1766, -2.1957, -2.1857, -2.1913, -2.2030, -2.1942,\n",
      "        -2.2113, -2.2012, -2.1978, -2.1791, -2.1918, -2.2320, -2.2141, -2.2013,\n",
      "        -2.1379, -2.1922, -2.1895, -2.1953, -2.2010, -2.1507, -2.2003, -2.1913,\n",
      "        -2.1966, -2.1018, -2.1604, -2.1193, -2.1848, -2.2108, -2.1897, -2.1956,\n",
      "        -2.1939, -2.2011], device='mps:0')\n",
      "mean: tensor(-2.1871, device='mps:0')\n",
      "iter_dt 1.03s; iter 83: train loss 0.22775 temperature: 9.150000000000006\n",
      "mean_logits tensor([-2.2500, -2.1080, -1.9942, -2.2711, -2.1380, -2.5897, -2.4103, -2.2797,\n",
      "        -2.0036, -2.3572, -2.2028, -2.3219, -1.8709, -2.2127, -2.2685, -2.1495,\n",
      "        -2.0997, -2.2506, -1.9998, -1.9732, -2.1804, -2.1128, -2.1885, -2.0483,\n",
      "        -2.2189, -2.0297, -2.0587, -1.9032, -1.9501, -2.1580, -2.2657, -2.2396,\n",
      "        -2.0119, -2.1563, -2.0392, -2.3191, -1.9989, -2.1178, -2.1581, -2.0308,\n",
      "        -2.1729, -2.1470, -2.0963, -2.1048, -2.1704, -2.2911, -2.0339, -2.1937,\n",
      "        -2.4123, -2.1504], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2010, -2.1928, -2.1954, -2.1948, -2.2031, -2.1982, -2.1646, -2.2090,\n",
      "        -2.1929, -2.1936, -2.1655, -2.1931, -2.1292, -2.1853, -2.1878, -2.2166,\n",
      "        -2.2986, -2.0887, -2.1887, -2.1955, -2.2099, -2.1937, -2.1956, -2.2012,\n",
      "        -2.1959, -2.1956, -2.1979, -2.1702, -2.1990, -2.2583, -2.1831, -2.1946,\n",
      "        -2.0914, -2.1945, -2.1634, -2.1935, -2.1910, -2.2235, -2.1791, -2.1947,\n",
      "        -2.1941, -2.1821, -2.1707, -2.1896, -2.2580, -2.1914, -2.2064, -2.1857,\n",
      "        -2.1959, -2.1946], device='mps:0')\n",
      "mean: tensor(-2.1918, device='mps:0')\n",
      "iter_dt 1.02s; iter 84: train loss 0.27155 temperature: 9.200000000000006\n",
      "mean_logits tensor([-2.2155, -2.1877, -2.2173, -2.2896, -2.0384, -2.1581, -2.0668, -1.9771,\n",
      "        -2.4530, -2.3570, -2.1985, -2.1972, -2.2201, -2.0247, -1.9951, -1.9814,\n",
      "        -2.2958, -2.2342, -2.4612, -2.0175, -2.2913, -2.0665, -2.1605, -2.3845,\n",
      "        -2.1596, -2.3874, -2.1516, -2.2453, -2.2450, -1.9624, -2.0884, -2.3344,\n",
      "        -2.4514, -2.1213, -2.2316, -2.2790, -2.1951, -2.1272, -2.1978, -2.0026,\n",
      "        -2.1349, -2.5454, -2.0728, -2.4641, -2.1638, -2.2007, -2.1629, -2.5104,\n",
      "        -2.1143, -2.1897], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1710, -2.2055, -2.2012, -2.2341, -2.1904, -2.1471, -2.1412, -2.2214,\n",
      "        -2.2321, -2.1920, -2.2187, -2.2152, -2.1498, -2.1929, -2.1504, -2.2101,\n",
      "        -2.2566, -2.1790, -2.1957, -2.1441, -2.2181, -2.2084, -2.1637, -2.1965,\n",
      "        -2.2113, -2.1691, -2.1195, -2.1808, -2.1643, -2.1272, -2.2672, -2.1444,\n",
      "        -2.1491, -2.1424, -2.2598, -2.1803, -2.1522, -2.1939, -2.1524, -2.2007,\n",
      "        -2.1994, -2.1469, -2.1905, -2.1971, -2.2037, -2.1656, -2.1769, -2.2002,\n",
      "        -2.1905, -2.1741], device='mps:0')\n",
      "mean: tensor(-2.1859, device='mps:0')\n",
      "iter_dt 1.03s; iter 85: train loss 0.29103 temperature: 9.250000000000007\n",
      "mean_logits tensor([-2.2456, -2.0301, -2.2562, -2.1488, -2.1891, -2.4337, -2.1829, -2.2350,\n",
      "        -2.2455, -2.3051, -2.5838, -2.0717, -2.0048, -2.1805, -2.1422, -2.2632,\n",
      "        -2.2310, -2.4068, -1.9371, -1.9009, -2.2876, -1.9495, -2.3540, -1.8293,\n",
      "        -2.3611, -2.2293, -2.2621, -2.0888, -2.1117, -2.0939, -2.0775, -2.0705,\n",
      "        -2.1815, -2.0577, -2.2036, -2.0971, -2.3208, -1.8701, -2.4064, -2.2481,\n",
      "        -2.2612, -2.1021, -2.3542, -2.2359, -2.3239, -2.3057, -2.2173, -2.4820,\n",
      "        -1.8862, -2.3347], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2613, -2.1944, -2.1682, -2.1751, -2.1577, -2.1804, -2.1564, -2.1709,\n",
      "        -2.2046, -2.1914, -2.2307, -2.1954, -2.1898, -2.1894, -2.1512, -2.1468,\n",
      "        -2.1581, -2.1899, -2.1629, -2.1934, -2.1893, -2.2624, -2.1896, -2.1621,\n",
      "        -2.1693, -2.1428, -2.1873, -2.1846, -2.1642, -2.1964, -2.1956, -2.1962,\n",
      "        -2.2010, -2.1938, -2.2613, -2.1935, -2.1675, -2.1620, -2.1992, -2.1885,\n",
      "        -2.2055, -2.1107, -2.1041, -2.1804, -2.2052, -2.2047, -2.1908, -2.1813,\n",
      "        -2.1958, -2.2118], device='mps:0')\n",
      "mean: tensor(-2.1853, device='mps:0')\n",
      "iter_dt 1.03s; iter 86: train loss 0.33831 temperature: 9.300000000000008\n",
      "mean_logits tensor([-1.8177, -2.4081, -2.1900, -2.2775, -2.0800, -2.3317, -1.8728, -2.5678,\n",
      "        -2.0722, -1.9977, -2.3305, -2.3114, -1.9649, -2.0348, -2.2816, -2.3056,\n",
      "        -1.9880, -2.2702, -2.1625, -1.9151, -1.9491, -2.3321, -2.2792, -2.0201,\n",
      "        -2.1136, -2.1050, -2.2102, -2.1680, -2.3174, -2.2148, -1.9982, -2.3661,\n",
      "        -2.3600, -2.3694, -2.2742, -2.2392, -2.3729, -2.1966, -2.0055, -2.2664,\n",
      "        -2.3702, -2.2697, -2.2149, -2.0133, -2.5239, -2.0176, -2.5393, -2.2988,\n",
      "        -2.0543, -2.3924], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1850, -2.1072, -2.1810, -2.1979, -2.1794, -2.1651, -2.1880, -2.2102,\n",
      "        -2.1970, -2.1991, -2.1948, -2.1537, -2.1798, -2.1694, -2.1758, -2.2333,\n",
      "        -2.1795, -2.1973, -2.1979, -2.1858, -2.1768, -2.1894, -2.1977, -2.1835,\n",
      "        -2.1987, -2.1722, -2.1738, -2.2190, -2.2075, -2.1897, -2.1901, -2.1643,\n",
      "        -2.2287, -2.1895, -2.1792, -2.1918, -2.1980, -2.2049, -2.1293, -2.2317,\n",
      "        -2.1876, -2.1192, -2.1994, -2.1101, -2.1945, -2.1720, -2.2226, -2.1790,\n",
      "        -2.1826, -2.1897], device='mps:0')\n",
      "mean: tensor(-2.1850, device='mps:0')\n",
      "iter_dt 1.02s; iter 87: train loss 0.40336 temperature: 9.350000000000009\n",
      "mean_logits tensor([-2.1742, -2.2147, -2.0553, -2.6577, -2.2026, -2.2345, -2.1168, -2.4132,\n",
      "        -2.1691, -2.2338, -2.2169, -2.1712, -2.1987, -2.0034, -2.2282, -2.2317,\n",
      "        -1.7991, -1.8617, -2.1280, -1.7966, -2.4766, -2.1748, -2.2188, -2.2473,\n",
      "        -2.4334, -2.2332, -2.0554, -2.0322, -2.0924, -1.8585, -2.3321, -2.0679,\n",
      "        -2.1012, -2.3670, -1.9544, -2.0500, -2.2442, -2.5524, -1.9989, -2.3686,\n",
      "        -2.0935, -2.2600, -2.2480, -2.0916, -2.5084, -2.0860, -2.4296, -2.1480,\n",
      "        -2.3341, -2.0536], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1444, -2.2066, -2.1806, -2.1555, -2.1614, -2.1354, -2.1673, -2.1977,\n",
      "        -2.1565, -2.1795, -2.1743, -2.1932, -2.1900, -2.1735, -2.1824, -2.1740,\n",
      "        -2.2311, -2.1932, -2.2072, -2.1747, -2.1899, -2.1812, -2.1980, -2.1828,\n",
      "        -2.1984, -2.1923, -2.2012, -2.1651, -2.1624, -2.2002, -2.1941, -2.1922,\n",
      "        -2.1947, -2.1942, -2.1827, -2.1730, -2.2011, -2.2000, -2.1906, -2.1967,\n",
      "        -2.1901, -2.1934, -2.1574, -2.1648, -2.1688, -2.1880, -2.1437, -2.1937,\n",
      "        -2.1975, -2.2033], device='mps:0')\n",
      "mean: tensor(-2.1834, device='mps:0')\n",
      "iter_dt 1.01s; iter 88: train loss 0.25036 temperature: 9.40000000000001\n",
      "mean_logits tensor([-1.8717, -2.2071, -2.2244, -2.1052, -1.7165, -2.0779, -2.3123, -2.2344,\n",
      "        -2.1663, -2.1997, -1.9697, -2.3689, -2.1095, -2.2329, -1.9688, -2.1994,\n",
      "        -2.2877, -2.3378, -2.2950, -2.0896, -2.3536, -1.9142, -2.2846, -2.1591,\n",
      "        -1.9252, -2.2448, -2.2888, -2.1479, -2.3032, -2.3172, -2.0695, -2.3452,\n",
      "        -2.2166, -2.2036, -2.3422, -2.1842, -2.2538, -2.3471, -2.1675, -2.1620,\n",
      "        -2.3125, -1.9764, -2.1124, -2.0937, -2.3271, -2.6538, -2.1034, -2.1885,\n",
      "        -2.4412, -2.2502], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1684, -2.2006, -2.2267, -2.1516, -2.1407, -2.1305, -2.1988, -2.1431,\n",
      "        -2.1547, -2.1866, -2.1578, -2.1797, -2.1908, -2.2252, -2.1939, -2.1794,\n",
      "        -2.1947, -2.1980, -2.1999, -2.1767, -2.2041, -2.2119, -2.1418, -2.1987,\n",
      "        -2.1663, -2.1954, -2.1641, -2.1907, -2.2117, -2.1900, -2.1956, -2.1433,\n",
      "        -2.1954, -2.2156, -2.2719, -2.1981, -2.2400, -2.1788, -2.1870, -2.1866,\n",
      "        -2.1942, -2.2514, -2.2634, -2.1568, -2.1937, -2.2615, -2.1731, -2.2056,\n",
      "        -2.1957, -2.2013], device='mps:0')\n",
      "mean: tensor(-2.1916, device='mps:0')\n",
      "iter_dt 1.02s; iter 89: train loss 0.22780 temperature: 9.45000000000001\n",
      "mean_logits tensor([-2.1002, -2.5693, -2.1357, -2.2661, -2.2874, -2.2918, -2.1015, -1.9565,\n",
      "        -2.2417, -2.1561, -2.2013, -2.0302, -2.0701, -2.1147, -2.2278, -2.0917,\n",
      "        -2.2211, -2.3636, -2.5814, -2.1945, -2.2220, -1.9533, -2.0939, -2.1566,\n",
      "        -2.1036, -2.2249, -2.2515, -2.2749, -2.2995, -2.2977, -2.2017, -2.0197,\n",
      "        -2.3016, -2.0095, -1.9223, -2.0252, -2.0464, -2.1412, -2.1360, -2.2002,\n",
      "        -2.2132, -2.2502, -2.0418, -2.1232, -2.3021, -2.0060, -2.2842, -1.9903,\n",
      "        -1.9238, -2.1210], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1580, -2.2103, -2.1934, -2.1917, -2.2015, -2.1832, -2.2216, -2.2342,\n",
      "        -2.1987, -2.1927, -2.2030, -2.2566, -2.1628, -2.1878, -2.1948, -2.1328,\n",
      "        -2.1960, -2.1980, -2.1993, -2.1917, -2.1652, -2.1945, -2.1372, -2.1976,\n",
      "        -2.1874, -2.2085, -2.1922, -2.1982, -2.1950, -2.1820, -2.1920, -2.2027,\n",
      "        -2.2113, -2.1816, -2.1977, -2.1957, -2.1966, -2.1894, -2.1697, -2.1931,\n",
      "        -2.1895, -2.1849, -2.2034, -2.2106, -2.1846, -2.1767, -2.1943, -2.1771,\n",
      "        -2.1793, -2.1607], device='mps:0')\n",
      "mean: tensor(-2.1911, device='mps:0')\n",
      "iter_dt 1.02s; iter 90: train loss 0.28476 temperature: 9.50000000000001\n",
      "mean_logits tensor([-2.2802, -1.9780, -2.3313, -2.2280, -1.9826, -2.2288, -2.0856, -2.1453,\n",
      "        -2.1857, -2.2668, -2.2179, -2.4681, -2.1694, -1.9924, -2.3234, -1.7737,\n",
      "        -2.0208, -1.9001, -1.9796, -2.0113, -2.0393, -2.2064, -2.0100, -1.9549,\n",
      "        -2.3031, -2.4590, -2.1386, -2.4944, -2.2700, -2.4095, -2.1169, -1.8994,\n",
      "        -2.2059, -2.2940, -2.1448, -1.9836, -2.0770, -2.2752, -2.0984, -2.2300,\n",
      "        -2.1144, -2.0709, -2.2611, -2.1806, -2.1293, -2.0889, -2.3592, -2.2445,\n",
      "        -2.0890, -1.9471], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1532, -2.1798, -2.1968, -2.1595, -2.1925, -2.1784, -2.1942, -2.1929,\n",
      "        -2.1773, -2.1618, -2.1885, -2.1830, -2.2777, -2.2022, -2.2567, -2.2000,\n",
      "        -2.1943, -2.2032, -2.2035, -2.2114, -2.2027, -2.1991, -2.1716, -2.1941,\n",
      "        -2.1844, -2.1785, -2.2214, -2.1426, -2.1955, -2.1969, -2.2072, -2.1742,\n",
      "        -2.2133, -2.2396, -2.1566, -2.1933, -2.1998, -2.1859, -2.1928, -2.1776,\n",
      "        -2.1477, -2.1969, -2.1902, -2.1907, -2.1794, -2.1937, -2.1947, -2.1957,\n",
      "        -2.1773, -2.2383], device='mps:0')\n",
      "mean: tensor(-2.1928, device='mps:0')\n",
      "iter_dt 1.03s; iter 91: train loss 0.26765 temperature: 9.550000000000011\n",
      "mean_logits tensor([-2.1611, -2.0527, -2.1150, -2.1972, -2.1349, -2.2077, -2.0880, -2.1534,\n",
      "        -2.2087, -2.0788, -2.0188, -2.2722, -2.4512, -2.4398, -2.3859, -2.3293,\n",
      "        -2.1199, -2.1583, -1.9451, -2.1148, -2.2015, -2.2992, -2.4870, -2.0152,\n",
      "        -2.1322, -2.2877, -2.2793, -2.1791, -2.0788, -2.3044, -2.1544, -2.4582,\n",
      "        -2.1977, -2.1911, -2.2705, -2.2234, -2.3033, -2.2921, -2.3910, -2.3435,\n",
      "        -2.5228, -2.0974, -2.1764, -1.9780, -2.1860, -1.9013, -1.9105, -2.1051,\n",
      "        -2.1111, -1.6782], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1415, -2.1943, -2.1876, -2.2707, -2.1707, -2.1585, -2.1920, -2.1902,\n",
      "        -2.1686, -2.1900, -2.1940, -2.1972, -2.1871, -2.1773, -2.1729, -2.1882,\n",
      "        -2.2063, -2.1935, -2.1913, -2.1597, -2.2101, -2.2032, -2.2138, -2.1980,\n",
      "        -2.1999, -2.1389, -2.1938, -2.2094, -2.1416, -2.2651, -2.1985, -2.1911,\n",
      "        -2.1797, -2.1924, -2.1843, -2.1945, -2.1852, -2.1704, -2.1982, -2.1822,\n",
      "        -2.2682, -2.2004, -2.1942, -2.1988, -2.1665, -2.1658, -2.2055, -2.1780,\n",
      "        -2.2280, -2.1817], device='mps:0')\n",
      "mean: tensor(-2.1914, device='mps:0')\n",
      "iter_dt 1.03s; iter 92: train loss 0.23403 temperature: 9.600000000000012\n",
      "mean_logits tensor([-2.1241, -1.9712, -2.4375, -2.2391, -2.0027, -2.1673, -2.1411, -2.3704,\n",
      "        -2.1970, -2.0355, -2.1682, -1.8837, -2.0519, -1.9815, -2.3420, -2.1641,\n",
      "        -2.2125, -1.9502, -2.1017, -2.4006, -1.9926, -2.0488, -1.9726, -2.2730,\n",
      "        -2.2335, -2.0428, -2.1279, -2.2684, -2.0683, -2.1072, -2.1530, -2.1166,\n",
      "        -1.9158, -2.2322, -2.2276, -2.0497, -2.2402, -2.1991, -2.2019, -2.0251,\n",
      "        -1.9937, -2.2221, -2.0157, -2.2975, -2.5213, -2.2575, -2.4379, -2.1843,\n",
      "        -2.0954, -2.1141], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1838, -2.1913, -2.2257, -2.2003, -2.2000, -2.1516, -2.1525, -2.2637,\n",
      "        -2.1459, -2.1916, -2.1941, -2.1799, -2.1926, -2.1235, -2.1498, -2.1774,\n",
      "        -2.2339, -2.1958, -2.2109, -2.1330, -2.1948, -2.1908, -2.2011, -2.0981,\n",
      "        -2.2042, -2.1940, -2.2005, -2.1696, -2.1797, -2.1890, -2.2309, -2.1893,\n",
      "        -2.1934, -2.1914, -2.1955, -2.1846, -2.1421, -2.1916, -2.1926, -2.1923,\n",
      "        -2.1948, -2.1929, -2.1986, -2.1883, -2.1855, -2.1966, -2.2084, -2.1406,\n",
      "        -2.1904, -2.2070], device='mps:0')\n",
      "mean: tensor(-2.1865, device='mps:0')\n",
      "iter_dt 1.01s; iter 93: train loss 0.26595 temperature: 9.650000000000013\n",
      "mean_logits tensor([-2.4082, -2.1551, -2.2765, -2.3759, -2.2580, -2.4657, -2.0038, -2.2383,\n",
      "        -2.0204, -2.1436, -2.2676, -1.9954, -2.1897, -2.0082, -2.1836, -2.0699,\n",
      "        -2.2472, -2.2662, -2.4196, -2.3403, -2.2369, -2.0401, -2.4502, -2.2028,\n",
      "        -2.2495, -2.1304, -2.3385, -2.1668, -2.1759, -1.9374, -2.2908, -2.2832,\n",
      "        -2.2931, -2.5279, -2.2972, -2.2190, -2.0103, -2.3132, -2.4516, -2.2813,\n",
      "        -2.0354, -2.3923, -1.9243, -2.0333, -1.9709, -2.0946, -2.3333, -2.3490,\n",
      "        -2.0318, -2.1562], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1672, -2.1671, -2.2003, -2.1923, -2.1923, -2.1974, -2.1785, -2.2003,\n",
      "        -2.1992, -2.2023, -2.1901, -2.2142, -2.1970, -2.1791, -2.2101, -2.1453,\n",
      "        -2.1991, -2.1768, -2.2615, -2.1889, -2.2369, -2.1945, -2.1745, -2.1729,\n",
      "        -2.1981, -2.1805, -2.2265, -2.1765, -2.2069, -2.1987, -2.2168, -2.1950,\n",
      "        -2.2064, -2.1901, -2.2017, -2.1498, -2.2031, -2.1950, -2.1965, -2.1967,\n",
      "        -2.1943, -2.1942, -2.1977, -2.1951, -2.1921, -2.1981, -2.2054, -2.1877,\n",
      "        -2.1884, -2.1657], device='mps:0')\n",
      "mean: tensor(-2.1939, device='mps:0')\n",
      "iter_dt 1.04s; iter 94: train loss 0.23712 temperature: 9.700000000000014\n",
      "mean_logits tensor([-2.0841, -1.8864, -2.0398, -1.9354, -1.9838, -1.8700, -2.2657, -2.1858,\n",
      "        -2.2627, -2.2464, -2.1526, -2.2494, -1.8619, -2.4260, -2.1655, -2.1068,\n",
      "        -2.1831, -2.3047, -2.0267, -1.9827, -1.9758, -2.2928, -2.1821, -2.1199,\n",
      "        -2.2339, -2.1277, -2.2403, -2.3065, -2.1170, -2.4745, -2.2172, -2.1120,\n",
      "        -2.2322, -2.3314, -1.9893, -2.3861, -2.4281, -2.1521, -2.0053, -2.1248,\n",
      "        -2.1349, -2.0312, -2.0367, -2.1083, -2.0948, -1.9540, -2.0628, -2.1024,\n",
      "        -2.1096, -1.8137], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1526, -2.1920, -2.1862, -2.2158, -2.1406, -2.1716, -2.1897, -2.1691,\n",
      "        -2.2157, -2.2203, -2.2404, -2.2041, -2.1969, -2.2776, -2.1886, -2.1836,\n",
      "        -2.1943, -2.2214, -2.1968, -2.1923, -2.1624, -2.1813, -2.1676, -2.1771,\n",
      "        -2.1928, -2.1711, -2.1926, -2.1999, -2.2048, -2.1227, -2.1944, -2.1958,\n",
      "        -2.1980, -2.1872, -2.1712, -2.1437, -2.2890, -2.1748, -2.1939, -2.1953,\n",
      "        -2.1770, -2.2087, -2.2073, -2.1881, -2.1967, -2.1683, -2.1534, -2.1970,\n",
      "        -2.1799, -2.2079], device='mps:0')\n",
      "mean: tensor(-2.1910, device='mps:0')\n",
      "iter_dt 1.05s; iter 95: train loss 0.42361 temperature: 9.750000000000014\n",
      "mean_logits tensor([-2.0212, -2.1892, -2.3386, -2.4119, -2.3262, -2.5855, -2.2988, -2.1918,\n",
      "        -2.2882, -2.1779, -1.9016, -2.2251, -2.2922, -2.0565, -2.2528, -1.9093,\n",
      "        -2.2441, -2.1335, -2.1801, -2.2481, -2.1569, -2.4399, -2.2972, -2.0801,\n",
      "        -2.1942, -2.0376, -2.0372, -2.2807, -2.0990, -2.4012, -2.4908, -2.1110,\n",
      "        -2.2823, -1.9070, -2.0914, -1.9605, -2.2655, -2.3275, -2.0239, -2.3274,\n",
      "        -1.6553, -2.0458, -2.3953, -2.1427, -2.6889, -2.1457, -1.8413, -2.4113,\n",
      "        -2.0655, -2.2291], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1851, -2.1903, -2.1819, -2.1758, -2.1265, -2.1915, -2.2005, -2.2115,\n",
      "        -2.1873, -2.1954, -2.1894, -2.1887, -2.1922, -2.1816, -2.1945, -2.1936,\n",
      "        -2.1829, -2.1946, -2.2206, -2.2067, -2.1828, -2.1684, -2.1576, -2.2291,\n",
      "        -2.1769, -2.1851, -2.1929, -2.2075, -2.1944, -2.1913, -2.1995, -2.1963,\n",
      "        -2.1942, -2.2099, -2.1773, -2.1301, -2.1892, -2.2212, -2.1541, -2.1933,\n",
      "        -2.2063, -2.1986, -2.1723, -2.1989, -2.1953, -2.1326, -2.1952, -2.1854,\n",
      "        -2.1768, -2.1999], device='mps:0')\n",
      "mean: tensor(-2.1881, device='mps:0')\n",
      "iter_dt 1.04s; iter 96: train loss 0.38307 temperature: 9.800000000000015\n",
      "mean_logits tensor([-2.2171, -2.1928, -2.3112, -2.3093, -2.0742, -1.9170, -2.1264, -2.2111,\n",
      "        -2.3240, -2.3863, -2.2096, -2.2516, -2.3287, -2.2221, -1.8294, -2.1436,\n",
      "        -2.3353, -2.3211, -2.1289, -1.9664, -2.3092, -2.1042, -2.5434, -2.1424,\n",
      "        -2.4546, -2.1650, -1.9826, -2.7086, -2.3740, -2.0590, -2.0596, -2.3804,\n",
      "        -2.3061, -2.1686, -2.3096, -2.3835, -1.9477, -2.1548, -2.1233, -2.0999,\n",
      "        -2.1889, -2.4048, -2.0427, -2.3469, -2.3242, -2.2054, -2.0034, -2.2310,\n",
      "        -2.1317, -1.9519], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1630, -2.2005, -2.1702, -2.1972, -2.1787, -2.1968, -2.2006, -2.1955,\n",
      "        -2.2132, -2.2039, -2.1654, -2.1615, -2.1982, -2.1607, -2.1948, -2.1776,\n",
      "        -2.1653, -2.1416, -2.1812, -2.1989, -2.1859, -2.2114, -2.1934, -2.2176,\n",
      "        -2.1927, -2.1713, -2.1924, -2.1668, -2.1871, -2.1958, -2.1769, -2.1238,\n",
      "        -2.1806, -2.1971, -2.1893, -2.1842, -2.2068, -2.1820, -2.1878, -2.2150,\n",
      "        -2.1946, -2.1413, -2.1706, -2.2000, -2.1637, -2.1994, -2.2074, -2.1621,\n",
      "        -2.1956, -2.1648], device='mps:0')\n",
      "mean: tensor(-2.1844, device='mps:0')\n",
      "iter_dt 1.02s; iter 97: train loss 0.21409 temperature: 9.850000000000016\n",
      "mean_logits tensor([-2.2265, -1.9319, -2.1136, -2.2362, -2.1340, -1.9777, -2.3442, -2.0565,\n",
      "        -2.0718, -2.2415, -2.3016, -2.2066, -2.1244, -2.2353, -2.2903, -2.3177,\n",
      "        -2.2971, -2.0391, -2.4268, -1.9340, -2.1341, -1.9329, -2.1448, -2.1438,\n",
      "        -2.1486, -1.7916, -1.8154, -2.1455, -2.2511, -2.0814, -2.2737, -2.1831,\n",
      "        -2.0582, -2.1654, -1.9813, -2.3001, -2.1843, -2.2429, -2.3346, -2.2554,\n",
      "        -1.8816, -2.3999, -2.1749, -2.0985, -2.3047, -2.1993, -2.2549, -2.4233,\n",
      "        -2.1486, -2.3238], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1864, -2.1846, -2.1953, -2.2620, -2.2113, -2.1954, -2.1616, -2.1380,\n",
      "        -2.1737, -2.2176, -2.1743, -2.2166, -2.1715, -2.1481, -2.1650, -2.2198,\n",
      "        -2.1935, -2.2353, -2.1909, -2.1989, -2.2053, -2.0984, -2.1981, -2.1978,\n",
      "        -2.2105, -2.1925, -2.1849, -2.1945, -2.2122, -2.1748, -2.2098, -2.2742,\n",
      "        -2.0879, -2.1810, -2.1880, -2.1140, -2.2043, -2.2019, -2.1937, -2.1849,\n",
      "        -2.1661, -2.1951, -2.1944, -2.2026, -2.2211, -2.1667, -2.1659, -2.1750,\n",
      "        -2.1738, -2.1739], device='mps:0')\n",
      "mean: tensor(-2.1877, device='mps:0')\n",
      "iter_dt 1.02s; iter 98: train loss 0.23271 temperature: 9.900000000000016\n",
      "mean_logits tensor([-2.2893, -2.3728, -2.0613, -2.1672, -2.0440, -2.2324, -2.3573, -2.1196,\n",
      "        -2.1441, -2.1098, -2.2132, -2.1248, -2.2368, -1.8455, -2.0343, -2.1350,\n",
      "        -2.3942, -2.1382, -2.3759, -2.1301, -2.3250, -2.0174, -2.2825, -2.2178,\n",
      "        -2.2722, -2.3343, -2.3192, -2.3225, -2.3258, -2.4630, -2.3258, -1.8012,\n",
      "        -2.1094, -2.2161, -2.0099, -2.1906, -2.0223, -2.2440, -2.2711, -2.0364,\n",
      "        -2.2510, -2.0046, -2.2328, -2.2230, -2.1895, -2.0626, -2.2863, -2.0508,\n",
      "        -1.8536, -2.4625], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1910, -2.1956, -2.1937, -2.1992, -2.1653, -2.1928, -2.2193, -2.2018,\n",
      "        -2.1770, -2.1985, -2.1631, -2.1688, -2.1733, -2.2007, -2.1600, -2.1890,\n",
      "        -2.1962, -2.1933, -2.1731, -2.1219, -2.1611, -2.1906, -2.1982, -2.1959,\n",
      "        -2.1941, -2.1930, -2.2067, -2.2067, -2.1895, -2.1936, -2.1233, -2.1779,\n",
      "        -2.1709, -2.1940, -2.1419, -2.1952, -2.1692, -2.1437, -2.1730, -2.1667,\n",
      "        -2.1628, -2.2134, -2.2075, -2.1952, -2.1632, -2.2062, -2.1495, -2.1428,\n",
      "        -2.1787, -2.1507], device='mps:0')\n",
      "mean: tensor(-2.1806, device='mps:0')\n",
      "iter_dt 1.02s; iter 99: train loss 0.24091 temperature: 9.950000000000017\n",
      "mean_logits tensor([-2.3929, -2.1018, -2.1336, -2.0967, -1.9751, -2.2227, -2.2306, -2.1526,\n",
      "        -2.0314, -1.9855, -2.0199, -2.2526, -2.2444, -2.0430, -2.1546, -2.0742,\n",
      "        -2.1581, -2.3133, -2.2929, -2.4664, -2.3666, -1.8848, -2.0027, -2.1555,\n",
      "        -2.2806, -2.1780, -1.9551, -2.1389, -2.0836, -2.2322, -2.3846, -2.1460,\n",
      "        -2.0853, -2.2093, -2.3293, -2.1423, -1.9484, -2.1618, -2.4310, -2.0278,\n",
      "        -2.3045, -1.9655, -2.0393, -2.3788, -2.2268, -2.2485, -2.2285, -1.8404,\n",
      "        -2.4239, -2.1347], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.1461, -2.1525, -2.2006, -2.1745, -2.1678, -2.1944, -2.1648, -2.1168,\n",
      "        -2.1773, -2.2049, -2.1906, -2.2158, -2.1899, -2.1937, -2.1942, -2.2592,\n",
      "        -2.1937, -2.1869, -2.2008, -2.2041, -2.1933, -2.2142, -2.1856, -2.1951,\n",
      "        -2.1893, -2.1759, -2.1578, -2.2021, -2.1803, -2.2121, -2.1948, -2.1873,\n",
      "        -2.1874, -2.1675, -2.2022, -2.1768, -2.1937, -2.1693, -2.1831, -2.1559,\n",
      "        -2.2036, -2.1600, -2.2184, -2.1646, -2.1985, -2.1628, -2.1948, -2.1945,\n",
      "        -2.1607, -2.2184], device='mps:0')\n",
      "mean: tensor(-2.1866, device='mps:0')\n",
      "current_prefixes: [7278 4037 5557 4534 4632 6985  380 4805 4101 4404 4883  611  346 1045\n",
      " 2273]\n",
      "layer: 4 starts running\n",
      "number of parameters: 91.99M\n",
      "running on device mps\n",
      "iter_dt 0.00s; iter 0: train loss 1.41638 temperature: 5\n",
      "mean_logits tensor([-1.7155, -1.7982, -2.0716, -1.7678, -1.9104, -1.8286, -1.8962, -2.2405,\n",
      "        -2.0389, -1.9567, -1.9174, -2.2152, -2.1311, -2.0761, -2.2014, -1.7102,\n",
      "        -1.5210, -2.1454, -1.8801, -2.0853, -2.1030, -2.0810, -1.8862, -2.0041,\n",
      "        -1.5754, -2.0170, -1.8668, -1.7271, -1.6073, -1.8533, -2.1888, -1.9742,\n",
      "        -1.8148, -1.9333, -1.7856, -2.2928, -1.8096, -1.9887, -1.9464, -2.0654,\n",
      "        -1.9961, -2.2290, -1.9892, -1.6990, -2.0968, -2.0102, -1.7214, -2.1919,\n",
      "        -1.4164, -2.2065], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3233, -2.3275, -2.3241, -2.3270, -2.3556, -2.3225, -2.3028, -2.3297,\n",
      "        -2.3267, -2.3152, -2.3267, -2.3221, -2.3169, -2.3314, -2.3140, -2.2533,\n",
      "        -2.2438, -2.3237, -2.2629, -2.3064, -2.2931, -2.3332, -2.2826, -2.3190,\n",
      "        -2.3259, -2.2897, -2.2188, -2.1923, -2.3811, -2.2662, -2.3168, -2.3073,\n",
      "        -2.3286, -2.3333, -2.3146, -2.3103, -2.3164, -2.3484, -2.3647, -2.3234,\n",
      "        -2.2116, -2.2430, -2.3095, -2.2718, -2.2957, -2.3101, -2.3189, -2.3302,\n",
      "        -2.3218, -2.3136], device='mps:0')\n",
      "mean: tensor(-2.3069, device='mps:0')\n",
      "iter_dt 1695864079.78s; iter 1: train loss 1.26778 temperature: 5.05\n",
      "mean_logits tensor([-2.3219, -1.9135, -1.8043, -1.8456, -2.0013, -2.2695, -1.9594, -2.0713,\n",
      "        -2.0144, -1.9709, -2.1232, -2.0835, -2.1815, -1.8246, -2.0153, -2.0083,\n",
      "        -2.1378, -2.5201, -2.2472, -1.7265, -1.6601, -2.0402, -1.8842, -2.1813,\n",
      "        -1.9023, -2.4459, -2.0868, -1.8649, -1.6343, -2.3468, -2.3537, -2.2605,\n",
      "        -2.0213, -1.7822, -1.6415, -1.3221, -2.2511, -1.8951, -1.9422, -2.1932,\n",
      "        -2.2138, -2.2028, -1.7034, -1.9029, -1.6624, -1.4746, -1.9197, -1.7394,\n",
      "        -1.8001, -2.1971], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2751, -2.2876, -2.2867, -2.3314, -2.3169, -2.3255, -2.2929, -2.2532,\n",
      "        -2.2757, -2.2981, -2.3261, -2.3037, -2.2913, -2.3355, -2.3306, -2.3147,\n",
      "        -2.3293, -2.3200, -2.2492, -2.2931, -2.2888, -2.2418, -2.3176, -2.2428,\n",
      "        -2.2874, -2.2689, -2.3147, -2.3142, -2.2916, -2.3296, -2.2890, -2.3378,\n",
      "        -2.2677, -2.2785, -2.3051, -2.2595, -2.3337, -2.3293, -2.3250, -2.3126,\n",
      "        -2.3420, -2.3251, -2.3296, -2.3598, -2.2312, -2.3033, -2.2879, -2.3270,\n",
      "        -2.3066, -2.3286], device='mps:0')\n",
      "mean: tensor(-2.3023, device='mps:0')\n",
      "iter_dt 1.05s; iter 2: train loss 1.41354 temperature: 5.1\n",
      "mean_logits tensor([-1.9965, -1.7302, -2.2460, -1.9070, -2.1234, -1.6785, -1.9878, -2.0753,\n",
      "        -1.7723, -2.5896, -1.9196, -1.9720, -1.8160, -1.5809, -2.0934, -2.0404,\n",
      "        -1.7480, -1.5580, -2.0925, -1.9172, -2.4147, -2.0801, -1.9869, -1.8309,\n",
      "        -1.6252, -2.3529, -1.8114, -1.7746, -1.9318, -1.6051, -1.9154, -1.5628,\n",
      "        -1.9386, -2.3466, -2.3924, -1.4232, -2.1683, -2.2477, -1.9852, -2.4510,\n",
      "        -2.0340, -1.8084, -1.8253, -2.1386, -2.2287, -1.6280, -2.1721, -2.0946,\n",
      "        -2.2661, -2.0128], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3248, -2.3042, -2.3081, -2.3268, -2.3206, -2.3104, -2.3385, -2.2885,\n",
      "        -2.2790, -2.3390, -2.2984, -2.3090, -2.3489, -2.2796, -2.3091, -2.2713,\n",
      "        -2.2644, -2.2902, -2.2780, -2.3293, -2.2711, -2.3097, -2.3100, -2.2466,\n",
      "        -2.3282, -2.2623, -2.3252, -2.2152, -2.3136, -2.3316, -2.3351, -2.3219,\n",
      "        -2.3275, -2.3244, -2.3306, -2.3292, -2.3046, -2.3245, -2.3089, -2.2573,\n",
      "        -2.2766, -2.3115, -2.2744, -2.2893, -2.3096, -2.2899, -2.3065, -2.3326,\n",
      "        -2.2743, -2.3187], device='mps:0')\n",
      "mean: tensor(-2.3036, device='mps:0')\n",
      "iter_dt 1.03s; iter 3: train loss 1.35700 temperature: 5.1499999999999995\n",
      "mean_logits tensor([-1.9825, -2.5217, -1.8470, -1.8808, -2.2310, -2.1680, -1.9813, -1.9148,\n",
      "        -2.0105, -1.8283, -1.6636, -2.8428, -2.1742, -1.8960, -1.9114, -2.2299,\n",
      "        -2.2216, -2.1770, -2.3588, -1.5538, -1.8197, -1.9399, -2.0078, -1.7513,\n",
      "        -2.0184, -2.1928, -2.2767, -2.0794, -1.9276, -2.0173, -2.0303, -1.8978,\n",
      "        -1.9066, -1.9064, -1.5296, -1.6095, -2.3928, -2.2522, -2.3824, -1.7214,\n",
      "        -1.8533, -1.9177, -1.6378, -1.8310, -2.1217, -1.9813, -2.0241, -2.2174,\n",
      "        -1.9736, -2.5188], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3311, -2.3271, -2.3085, -2.3359, -2.2870, -2.3218, -2.2621, -2.2307,\n",
      "        -2.3190, -2.3067, -2.3285, -2.3338, -2.2980, -2.3231, -2.3059, -2.2695,\n",
      "        -2.2984, -2.3223, -2.3040, -2.3294, -2.3008, -2.2951, -2.3203, -2.3308,\n",
      "        -2.3279, -2.3290, -2.3282, -2.2727, -2.2831, -2.3058, -2.3064, -2.2886,\n",
      "        -2.3295, -2.3187, -2.3069, -2.2954, -2.3283, -2.3113, -2.3070, -2.3187,\n",
      "        -2.2380, -2.3835, -2.3377, -2.2783, -2.3119, -2.3254, -2.3183, -2.3355,\n",
      "        -2.3051, -2.3123], device='mps:0')\n",
      "mean: tensor(-2.3099, device='mps:0')\n",
      "iter_dt 1.03s; iter 4: train loss 1.12495 temperature: 5.199999999999999\n",
      "mean_logits tensor([-1.9959, -2.0516, -2.1808, -2.0499, -2.4485, -1.9668, -2.2137, -2.2914,\n",
      "        -2.3766, -1.9758, -2.1923, -2.4904, -1.8761, -2.1306, -1.9184, -1.7249,\n",
      "        -1.9424, -2.0613, -1.5837, -1.8279, -1.9370, -2.4156, -1.6865, -2.0251,\n",
      "        -2.5981, -2.3902, -1.8919, -1.6419, -2.5651, -2.1879, -2.4680, -1.9505,\n",
      "        -2.4553, -2.3642, -1.9580, -2.1534, -2.1609, -2.2323, -2.1664, -1.5579,\n",
      "        -1.6443, -1.8865, -1.9377, -2.1686, -2.0952, -1.9615, -1.6207, -2.0830,\n",
      "        -1.8806, -2.0622], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2700, -2.3001, -2.2952, -2.3240, -2.3385, -2.3408, -2.3156, -2.3128,\n",
      "        -2.3111, -2.3106, -2.3247, -2.3400, -2.3060, -2.3080, -2.3350, -2.3051,\n",
      "        -2.2842, -2.3274, -2.3258, -2.3204, -2.3296, -2.3350, -2.3283, -2.3288,\n",
      "        -2.2791, -2.3499, -2.2740, -2.3201, -2.3194, -2.3213, -2.2959, -2.3140,\n",
      "        -2.3220, -2.2866, -2.2915, -2.2655, -2.2608, -2.3371, -2.2582, -2.2804,\n",
      "        -2.3198, -2.3408, -2.3193, -2.3392, -2.3152, -2.2741, -2.3308, -2.3062,\n",
      "        -2.3237, -2.3317], device='mps:0')\n",
      "mean: tensor(-2.3119, device='mps:0')\n",
      "iter_dt 1.04s; iter 5: train loss 0.88501 temperature: 5.249999999999999\n",
      "mean_logits tensor([-1.8227, -2.3204, -2.2388, -1.6135, -2.0284, -2.3963, -1.7726, -2.1360,\n",
      "        -2.2670, -2.1249, -2.1534, -2.3097, -1.9992, -2.2163, -2.2214, -1.9641,\n",
      "        -2.3844, -2.3724, -2.4445, -1.4412, -2.0722, -2.2321, -1.9203, -1.8059,\n",
      "        -2.1243, -1.6870, -1.7887, -2.3590, -1.9062, -2.1198, -2.3680, -2.2300,\n",
      "        -2.1978, -2.4337, -1.8360, -2.1334, -2.0374, -2.3166, -2.3015, -2.1653,\n",
      "        -1.7068, -2.0587, -1.9708, -1.9507, -1.9675, -2.1907, -1.8369, -2.1433,\n",
      "        -1.9983, -2.3013], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3282, -2.2741, -2.3041, -2.3075, -2.2958, -2.3242, -2.2524, -2.3057,\n",
      "        -2.3115, -2.3237, -2.2247, -2.3561, -2.3300, -2.3036, -2.3149, -2.3255,\n",
      "        -2.3162, -2.3365, -2.3342, -2.2904, -2.3269, -2.3102, -2.3217, -2.2673,\n",
      "        -2.3214, -2.3287, -2.2998, -2.3148, -2.3018, -2.3271, -2.3361, -2.4189,\n",
      "        -2.2900, -2.3027, -2.3216, -2.3254, -2.3485, -2.3348, -2.3152, -2.3245,\n",
      "        -2.3310, -2.2836, -2.3167, -2.3202, -2.3157, -2.2808, -2.3269, -2.3353,\n",
      "        -2.3301, -2.3017], device='mps:0')\n",
      "mean: tensor(-2.3148, device='mps:0')\n",
      "iter_dt 1.04s; iter 6: train loss 1.14079 temperature: 5.299999999999999\n",
      "mean_logits tensor([-1.9080, -1.7522, -2.4825, -2.1844, -2.2756, -2.3892, -2.1137, -1.9876,\n",
      "        -1.7400, -2.0187, -1.8566, -2.0737, -2.2016, -1.8645, -2.2404, -1.9308,\n",
      "        -1.9625, -1.3577, -1.9646, -2.4549, -1.8251, -1.9863, -1.9680, -2.1972,\n",
      "        -2.5310, -2.0405, -1.8730, -1.9128, -2.0806, -2.1538, -1.8388, -2.2826,\n",
      "        -2.2948, -1.8177, -1.9756, -1.7646, -2.2574, -2.0627, -2.3089, -2.0153,\n",
      "        -2.4498, -1.8640, -1.5773, -1.9045, -2.1163, -1.9252, -2.0715, -1.8816,\n",
      "        -1.8561, -2.1738], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2794, -2.2874, -2.2791, -2.3033, -2.2571, -2.3114, -2.2355, -2.3257,\n",
      "        -2.3284, -2.3363, -2.3306, -2.3161, -2.3316, -2.3184, -2.3088, -2.3231,\n",
      "        -2.3177, -2.3317, -2.3323, -2.3309, -2.3220, -2.2549, -2.2916, -2.3161,\n",
      "        -2.3300, -2.2961, -2.2687, -2.3301, -2.3351, -2.2691, -2.3285, -2.3375,\n",
      "        -2.2852, -2.3260, -2.3357, -2.3011, -2.3339, -2.3470, -2.3065, -2.3339,\n",
      "        -2.2877, -2.3248, -2.2413, -2.2730, -2.3382, -2.3355, -2.3861, -2.2852,\n",
      "        -2.3134, -2.3024], device='mps:0')\n",
      "mean: tensor(-2.3104, device='mps:0')\n",
      "iter_dt 1.07s; iter 7: train loss 0.81912 temperature: 5.349999999999999\n",
      "mean_logits tensor([-1.6055, -2.3770, -1.7950, -2.3474, -2.2874, -1.9901, -1.8774, -2.0213,\n",
      "        -2.2232, -2.0097, -2.3779, -2.5056, -2.0280, -2.3795, -2.0639, -2.0044,\n",
      "        -2.1144, -1.9834, -2.1663, -1.9005, -2.1109, -2.1881, -1.6883, -1.9307,\n",
      "        -1.5715, -2.1442, -2.1457, -2.1176, -1.9278, -1.9384, -2.0231, -2.2425,\n",
      "        -2.1285, -2.1516, -2.1418, -2.1074, -1.9154, -2.5411, -2.0652, -2.2739,\n",
      "        -2.6067, -2.3082, -2.3770, -2.3393, -2.0104, -2.0752, -1.8594, -2.1842,\n",
      "        -2.1313, -2.2977], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3203, -2.3180, -2.3114, -2.3179, -2.3315, -2.3186, -2.2945, -2.3031,\n",
      "        -2.3220, -2.3305, -2.3205, -2.3093, -2.3286, -2.3330, -2.3267, -2.3043,\n",
      "        -2.3327, -2.2925, -2.3119, -2.3265, -2.3073, -2.3290, -2.2675, -2.3126,\n",
      "        -2.2815, -2.2800, -2.3223, -2.3288, -2.3068, -2.2951, -2.3314, -2.3287,\n",
      "        -2.3255, -2.3272, -2.3061, -2.3154, -2.3219, -2.2713, -2.3169, -2.1729,\n",
      "        -2.3367, -2.3331, -2.3160, -2.3268, -2.2864, -2.3257, -2.3274, -2.3321,\n",
      "        -2.3316, -2.3112], device='mps:0')\n",
      "mean: tensor(-2.3126, device='mps:0')\n",
      "iter_dt 1.04s; iter 8: train loss 0.86392 temperature: 5.399999999999999\n",
      "mean_logits tensor([-2.4419, -2.0608, -2.0506, -2.1326, -2.5703, -2.0574, -1.9091, -2.4709,\n",
      "        -2.1215, -2.6187, -2.1224, -1.8262, -2.5543, -2.2777, -2.3722, -2.2347,\n",
      "        -2.2275, -1.6491, -1.9669, -2.4126, -2.1059, -2.5208, -2.3548, -1.9034,\n",
      "        -2.3694, -2.3191, -1.9227, -2.3282, -2.1438, -1.8386, -2.2858, -2.1566,\n",
      "        -1.9962, -1.8304, -2.0397, -2.0543, -2.0624, -1.9005, -1.8856, -2.2213,\n",
      "        -2.0781, -1.8456, -1.9883, -1.9175, -1.6557, -2.2473, -1.8808, -2.0007,\n",
      "        -2.0081, -2.0772], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3019, -2.3108, -2.2358, -2.3276, -2.2944, -2.2544, -2.3355, -2.3275,\n",
      "        -2.3157, -2.3075, -2.3331, -2.2813, -2.3158, -2.2370, -2.3131, -2.3133,\n",
      "        -2.3307, -2.2440, -2.2948, -2.3243, -2.2865, -2.3040, -2.2858, -2.3072,\n",
      "        -2.2898, -2.3116, -2.3354, -2.3274, -2.3003, -2.3206, -2.3273, -2.3190,\n",
      "        -2.3101, -2.3298, -2.3093, -2.2599, -2.3337, -2.3236, -2.3279, -2.3297,\n",
      "        -2.2951, -2.2980, -2.3054, -2.2835, -2.3327, -2.2955, -2.2865, -2.3075,\n",
      "        -2.3093, -2.3521], device='mps:0')\n",
      "mean: tensor(-2.3061, device='mps:0')\n",
      "iter_dt 1.05s; iter 9: train loss 0.92027 temperature: 5.449999999999998\n",
      "mean_logits tensor([-2.5613, -2.2267, -1.8629, -1.8981, -1.7813, -1.9146, -2.3132, -1.9608,\n",
      "        -1.9306, -2.4874, -1.9539, -1.7695, -2.1477, -1.9294, -2.3908, -2.2765,\n",
      "        -2.0400, -2.3933, -2.2442, -2.0848, -1.7200, -1.9124, -1.5669, -1.9724,\n",
      "        -2.2860, -1.7584, -2.0542, -2.3989, -1.9250, -2.2073, -1.9068, -2.2191,\n",
      "        -2.1300, -1.8634, -2.0023, -2.1040, -2.0639, -2.1748, -2.1137, -2.0098,\n",
      "        -2.4335, -2.3255, -1.9354, -2.1906, -2.2922, -2.4456, -1.9628, -1.8981,\n",
      "        -2.2255, -2.2972], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3184, -2.3373, -2.3104, -2.3574, -2.3189, -2.3545, -2.3113, -2.3357,\n",
      "        -2.3232, -2.3233, -2.3389, -2.2560, -2.3257, -2.2955, -2.3394, -2.3325,\n",
      "        -2.3291, -2.3368, -2.3488, -2.3298, -2.3275, -2.3054, -2.3413, -2.3179,\n",
      "        -2.2514, -2.3009, -2.3214, -2.2990, -2.3237, -2.3264, -2.3062, -2.3371,\n",
      "        -2.3277, -2.3237, -2.3111, -2.3189, -2.2864, -2.3062, -2.3406, -2.2973,\n",
      "        -2.3319, -2.3289, -2.2889, -2.3174, -2.3265, -2.3467, -2.2984, -2.2536,\n",
      "        -2.2846, -2.3385], device='mps:0')\n",
      "mean: tensor(-2.3182, device='mps:0')\n",
      "iter_dt 1.07s; iter 10: train loss 0.85483 temperature: 5.499999999999998\n",
      "mean_logits tensor([-2.3380, -1.9168, -2.1342, -2.0489, -2.1894, -2.2388, -1.8897, -2.0140,\n",
      "        -2.0592, -1.7520, -2.6190, -2.5772, -2.0241, -2.4764, -2.0570, -2.2387,\n",
      "        -2.6410, -2.3958, -2.5358, -1.8483, -2.3058, -2.1701, -1.7495, -2.5213,\n",
      "        -2.4589, -1.9032, -2.2835, -1.7460, -2.1381, -2.7064, -2.0317, -2.2970,\n",
      "        -2.1944, -1.9621, -2.1524, -1.9722, -2.1835, -2.2439, -2.3580, -2.1728,\n",
      "        -1.9682, -2.1645, -2.1104, -2.2827, -2.0470, -2.3393, -2.2836, -1.9492,\n",
      "        -2.0375, -1.8996], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3353, -2.3251, -2.3061, -2.3148, -2.3313, -2.3217, -2.3344, -2.2830,\n",
      "        -2.3168, -2.2664, -2.2894, -2.2492, -2.3323, -2.2881, -2.3300, -2.3111,\n",
      "        -2.3216, -2.3110, -2.3071, -2.3269, -2.3289, -2.3219, -2.3389, -2.3139,\n",
      "        -2.3175, -2.3038, -2.3140, -2.3010, -2.3334, -2.3317, -2.3240, -2.2781,\n",
      "        -2.2662, -2.3408, -2.3236, -2.3028, -2.3274, -2.3112, -2.3306, -2.3037,\n",
      "        -2.3175, -2.3254, -2.3300, -2.2654, -2.3510, -2.3223, -2.3193, -2.3192,\n",
      "        -2.3123, -2.3346], device='mps:0')\n",
      "mean: tensor(-2.3142, device='mps:0')\n",
      "iter_dt 1.05s; iter 11: train loss 0.79683 temperature: 5.549999999999998\n",
      "mean_logits tensor([-2.3369, -2.1572, -1.8969, -2.7175, -2.4911, -2.1538, -2.3059, -2.2846,\n",
      "        -2.1367, -2.2307, -2.5294, -2.4536, -2.4302, -2.0688, -2.0518, -2.2659,\n",
      "        -1.9169, -1.9549, -2.3984, -2.4113, -2.0052, -1.9670, -2.6053, -1.7671,\n",
      "        -1.8633, -2.1724, -2.4534, -2.3935, -1.9165, -2.0571, -2.1563, -1.9746,\n",
      "        -2.3952, -2.1568, -2.1106, -1.8522, -2.2084, -2.0575, -2.3421, -2.1537,\n",
      "        -1.6478, -2.3839, -2.0293, -2.4446, -2.3309, -2.1201, -2.0201, -2.4280,\n",
      "        -2.6071, -2.6499], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3242, -2.2727, -2.3380, -2.3032, -2.3108, -2.3217, -2.3277, -2.3013,\n",
      "        -2.3405, -2.3308, -2.2511, -2.2811, -2.2237, -2.2759, -2.3299, -2.3144,\n",
      "        -2.3280, -2.3325, -2.3288, -2.3114, -2.3125, -2.3349, -2.3387, -2.3363,\n",
      "        -2.3284, -2.3304, -2.3202, -2.3200, -2.3127, -2.2914, -2.2209, -2.2516,\n",
      "        -2.3183, -2.3155, -2.3276, -2.3294, -2.2978, -2.3055, -2.3053, -2.3380,\n",
      "        -2.3289, -2.3297, -2.3265, -2.3281, -2.3438, -2.3386, -2.3096, -2.3229,\n",
      "        -2.3169, -2.3388], device='mps:0')\n",
      "mean: tensor(-2.3133, device='mps:0')\n",
      "iter_dt 1.04s; iter 12: train loss 0.93994 temperature: 5.599999999999998\n",
      "mean_logits tensor([-2.0489, -2.0974, -1.5910, -2.0089, -2.0841, -2.7780, -2.4461, -2.1517,\n",
      "        -2.0744, -2.2612, -2.3271, -2.2996, -2.3927, -1.8692, -1.7766, -2.1427,\n",
      "        -2.3681, -2.2047, -2.4830, -2.3904, -2.4251, -2.2947, -1.9399, -1.5144,\n",
      "        -2.6503, -2.4482, -1.9953, -2.1385, -2.2395, -2.1272, -1.9015, -2.0768,\n",
      "        -1.8869, -2.1815, -2.6506, -2.5037, -2.1228, -2.3738, -2.6714, -2.3227,\n",
      "        -2.1122, -2.5194, -2.3780, -2.1390, -2.0472, -1.9079, -1.8639, -2.4203,\n",
      "        -2.3863, -1.8351], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3275, -2.3110, -2.3284, -2.3296, -2.3192, -2.3344, -2.3315, -2.2323,\n",
      "        -2.3236, -2.3017, -2.2887, -2.3343, -2.3238, -2.3272, -2.2915, -2.3282,\n",
      "        -2.3206, -2.3168, -2.3321, -2.3293, -2.2978, -2.2585, -2.2704, -2.3324,\n",
      "        -2.2075, -2.2685, -2.3096, -2.2507, -2.3303, -2.2791, -2.2812, -2.3227,\n",
      "        -2.2963, -2.3017, -2.2876, -2.3290, -2.2785, -2.2750, -2.3138, -2.3268,\n",
      "        -2.3302, -2.2656, -2.3185, -2.2992, -2.3113, -2.3149, -2.3215, -2.3034,\n",
      "        -2.3032, -2.3213], device='mps:0')\n",
      "mean: tensor(-2.3048, device='mps:0')\n",
      "iter_dt 1.03s; iter 13: train loss 1.03195 temperature: 5.649999999999998\n",
      "mean_logits tensor([-1.9539, -2.5795, -2.2527, -2.6573, -1.8375, -2.0354, -1.9745, -2.2813,\n",
      "        -2.3431, -1.7712, -2.1600, -2.4672, -1.7840, -2.3698, -2.1800, -1.8003,\n",
      "        -1.8112, -2.0988, -1.9139, -2.5079, -1.9630, -2.3446, -1.8212, -2.0092,\n",
      "        -2.0712, -2.0149, -2.3664, -1.9224, -2.6896, -2.1525, -2.4074, -1.8540,\n",
      "        -2.6448, -2.2276, -1.7709, -1.8648, -2.2491, -2.1792, -2.1430, -2.1238,\n",
      "        -2.1767, -2.2624, -2.4534, -2.1324, -2.3533, -2.2411, -1.6637, -2.5341,\n",
      "        -2.1917, -1.9088], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3195, -2.2663, -2.3037, -2.3025, -2.3243, -2.3279, -2.3303, -2.3310,\n",
      "        -2.2705, -2.3194, -2.3134, -2.3148, -2.3026, -2.3194, -2.3313, -2.3127,\n",
      "        -2.3244, -2.2660, -2.3447, -2.2900, -2.3059, -2.3239, -2.3287, -2.3313,\n",
      "        -2.3240, -2.3465, -2.3050, -2.3211, -2.3086, -2.2942, -2.2958, -2.3226,\n",
      "        -2.3094, -2.3313, -2.3236, -2.3052, -2.3824, -2.2748, -2.2770, -2.3327,\n",
      "        -2.3111, -2.3802, -2.2910, -2.3097, -2.3156, -2.3135, -2.3520, -2.3126,\n",
      "        -2.2923, -2.3346], device='mps:0')\n",
      "mean: tensor(-2.3154, device='mps:0')\n",
      "iter_dt 1.03s; iter 14: train loss 0.49958 temperature: 5.6999999999999975\n",
      "mean_logits tensor([-2.3904, -2.1579, -2.1477, -2.1723, -2.4065, -2.1576, -2.4917, -1.4884,\n",
      "        -2.1183, -2.2470, -2.1105, -2.1374, -2.0034, -2.3874, -2.4692, -2.1857,\n",
      "        -2.1239, -2.0655, -2.5098, -2.2211, -2.1496, -2.3394, -2.0812, -2.1177,\n",
      "        -2.3059, -2.5643, -2.3100, -2.3541, -2.2520, -2.1365, -2.5713, -2.4674,\n",
      "        -2.1792, -2.4231, -2.4091, -2.3329, -2.1882, -2.5301, -2.4053, -2.2100,\n",
      "        -2.0779, -2.1196, -2.3826, -2.4632, -2.3568, -2.4258, -2.1972, -1.9989,\n",
      "        -2.0510, -1.7187], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3091, -2.3319, -2.3278, -2.3065, -2.3252, -2.3027, -2.3128, -2.3321,\n",
      "        -2.2904, -2.3222, -2.3350, -2.1960, -2.2940, -2.2736, -2.3319, -2.3344,\n",
      "        -2.3240, -2.3261, -2.3006, -2.2521, -2.3403, -2.3157, -2.2438, -2.3068,\n",
      "        -2.3170, -2.3114, -2.3290, -2.3256, -2.3034, -2.2874, -2.2982, -2.3184,\n",
      "        -2.3299, -2.2894, -2.3028, -2.3091, -2.3552, -2.2974, -2.2937, -2.3508,\n",
      "        -2.3320, -2.3066, -2.3315, -2.3064, -2.2381, -2.2902, -2.3260, -2.3203,\n",
      "        -2.3254, -2.3286], device='mps:0')\n",
      "mean: tensor(-2.3092, device='mps:0')\n",
      "iter_dt 1.04s; iter 15: train loss 0.79085 temperature: 5.749999999999997\n",
      "mean_logits tensor([-2.3288, -1.9803, -2.1762, -2.4468, -2.1919, -2.2074, -2.0358, -2.2038,\n",
      "        -2.2946, -2.2326, -2.8401, -2.1935, -2.0720, -2.1498, -2.1515, -2.2017,\n",
      "        -2.0387, -2.6814, -2.1865, -2.3532, -2.1287, -2.5215, -2.0780, -2.3110,\n",
      "        -2.3291, -2.2154, -2.5484, -2.6452, -1.9636, -1.8109, -1.8086, -2.1374,\n",
      "        -2.4279, -2.3427, -2.4779, -2.2979, -2.6863, -2.3153, -2.6342, -2.0779,\n",
      "        -2.1922, -2.0577, -2.0030, -1.8249, -2.3451, -2.2529, -2.1371, -2.2217,\n",
      "        -1.9807, -2.4187], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2560, -2.3456, -2.2831, -2.3194, -2.3329, -2.3320, -2.2713, -2.3032,\n",
      "        -2.3316, -2.3207, -2.3356, -2.3489, -2.3061, -2.3339, -2.3175, -2.3289,\n",
      "        -2.3080, -2.2821, -2.2840, -2.3257, -2.3261, -2.3342, -2.3371, -2.3257,\n",
      "        -2.3356, -2.2925, -2.3159, -2.3427, -2.3273, -2.3760, -2.3286, -2.3281,\n",
      "        -2.3048, -2.2751, -2.2954, -2.2336, -2.3241, -2.2844, -2.2508, -2.3841,\n",
      "        -2.3207, -2.2723, -2.2718, -2.3035, -2.3226, -2.3308, -2.3004, -2.3138,\n",
      "        -2.3294, -2.2958], device='mps:0')\n",
      "mean: tensor(-2.3130, device='mps:0')\n",
      "iter_dt 1.05s; iter 16: train loss 0.46691 temperature: 5.799999999999997\n",
      "mean_logits tensor([-1.9016, -2.3609, -2.3347, -2.2676, -2.2077, -2.2429, -2.2743, -2.1120,\n",
      "        -2.0458, -2.1819, -2.3509, -2.4140, -2.4547, -2.5153, -1.8514, -2.1965,\n",
      "        -2.3460, -2.1400, -2.2207, -2.2213, -1.9135, -2.4846, -2.5135, -2.0759,\n",
      "        -2.0960, -2.5054, -2.4761, -2.3473, -2.5815, -2.1059, -2.0616, -2.1810,\n",
      "        -2.3908, -2.0201, -2.3741, -2.1945, -2.0408, -2.5426, -2.2538, -2.0680,\n",
      "        -2.5518, -2.2743, -2.4115, -1.9404, -2.1623, -2.2383, -2.4909, -2.4209,\n",
      "        -2.3832, -2.3583], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3395, -2.3162, -2.3280, -2.3338, -2.3269, -2.2738, -2.3069, -2.2318,\n",
      "        -2.3274, -2.3338, -2.2779, -2.3088, -2.2782, -2.3365, -2.3279, -2.3252,\n",
      "        -2.3209, -2.3083, -2.3022, -2.3084, -2.3199, -2.2928, -2.2739, -2.3267,\n",
      "        -2.2907, -2.3260, -2.2939, -2.2958, -2.3180, -2.3126, -2.3143, -2.3275,\n",
      "        -2.3217, -2.3906, -2.3276, -2.3213, -2.3239, -2.3217, -2.3148, -2.3143,\n",
      "        -2.3205, -2.3133, -2.3172, -2.3281, -2.3151, -2.2749, -2.3091, -2.3500,\n",
      "        -2.3294, -2.3093], device='mps:0')\n",
      "mean: tensor(-2.3142, device='mps:0')\n",
      "iter_dt 1.06s; iter 17: train loss 1.00703 temperature: 5.849999999999997\n",
      "mean_logits tensor([-2.3055, -2.2991, -2.0733, -2.6523, -2.3846, -2.6671, -1.6188, -2.2512,\n",
      "        -2.1174, -2.4028, -2.0258, -2.5573, -2.3361, -2.2061, -2.0353, -2.8025,\n",
      "        -2.4854, -2.1704, -2.5970, -2.4191, -2.0226, -2.2344, -2.4844, -2.3462,\n",
      "        -2.2068, -1.8333, -2.3361, -2.6570, -1.8763, -2.4544, -2.0782, -1.9128,\n",
      "        -2.7927, -2.0088, -2.1847, -2.2417, -2.3639, -2.0950, -2.4191, -1.8318,\n",
      "        -2.5949, -1.7335, -2.3460, -2.3240, -2.0261, -2.1977, -1.7307, -2.1839,\n",
      "        -2.3812, -2.4376], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3427, -2.2786, -2.2622, -2.3357, -2.2650, -2.3206, -2.3292, -2.3252,\n",
      "        -2.3267, -2.3018, -2.2953, -2.3143, -2.2581, -2.3024, -2.3241, -2.2929,\n",
      "        -2.2894, -2.3650, -2.3210, -2.3071, -2.3410, -2.3065, -2.3319, -2.2524,\n",
      "        -2.2766, -2.3298, -2.3265, -2.2895, -2.3269, -2.3288, -2.3226, -2.3119,\n",
      "        -2.3098, -2.3208, -2.3240, -2.3144, -2.3283, -2.3085, -2.2557, -2.3227,\n",
      "        -2.2770, -2.3310, -2.3289, -2.3017, -2.3164, -2.2445, -2.3327, -2.3140,\n",
      "        -2.2967, -2.3338], device='mps:0')\n",
      "mean: tensor(-2.3093, device='mps:0')\n",
      "iter_dt 1.03s; iter 18: train loss 0.94564 temperature: 5.899999999999997\n",
      "mean_logits tensor([-2.5967, -1.8830, -2.3078, -2.7751, -2.4384, -1.7557, -2.3358, -2.7997,\n",
      "        -2.3801, -1.9749, -2.5506, -2.0198, -2.2818, -2.4282, -2.2835, -1.8368,\n",
      "        -2.4646, -2.1860, -2.3723, -2.4968, -2.1863, -2.5345, -1.9952, -2.7196,\n",
      "        -2.3429, -2.0099, -2.4033, -2.4011, -2.4601, -1.7556, -2.2785, -2.1222,\n",
      "        -2.1812, -2.0186, -2.6304, -2.2299, -2.0618, -2.2337, -2.2728, -2.0653,\n",
      "        -2.1617, -2.4908, -2.6329, -2.2000, -2.5306, -1.6788, -2.2440, -1.9026,\n",
      "        -2.0112, -2.4629], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2713, -2.3344, -2.3234, -2.3323, -2.3018, -2.2908, -2.3217, -2.3273,\n",
      "        -2.3259, -2.3286, -2.3286, -2.3212, -2.3044, -2.2519, -2.3237, -2.2908,\n",
      "        -2.3205, -2.2727, -2.3073, -2.3177, -2.3179, -2.3188, -2.3192, -2.3305,\n",
      "        -2.3144, -2.2922, -2.3732, -2.2749, -2.2884, -2.3245, -2.3210, -2.3295,\n",
      "        -2.3131, -2.3367, -2.2645, -2.3296, -2.3394, -2.3066, -2.3511, -2.3021,\n",
      "        -2.3247, -2.2773, -2.2733, -2.3238, -2.2985, -2.2622, -2.2821, -2.2818,\n",
      "        -2.2899, -2.3292], device='mps:0')\n",
      "mean: tensor(-2.3097, device='mps:0')\n",
      "iter_dt 1.10s; iter 19: train loss 0.62604 temperature: 5.949999999999997\n",
      "mean_logits tensor([-2.0216, -2.0752, -2.1607, -2.0353, -1.9370, -2.3254, -2.5145, -2.1380,\n",
      "        -2.1603, -2.3925, -2.1824, -2.1654, -1.8398, -1.7088, -2.1947, -2.3206,\n",
      "        -2.3672, -2.5582, -2.3469, -2.4093, -2.3112, -2.4030, -2.0777, -1.7430,\n",
      "        -2.0032, -2.3232, -2.5162, -2.6933, -2.2790, -2.3086, -2.1459, -2.2689,\n",
      "        -2.0473, -2.5021, -2.4517, -1.9153, -2.2808, -2.3722, -2.4607, -2.2117,\n",
      "        -2.2847, -1.9677, -2.1066, -2.3209, -2.1904, -2.5408, -2.0770, -1.7860,\n",
      "        -2.1045, -2.5944], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3233, -2.3143, -2.2840, -2.3361, -2.3181, -2.3215, -2.3213, -2.2819,\n",
      "        -2.2818, -2.3267, -2.3183, -2.2320, -2.3282, -2.3053, -2.2048, -2.3292,\n",
      "        -2.3338, -2.2542, -2.2985, -2.2820, -2.3237, -2.3203, -2.3320, -2.2995,\n",
      "        -2.3052, -2.3455, -2.2805, -2.3320, -2.2866, -2.3246, -2.3109, -2.3302,\n",
      "        -2.2926, -2.3136, -2.3224, -2.3380, -2.3150, -2.3213, -2.2367, -2.3427,\n",
      "        -2.3295, -2.2699, -2.2774, -2.3074, -2.2954, -2.3111, -2.3286, -2.2601,\n",
      "        -2.3273, -2.3306], device='mps:0')\n",
      "mean: tensor(-2.3061, device='mps:0')\n",
      "iter_dt 1.05s; iter 20: train loss 1.06160 temperature: 5.9999999999999964\n",
      "mean_logits tensor([-1.9552, -2.1915, -2.1409, -1.9393, -2.1663, -2.1610, -2.4933, -2.1912,\n",
      "        -1.9733, -2.1837, -2.3930, -2.1276, -2.3214, -2.1108, -2.6798, -2.2505,\n",
      "        -1.8776, -2.6997, -2.0835, -2.0179, -2.5835, -1.9509, -2.5864, -2.4530,\n",
      "        -1.8551, -2.5801, -1.9184, -2.4158, -2.2839, -2.1843, -2.2254, -2.8204,\n",
      "        -2.4797, -2.3385, -2.2169, -2.1202, -2.3555, -2.2074, -2.3086, -2.3573,\n",
      "        -2.6785, -2.7458, -1.5866, -2.3978, -2.1281, -1.7035, -1.5867, -1.8755,\n",
      "        -2.0266, -2.1058], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2860, -2.3270, -2.3362, -2.3282, -2.3263, -2.3276, -2.2745, -2.2868,\n",
      "        -2.3211, -2.2853, -2.2794, -2.2555, -2.3384, -2.3243, -2.3330, -2.3175,\n",
      "        -2.3277, -2.3431, -2.3059, -2.3293, -2.3197, -2.3275, -2.2992, -2.2909,\n",
      "        -2.3060, -2.3291, -2.3304, -2.2424, -2.3046, -2.3100, -2.3257, -2.3192,\n",
      "        -2.3301, -2.3583, -2.3218, -2.2942, -2.2662, -2.3383, -2.3219, -2.3197,\n",
      "        -2.2894, -2.3200, -2.3259, -2.3113, -2.3015, -2.2827, -2.3150, -2.3107,\n",
      "        -2.2871, -2.3233], device='mps:0')\n",
      "mean: tensor(-2.3115, device='mps:0')\n",
      "iter_dt 1.04s; iter 21: train loss 0.66394 temperature: 6.049999999999996\n",
      "mean_logits tensor([-2.6096, -2.5122, -2.3263, -2.3058, -2.2580, -2.4160, -2.6543, -2.3132,\n",
      "        -2.2461, -2.1596, -2.4060, -2.4496, -2.1961, -2.3697, -2.4443, -2.3400,\n",
      "        -1.9575, -2.6880, -2.1756, -2.5475, -1.8204, -2.4128, -2.3935, -2.1453,\n",
      "        -2.2450, -2.2233, -2.4579, -2.5447, -2.3781, -2.2247, -2.2822, -2.0568,\n",
      "        -2.2548, -1.9310, -2.1693, -2.6330, -2.1066, -2.4513, -2.5815, -2.7412,\n",
      "        -2.5870, -2.5214, -2.1156, -2.4155, -2.4465, -2.2180, -2.5929, -2.5540,\n",
      "        -2.1935, -1.8981], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3333, -2.3023, -2.3316, -2.2838, -2.2968, -2.3292, -2.3254, -2.2735,\n",
      "        -2.3206, -2.3139, -2.3328, -2.3088, -2.3215, -2.3270, -2.3218, -2.3356,\n",
      "        -2.3271, -2.3221, -2.2827, -2.3241, -2.3248, -2.2960, -2.3078, -2.3076,\n",
      "        -2.2878, -2.3070, -2.2542, -2.3260, -2.3222, -2.3257, -2.3320, -2.3241,\n",
      "        -2.3094, -2.2744, -2.3106, -2.3046, -2.2883, -2.3278, -2.3112, -2.3315,\n",
      "        -2.2757, -2.3106, -2.2585, -2.2954, -2.3265, -2.3272, -2.2659, -2.3283,\n",
      "        -2.2800, -2.3285], device='mps:0')\n",
      "mean: tensor(-2.3097, device='mps:0')\n",
      "iter_dt 1.03s; iter 22: train loss 0.83891 temperature: 6.099999999999996\n",
      "mean_logits tensor([-1.9033, -2.5314, -1.8956, -2.2556, -2.6707, -2.5350, -2.6599, -2.0084,\n",
      "        -2.5182, -2.4710, -2.1405, -2.2024, -2.6275, -2.1131, -2.2188, -2.3649,\n",
      "        -1.9014, -2.2820, -2.4613, -2.4772, -2.2840, -2.2875, -2.6436, -1.8918,\n",
      "        -2.2076, -2.4379, -2.2750, -1.9035, -2.7021, -2.2882, -2.0816, -2.3943,\n",
      "        -1.9426, -2.5224, -2.4404, -2.2701, -2.4814, -2.3427, -2.3906, -2.0972,\n",
      "        -2.1829, -2.3509, -2.0243, -1.9166, -2.1853, -2.5910, -2.3402, -2.8437,\n",
      "        -2.0475, -2.3248], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2974, -2.2670, -2.3172, -2.2709, -2.3294, -2.3421, -2.2934, -2.3321,\n",
      "        -2.2941, -2.3392, -2.3094, -2.3138, -2.3331, -2.3155, -2.3278, -2.2925,\n",
      "        -2.3228, -2.3334, -2.3275, -2.2790, -2.3297, -2.3216, -2.2685, -2.2997,\n",
      "        -2.2904, -2.3172, -2.3027, -2.2911, -2.3037, -2.3132, -2.3239, -2.3459,\n",
      "        -2.3208, -2.3264, -2.3304, -2.3109, -2.2807, -2.2779, -2.3297, -2.3185,\n",
      "        -2.3002, -2.3205, -2.2887, -2.2687, -2.3128, -2.3312, -2.3274, -2.3185,\n",
      "        -2.3304, -2.3307], device='mps:0')\n",
      "mean: tensor(-2.3114, device='mps:0')\n",
      "iter_dt 1.05s; iter 23: train loss 0.78531 temperature: 6.149999999999996\n",
      "mean_logits tensor([-2.2202, -2.1884, -2.6093, -2.0366, -2.5087, -2.0691, -1.8124, -1.8880,\n",
      "        -1.8881, -2.1289, -2.4601, -2.1254, -2.2303, -2.3753, -2.5264, -1.8734,\n",
      "        -2.6651, -2.1005, -2.1556, -2.4607, -2.1028, -2.2637, -2.0855, -2.0485,\n",
      "        -2.2106, -2.5940, -2.1517, -2.5134, -2.7508, -2.1503, -1.8771, -2.4371,\n",
      "        -2.7169, -2.4988, -2.5210, -2.2808, -2.1846, -2.4313, -2.2886, -2.0889,\n",
      "        -2.4243, -2.1124, -2.1673, -1.8808, -2.1869, -2.1583, -1.9911, -2.5035,\n",
      "        -2.4681, -2.2319], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3063, -2.2651, -2.3370, -2.3267, -2.3031, -2.3240, -2.3304, -2.2882,\n",
      "        -2.2939, -2.2906, -2.3338, -2.3086, -2.3228, -2.3223, -2.3159, -2.3300,\n",
      "        -2.3129, -2.2792, -2.3057, -2.2696, -2.3305, -2.3091, -2.2864, -2.2962,\n",
      "        -2.3301, -2.2670, -2.3046, -2.3182, -2.3247, -2.3428, -2.3163, -2.3180,\n",
      "        -2.3289, -2.3332, -2.3071, -2.3086, -2.2709, -2.2997, -2.3345, -2.3326,\n",
      "        -2.2895, -2.3327, -2.3233, -2.3610, -2.2934, -2.3081, -2.3218, -2.3140,\n",
      "        -2.2819, -2.3105], device='mps:0')\n",
      "mean: tensor(-2.3112, device='mps:0')\n",
      "iter_dt 1.03s; iter 24: train loss 0.89398 temperature: 6.199999999999996\n",
      "mean_logits tensor([-1.7941, -2.5898, -2.4544, -2.3311, -2.2939, -2.3407, -2.2957, -2.2674,\n",
      "        -2.3030, -2.5686, -2.0916, -2.5258, -2.4728, -1.9839, -2.3100, -2.2837,\n",
      "        -2.5095, -2.1354, -2.3420, -2.3173, -2.7107, -2.3894, -1.9698, -1.9109,\n",
      "        -2.2095, -2.2657, -2.2287, -2.1236, -2.4926, -2.2389, -2.4964, -2.6898,\n",
      "        -2.2105, -2.5825, -2.3561, -2.3922, -1.8174, -2.3041, -2.4309, -2.0190,\n",
      "        -2.1339, -2.4947, -2.4719, -2.8925, -2.6657, -2.3926, -2.6747, -1.9322,\n",
      "        -2.1025, -1.7005], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2769, -2.2906, -2.3287, -2.3071, -2.2382, -2.3074, -2.3380, -2.2966,\n",
      "        -2.2698, -2.3428, -2.3279, -2.3179, -2.2902, -2.3058, -2.3245, -2.3207,\n",
      "        -2.2857, -2.2653, -2.2920, -2.3251, -2.2880, -2.3319, -2.3089, -2.2391,\n",
      "        -2.3034, -2.3340, -2.3192, -2.3333, -2.3302, -2.3280, -2.3262, -2.3020,\n",
      "        -2.2734, -2.3070, -2.3253, -2.3085, -2.3042, -2.3015, -2.3369, -2.3232,\n",
      "        -2.3090, -2.2913, -2.2894, -2.3277, -2.2871, -2.3026, -2.2930, -2.3096,\n",
      "        -2.3318, -2.3309], device='mps:0')\n",
      "mean: tensor(-2.3070, device='mps:0')\n",
      "iter_dt 1.03s; iter 25: train loss 0.67340 temperature: 6.249999999999996\n",
      "mean_logits tensor([-1.9182, -2.0548, -2.1272, -2.2741, -2.4225, -2.5629, -2.1740, -2.0116,\n",
      "        -1.8550, -2.1743, -2.4129, -2.6787, -1.9104, -1.9549, -2.1660, -2.5288,\n",
      "        -2.4827, -2.4467, -2.2589, -2.3404, -2.4698, -1.6533, -2.1546, -2.4025,\n",
      "        -2.2020, -2.1702, -2.0860, -2.6007, -1.6809, -2.3249, -2.3166, -2.2203,\n",
      "        -2.0525, -1.9520, -2.0510, -2.6897, -2.3100, -2.5508, -2.1481, -2.3428,\n",
      "        -2.4181, -2.1417, -2.2998, -2.2595, -2.3353, -2.5256, -2.0155, -2.2015,\n",
      "        -2.5421, -1.9343], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2438, -2.2675, -2.2909, -2.3176, -2.2909, -2.3126, -2.3317, -2.2739,\n",
      "        -2.2265, -2.2546, -2.3091, -2.3303, -2.3007, -2.3178, -2.3287, -2.3182,\n",
      "        -2.2799, -2.3564, -2.3000, -2.3194, -2.2784, -2.3010, -2.3330, -2.3176,\n",
      "        -2.3201, -2.3254, -2.3126, -2.3085, -2.3176, -2.3104, -2.3244, -2.2986,\n",
      "        -2.2973, -2.3335, -2.3002, -2.3128, -2.3328, -2.3005, -2.3334, -2.3036,\n",
      "        -2.3110, -2.2777, -2.3166, -2.3088, -2.3105, -2.3190, -2.3098, -2.2508,\n",
      "        -2.3298, -2.2891], device='mps:0')\n",
      "mean: tensor(-2.3051, device='mps:0')\n",
      "iter_dt 1.05s; iter 26: train loss 0.50678 temperature: 6.299999999999995\n",
      "mean_logits tensor([-2.1868, -2.4259, -2.1239, -2.0172, -2.6070, -2.4798, -2.1203, -2.0992,\n",
      "        -2.4142, -2.4161, -2.4039, -2.0889, -2.2899, -2.2097, -2.6193, -2.4055,\n",
      "        -2.1410, -2.5706, -2.5045, -2.3212, -2.3253, -2.5263, -2.2638, -2.0207,\n",
      "        -2.1114, -2.2017, -2.1159, -2.3284, -2.5497, -2.3483, -1.9407, -2.0188,\n",
      "        -2.1773, -2.3550, -2.6100, -2.1798, -2.1600, -1.9959, -2.0882, -2.4390,\n",
      "        -2.1457, -2.4542, -1.8279, -2.4266, -2.3721, -1.9981, -2.4427, -2.4534,\n",
      "        -2.2650, -2.3450], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2942, -2.2965, -2.3217, -2.3439, -2.3256, -2.3145, -2.3362, -2.3281,\n",
      "        -2.3228, -2.3123, -2.3361, -2.3262, -2.3234, -2.3340, -2.3279, -2.3015,\n",
      "        -2.3155, -2.3277, -2.3032, -2.3317, -2.2891, -2.3378, -2.3185, -2.2843,\n",
      "        -2.2679, -2.3055, -2.2767, -2.3697, -2.3226, -2.3218, -2.3391, -2.2954,\n",
      "        -2.2866, -2.3334, -2.2731, -2.3271, -2.3246, -2.3144, -2.3225, -2.3184,\n",
      "        -2.3138, -2.2890, -2.3311, -2.3056, -2.3086, -2.3286, -2.2946, -2.3234,\n",
      "        -2.3382, -2.2947], device='mps:0')\n",
      "mean: tensor(-2.3156, device='mps:0')\n",
      "iter_dt 1.01s; iter 27: train loss 0.92228 temperature: 6.349999999999995\n",
      "mean_logits tensor([-2.2065, -2.0152, -2.1230, -2.2826, -1.9132, -2.3591, -1.9954, -2.1597,\n",
      "        -2.4535, -2.0981, -2.2893, -2.2879, -2.3315, -2.2395, -2.3163, -2.1638,\n",
      "        -2.3762, -1.8852, -2.3508, -2.3825, -2.9096, -2.3761, -2.2216, -1.9639,\n",
      "        -2.4639, -2.3291, -2.2713, -2.0048, -2.2355, -2.3658, -2.2012, -2.6411,\n",
      "        -2.7169, -1.8166, -2.6418, -2.4303, -2.0576, -2.6868, -2.0165, -1.9164,\n",
      "        -1.8413, -2.1805, -2.6366, -2.7734, -2.4075, -1.8927, -2.1883, -2.5044,\n",
      "        -2.3601, -2.2216], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3324, -2.3300, -2.3134, -2.3400, -2.3181, -2.2447, -2.3188, -2.2796,\n",
      "        -2.2815, -2.2486, -2.2683, -2.2899, -2.3350, -2.3152, -2.2922, -2.3136,\n",
      "        -2.2899, -2.3256, -2.3200, -2.3121, -2.3426, -2.3189, -2.2964, -2.3100,\n",
      "        -2.3098, -2.3115, -2.3281, -2.2902, -2.3270, -2.2876, -2.3329, -2.2950,\n",
      "        -2.3132, -2.2995, -2.3223, -2.3331, -2.2891, -2.3177, -2.2674, -2.3288,\n",
      "        -2.3314, -2.3157, -2.3302, -2.3268, -2.3376, -2.3331, -2.3047, -2.3200,\n",
      "        -2.3036, -2.3172], device='mps:0')\n",
      "mean: tensor(-2.3102, device='mps:0')\n",
      "iter_dt 1.02s; iter 28: train loss 0.35214 temperature: 6.399999999999995\n",
      "mean_logits tensor([-2.1057, -2.4387, -2.0612, -2.0740, -2.2777, -2.1168, -2.0931, -2.3239,\n",
      "        -2.4328, -2.4361, -2.1847, -2.2135, -2.2314, -2.3009, -2.1116, -2.2848,\n",
      "        -2.2879, -2.3034, -2.2235, -2.4562, -2.1845, -2.5076, -2.3356, -2.4275,\n",
      "        -2.5618, -2.2272, -1.9868, -2.2775, -2.1732, -2.0196, -2.2825, -2.2156,\n",
      "        -2.1525, -2.1924, -2.1138, -2.3872, -2.0585, -2.5912, -2.2459, -1.9296,\n",
      "        -2.0309, -2.1432, -1.8939, -2.1102, -2.3151, -2.2291, -2.5382, -2.4741,\n",
      "        -2.2995, -2.3272], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2987, -2.2898, -2.2843, -2.2848, -2.3313, -2.3614, -2.2829, -2.3246,\n",
      "        -2.3296, -2.3149, -2.3224, -2.2806, -2.3279, -2.3277, -2.2714, -2.2777,\n",
      "        -2.3051, -2.3265, -2.1884, -2.3385, -2.3036, -2.3275, -2.3031, -2.3149,\n",
      "        -2.3116, -2.3181, -2.3091, -2.3320, -2.3215, -2.3280, -2.3114, -2.3280,\n",
      "        -2.2955, -2.2972, -2.2604, -2.3318, -2.3130, -2.3208, -2.2672, -2.2911,\n",
      "        -2.3171, -2.3039, -2.3188, -2.2866, -2.2652, -2.3263, -2.3114, -2.3048,\n",
      "        -2.2208, -2.3296], device='mps:0')\n",
      "mean: tensor(-2.3048, device='mps:0')\n",
      "iter_dt 1.10s; iter 29: train loss 0.68375 temperature: 6.449999999999995\n",
      "mean_logits tensor([-2.2145, -2.3465, -2.1127, -2.0296, -2.3779, -2.4267, -2.3613, -2.4144,\n",
      "        -2.1433, -2.0741, -2.0579, -2.1478, -2.1816, -2.3330, -2.2265, -2.3459,\n",
      "        -2.2117, -2.5965, -2.2551, -2.2066, -2.1916, -2.1715, -2.3935, -2.6484,\n",
      "        -2.0623, -2.7161, -2.1201, -2.4623, -2.2156, -2.3084, -1.9925, -2.2487,\n",
      "        -2.4391, -2.0409, -2.2755, -2.3776, -2.7043, -2.7086, -2.2626, -2.0857,\n",
      "        -1.9856, -2.2189, -2.3365, -1.7664, -2.3381, -1.8860, -2.0009, -2.5675,\n",
      "        -2.5733, -2.4586], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3194, -2.3289, -2.2999, -2.3420, -2.3306, -2.3128, -2.3031, -2.3324,\n",
      "        -2.3089, -2.3296, -2.2766, -2.3305, -2.3257, -2.2699, -2.2814, -2.3217,\n",
      "        -2.3324, -2.3082, -2.2587, -2.2948, -2.2580, -2.3432, -2.3318, -2.2855,\n",
      "        -2.3269, -2.3101, -2.3260, -2.3917, -2.3071, -2.3183, -2.3209, -2.2859,\n",
      "        -2.3190, -2.3262, -2.3283, -2.3485, -2.2877, -2.2942, -2.2984, -2.3707,\n",
      "        -2.3171, -2.3211, -2.3169, -2.3397, -2.2660, -2.3218, -2.3212, -2.2869,\n",
      "        -2.3286, -2.2600], device='mps:0')\n",
      "mean: tensor(-2.3133, device='mps:0')\n",
      "iter_dt 1.05s; iter 30: train loss 0.47365 temperature: 6.499999999999995\n",
      "mean_logits tensor([-2.2988, -1.8475, -2.0097, -2.3527, -2.0919, -2.2747, -2.2323, -2.3627,\n",
      "        -2.3307, -2.2469, -2.3705, -2.4308, -2.2610, -2.4824, -2.5275, -1.9233,\n",
      "        -2.0616, -2.3086, -2.1640, -2.4011, -2.2622, -2.1921, -1.9402, -2.3570,\n",
      "        -1.6536, -2.1267, -2.1680, -2.3709, -2.5815, -2.1297, -2.0230, -1.9835,\n",
      "        -2.0628, -2.2054, -2.2671, -2.1853, -2.1935, -2.3989, -2.0154, -2.1596,\n",
      "        -2.3766, -2.1382, -2.3060, -2.4187, -1.9175, -2.4646, -2.0316, -2.1147,\n",
      "        -2.4440, -2.0080], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3191, -2.3292, -2.2355, -2.3338, -2.3290, -2.3085, -2.2874, -2.3273,\n",
      "        -2.3084, -2.2903, -2.2721, -2.2904, -2.3199, -2.3106, -2.3119, -2.2645,\n",
      "        -2.3272, -2.3143, -2.3026, -2.3240, -2.3310, -2.3060, -2.3130, -2.2293,\n",
      "        -2.3070, -2.3121, -2.2727, -2.3247, -2.3177, -2.2803, -2.2802, -2.3097,\n",
      "        -2.3290, -2.3213, -2.3155, -2.3278, -2.3122, -2.2735, -2.3259, -2.3133,\n",
      "        -2.2971, -2.3266, -2.3147, -2.2914, -2.3289, -2.3193, -2.2094, -2.2812,\n",
      "        -2.2817, -2.3309], device='mps:0')\n",
      "mean: tensor(-2.3038, device='mps:0')\n",
      "iter_dt 1.06s; iter 31: train loss 0.44520 temperature: 6.5499999999999945\n",
      "mean_logits tensor([-2.4777, -2.2274, -2.2380, -2.3157, -2.0028, -2.3948, -2.2972, -2.3753,\n",
      "        -2.2061, -1.8584, -2.7210, -2.2019, -2.2203, -2.3771, -2.3941, -2.3722,\n",
      "        -2.4581, -2.2600, -2.0628, -1.9380, -1.9905, -2.2100, -2.3571, -2.1017,\n",
      "        -2.3134, -2.4097, -2.0777, -2.2726, -2.4389, -2.5774, -2.3684, -2.2212,\n",
      "        -2.2190, -2.0659, -2.3446, -2.1387, -2.0452, -1.8262, -2.0210, -2.4608,\n",
      "        -2.2221, -2.2083, -2.5046, -2.2585, -2.1646, -2.3289, -2.2398, -2.2978,\n",
      "        -2.0767, -2.2517], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3103, -2.3183, -2.3288, -2.2929, -2.3236, -2.3090, -2.3285, -2.2670,\n",
      "        -2.3181, -2.3242, -2.2912, -2.3218, -2.3331, -2.3289, -2.2688, -2.3119,\n",
      "        -2.3213, -2.2509, -2.3021, -2.3105, -2.3041, -2.3276, -2.2885, -2.3307,\n",
      "        -2.3037, -2.3141, -2.2510, -2.3682, -2.3178, -2.2896, -2.3393, -2.2788,\n",
      "        -2.3157, -2.3556, -2.3368, -2.3388, -2.2611, -2.2926, -2.3282, -2.3563,\n",
      "        -2.3238, -2.3280, -2.2805, -2.3177, -2.3159, -2.3081, -2.2432, -2.3167,\n",
      "        -2.3225, -2.3273], device='mps:0')\n",
      "mean: tensor(-2.3109, device='mps:0')\n",
      "iter_dt 1.06s; iter 32: train loss 0.49891 temperature: 6.599999999999994\n",
      "mean_logits tensor([-2.3184, -2.4924, -2.3318, -2.5924, -2.2632, -2.1191, -1.7504, -2.1925,\n",
      "        -2.1262, -2.1866, -2.3551, -2.5171, -2.2754, -2.0882, -2.1283, -2.2490,\n",
      "        -2.3737, -2.0442, -2.1661, -2.1389, -1.5641, -2.4935, -2.2205, -2.0681,\n",
      "        -2.6185, -2.4450, -2.2577, -1.8976, -2.4568, -2.0973, -2.0800, -2.3621,\n",
      "        -2.1654, -2.1741, -2.4506, -2.0351, -2.3591, -2.2010, -2.2016, -2.2925,\n",
      "        -2.4564, -2.2662, -2.2286, -2.2639, -2.1848, -2.3658, -1.8865, -2.1090,\n",
      "        -2.0088, -2.2212], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3299, -2.2876, -2.3076, -2.3270, -2.3202, -2.3284, -2.3445, -2.3290,\n",
      "        -2.3085, -2.3008, -2.2925, -2.3247, -2.3204, -2.2862, -2.2825, -2.3253,\n",
      "        -2.3077, -2.3302, -2.2815, -2.2553, -2.3271, -2.3310, -2.3261, -2.3053,\n",
      "        -2.3277, -2.3433, -2.2435, -2.3142, -2.2950, -2.3232, -2.2886, -2.3180,\n",
      "        -2.3281, -2.2733, -2.3260, -2.2834, -2.3178, -2.3107, -2.3140, -2.3367,\n",
      "        -2.2837, -2.3299, -2.2853, -2.3164, -2.3385, -2.3276, -2.3265, -2.2920,\n",
      "        -2.3067, -2.3306], device='mps:0')\n",
      "mean: tensor(-2.3112, device='mps:0')\n",
      "iter_dt 1.04s; iter 33: train loss 0.58202 temperature: 6.649999999999994\n",
      "mean_logits tensor([-1.9833, -2.3604, -2.0597, -2.1560, -2.1650, -2.0979, -2.3559, -2.5043,\n",
      "        -2.1088, -1.7821, -2.4716, -2.1185, -2.5230, -2.3524, -2.0109, -2.0385,\n",
      "        -2.2516, -2.3135, -2.3380, -2.2252, -2.3488, -2.0645, -2.1242, -2.2426,\n",
      "        -1.9492, -2.6464, -2.1184, -2.1404, -2.2341, -2.4605, -2.3088, -2.4376,\n",
      "        -2.3885, -1.9613, -2.4204, -2.1618, -2.4008, -2.2275, -2.4221, -2.5570,\n",
      "        -2.1187, -2.2935, -2.2952, -1.8915, -2.2483, -2.2409, -2.1259, -1.8887,\n",
      "        -2.4459, -2.7023], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3216, -2.2434, -2.3086, -2.3390, -2.3034, -2.3195, -2.3138, -2.3188,\n",
      "        -2.3314, -2.3404, -2.3403, -2.3306, -2.2912, -2.3030, -2.3320, -2.3155,\n",
      "        -2.3351, -2.3117, -2.3313, -2.2838, -2.3147, -2.3296, -2.2682, -2.3132,\n",
      "        -2.3285, -2.2754, -2.3022, -2.3313, -2.3369, -2.3083, -2.2509, -2.3315,\n",
      "        -2.3170, -2.3328, -2.2918, -2.3270, -2.3364, -2.3277, -2.2758, -2.3123,\n",
      "        -2.2755, -2.3268, -2.3300, -2.3367, -2.2778, -2.3301, -2.3322, -2.2972,\n",
      "        -2.3251, -2.2845], device='mps:0')\n",
      "mean: tensor(-2.3128, device='mps:0')\n",
      "iter_dt 1.06s; iter 34: train loss 0.52968 temperature: 6.699999999999994\n",
      "mean_logits tensor([-2.2998, -2.2904, -2.5160, -2.4069, -2.3007, -2.4276, -2.2592, -2.1693,\n",
      "        -2.4591, -1.9610, -2.2342, -2.0229, -2.3870, -2.1432, -2.0071, -2.1675,\n",
      "        -2.3610, -2.3276, -2.2974, -1.8563, -1.9134, -2.4262, -1.9616, -2.5158,\n",
      "        -2.3287, -2.4181, -2.1774, -2.3933, -2.4563, -2.2296, -2.2852, -2.2217,\n",
      "        -1.8859, -2.5788, -2.3012, -2.0618, -1.9309, -2.3870, -1.9941, -1.9439,\n",
      "        -2.5243, -2.0115, -2.3978, -2.7613, -2.3017, -2.3951, -2.2676, -2.3308,\n",
      "        -2.0378, -2.4356], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3289, -2.2891, -2.3246, -2.2942, -2.3192, -2.2943, -2.3139, -2.3202,\n",
      "        -2.3075, -2.3163, -2.3039, -2.3023, -2.3275, -2.2571, -2.3127, -2.3179,\n",
      "        -2.3104, -2.2523, -2.2987, -2.3062, -2.3251, -2.3294, -2.2893, -2.3240,\n",
      "        -2.3233, -2.2879, -2.3315, -2.3098, -2.3242, -2.3227, -2.3014, -2.3158,\n",
      "        -2.3185, -2.2942, -2.3443, -2.2799, -2.3255, -2.3198, -2.2823, -2.3343,\n",
      "        -2.3251, -2.3296, -2.2842, -2.3179, -2.3349, -2.3264, -2.3109, -2.3290,\n",
      "        -2.2508, -2.3079], device='mps:0')\n",
      "mean: tensor(-2.3099, device='mps:0')\n",
      "iter_dt 1.06s; iter 35: train loss 0.61472 temperature: 6.749999999999994\n",
      "mean_logits tensor([-2.1661, -2.1810, -2.3027, -2.3850, -2.2695, -2.2233, -2.2995, -2.0340,\n",
      "        -2.3190, -2.2433, -1.9866, -2.6202, -2.2534, -2.1026, -2.2251, -2.1020,\n",
      "        -2.4351, -2.1532, -2.1855, -1.9209, -2.2641, -1.7491, -2.5900, -2.2012,\n",
      "        -2.1847, -1.9461, -2.1513, -1.9564, -2.4914, -2.5637, -2.7140, -2.1391,\n",
      "        -2.6380, -2.2079, -2.2170, -2.6688, -2.0024, -2.0744, -2.1805, -2.4997,\n",
      "        -2.3615, -1.9386, -2.5743, -2.2994, -2.1421, -2.4189, -2.3594, -2.1351,\n",
      "        -2.2069, -2.2577], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3045, -2.3274, -2.3262, -2.2713, -2.3043, -2.2679, -2.3434, -2.3200,\n",
      "        -2.3119, -2.2368, -2.3050, -2.2809, -2.3329, -2.3302, -2.3007, -2.3302,\n",
      "        -2.3134, -2.2586, -2.3046, -2.3005, -2.3581, -2.3081, -2.3379, -2.3353,\n",
      "        -2.3283, -2.3515, -2.3384, -2.3330, -2.3090, -2.3238, -2.3285, -2.2691,\n",
      "        -2.3212, -2.3259, -2.3055, -2.3262, -2.3104, -2.2939, -2.3257, -2.2965,\n",
      "        -2.3274, -2.2578, -2.3282, -2.3107, -2.3091, -2.3113, -2.3248, -2.2905,\n",
      "        -2.3251, -2.2839], device='mps:0')\n",
      "mean: tensor(-2.3113, device='mps:0')\n",
      "iter_dt 1.05s; iter 36: train loss 0.63660 temperature: 6.799999999999994\n",
      "mean_logits tensor([-2.2487, -2.1902, -2.0468, -2.3557, -2.0036, -2.1406, -2.6081, -2.1761,\n",
      "        -2.3258, -2.2520, -1.9952, -2.2033, -2.3799, -1.8211, -2.3970, -1.9814,\n",
      "        -2.5104, -2.1093, -1.9957, -2.1598, -2.0310, -1.9658, -1.9566, -2.0520,\n",
      "        -1.9206, -1.7907, -1.8627, -2.3865, -2.0863, -2.0162, -2.6231, -2.1534,\n",
      "        -2.3395, -2.4052, -2.0070, -1.9465, -2.2494, -2.4762, -2.2747, -2.0934,\n",
      "        -2.1321, -2.1275, -2.3240, -2.0693, -2.1465, -2.1313, -2.5312, -1.7389,\n",
      "        -2.2314, -2.2898], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3258, -2.3169, -2.2417, -2.3276, -2.3001, -2.1915, -2.3175, -2.3249,\n",
      "        -2.3403, -2.2960, -2.2641, -2.2894, -2.3237, -2.3316, -2.3284, -2.3320,\n",
      "        -2.2998, -2.3221, -2.2871, -2.3229, -2.2100, -2.2799, -2.3104, -2.3110,\n",
      "        -2.3148, -2.2453, -2.2796, -2.3121, -2.3857, -2.3068, -2.3147, -2.3223,\n",
      "        -2.3175, -2.3304, -2.2791, -2.3329, -2.3576, -2.3001, -2.3169, -2.3247,\n",
      "        -2.3029, -2.3098, -2.2877, -2.3327, -2.2691, -2.3115, -2.2958, -2.3311,\n",
      "        -2.3285, -2.3147], device='mps:0')\n",
      "mean: tensor(-2.3064, device='mps:0')\n",
      "iter_dt 1.04s; iter 37: train loss 0.40111 temperature: 6.849999999999993\n",
      "mean_logits tensor([-2.1984, -2.1619, -2.3105, -2.1477, -2.2211, -2.4783, -2.4246, -2.1152,\n",
      "        -2.3886, -2.1418, -2.1303, -2.1071, -1.9618, -2.2759, -2.1400, -2.4877,\n",
      "        -2.3690, -2.4387, -2.5576, -2.1800, -2.2991, -2.3462, -2.1821, -1.9857,\n",
      "        -2.3052, -2.1221, -2.0473, -2.1624, -2.6081, -2.2161, -2.3351, -2.0777,\n",
      "        -2.4264, -2.2575, -2.6127, -2.3276, -2.1835, -2.0705, -1.8522, -2.2283,\n",
      "        -1.9295, -2.1660, -2.2835, -2.2179, -2.3800, -2.0760, -2.0831, -2.3829,\n",
      "        -2.2315, -2.4560], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3164, -2.3019, -2.2273, -2.3371, -2.3269, -2.3246, -2.2877, -2.2527,\n",
      "        -2.2996, -2.2818, -2.3258, -2.2963, -2.2868, -2.3238, -2.3382, -2.3173,\n",
      "        -2.3240, -2.3307, -2.3331, -2.3111, -2.2811, -2.2933, -2.3291, -2.3211,\n",
      "        -2.3319, -2.3195, -2.2423, -2.3241, -2.3263, -2.2943, -2.2870, -2.3294,\n",
      "        -2.3531, -2.3329, -2.3082, -2.3044, -2.3382, -2.3226, -2.3331, -2.3377,\n",
      "        -2.3290, -2.2924, -2.3316, -2.3287, -2.3195, -2.2551, -2.3569, -2.3004,\n",
      "        -2.3098, -2.3515], device='mps:0')\n",
      "mean: tensor(-2.3126, device='mps:0')\n",
      "iter_dt 1.05s; iter 38: train loss 0.44510 temperature: 6.899999999999993\n",
      "mean_logits tensor([-2.0551, -2.0658, -2.3696, -2.3427, -2.5592, -2.1603, -2.2942, -2.5518,\n",
      "        -2.5618, -2.0912, -2.3700, -2.6483, -2.4947, -2.2503, -2.2489, -2.0573,\n",
      "        -2.2786, -2.3006, -2.3523, -2.0250, -2.3609, -2.3765, -2.3240, -2.3836,\n",
      "        -2.1744, -2.4016, -2.2251, -2.3193, -2.2772, -2.3159, -2.1945, -2.1836,\n",
      "        -2.2433, -2.4744, -2.2290, -2.3908, -2.0673, -2.5064, -2.5178, -2.3979,\n",
      "        -2.6990, -2.0450, -2.3310, -2.3855, -2.3876, -2.0234, -2.2849, -2.1805,\n",
      "        -2.1563, -2.0305], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3254, -2.3290, -2.2558, -2.3266, -2.3265, -2.3122, -2.2675, -2.2803,\n",
      "        -2.2524, -2.3290, -2.3730, -2.2905, -2.3337, -2.3120, -2.3022, -2.3311,\n",
      "        -2.3320, -2.3064, -2.3102, -2.3317, -2.3317, -2.3303, -2.3355, -2.3103,\n",
      "        -2.3414, -2.2345, -2.3114, -2.2678, -2.3187, -2.3289, -2.3332, -2.2951,\n",
      "        -2.3118, -2.2784, -2.2492, -2.3284, -2.3281, -2.3412, -2.2514, -2.3050,\n",
      "        -2.3104, -2.3038, -2.2992, -2.3305, -2.3107, -2.3286, -2.2857, -2.3336,\n",
      "        -2.3349, -2.2830], device='mps:0')\n",
      "mean: tensor(-2.3096, device='mps:0')\n",
      "iter_dt 1.05s; iter 39: train loss 0.58986 temperature: 6.949999999999993\n",
      "mean_logits tensor([-1.8752, -2.6624, -2.4314, -2.2136, -2.5815, -2.2270, -2.1547, -2.1599,\n",
      "        -2.1995, -1.8876, -2.1906, -1.9593, -2.1859, -2.1766, -2.0194, -2.2428,\n",
      "        -1.9984, -2.4254, -2.3313, -2.0390, -2.4120, -2.2973, -2.4637, -2.3164,\n",
      "        -2.2033, -2.1465, -2.1568, -2.2036, -1.9351, -2.0593, -2.1614, -2.1772,\n",
      "        -2.2828, -2.0918, -1.8784, -2.6049, -2.3365, -2.2480, -2.3173, -2.4602,\n",
      "        -2.6912, -2.2053, -2.1412, -2.4361, -2.4540, -2.2123, -2.1275, -2.6408,\n",
      "        -2.3163, -2.4582], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2863, -2.2552, -2.2907, -2.3037, -2.3087, -2.3207, -2.3115, -2.2542,\n",
      "        -2.1783, -2.3368, -2.2991, -2.3109, -2.3305, -2.3380, -2.3172, -2.2947,\n",
      "        -2.3335, -2.3311, -2.3305, -2.3207, -2.2895, -2.3287, -2.2852, -2.3297,\n",
      "        -2.3288, -2.3181, -2.3134, -2.3194, -2.3151, -2.3288, -2.3063, -2.3310,\n",
      "        -2.3287, -2.3375, -2.3084, -2.3137, -2.2698, -2.3252, -2.2979, -2.3219,\n",
      "        -2.3108, -2.3216, -2.2574, -2.3172, -2.3146, -2.3245, -2.3226, -2.3238,\n",
      "        -2.3311, -2.2904], device='mps:0')\n",
      "mean: tensor(-2.3093, device='mps:0')\n",
      "iter_dt 1.04s; iter 40: train loss 0.57782 temperature: 6.999999999999993\n",
      "mean_logits tensor([-2.5362, -2.4988, -2.2392, -2.4136, -2.0792, -2.1654, -2.5668, -2.0518,\n",
      "        -2.3769, -1.9220, -2.2032, -2.3000, -2.5214, -2.2857, -2.1479, -2.0448,\n",
      "        -2.1750, -1.8495, -2.5285, -2.1228, -2.5032, -2.2284, -2.1380, -2.5556,\n",
      "        -2.4987, -2.0931, -2.0938, -2.2350, -2.7559, -2.4703, -2.3696, -2.0874,\n",
      "        -2.3274, -2.5000, -1.9310, -2.1877, -2.5275, -2.1653, -2.0572, -2.1641,\n",
      "        -2.1604, -1.9412, -2.0911, -2.2046, -2.3092, -2.3122, -2.0910, -2.3575,\n",
      "        -2.1115, -2.3179], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2424, -2.3154, -2.2988, -2.3290, -2.2980, -2.2553, -2.3218, -2.2917,\n",
      "        -2.3234, -2.2756, -2.2952, -2.3306, -2.3185, -2.3315, -2.3403, -2.3227,\n",
      "        -2.3238, -2.3260, -2.3074, -2.3092, -2.2428, -2.3463, -2.3144, -2.3256,\n",
      "        -2.2568, -2.3099, -2.2737, -2.3170, -2.2853, -2.3321, -2.3320, -2.3395,\n",
      "        -2.3199, -2.3211, -2.3250, -2.3285, -2.3283, -2.3358, -2.3257, -2.2810,\n",
      "        -2.2856, -2.2817, -2.2934, -2.3032, -2.2674, -2.3139, -2.3290, -2.3205,\n",
      "        -2.3418, -2.3365], device='mps:0')\n",
      "mean: tensor(-2.3094, device='mps:0')\n",
      "iter_dt 1.03s; iter 41: train loss 0.49008 temperature: 7.049999999999993\n",
      "mean_logits tensor([-2.2280, -2.5953, -2.0266, -2.2606, -2.4393, -2.1828, -2.6328, -2.0190,\n",
      "        -2.0182, -2.0916, -2.4410, -2.0984, -2.1985, -2.0528, -2.3255, -2.4412,\n",
      "        -2.4060, -2.2551, -2.1538, -2.2400, -2.5200, -2.3203, -2.3109, -2.4209,\n",
      "        -2.4751, -1.7023, -2.2933, -1.9461, -2.2238, -2.2244, -2.0119, -2.3509,\n",
      "        -2.3752, -2.2619, -1.8222, -2.4233, -2.1428, -2.1847, -2.2067, -2.0740,\n",
      "        -2.3422, -2.0248, -1.9147, -2.6077, -2.4000, -2.0214, -2.0436, -2.1009,\n",
      "        -2.0335, -2.2739], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3381, -2.3337, -2.2821, -2.3210, -2.3239, -2.3213, -2.3091, -2.2986,\n",
      "        -2.2548, -2.3230, -2.3232, -2.2847, -2.2824, -2.3227, -2.2676, -2.3279,\n",
      "        -2.3220, -2.3303, -2.3210, -2.3099, -2.3274, -2.3197, -2.3241, -2.3285,\n",
      "        -2.2930, -2.2871, -2.3183, -2.3411, -2.3354, -2.3230, -2.3093, -2.2933,\n",
      "        -2.3339, -2.3004, -2.2670, -2.3262, -2.3277, -2.3283, -2.3310, -2.3288,\n",
      "        -2.3248, -2.2722, -2.2677, -2.3243, -2.3557, -2.2633, -2.2769, -2.3092,\n",
      "        -2.2846, -2.3238], device='mps:0')\n",
      "mean: tensor(-2.3109, device='mps:0')\n",
      "iter_dt 1.04s; iter 42: train loss 0.55480 temperature: 7.0999999999999925\n",
      "mean_logits tensor([-2.3547, -2.0314, -1.5607, -2.2256, -2.1087, -2.0126, -2.2088, -2.1722,\n",
      "        -2.3321, -2.0586, -2.4857, -2.2508, -2.3796, -2.2921, -2.0397, -2.3526,\n",
      "        -2.1317, -2.7741, -2.2572, -2.0591, -2.3757, -1.9061, -2.5275, -2.3641,\n",
      "        -2.0760, -2.0957, -2.1917, -1.9759, -2.3600, -2.3038, -2.6298, -2.4071,\n",
      "        -2.4362, -2.2728, -2.0287, -2.0172, -2.3040, -2.3461, -2.4603, -1.9174,\n",
      "        -2.4476, -2.2303, -2.3892, -2.3481, -1.9090, -2.4251, -2.2581, -2.1603,\n",
      "        -2.4392, -2.1475], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3105, -2.2951, -2.3327, -2.3336, -2.3284, -2.2978, -2.3319, -2.3096,\n",
      "        -2.3304, -2.3221, -2.3150, -2.2853, -2.3199, -2.3161, -2.2921, -2.3161,\n",
      "        -2.2951, -2.3463, -2.2670, -2.3362, -2.3318, -2.3237, -2.3286, -2.3080,\n",
      "        -2.3310, -2.3374, -2.3185, -2.3247, -2.3583, -2.3287, -2.3288, -2.3020,\n",
      "        -2.3103, -2.3183, -2.3271, -2.2430, -2.3292, -2.3294, -2.3163, -2.3302,\n",
      "        -2.3321, -2.2933, -2.3164, -2.3094, -2.2857, -2.3173, -2.2934, -2.3175,\n",
      "        -2.3107, -2.3011], device='mps:0')\n",
      "mean: tensor(-2.3157, device='mps:0')\n",
      "iter_dt 1.04s; iter 43: train loss 0.50390 temperature: 7.149999999999992\n",
      "mean_logits tensor([-2.0948, -2.4386, -1.6108, -1.9562, -2.3219, -2.1543, -2.2514, -2.2578,\n",
      "        -2.3715, -2.2700, -2.3454, -2.4527, -1.8143, -2.1160, -2.1475, -2.1052,\n",
      "        -2.1190, -2.2101, -1.9850, -2.3902, -2.3618, -2.3072, -2.2089, -2.2506,\n",
      "        -2.1190, -2.4169, -2.3644, -2.2260, -2.1116, -2.1972, -2.0161, -2.5599,\n",
      "        -2.0215, -1.9768, -2.3156, -2.2600, -2.0605, -2.2374, -2.4532, -2.6353,\n",
      "        -2.4233, -2.0862, -2.5649, -2.4416, -2.3287, -2.4185, -1.9271, -2.1456,\n",
      "        -2.1766, -2.4136], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3298, -2.3174, -2.3137, -2.3521, -2.3120, -2.3032, -2.3263, -2.2895,\n",
      "        -2.2431, -2.3201, -2.3284, -2.3232, -2.3126, -2.2844, -2.3445, -2.3205,\n",
      "        -2.2901, -2.3171, -2.3317, -2.3352, -2.2975, -2.3255, -2.2817, -2.3257,\n",
      "        -2.2621, -2.3287, -2.2927, -2.3366, -2.3285, -2.2960, -2.3282, -2.3241,\n",
      "        -2.3187, -2.3121, -2.2733, -2.3100, -2.3172, -2.3437, -2.3152, -2.3101,\n",
      "        -2.2819, -2.3097, -2.3204, -2.3316, -2.2974, -2.3285, -2.3301, -2.3321,\n",
      "        -2.2465, -2.3387], device='mps:0')\n",
      "mean: tensor(-2.3128, device='mps:0')\n",
      "iter_dt 1.05s; iter 44: train loss 0.56037 temperature: 7.199999999999992\n",
      "mean_logits tensor([-2.0182, -2.2675, -2.4430, -2.5267, -2.1848, -2.0991, -2.2753, -2.3238,\n",
      "        -1.8791, -1.8703, -2.3061, -1.9986, -2.0486, -2.1862, -2.1912, -2.0861,\n",
      "        -2.4744, -1.9123, -2.1815, -2.4661, -2.5072, -2.6149, -2.5313, -2.5031,\n",
      "        -2.1059, -2.5519, -2.4271, -2.0738, -2.5449, -1.9433, -2.0540, -2.1364,\n",
      "        -1.9219, -2.4208, -2.1582, -2.3220, -2.2765, -2.4684, -2.4516, -2.1079,\n",
      "        -1.9468, -2.5201, -2.3276, -2.2926, -2.3998, -2.0931, -2.3890, -2.0759,\n",
      "        -2.4007, -2.3200], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3278, -2.3234, -2.3319, -2.3344, -2.3063, -2.3143, -2.3315, -2.2593,\n",
      "        -2.3284, -2.3260, -2.3176, -2.2847, -2.3050, -2.2911, -2.3037, -2.3170,\n",
      "        -2.2864, -2.3054, -2.3097, -2.3150, -2.3283, -2.3069, -2.3047, -2.3270,\n",
      "        -2.3369, -2.3172, -2.2922, -2.3297, -2.3229, -2.3296, -2.3311, -2.3108,\n",
      "        -2.2998, -2.3288, -2.2851, -2.3143, -2.3329, -2.3193, -2.3370, -2.3425,\n",
      "        -2.3362, -2.3250, -2.3247, -2.3207, -2.3197, -2.2851, -2.3023, -2.3356,\n",
      "        -2.2610, -2.2727], device='mps:0')\n",
      "mean: tensor(-2.3140, device='mps:0')\n",
      "iter_dt 1.04s; iter 45: train loss 0.48507 temperature: 7.249999999999992\n",
      "mean_logits tensor([-2.5304, -2.3070, -2.4538, -2.1984, -2.4197, -2.5195, -2.3057, -2.4089,\n",
      "        -1.9576, -1.9395, -2.1040, -2.1854, -2.3654, -2.3498, -1.9201, -2.4374,\n",
      "        -2.0951, -2.1199, -2.0036, -2.1536, -2.1118, -2.2254, -2.5458, -2.1340,\n",
      "        -2.2803, -2.0281, -2.4830, -2.4346, -2.5204, -2.2495, -2.0413, -2.1241,\n",
      "        -2.4190, -2.4933, -2.0711, -2.4308, -1.8662, -1.8777, -2.2504, -2.3007,\n",
      "        -2.2565, -2.4537, -2.3112, -2.2765, -2.2174, -2.2698, -2.0738, -2.0905,\n",
      "        -2.0703, -2.2270], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2911, -2.2416, -2.2759, -2.3193, -2.2948, -2.3221, -2.3207, -2.3228,\n",
      "        -2.3288, -2.3305, -2.2604, -2.2917, -2.3243, -2.2867, -2.3262, -2.3314,\n",
      "        -2.3092, -2.3189, -2.3086, -2.3342, -2.3825, -2.3322, -2.3169, -2.3167,\n",
      "        -2.3023, -2.3256, -2.2992, -2.2736, -2.3328, -2.2990, -2.2719, -2.3170,\n",
      "        -2.3405, -2.3289, -2.3259, -2.3200, -2.3564, -2.3154, -2.2910, -2.3163,\n",
      "        -2.3179, -2.2882, -2.3321, -2.3027, -2.3067, -2.3236, -2.3320, -2.3240,\n",
      "        -2.3184, -2.3282], device='mps:0')\n",
      "mean: tensor(-2.3135, device='mps:0')\n",
      "iter_dt 1.04s; iter 46: train loss 0.29312 temperature: 7.299999999999992\n",
      "mean_logits tensor([-2.1666, -2.3361, -2.3658, -2.1672, -2.2652, -2.2039, -2.1485, -2.1778,\n",
      "        -2.1028, -2.0964, -2.3332, -2.2796, -2.5798, -2.4475, -2.1585, -2.1121,\n",
      "        -2.3695, -2.1775, -2.0360, -2.5543, -2.4701, -2.3983, -2.1053, -2.3017,\n",
      "        -2.3620, -2.2365, -2.1198, -2.3275, -2.2478, -2.3019, -2.0658, -2.3028,\n",
      "        -2.3591, -1.9039, -2.2922, -2.1158, -2.1871, -2.1314, -2.1451, -2.4166,\n",
      "        -2.1746, -2.1561, -2.0789, -2.2597, -2.2378, -2.0734, -2.1759, -2.2095,\n",
      "        -2.3555, -1.8705], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2736, -2.2773, -2.3240, -2.3229, -2.3005, -2.2760, -2.3104, -2.3104,\n",
      "        -2.3246, -2.3126, -2.3225, -2.3306, -2.3365, -2.3313, -2.3178, -2.3101,\n",
      "        -2.2836, -2.3322, -2.3287, -2.3096, -2.3201, -2.3064, -2.3187, -2.3127,\n",
      "        -2.3054, -2.3187, -2.2418, -2.3134, -2.2308, -2.3063, -2.2994, -2.3060,\n",
      "        -2.3149, -2.3283, -2.3238, -2.3216, -2.3042, -2.2744, -2.3378, -2.2589,\n",
      "        -2.3221, -2.3261, -2.2845, -2.3106, -2.2560, -2.2842, -2.2893, -2.3201,\n",
      "        -2.3336, -2.1880], device='mps:0')\n",
      "mean: tensor(-2.3039, device='mps:0')\n",
      "iter_dt 1.06s; iter 47: train loss 0.38978 temperature: 7.349999999999992\n",
      "mean_logits tensor([-2.1353, -2.3609, -2.2079, -2.3006, -2.1381, -2.3544, -2.1366, -2.2681,\n",
      "        -2.4068, -2.0288, -2.3659, -2.3095, -2.3686, -2.1065, -2.3507, -2.3685,\n",
      "        -2.0607, -1.9556, -2.3219, -2.2309, -2.1859, -2.0042, -2.5856, -2.3169,\n",
      "        -2.0293, -2.4841, -2.2136, -2.0174, -2.5591, -2.3263, -2.1774, -2.1821,\n",
      "        -2.1492, -2.1320, -2.3723, -2.1315, -2.1007, -2.3181, -2.1142, -2.6865,\n",
      "        -2.2769, -2.4318, -2.2463, -2.5515, -2.1094, -2.1624, -2.1906, -2.0186,\n",
      "        -2.4394, -2.2975], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3282, -2.2640, -2.3138, -2.3289, -2.3287, -2.3226, -2.3203, -2.3314,\n",
      "        -2.3102, -2.3177, -2.2914, -2.2864, -2.3052, -2.3551, -2.2652, -2.3271,\n",
      "        -2.3383, -2.3388, -2.3255, -2.3313, -2.2033, -2.3099, -2.3020, -2.3194,\n",
      "        -2.3168, -2.3299, -2.3068, -2.2800, -2.3292, -2.2973, -2.3046, -2.3090,\n",
      "        -2.3291, -2.3268, -2.2905, -2.3283, -2.3030, -2.2983, -2.2526, -2.3584,\n",
      "        -2.2880, -2.3387, -2.2746, -2.3279, -2.3382, -2.3253, -2.2877, -2.3015,\n",
      "        -2.2934, -2.3275], device='mps:0')\n",
      "mean: tensor(-2.3106, device='mps:0')\n",
      "iter_dt 1.07s; iter 48: train loss 0.30834 temperature: 7.3999999999999915\n",
      "mean_logits tensor([-2.1345, -2.4858, -2.3632, -2.4180, -2.3452, -2.1377, -2.3202, -2.5184,\n",
      "        -2.1583, -2.2032, -2.3174, -2.1385, -2.2417, -2.4336, -2.4350, -2.3986,\n",
      "        -2.2463, -2.3169, -2.3408, -2.4420, -2.0930, -2.2576, -2.5237, -2.2062,\n",
      "        -2.3409, -2.3204, -2.4137, -2.1096, -2.3997, -2.5153, -2.1669, -2.3497,\n",
      "        -2.3880, -2.0547, -2.4307, -2.3457, -2.5841, -2.1681, -2.3600, -2.5767,\n",
      "        -2.3738, -2.2104, -2.3795, -2.3990, -2.4045, -2.1521, -2.3162, -2.0992,\n",
      "        -2.5214, -2.0306], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3232, -2.2997, -2.3154, -2.3204, -2.3397, -2.3343, -2.2587, -2.3147,\n",
      "        -2.3276, -2.3282, -2.3105, -2.3212, -2.3185, -2.3044, -2.3332, -2.3116,\n",
      "        -2.3158, -2.2327, -2.3241, -2.2755, -2.3313, -2.3256, -2.3284, -2.3293,\n",
      "        -2.3250, -2.2416, -2.3342, -2.3286, -2.3130, -2.2762, -2.2159, -2.3015,\n",
      "        -2.3196, -2.2778, -2.3054, -2.2840, -2.3065, -2.3324, -2.3267, -2.3116,\n",
      "        -2.2703, -2.3306, -2.3087, -2.3283, -2.3175, -2.2608, -2.3130, -2.3208,\n",
      "        -2.2268, -2.3305], device='mps:0')\n",
      "mean: tensor(-2.3066, device='mps:0')\n",
      "iter_dt 1.06s; iter 49: train loss 0.27585 temperature: 7.449999999999991\n",
      "mean_logits tensor([-2.2454, -2.2921, -2.2835, -2.3768, -2.1727, -2.3539, -2.4071, -2.2894,\n",
      "        -2.1056, -2.3221, -2.5497, -2.2991, -2.1727, -2.2175, -2.1790, -2.3498,\n",
      "        -2.3890, -2.1985, -2.3969, -2.2142, -2.0542, -2.0669, -2.1696, -2.2234,\n",
      "        -2.3612, -2.4957, -2.5039, -1.9764, -2.1867, -2.2993, -2.0731, -2.3038,\n",
      "        -2.3902, -2.2744, -2.5568, -2.0840, -2.3813, -2.3270, -2.3855, -2.1165,\n",
      "        -2.4989, -2.3551, -2.3927, -2.3958, -2.4451, -1.9997, -2.4180, -2.1787,\n",
      "        -2.2258, -2.1752], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3290, -2.3257, -2.3281, -2.3309, -2.3222, -2.2976, -2.2708, -2.3276,\n",
      "        -2.3293, -2.3311, -2.3202, -2.3381, -2.3086, -2.3213, -2.3279, -2.2956,\n",
      "        -2.3222, -2.2780, -2.3181, -2.3297, -2.3427, -2.2855, -2.2993, -2.3368,\n",
      "        -2.3158, -2.3238, -2.3293, -2.3245, -2.3054, -2.3182, -2.3303, -2.2704,\n",
      "        -2.3905, -2.3148, -2.2618, -2.2935, -2.2939, -2.3249, -2.3031, -2.3115,\n",
      "        -2.3342, -2.2717, -2.3313, -2.3331, -2.3295, -2.3282, -2.3145, -2.3048,\n",
      "        -2.3281, -2.3367], device='mps:0')\n",
      "mean: tensor(-2.3168, device='mps:0')\n",
      "iter_dt 1.07s; iter 50: train loss 0.70007 temperature: 7.499999999999991\n",
      "mean_logits tensor([-2.2662, -2.3896, -1.8718, -2.3106, -2.2424, -1.9780, -2.3909, -2.3200,\n",
      "        -2.0628, -2.5492, -2.3039, -2.5445, -2.0873, -2.3929, -2.4827, -1.9832,\n",
      "        -2.0623, -2.2423, -2.3290, -2.6183, -2.3683, -1.7419, -2.1585, -2.3060,\n",
      "        -2.2103, -2.5590, -2.0604, -2.4390, -1.9238, -2.0017, -2.2339, -2.4908,\n",
      "        -1.8524, -1.8876, -2.3382, -1.8076, -2.2450, -2.4637, -2.4359, -1.5692,\n",
      "        -2.5045, -2.4084, -2.3731, -2.2162, -2.0967, -2.5234, -2.1476, -2.1967,\n",
      "        -1.9132, -2.4227], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3302, -2.2518, -2.3280, -2.2756, -2.3263, -2.3277, -2.3301, -2.2916,\n",
      "        -2.3177, -2.2684, -2.3323, -2.3161, -2.3362, -2.3305, -2.2683, -2.2945,\n",
      "        -2.3287, -2.3231, -2.2135, -2.3526, -2.3284, -2.3502, -2.3134, -2.3260,\n",
      "        -2.3383, -2.3098, -2.3167, -2.3482, -2.3570, -2.3329, -2.3090, -2.3165,\n",
      "        -2.3236, -2.3297, -2.3563, -2.3326, -2.2719, -2.2713, -2.2991, -2.2760,\n",
      "        -2.3139, -2.3267, -2.3075, -2.2686, -2.3151, -2.3291, -2.3047, -2.3427,\n",
      "        -2.2834, -2.3069], device='mps:0')\n",
      "mean: tensor(-2.3130, device='mps:0')\n",
      "iter_dt 1.03s; iter 51: train loss 0.60586 temperature: 7.549999999999991\n",
      "mean_logits tensor([-2.3320, -2.1727, -2.3447, -2.7000, -2.4279, -2.1086, -2.2522, -2.2354,\n",
      "        -2.0249, -2.1707, -1.9943, -2.2522, -2.0585, -2.0718, -2.4839, -2.4415,\n",
      "        -2.1684, -2.1086, -2.6014, -2.4735, -2.2953, -2.4892, -2.1205, -2.1020,\n",
      "        -1.9750, -2.4595, -2.3570, -2.4666, -2.0260, -2.5781, -2.1702, -2.4384,\n",
      "        -2.2995, -2.4178, -2.1069, -2.2609, -2.3097, -1.9608, -2.8405, -2.5188,\n",
      "        -2.3031, -2.5172, -2.4654, -2.5062, -2.2910, -2.1271, -2.2353, -2.4206,\n",
      "        -1.9998, -2.0458], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3297, -2.3048, -2.3233, -2.3287, -2.3164, -2.3200, -2.3293, -2.3015,\n",
      "        -2.3380, -2.3260, -2.3270, -2.2925, -2.3217, -2.2688, -2.2976, -2.3357,\n",
      "        -2.3155, -2.3262, -2.3294, -2.3307, -2.2889, -2.3286, -2.2711, -2.3243,\n",
      "        -2.2683, -2.2939, -2.3109, -2.3015, -2.3538, -2.3283, -2.3180, -2.3197,\n",
      "        -2.3240, -2.3146, -2.3363, -2.3036, -2.3284, -2.3313, -2.3190, -2.2766,\n",
      "        -2.3283, -2.3245, -2.3648, -2.3159, -2.3245, -2.2735, -2.3125, -2.3064,\n",
      "        -2.3297, -2.3295], device='mps:0')\n",
      "mean: tensor(-2.3163, device='mps:0')\n",
      "iter_dt 1.07s; iter 52: train loss 0.48976 temperature: 7.599999999999991\n",
      "mean_logits tensor([-2.2010, -2.0679, -1.8859, -2.3371, -2.2466, -1.8479, -2.2645, -2.2010,\n",
      "        -2.0651, -2.3449, -2.4400, -2.1172, -2.0966, -2.3807, -2.2423, -2.4201,\n",
      "        -1.9071, -2.4988, -2.2668, -2.2364, -2.1556, -2.0160, -1.9979, -2.4946,\n",
      "        -2.1708, -2.0826, -2.2392, -2.3096, -2.0918, -2.3185, -2.0764, -2.2565,\n",
      "        -2.3020, -2.1967, -1.9220, -2.5085, -2.0926, -2.0085, -2.2332, -2.1292,\n",
      "        -2.4440, -1.9812, -2.5983, -2.0699, -2.2055, -2.1076, -2.4018, -2.2886,\n",
      "        -2.3404, -2.2594], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3445, -2.2864, -2.3362, -2.3295, -2.2978, -2.3289, -2.2247, -2.3012,\n",
      "        -2.3192, -2.2942, -2.3358, -2.3299, -2.3384, -2.3056, -2.2869, -2.2772,\n",
      "        -2.3337, -2.3282, -2.3204, -2.3029, -2.3350, -2.2999, -2.3273, -2.3000,\n",
      "        -2.2942, -2.3167, -2.2958, -2.2875, -2.3200, -2.3298, -2.2770, -2.3084,\n",
      "        -2.3180, -2.3200, -2.3588, -2.3031, -2.2895, -2.2822, -2.3220, -2.3253,\n",
      "        -2.2827, -2.3467, -2.2852, -2.2888, -2.3094, -2.4027, -2.3338, -2.3228,\n",
      "        -2.3177, -2.2843], device='mps:0')\n",
      "mean: tensor(-2.3121, device='mps:0')\n",
      "iter_dt 1.05s; iter 53: train loss 0.58920 temperature: 7.649999999999991\n",
      "mean_logits tensor([-2.2263, -2.4286, -2.2412, -2.2829, -2.0690, -1.7823, -1.8781, -2.1066,\n",
      "        -2.4364, -2.3546, -2.4635, -2.5494, -2.3846, -2.2509, -1.9843, -2.6868,\n",
      "        -2.2244, -2.4888, -2.3357, -2.0574, -2.3972, -2.0368, -2.4580, -2.3169,\n",
      "        -2.5902, -2.0663, -2.4223, -2.0800, -2.0645, -2.4603, -2.2664, -2.2826,\n",
      "        -2.5374, -2.5394, -2.3561, -2.2409, -2.5212, -2.3151, -2.1902, -2.3168,\n",
      "        -1.5370, -2.2174, -1.9528, -2.7616, -2.3141, -2.3690, -2.3973, -2.2862,\n",
      "        -2.5121, -2.0576], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3245, -2.3377, -2.2611, -2.2834, -2.2713, -2.2662, -2.2837, -2.3239,\n",
      "        -2.3265, -2.3064, -2.3061, -2.3277, -2.3296, -2.2426, -2.3080, -2.3254,\n",
      "        -2.3068, -2.3288, -2.2634, -2.2592, -2.2888, -2.2074, -2.2142, -2.3179,\n",
      "        -2.3307, -2.3163, -2.3116, -2.3126, -2.3126, -2.3270, -2.3329, -2.3304,\n",
      "        -2.3300, -2.2936, -2.3224, -2.2851, -2.3263, -2.3012, -2.3094, -2.3271,\n",
      "        -2.3135, -2.3220, -2.2801, -2.3383, -2.3135, -2.2865, -2.3227, -2.3239,\n",
      "        -2.3007, -2.3200], device='mps:0')\n",
      "mean: tensor(-2.3040, device='mps:0')\n",
      "iter_dt 1.03s; iter 54: train loss 0.51346 temperature: 7.69999999999999\n",
      "mean_logits tensor([-2.2453, -2.1744, -2.0205, -1.8525, -2.3849, -2.3625, -2.3210, -2.5250,\n",
      "        -2.3350, -2.3215, -2.6923, -2.1426, -2.3111, -2.4385, -2.3142, -2.2594,\n",
      "        -2.3508, -2.0948, -2.1858, -2.1567, -2.3540, -2.3022, -2.4570, -1.9765,\n",
      "        -1.9787, -2.2152, -2.0935, -2.3658, -1.7115, -1.9562, -2.4654, -2.0671,\n",
      "        -2.1372, -2.0991, -2.3824, -2.6484, -2.3275, -2.0709, -2.3804, -2.2220,\n",
      "        -1.7412, -2.4508, -2.2879, -2.4171, -2.1261, -2.0777, -2.2132, -1.9960,\n",
      "        -2.3627, -2.3266], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3294, -2.2750, -2.3295, -2.3285, -2.3188, -2.2868, -2.3077, -2.3262,\n",
      "        -2.3290, -2.2680, -2.3306, -2.2946, -2.3299, -2.3010, -2.3263, -2.3302,\n",
      "        -2.3245, -2.2915, -2.3123, -2.2804, -2.2785, -2.2816, -2.3154, -2.3087,\n",
      "        -2.3155, -2.2497, -2.3229, -2.3125, -2.2869, -2.3382, -2.3257, -2.2661,\n",
      "        -2.3310, -2.3282, -2.3254, -2.3262, -2.2755, -2.2771, -2.3316, -2.3195,\n",
      "        -2.3234, -2.3226, -2.3189, -2.2760, -2.3217, -2.2926, -2.3264, -2.3320,\n",
      "        -2.3254, -2.3426], device='mps:0')\n",
      "mean: tensor(-2.3104, device='mps:0')\n",
      "iter_dt 1.05s; iter 55: train loss 0.48385 temperature: 7.74999999999999\n",
      "mean_logits tensor([-2.8116, -2.2686, -2.4001, -2.2141, -2.3935, -2.5011, -2.4128, -2.3420,\n",
      "        -2.3729, -1.9968, -2.3587, -2.2642, -2.1750, -2.1140, -2.2278, -2.5077,\n",
      "        -2.7053, -2.2722, -1.9657, -2.4440, -2.3953, -2.2716, -2.1011, -2.0927,\n",
      "        -2.3061, -2.3544, -2.3646, -2.1709, -2.2581, -2.0990, -2.6004, -2.5765,\n",
      "        -2.4694, -2.1621, -2.0595, -2.2351, -2.0568, -2.3241, -2.2678, -2.0375,\n",
      "        -2.4531, -2.5065, -2.4281, -2.1914, -2.3482, -2.2358, -2.0552, -2.3624,\n",
      "        -2.0887, -2.0660], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3282, -2.3298, -2.3224, -2.3097, -2.3295, -2.3264, -2.2940, -2.3308,\n",
      "        -2.3222, -2.3291, -2.3182, -2.3069, -2.3124, -2.3116, -2.3517, -2.3416,\n",
      "        -2.3099, -2.3317, -2.2920, -2.2678, -2.3275, -2.3014, -2.3228, -2.3206,\n",
      "        -2.3126, -2.2818, -2.3101, -2.2865, -2.3180, -2.2598, -2.3127, -2.3150,\n",
      "        -2.2512, -2.3334, -2.2602, -2.2865, -2.2392, -2.3288, -2.3280, -2.2883,\n",
      "        -2.3148, -2.3292, -2.3113, -2.2912, -2.3261, -2.2926, -2.3133, -2.2805,\n",
      "        -2.2767, -2.3247], device='mps:0')\n",
      "mean: tensor(-2.3082, device='mps:0')\n",
      "iter_dt 1.04s; iter 56: train loss 0.42238 temperature: 7.79999999999999\n",
      "mean_logits tensor([-2.6353, -2.1198, -2.4777, -2.5446, -2.0321, -2.0345, -2.5166, -2.7585,\n",
      "        -2.3823, -2.2455, -2.5098, -2.2058, -2.3155, -2.2929, -2.1527, -2.1400,\n",
      "        -2.2535, -2.0863, -1.9816, -2.4406, -2.0552, -2.3754, -2.4287, -2.3470,\n",
      "        -2.4972, -1.9925, -1.9881, -2.2585, -2.3787, -2.3894, -2.1648, -2.3395,\n",
      "        -2.3608, -2.2549, -2.1716, -2.3289, -2.2454, -2.3530, -2.3277, -2.2137,\n",
      "        -2.3045, -2.4084, -2.2714, -2.2667, -2.2396, -2.2039, -2.2814, -2.1480,\n",
      "        -2.3373, -2.1826], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3222, -2.3343, -2.2513, -2.3236, -2.2888, -2.3008, -2.1897, -2.3292,\n",
      "        -2.2594, -2.3173, -2.2723, -2.2898, -2.3455, -2.3159, -2.2515, -2.3314,\n",
      "        -2.3248, -2.2548, -2.3290, -2.3009, -2.3096, -2.3292, -2.2829, -2.3487,\n",
      "        -2.3146, -2.3207, -2.3270, -2.3397, -2.3362, -2.3284, -2.3241, -2.3277,\n",
      "        -2.3089, -2.3290, -2.2981, -2.3259, -2.2680, -2.2710, -2.3165, -2.3251,\n",
      "        -2.3064, -2.3238, -2.3292, -2.3294, -2.3296, -2.3492, -2.3173, -2.3286,\n",
      "        -2.3360, -2.3264], device='mps:0')\n",
      "mean: tensor(-2.3108, device='mps:0')\n",
      "iter_dt 1.04s; iter 57: train loss 0.40908 temperature: 7.84999999999999\n",
      "mean_logits tensor([-2.6728, -2.5540, -2.2363, -2.2007, -2.2586, -2.2529, -1.8491, -2.1798,\n",
      "        -2.3668, -2.3515, -2.2680, -2.2102, -2.4084, -2.1245, -2.2524, -2.3664,\n",
      "        -2.2855, -2.2601, -2.1166, -2.3806, -2.2273, -2.3901, -2.2232, -2.6560,\n",
      "        -2.3546, -2.5002, -2.1892, -2.3373, -2.4264, -2.0434, -2.0930, -2.1671,\n",
      "        -2.4835, -2.2069, -1.9941, -2.3237, -2.4058, -2.2875, -2.0179, -2.1569,\n",
      "        -2.2934, -2.1648, -2.5046, -2.4060, -2.2780, -2.1731, -2.2687, -2.0332,\n",
      "        -1.9677, -2.2804], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3138, -2.3233, -2.3182, -2.3315, -2.3282, -2.3078, -2.3254, -2.3216,\n",
      "        -2.3316, -2.3246, -2.2679, -2.2756, -2.2834, -2.2954, -2.2794, -2.2795,\n",
      "        -2.3296, -2.3243, -2.3152, -2.2880, -2.3159, -2.2882, -2.3029, -2.3273,\n",
      "        -2.2959, -2.2575, -2.3313, -2.2522, -2.2428, -2.3369, -2.3296, -2.2770,\n",
      "        -2.2652, -2.3109, -2.2715, -2.2694, -2.3042, -2.3418, -2.3216, -2.3319,\n",
      "        -2.3176, -2.3123, -2.3242, -2.2570, -2.3224, -2.2760, -2.3264, -2.3383,\n",
      "        -2.3212, -2.3296], device='mps:0')\n",
      "mean: tensor(-2.3053, device='mps:0')\n",
      "iter_dt 1.08s; iter 58: train loss 0.39984 temperature: 7.89999999999999\n",
      "mean_logits tensor([-2.2798, -2.1571, -2.1574, -2.3272, -2.5842, -2.5309, -1.8638, -2.4238,\n",
      "        -2.3280, -2.0116, -2.3631, -2.1877, -2.2515, -2.3069, -2.2616, -2.0830,\n",
      "        -2.4195, -2.3088, -1.8615, -2.4227, -2.3440, -2.0174, -2.2331, -2.2862,\n",
      "        -2.2928, -2.0594, -2.1394, -2.4066, -2.2331, -2.3893, -2.0840, -2.1850,\n",
      "        -2.2078, -2.1976, -2.1369, -2.1589, -2.3587, -2.0657, -2.0161, -1.9103,\n",
      "        -2.2541, -2.4601, -2.2891, -2.0242, -2.4136, -2.3242, -2.5870, -2.0985,\n",
      "        -2.1628, -2.3876], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3092, -2.2702, -2.3210, -2.3086, -2.2834, -2.3416, -2.3189, -2.3038,\n",
      "        -2.3291, -2.3241, -2.2858, -2.3083, -2.3259, -2.3320, -2.2999, -2.3301,\n",
      "        -2.3120, -2.3173, -2.2828, -2.2764, -2.3318, -2.2512, -2.3236, -2.3062,\n",
      "        -2.3377, -2.3178, -2.3257, -2.2883, -2.2916, -2.3375, -2.3380, -2.3487,\n",
      "        -2.3313, -2.2989, -2.2622, -2.3240, -2.3127, -2.3245, -2.3332, -2.3415,\n",
      "        -2.3191, -2.3113, -2.2995, -2.2939, -2.3292, -2.2780, -2.3323, -2.3260,\n",
      "        -2.3270, -2.3240], device='mps:0')\n",
      "mean: tensor(-2.3129, device='mps:0')\n",
      "iter_dt 1.05s; iter 59: train loss 0.42942 temperature: 7.9499999999999895\n",
      "mean_logits tensor([-2.4850, -2.0583, -1.9147, -2.4832, -2.2686, -2.1942, -2.2307, -2.2173,\n",
      "        -2.0788, -2.2627, -2.3328, -2.2646, -2.1622, -2.3362, -2.4419, -2.2601,\n",
      "        -2.0681, -2.3701, -2.4034, -2.4466, -2.3344, -2.5225, -2.4414, -2.3807,\n",
      "        -1.8914, -2.3167, -2.5013, -2.1238, -2.0689, -2.1985, -2.4889, -2.1977,\n",
      "        -2.0060, -2.1803, -2.0776, -2.2243, -1.6175, -2.3630, -2.2705, -2.3338,\n",
      "        -2.3860, -2.5348, -2.1371, -2.4123, -2.5015, -2.3484, -2.3848, -2.0536,\n",
      "        -2.2886, -2.4838], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2390, -2.3110, -2.3273, -2.3294, -2.2550, -2.3294, -2.2674, -2.3156,\n",
      "        -2.3277, -2.3199, -2.3344, -2.3247, -2.3109, -2.3045, -2.3293, -2.3320,\n",
      "        -2.3205, -2.3216, -2.3191, -2.3057, -2.2992, -2.3299, -2.3079, -2.3279,\n",
      "        -2.3215, -2.3028, -2.3277, -2.3269, -2.3317, -2.3366, -2.3163, -2.2991,\n",
      "        -2.3201, -2.3140, -2.3275, -2.3244, -2.3283, -2.3183, -2.3061, -2.3295,\n",
      "        -2.3277, -2.2921, -2.3316, -2.3237, -2.3181, -2.2906, -2.2919, -2.3475,\n",
      "        -2.3289, -2.3031], device='mps:0')\n",
      "mean: tensor(-2.3155, device='mps:0')\n",
      "iter_dt 1.06s; iter 60: train loss 0.40212 temperature: 7.999999999999989\n",
      "mean_logits tensor([-2.2353, -2.1154, -2.3990, -2.1878, -2.4008, -2.3920, -2.2084, -2.2223,\n",
      "        -2.2667, -2.1958, -2.4070, -2.3850, -2.3432, -2.0416, -2.4452, -2.2695,\n",
      "        -2.1410, -2.0181, -2.3716, -2.1344, -2.0163, -2.3448, -2.0201, -2.2183,\n",
      "        -2.7359, -2.6090, -2.2585, -2.2798, -2.2690, -2.0019, -2.4168, -2.2531,\n",
      "        -1.9751, -2.1476, -2.5722, -2.2299, -2.2420, -2.3513, -2.3476, -2.3733,\n",
      "        -2.4705, -2.3608, -2.0149, -2.3029, -1.8773, -2.1922, -2.3814, -2.2744,\n",
      "        -2.3332, -2.1869], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3255, -2.2882, -2.3331, -2.2761, -2.2891, -2.2886, -2.2826, -2.3182,\n",
      "        -2.3116, -2.3093, -2.2708, -2.3317, -2.2951, -2.2765, -2.3244, -2.3132,\n",
      "        -2.3169, -2.3272, -2.3259, -2.2895, -2.3134, -2.3294, -2.3554, -2.3221,\n",
      "        -2.3244, -2.3020, -2.3346, -2.3195, -2.3312, -2.3215, -2.3191, -2.2701,\n",
      "        -2.3147, -2.3295, -2.3344, -2.2800, -2.2773, -2.3164, -2.3022, -2.3255,\n",
      "        -2.2692, -2.2592, -2.3291, -2.3396, -2.3391, -2.2929, -2.3189, -2.3144,\n",
      "        -2.3171, -2.3126], device='mps:0')\n",
      "mean: tensor(-2.3102, device='mps:0')\n",
      "iter_dt 1.05s; iter 61: train loss 0.43301 temperature: 8.04999999999999\n",
      "mean_logits tensor([-1.8047, -2.0789, -2.1912, -2.3176, -2.4395, -2.1560, -2.3519, -2.4771,\n",
      "        -2.2610, -2.2587, -2.0555, -2.4597, -1.9939, -2.3656, -2.6328, -2.2281,\n",
      "        -2.3555, -2.2882, -2.1175, -2.0130, -2.2712, -2.5246, -2.1879, -2.3943,\n",
      "        -2.2813, -2.1656, -2.3874, -1.9200, -2.4004, -2.0558, -2.3808, -2.0521,\n",
      "        -1.9742, -2.2624, -2.3604, -2.1637, -2.1175, -1.9732, -2.0719, -2.4068,\n",
      "        -2.3794, -2.2320, -2.0506, -2.0435, -2.1815, -2.2802, -2.3165, -2.1171,\n",
      "        -2.0481, -2.0912], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3052, -2.2795, -2.3123, -2.3346, -2.2394, -2.3143, -2.3363, -2.3283,\n",
      "        -2.2940, -2.3293, -2.3150, -2.3287, -2.3071, -2.3208, -2.3298, -2.2501,\n",
      "        -2.2128, -2.2851, -2.2903, -2.3007, -2.2862, -2.3195, -2.3138, -2.3141,\n",
      "        -2.3382, -2.3157, -2.3255, -2.2607, -2.3322, -2.3114, -2.3337, -2.3615,\n",
      "        -2.3234, -2.3383, -2.3197, -2.2990, -2.3305, -2.3283, -2.3236, -2.3294,\n",
      "        -2.3259, -2.3144, -2.3043, -2.3238, -2.3110, -2.2583, -2.2943, -2.3360,\n",
      "        -2.3241, -2.3294], device='mps:0')\n",
      "mean: tensor(-2.3108, device='mps:0')\n",
      "iter_dt 1.03s; iter 62: train loss 0.36945 temperature: 8.09999999999999\n",
      "mean_logits tensor([-2.1961, -2.4060, -2.3356, -2.3104, -2.3001, -2.1404, -2.4700, -2.2915,\n",
      "        -2.3926, -2.1404, -2.2510, -2.1883, -2.5919, -2.1250, -2.5090, -2.1607,\n",
      "        -1.9361, -2.1403, -2.0511, -2.5197, -2.4123, -2.3024, -2.1151, -2.2247,\n",
      "        -2.2195, -2.3933, -2.1844, -2.4938, -2.1536, -2.3494, -2.3063, -2.4018,\n",
      "        -2.2891, -2.2272, -2.2857, -2.3619, -2.3273, -2.5760, -2.2107, -2.0720,\n",
      "        -2.3940, -2.2915, -2.2841, -2.3826, -2.4101, -2.4938, -1.8936, -2.6410,\n",
      "        -2.1524, -2.1409], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2998, -2.2546, -2.3016, -2.3338, -2.3316, -2.3294, -2.3038, -2.3126,\n",
      "        -2.2939, -2.3229, -2.3237, -2.3341, -2.3308, -2.3198, -2.3603, -2.3296,\n",
      "        -2.3326, -2.3242, -2.3290, -2.2760, -2.3393, -2.3271, -2.3573, -2.2829,\n",
      "        -2.3072, -2.3177, -2.3055, -2.2558, -2.2832, -2.3102, -2.2872, -2.2340,\n",
      "        -2.2494, -2.3323, -2.3176, -2.3128, -2.3182, -2.3370, -2.2410, -2.3183,\n",
      "        -2.3311, -2.3179, -2.3090, -2.3276, -2.3178, -2.3390, -2.2771, -2.2575,\n",
      "        -2.3293, -2.3123], device='mps:0')\n",
      "mean: tensor(-2.3099, device='mps:0')\n",
      "iter_dt 1.04s; iter 63: train loss 0.30311 temperature: 8.149999999999991\n",
      "mean_logits tensor([-2.3719, -2.2999, -2.3966, -2.3202, -2.4394, -2.3600, -2.3252, -2.5182,\n",
      "        -2.4758, -2.2307, -2.2398, -2.4553, -2.3963, -2.2905, -2.4004, -2.2091,\n",
      "        -2.4721, -2.3488, -2.0332, -1.9771, -2.1941, -2.3352, -2.1113, -1.9365,\n",
      "        -2.3897, -2.4366, -2.3043, -2.3301, -2.0284, -2.4428, -2.3063, -2.2168,\n",
      "        -2.3298, -2.3912, -2.0364, -2.4809, -2.3773, -2.0720, -2.4288, -2.1746,\n",
      "        -1.9954, -2.3142, -2.2653, -2.4804, -1.9159, -2.1941, -2.2642, -2.5674,\n",
      "        -2.0471, -2.3093], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2879, -2.3116, -2.2717, -2.3283, -2.3126, -2.3058, -2.2645, -2.3287,\n",
      "        -2.3027, -2.3272, -2.3276, -2.3190, -2.3370, -2.3299, -2.2255, -2.3287,\n",
      "        -2.3220, -2.2756, -2.2538, -2.2331, -2.3293, -2.3188, -2.3169, -2.3261,\n",
      "        -2.3099, -2.3098, -2.2247, -2.2867, -2.2767, -2.2807, -2.3233, -2.3067,\n",
      "        -2.3280, -2.3292, -2.3144, -2.3084, -2.3278, -2.3256, -2.3298, -2.3099,\n",
      "        -2.2353, -2.2343, -2.3118, -2.3305, -2.3289, -2.3288, -2.3232, -2.3805,\n",
      "        -2.3178, -2.2684], device='mps:0')\n",
      "mean: tensor(-2.3047, device='mps:0')\n",
      "iter_dt 1.23s; iter 64: train loss 0.34889 temperature: 8.199999999999992\n",
      "mean_logits tensor([-2.4284, -2.3058, -2.1480, -2.1053, -2.1755, -2.3596, -2.4053, -2.3039,\n",
      "        -2.3572, -1.9980, -2.1747, -2.1272, -2.2085, -2.2101, -2.4218, -2.1931,\n",
      "        -2.2166, -2.3482, -2.5538, -2.3045, -2.6073, -2.3972, -2.2058, -2.4258,\n",
      "        -2.0382, -2.0842, -1.9705, -2.0356, -2.1877, -2.4687, -2.4044, -2.2912,\n",
      "        -2.4084, -2.2011, -2.1107, -2.3199, -2.2388, -2.1581, -2.1348, -2.2564,\n",
      "        -2.3991, -2.0486, -2.1367, -2.4731, -1.8735, -2.2896, -2.3334, -2.5349,\n",
      "        -2.1034, -2.3021], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3187, -2.3125, -2.3168, -2.3544, -2.3185, -2.3154, -2.3237, -2.3278,\n",
      "        -2.2990, -2.3216, -2.2892, -2.2918, -2.2673, -2.2804, -2.3346, -2.3133,\n",
      "        -2.3032, -2.2918, -2.3154, -2.3246, -2.3275, -2.2795, -2.3233, -2.3258,\n",
      "        -2.3230, -2.2900, -2.3237, -2.3166, -2.2923, -2.2834, -2.3438, -2.2725,\n",
      "        -2.3284, -2.3113, -2.3272, -2.3188, -2.2987, -2.2867, -2.3280, -2.2674,\n",
      "        -2.3370, -2.3309, -2.3128, -2.3051, -2.3463, -2.3296, -2.3249, -2.3343,\n",
      "        -2.3106, -2.3134], device='mps:0')\n",
      "mean: tensor(-2.3127, device='mps:0')\n",
      "iter_dt 1.05s; iter 65: train loss 0.31053 temperature: 8.249999999999993\n",
      "mean_logits tensor([-2.2424, -2.4332, -2.0507, -2.2490, -2.5460, -2.3076, -2.1865, -2.1744,\n",
      "        -2.0172, -2.2944, -2.3113, -1.8982, -2.3713, -2.2077, -2.1178, -2.4238,\n",
      "        -2.2980, -2.2593, -2.2294, -2.4477, -2.2596, -2.1613, -2.3467, -2.3906,\n",
      "        -2.3552, -2.2045, -2.1221, -2.5473, -2.2449, -2.3058, -2.2230, -2.5152,\n",
      "        -2.4685, -2.4512, -2.3150, -2.2295, -2.3484, -2.2951, -2.3023, -2.2892,\n",
      "        -2.6582, -2.3089, -2.3713, -2.1358, -2.2063, -2.1286, -2.0558, -2.5090,\n",
      "        -2.2003, -2.5695], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2465, -2.3048, -2.3276, -2.3286, -2.3372, -2.2723, -2.3332, -2.3386,\n",
      "        -2.3300, -2.3208, -2.3166, -2.3322, -2.3362, -2.3353, -2.2741, -2.3388,\n",
      "        -2.3195, -2.2948, -2.3367, -2.2819, -2.3008, -2.2681, -2.3174, -2.2864,\n",
      "        -2.3112, -2.3263, -2.2914, -2.3305, -2.3011, -2.3265, -2.3104, -2.3245,\n",
      "        -2.2917, -2.3302, -2.2914, -2.3185, -2.3281, -2.3327, -2.3283, -2.3205,\n",
      "        -2.2975, -2.3323, -2.3257, -2.3129, -2.2705, -2.2809, -2.2493, -2.3331,\n",
      "        -2.3017, -2.2977], device='mps:0')\n",
      "mean: tensor(-2.3109, device='mps:0')\n",
      "iter_dt 1.04s; iter 66: train loss 0.31049 temperature: 8.299999999999994\n",
      "mean_logits tensor([-2.2937, -2.4846, -2.3915, -2.1676, -2.1404, -2.1823, -2.3831, -2.2974,\n",
      "        -2.2807, -2.1921, -2.1192, -2.1859, -2.1824, -2.2759, -2.1092, -2.3030,\n",
      "        -2.2333, -2.1488, -2.3083, -2.4406, -2.1539, -2.0367, -1.8849, -2.5064,\n",
      "        -2.4024, -2.4493, -2.4806, -2.6911, -2.2512, -2.3136, -2.1990, -2.3984,\n",
      "        -2.2237, -2.4508, -1.9340, -2.4756, -2.3527, -2.1464, -2.2960, -2.1008,\n",
      "        -2.3764, -2.2457, -2.0484, -2.2496, -2.3924, -2.3342, -2.0065, -2.3569,\n",
      "        -2.4318, -2.3491], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3143, -2.3120, -2.3312, -2.3058, -2.2338, -2.3092, -2.3290, -2.3292,\n",
      "        -2.3104, -2.3091, -2.3196, -2.3146, -2.3308, -2.3356, -2.2947, -2.3310,\n",
      "        -2.3080, -2.3266, -2.3291, -2.3339, -2.3313, -2.2414, -2.3071, -2.3298,\n",
      "        -2.2599, -2.3211, -2.3251, -2.3314, -2.3298, -2.2913, -2.3049, -2.3301,\n",
      "        -2.2899, -2.3094, -2.3286, -2.3300, -2.2665, -2.2938, -2.2821, -2.2597,\n",
      "        -2.3343, -2.3277, -2.3070, -2.3337, -2.2765, -2.3236, -2.3317, -2.2907,\n",
      "        -2.3252, -2.3291], device='mps:0')\n",
      "mean: tensor(-2.3110, device='mps:0')\n",
      "iter_dt 1.04s; iter 67: train loss 0.30063 temperature: 8.349999999999994\n",
      "mean_logits tensor([-2.2287, -2.3873, -2.1475, -2.2909, -2.4420, -2.4311, -2.3064, -2.3338,\n",
      "        -2.1726, -2.3432, -2.0370, -2.2584, -2.5498, -2.2141, -1.9488, -2.1850,\n",
      "        -2.2152, -2.5467, -2.1879, -2.1966, -2.0564, -2.2469, -2.1345, -2.3645,\n",
      "        -2.3061, -2.4044, -2.3130, -2.3525, -2.5346, -2.3679, -2.4380, -2.1894,\n",
      "        -2.4634, -2.2053, -2.2426, -2.1721, -2.3391, -2.5106, -2.3804, -2.2636,\n",
      "        -2.1919, -2.2277, -1.9694, -2.6024, -2.4489, -2.0756, -2.1798, -2.2835,\n",
      "        -2.4726, -2.4218], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3370, -2.3402, -2.2599, -2.3568, -2.3182, -2.3490, -2.3345, -2.3196,\n",
      "        -2.3286, -2.3269, -2.3293, -2.2519, -2.3201, -2.3366, -2.2730, -2.2567,\n",
      "        -2.2936, -2.3092, -2.3235, -2.3111, -2.3297, -2.3161, -2.2930, -2.3279,\n",
      "        -2.2787, -2.3305, -2.3345, -2.3283, -2.2546, -2.3277, -2.3329, -2.3390,\n",
      "        -2.2760, -2.3317, -2.3279, -2.2522, -2.3178, -2.3112, -2.2874, -2.2253,\n",
      "        -2.3265, -2.3294, -2.2955, -2.3239, -2.3390, -2.3278, -2.3239, -2.3082,\n",
      "        -2.3096, -2.3049], device='mps:0')\n",
      "mean: tensor(-2.3117, device='mps:0')\n",
      "iter_dt 1.06s; iter 68: train loss 0.62080 temperature: 8.399999999999995\n",
      "mean_logits tensor([-2.5192, -1.8578, -2.4607, -2.1998, -2.1990, -1.8017, -2.2306, -2.0325,\n",
      "        -2.4934, -2.3499, -2.0533, -2.1939, -2.0722, -2.2381, -2.3151, -2.4254,\n",
      "        -2.1066, -2.2259, -2.1526, -2.3651, -2.3440, -2.8058, -2.1394, -2.1883,\n",
      "        -2.1979, -2.1225, -2.6822, -2.2601, -2.1675, -1.9514, -2.1944, -2.4605,\n",
      "        -2.5590, -2.0365, -2.5186, -2.3931, -2.2929, -2.1770, -2.2668, -2.3444,\n",
      "        -2.2060, -2.4063, -2.0369, -2.3846, -2.0960, -2.1397, -2.5514, -2.5395,\n",
      "        -2.1858, -1.9944], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3117, -2.3173, -2.2488, -2.2844, -2.3273, -2.2327, -2.3392, -2.3285,\n",
      "        -2.3340, -2.2892, -2.3147, -2.3255, -2.3142, -2.3290, -2.3305, -2.3276,\n",
      "        -2.3514, -2.3233, -2.3255, -2.3237, -2.3257, -2.3130, -2.3283, -2.2907,\n",
      "        -2.3249, -2.3229, -2.2558, -2.2805, -2.3347, -2.3363, -2.3349, -2.2545,\n",
      "        -2.3191, -2.3298, -2.3191, -2.3099, -2.3303, -2.3100, -2.3048, -2.3243,\n",
      "        -2.2669, -2.3291, -2.3031, -2.2524, -2.3398, -2.3262, -2.2893, -2.3253,\n",
      "        -2.3231, -2.2978], device='mps:0')\n",
      "mean: tensor(-2.3116, device='mps:0')\n",
      "iter_dt 1.03s; iter 69: train loss 0.36102 temperature: 8.449999999999996\n",
      "mean_logits tensor([-2.3761, -2.1774, -2.2896, -2.3031, -2.3051, -2.3967, -1.7756, -2.3203,\n",
      "        -2.3460, -2.0797, -2.2839, -1.8701, -2.3054, -2.2244, -2.1757, -2.0890,\n",
      "        -2.1389, -2.2595, -2.1796, -2.3097, -2.3769, -1.9631, -2.3615, -2.2804,\n",
      "        -2.2892, -2.4222, -2.2034, -2.3284, -1.8648, -2.1775, -1.9627, -2.1013,\n",
      "        -2.3808, -2.1489, -2.3072, -2.3398, -2.4287, -2.3695, -2.0665, -2.3794,\n",
      "        -2.1270, -2.2584, -2.3672, -2.4781, -2.1115, -2.5844, -2.3687, -2.5443,\n",
      "        -2.2020, -2.3277], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3081, -2.3375, -2.3227, -2.3234, -2.3212, -2.3295, -2.2896, -2.3079,\n",
      "        -2.3187, -2.3324, -2.3069, -2.3039, -2.2898, -2.2959, -2.3321, -2.2909,\n",
      "        -2.3223, -2.3182, -2.2103, -2.3284, -2.3265, -2.3442, -2.3836, -2.3185,\n",
      "        -2.2918, -2.2806, -2.3315, -2.3345, -2.3246, -2.3246, -2.3324, -2.2945,\n",
      "        -2.3058, -2.3102, -2.3227, -2.3375, -2.3198, -2.3280, -2.3116, -2.3199,\n",
      "        -2.3164, -2.3016, -2.3039, -2.2865, -2.3566, -2.3167, -2.3264, -2.2900,\n",
      "        -2.3270, -2.3309], device='mps:0')\n",
      "mean: tensor(-2.3158, device='mps:0')\n",
      "iter_dt 1.02s; iter 70: train loss 0.48231 temperature: 8.499999999999996\n",
      "mean_logits tensor([-2.3236, -2.3408, -2.5082, -2.2239, -2.1353, -2.4143, -2.6365, -2.0274,\n",
      "        -2.5707, -2.2836, -2.4293, -2.3821, -2.3304, -2.1873, -2.4629, -2.1252,\n",
      "        -2.2228, -2.4154, -2.3498, -2.1265, -2.2187, -2.3546, -2.4038, -2.6349,\n",
      "        -2.2120, -2.3220, -2.2786, -2.1934, -2.3613, -2.3393, -2.1639, -2.0012,\n",
      "        -1.9973, -2.2836, -2.2218, -1.9816, -2.0609, -2.0981, -2.1926, -2.7549,\n",
      "        -2.2204, -2.1990, -2.6225, -2.5178, -2.5273, -2.3400, -2.4175, -2.4856,\n",
      "        -2.1291, -2.3525], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3089, -2.2907, -2.3063, -2.3203, -2.3192, -2.3288, -2.3129, -2.3110,\n",
      "        -2.3109, -2.1887, -2.2841, -2.3190, -2.3361, -2.3164, -2.3180, -2.3254,\n",
      "        -2.3151, -2.2969, -2.3223, -2.3301, -2.3185, -2.3153, -2.3114, -2.3309,\n",
      "        -2.2952, -2.2824, -2.3243, -2.3276, -2.2923, -2.3129, -2.3293, -2.2594,\n",
      "        -2.2506, -2.3261, -2.3105, -2.3552, -2.3115, -2.3180, -2.3269, -2.2737,\n",
      "        -2.3463, -2.3610, -2.3352, -2.3056, -2.3391, -2.3293, -2.3040, -2.3305,\n",
      "        -2.2589, -2.2855], device='mps:0')\n",
      "mean: tensor(-2.3106, device='mps:0')\n",
      "iter_dt 1.07s; iter 71: train loss 0.42963 temperature: 8.549999999999997\n",
      "mean_logits tensor([-2.4136, -2.2602, -2.3617, -2.2981, -1.9736, -2.2074, -2.0947, -2.0622,\n",
      "        -2.6505, -2.2827, -2.3060, -2.3394, -2.7318, -2.2115, -2.4140, -2.3419,\n",
      "        -2.3938, -2.3415, -2.2792, -2.2599, -2.5986, -2.1197, -2.2548, -2.2893,\n",
      "        -2.1233, -2.3754, -2.2415, -2.1833, -2.1909, -2.0378, -2.2469, -2.2910,\n",
      "        -2.2152, -2.4584, -2.2625, -2.4185, -2.2451, -2.0619, -2.3337, -2.2246,\n",
      "        -2.4353, -2.1571, -2.2233, -2.0772, -2.1619, -2.4129, -2.1352, -1.7545,\n",
      "        -2.6375, -2.0798], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3110, -2.3029, -2.2554, -2.2693, -2.2926, -2.3236, -2.3131, -2.3044,\n",
      "        -2.3178, -2.3171, -2.2937, -2.3292, -2.3287, -2.2881, -2.3317, -2.3055,\n",
      "        -2.3462, -2.3335, -2.2467, -2.3019, -2.2996, -2.2787, -2.2686, -2.2690,\n",
      "        -2.2957, -2.3077, -2.3258, -2.3219, -2.2930, -2.3026, -2.3354, -2.2601,\n",
      "        -2.3061, -2.2606, -2.3244, -2.3308, -2.3288, -2.3253, -2.3536, -2.2762,\n",
      "        -2.3403, -2.3304, -2.3257, -2.3245, -2.3293, -2.3091, -2.3068, -2.3054,\n",
      "        -2.2918, -2.3117], device='mps:0')\n",
      "mean: tensor(-2.3070, device='mps:0')\n",
      "iter_dt 1.15s; iter 72: train loss 0.35456 temperature: 8.599999999999998\n",
      "mean_logits tensor([-2.5272, -2.2430, -2.1415, -2.5090, -2.4707, -2.4091, -2.4452, -2.5478,\n",
      "        -2.4139, -2.4605, -2.2690, -2.5326, -2.3863, -2.5612, -2.2524, -2.3238,\n",
      "        -2.2969, -2.4020, -2.1203, -2.2712, -2.3734, -2.2179, -2.1377, -2.0605,\n",
      "        -2.5743, -2.0165, -2.2191, -1.9950, -2.1506, -2.1734, -2.2659, -2.3820,\n",
      "        -2.5162, -2.2245, -2.2547, -2.2662, -2.4668, -2.0419, -2.4138, -2.4567,\n",
      "        -2.1676, -2.0786, -2.1672, -2.3376, -2.0882, -2.2817, -2.1839, -2.2325,\n",
      "        -2.2833, -2.2059], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3204, -2.3122, -2.3132, -2.3209, -2.3109, -2.2919, -2.3266, -2.2590,\n",
      "        -2.2673, -2.2999, -2.3179, -2.3217, -2.3027, -2.3228, -2.2860, -2.3299,\n",
      "        -2.3295, -2.2762, -2.3174, -2.3260, -2.2533, -2.2707, -2.3124, -2.3337,\n",
      "        -2.3106, -2.3204, -2.3296, -2.3394, -2.3036, -2.3047, -2.2968, -2.2802,\n",
      "        -2.3322, -2.3191, -2.2592, -2.3310, -2.3103, -2.2866, -2.3244, -2.3014,\n",
      "        -2.3313, -2.3369, -2.3145, -2.3432, -2.3318, -2.3153, -2.2976, -2.3234,\n",
      "        -2.2750, -2.3079], device='mps:0')\n",
      "mean: tensor(-2.3090, device='mps:0')\n",
      "iter_dt 1.13s; iter 73: train loss 0.49576 temperature: 8.649999999999999\n",
      "mean_logits tensor([-2.2452, -2.6028, -2.5386, -2.2645, -2.4604, -2.3108, -2.4337, -2.2475,\n",
      "        -2.4557, -2.2256, -2.1391, -2.4313, -2.1098, -2.5881, -2.0759, -2.1130,\n",
      "        -2.4688, -2.6715, -2.3139, -2.4340, -2.1738, -2.2236, -2.2945, -2.3655,\n",
      "        -2.4830, -2.4278, -2.4016, -2.6819, -2.2435, -2.1985, -2.4120, -2.2838,\n",
      "        -2.3262, -2.4842, -2.3221, -2.2554, -2.1246, -2.4519, -2.1098, -2.2226,\n",
      "        -2.2239, -2.2627, -2.2149, -2.1900, -2.4313, -2.6236, -2.6711, -1.9308,\n",
      "        -1.9042, -2.4049], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3218, -2.3478, -2.3071, -2.3527, -2.3194, -2.3313, -2.3070, -2.2939,\n",
      "        -2.2876, -2.3271, -2.3349, -2.3275, -2.3459, -2.3282, -2.3268, -2.3198,\n",
      "        -2.2924, -2.3205, -2.3097, -2.2362, -2.3207, -2.3268, -2.2661, -2.2927,\n",
      "        -2.3286, -2.3017, -2.3026, -2.3170, -2.3549, -2.3334, -2.3294, -2.2944,\n",
      "        -2.3102, -2.3308, -2.3302, -2.3125, -2.3265, -2.3448, -2.3280, -2.2659,\n",
      "        -2.3358, -2.3300, -2.3289, -2.3197, -2.3254, -2.3292, -2.3102, -2.3319,\n",
      "        -2.2554, -2.3040], device='mps:0')\n",
      "mean: tensor(-2.3165, device='mps:0')\n",
      "iter_dt 1.06s; iter 74: train loss 0.42639 temperature: 8.7\n",
      "mean_logits tensor([-2.0822, -2.6939, -2.7301, -2.1292, -2.4975, -2.1162, -2.2748, -2.4225,\n",
      "        -2.0904, -2.1341, -1.9983, -2.2079, -2.3373, -2.4810, -2.2391, -2.1841,\n",
      "        -2.1439, -2.4858, -2.1524, -2.3895, -2.3679, -2.4319, -2.2903, -2.4157,\n",
      "        -2.5301, -2.2328, -2.1660, -2.2640, -2.1812, -2.4784, -2.1680, -2.1334,\n",
      "        -2.2739, -2.3009, -2.6752, -2.3392, -2.1315, -2.3659, -2.2644, -2.5344,\n",
      "        -2.3116, -2.4634, -2.3813, -2.4406, -2.0535, -2.2694, -2.4228, -2.4191,\n",
      "        -2.2472, -2.3989], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3301, -2.3851, -2.2805, -2.3208, -2.2874, -2.3377, -2.3205, -2.2975,\n",
      "        -2.3159, -2.2598, -2.3288, -2.2659, -2.3416, -2.2389, -2.3288, -2.2791,\n",
      "        -2.2199, -2.3302, -2.3239, -2.3157, -2.3058, -2.3291, -2.2940, -2.3143,\n",
      "        -2.3296, -2.2860, -2.2592, -2.3269, -2.3290, -2.3129, -2.2653, -2.3291,\n",
      "        -2.2994, -2.3237, -2.3075, -2.2955, -2.3050, -2.3326, -2.3280, -2.3240,\n",
      "        -2.3169, -2.3272, -2.2911, -2.3293, -2.2723, -2.3291, -2.3140, -2.2517,\n",
      "        -2.2832, -2.2732], device='mps:0')\n",
      "mean: tensor(-2.3059, device='mps:0')\n",
      "iter_dt 1.04s; iter 75: train loss 0.36155 temperature: 8.75\n",
      "mean_logits tensor([-2.5048, -2.2844, -2.3727, -2.3082, -2.4414, -2.2820, -1.9579, -2.4605,\n",
      "        -2.2422, -2.2184, -2.2060, -2.3742, -2.4089, -2.2445, -2.2647, -2.2359,\n",
      "        -2.2685, -2.3593, -2.5215, -2.1306, -1.9406, -2.2073, -2.1277, -2.3164,\n",
      "        -2.5578, -2.4186, -2.3904, -2.4491, -2.3298, -2.4042, -2.2958, -2.1508,\n",
      "        -2.2063, -2.3276, -2.4805, -2.1966, -2.2824, -1.8891, -2.3831, -1.9937,\n",
      "        -2.5290, -2.0506, -2.3026, -2.2928, -2.1288, -2.0823, -2.6116, -2.3619,\n",
      "        -2.4721, -2.5127], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3213, -2.3250, -2.3604, -2.3369, -2.3801, -2.2817, -2.3286, -2.3288,\n",
      "        -2.3017, -2.3393, -2.3304, -2.3323, -2.3078, -2.2732, -2.3042, -2.3179,\n",
      "        -2.3547, -2.3312, -2.3136, -2.3135, -2.2927, -2.3207, -2.3132, -2.2653,\n",
      "        -2.2941, -2.2339, -2.2519, -2.3245, -2.2712, -2.2982, -2.2847, -2.3235,\n",
      "        -2.2902, -2.3227, -2.2840, -2.3307, -2.3234, -2.3181, -2.3042, -2.3226,\n",
      "        -2.3179, -2.3288, -2.3326, -2.2900, -2.3134, -2.3217, -2.3292, -2.3173,\n",
      "        -2.3024, -2.3038], device='mps:0')\n",
      "mean: tensor(-2.3122, device='mps:0')\n",
      "iter_dt 1.04s; iter 76: train loss 0.26055 temperature: 8.8\n",
      "mean_logits tensor([-1.8337, -2.4230, -2.3743, -2.2291, -2.2575, -2.3955, -2.2196, -2.3405,\n",
      "        -2.2994, -2.2856, -2.4310, -2.2759, -2.1484, -2.1679, -2.1154, -2.3044,\n",
      "        -2.2169, -2.4850, -2.3820, -2.1597, -2.3345, -2.3984, -2.2308, -2.4005,\n",
      "        -2.2363, -2.4994, -2.4849, -2.5030, -2.2889, -2.6413, -2.3319, -2.3333,\n",
      "        -2.2202, -2.3372, -2.4843, -2.2065, -2.0163, -2.2240, -2.4490, -2.1482,\n",
      "        -2.1560, -2.3622, -2.3792, -2.2968, -2.2753, -2.0317, -2.4480, -2.3150,\n",
      "        -2.1271, -2.2215], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3356, -2.3133, -2.3022, -2.3325, -2.3295, -2.2798, -2.3134, -2.2755,\n",
      "        -2.2854, -2.3228, -2.3148, -2.3087, -2.3192, -2.3130, -2.3295, -2.2875,\n",
      "        -2.2358, -2.3282, -2.3207, -2.2398, -2.3283, -2.3182, -2.3387, -2.3593,\n",
      "        -2.3275, -2.3201, -2.3282, -2.3193, -2.3360, -2.3623, -2.3253, -2.3286,\n",
      "        -2.3426, -2.3180, -2.3406, -2.3315, -2.3000, -2.3152, -2.3305, -2.3137,\n",
      "        -2.3263, -2.3306, -2.3234, -2.3117, -2.3270, -2.3300, -2.3283, -2.3285,\n",
      "        -2.3298, -2.3373], device='mps:0')\n",
      "mean: tensor(-2.3189, device='mps:0')\n",
      "iter_dt 1.04s; iter 77: train loss 0.35517 temperature: 8.850000000000001\n",
      "mean_logits tensor([-2.4263, -2.3197, -2.3131, -2.1824, -2.6065, -2.2438, -2.1220, -2.2266,\n",
      "        -2.1743, -2.3048, -2.3288, -2.3523, -2.1612, -2.2897, -2.4624, -2.3213,\n",
      "        -2.1894, -2.4219, -2.5928, -2.1661, -2.3759, -1.9683, -2.1335, -2.1826,\n",
      "        -2.2698, -2.4048, -2.3983, -2.1441, -2.2331, -2.0343, -2.3549, -2.1262,\n",
      "        -2.0056, -2.1424, -2.0691, -2.0557, -2.2973, -2.3078, -2.5149, -2.0778,\n",
      "        -2.3644, -2.4814, -1.9554, -2.3296, -2.0436, -2.4055, -2.1125, -2.1171,\n",
      "        -2.4203, -2.0950], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3285, -2.3264, -2.3288, -2.2590, -2.3286, -2.3321, -2.3152, -2.2982,\n",
      "        -2.2334, -2.2694, -2.3101, -2.3257, -2.3296, -2.3305, -2.3295, -2.2683,\n",
      "        -2.3089, -2.3108, -2.3298, -2.3247, -2.3100, -2.3279, -2.3511, -2.3013,\n",
      "        -2.2927, -2.3134, -2.3119, -2.3095, -2.3296, -2.2859, -2.3531, -2.3367,\n",
      "        -2.3227, -2.3276, -2.3087, -2.3384, -2.3344, -2.3294, -2.2651, -2.3262,\n",
      "        -2.2970, -2.3178, -2.3064, -2.2977, -2.2858, -2.3253, -2.3012, -2.3281,\n",
      "        -2.3170, -2.3298], device='mps:0')\n",
      "mean: tensor(-2.3134, device='mps:0')\n",
      "iter_dt 1.04s; iter 78: train loss 0.30441 temperature: 8.900000000000002\n",
      "mean_logits tensor([-2.1546, -2.6668, -2.2325, -2.4561, -2.2671, -2.3752, -2.0613, -2.2098,\n",
      "        -2.3056, -2.1214, -2.2915, -2.4143, -2.1940, -2.0959, -2.3454, -2.3395,\n",
      "        -2.5022, -2.2354, -2.2564, -2.3113, -2.1227, -2.3857, -2.3834, -2.4006,\n",
      "        -2.4248, -2.3198, -2.2870, -2.2110, -2.3717, -2.4323, -2.2064, -2.2160,\n",
      "        -1.9252, -2.3855, -2.4443, -2.0730, -2.3674, -2.2573, -2.4718, -2.1185,\n",
      "        -2.2286, -2.2527, -2.1593, -1.9488, -2.2229, -2.2741, -2.5546, -2.1087,\n",
      "        -2.1260, -2.3678], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2565, -2.2686, -2.3291, -2.2419, -2.3256, -2.3269, -2.3284, -2.3275,\n",
      "        -2.3191, -2.2751, -2.3274, -2.3272, -2.3223, -2.2818, -2.3303, -2.3137,\n",
      "        -2.2908, -2.2593, -2.2840, -2.3340, -2.3114, -2.3013, -2.2797, -2.3109,\n",
      "        -2.3358, -2.3406, -2.3053, -2.2740, -2.2883, -2.3216, -2.3260, -2.2326,\n",
      "        -2.3305, -2.3021, -2.3308, -2.2920, -2.3276, -2.3095, -2.2945, -2.3283,\n",
      "        -2.3284, -2.3459, -2.3337, -2.2732, -2.3086, -2.3281, -2.3368, -2.3073,\n",
      "        -2.3280, -2.3039], device='mps:0')\n",
      "mean: tensor(-2.3081, device='mps:0')\n",
      "iter_dt 1.03s; iter 79: train loss 0.41732 temperature: 8.950000000000003\n",
      "mean_logits tensor([-2.6042, -2.3346, -2.1160, -2.1811, -2.3290, -2.1456, -2.3227, -2.2715,\n",
      "        -2.4597, -2.1977, -2.3729, -2.2793, -2.7619, -2.3385, -2.1607, -2.0901,\n",
      "        -2.4695, -2.2098, -2.3478, -2.3601, -2.4124, -2.3365, -2.2043, -2.2541,\n",
      "        -2.1025, -2.2094, -2.0519, -2.2828, -2.1643, -2.2035, -2.1103, -2.3620,\n",
      "        -2.1699, -2.5064, -2.3223, -2.2381, -2.2484, -2.3139, -2.5528, -2.1355,\n",
      "        -2.3525, -2.3424, -2.6533, -2.0324, -2.4798, -2.6105, -2.3480, -2.5357,\n",
      "        -2.3237, -2.2601], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3189, -2.3146, -2.3105, -2.3087, -2.3272, -2.2962, -2.3297, -2.3132,\n",
      "        -2.3109, -2.3261, -2.3301, -2.3170, -2.3286, -2.3234, -2.2860, -2.3321,\n",
      "        -2.3015, -2.3083, -2.2938, -2.3093, -2.3342, -2.3392, -2.2879, -2.3292,\n",
      "        -2.3363, -2.3268, -2.2862, -2.3187, -2.3387, -2.2544, -2.3191, -2.3039,\n",
      "        -2.3478, -2.3090, -2.3136, -2.3189, -2.3337, -2.3298, -2.2870, -2.3263,\n",
      "        -2.2988, -2.3298, -2.2726, -2.3286, -2.2786, -2.3279, -2.3344, -2.3327,\n",
      "        -2.3094, -2.3194], device='mps:0')\n",
      "mean: tensor(-2.3152, device='mps:0')\n",
      "iter_dt 1.06s; iter 80: train loss 0.23224 temperature: 9.000000000000004\n",
      "mean_logits tensor([-2.2838, -2.3001, -2.3726, -2.3211, -2.3841, -2.3641, -2.4550, -2.2363,\n",
      "        -2.1681, -2.2453, -2.0170, -2.3669, -2.4770, -2.4606, -2.3380, -2.3015,\n",
      "        -2.2175, -2.3078, -2.3940, -2.4314, -2.2410, -2.2908, -2.1542, -2.4348,\n",
      "        -2.1890, -2.4174, -2.2293, -2.3221, -2.5110, -2.1517, -2.2630, -2.3374,\n",
      "        -2.5199, -2.2646, -2.4418, -2.6079, -2.1499, -2.0422, -2.2982, -2.3595,\n",
      "        -2.3232, -2.4867, -2.3852, -2.5215, -2.5935, -2.3408, -2.4166, -2.3810,\n",
      "        -2.1199, -2.3745], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3177, -2.3226, -2.2914, -2.3206, -2.3183, -2.3349, -2.3294, -2.3551,\n",
      "        -2.3272, -2.3309, -2.3249, -2.3278, -2.3319, -2.3287, -2.3273, -2.3169,\n",
      "        -2.2687, -2.3227, -2.3301, -2.3170, -2.3245, -2.3181, -2.2920, -2.3210,\n",
      "        -2.3097, -2.3383, -2.2883, -2.2741, -2.2947, -2.2787, -2.3108, -2.2903,\n",
      "        -2.3109, -2.3196, -2.3305, -2.3295, -2.3058, -2.3308, -2.3318, -2.2816,\n",
      "        -2.2698, -2.3098, -2.3356, -2.3615, -2.3211, -2.3366, -2.3301, -2.2917,\n",
      "        -2.2760, -2.3151], device='mps:0')\n",
      "mean: tensor(-2.3155, device='mps:0')\n",
      "iter_dt 1.08s; iter 81: train loss 0.39180 temperature: 9.050000000000004\n",
      "mean_logits tensor([-2.1919, -2.3678, -2.0788, -2.2350, -2.2527, -2.3113, -2.3462, -2.3241,\n",
      "        -2.1357, -2.3906, -2.0553, -2.4080, -2.3168, -2.4148, -2.0216, -2.4463,\n",
      "        -2.2496, -1.9094, -2.2845, -2.1999, -2.6348, -2.4642, -2.1966, -2.3923,\n",
      "        -2.0305, -2.1400, -2.2607, -2.1198, -2.6293, -2.2938, -2.2511, -2.5034,\n",
      "        -2.6687, -2.3824, -2.5244, -2.1326, -2.1345, -2.2732, -2.5731, -2.2221,\n",
      "        -2.5128, -2.3743, -2.0785, -2.4500, -2.4803, -2.3953, -2.1335, -2.3383,\n",
      "        -2.4150, -2.2507], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3126, -2.3016, -2.2656, -2.3359, -2.3315, -2.3370, -2.3318, -2.3097,\n",
      "        -2.2692, -2.3105, -2.3280, -2.3222, -2.3173, -2.3446, -2.3256, -2.3035,\n",
      "        -2.3035, -2.3318, -2.2921, -2.3254, -2.3593, -2.3025, -2.3273, -2.3218,\n",
      "        -2.2945, -2.3195, -2.3215, -2.3162, -2.3074, -2.3298, -2.3241, -2.3251,\n",
      "        -2.3500, -2.3221, -2.2819, -2.2877, -2.3219, -2.3259, -2.2939, -2.3119,\n",
      "        -2.3265, -2.3167, -2.2766, -2.3026, -2.3244, -2.3087, -2.3076, -2.3398,\n",
      "        -2.3147, -2.3198], device='mps:0')\n",
      "mean: tensor(-2.3156, device='mps:0')\n",
      "iter_dt 1.04s; iter 82: train loss 0.41215 temperature: 9.100000000000005\n",
      "mean_logits tensor([-2.0394, -2.2031, -2.3393, -2.4742, -2.4177, -2.4654, -1.9368, -2.2029,\n",
      "        -2.2970, -2.3192, -2.3667, -2.4993, -2.1479, -2.1343, -2.0843, -2.3829,\n",
      "        -2.4691, -2.1643, -2.1093, -2.4573, -2.3416, -2.2214, -2.4265, -2.2174,\n",
      "        -2.4113, -2.5890, -2.2592, -2.4687, -2.3754, -2.4044, -2.5963, -2.1135,\n",
      "        -2.1847, -1.9411, -2.4184, -2.4078, -1.9165, -2.1923, -2.4095, -2.2356,\n",
      "        -2.2715, -2.1822, -2.1016, -2.4531, -2.4355, -2.5446, -2.3370, -2.4812,\n",
      "        -1.9597, -2.3867], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3401, -2.3230, -2.2667, -2.3372, -2.2745, -2.3333, -2.3305, -2.3333,\n",
      "        -2.3386, -2.3152, -2.3121, -2.3133, -2.3288, -2.3206, -2.3262, -2.3267,\n",
      "        -2.2918, -2.3193, -2.3237, -2.3287, -2.3036, -2.3144, -2.2512, -2.3289,\n",
      "        -2.2940, -2.3279, -2.3101, -2.2986, -2.3437, -2.3358, -2.2955, -2.3369,\n",
      "        -2.2768, -2.3239, -2.2012, -2.2182, -2.3294, -2.2656, -2.2898, -2.2849,\n",
      "        -2.3065, -2.3153, -2.2756, -2.3320, -2.3126, -2.3067, -2.2789, -2.3194,\n",
      "        -2.2639, -2.3482], device='mps:0')\n",
      "mean: tensor(-2.3075, device='mps:0')\n",
      "iter_dt 1.05s; iter 83: train loss 0.42600 temperature: 9.150000000000006\n",
      "mean_logits tensor([-2.3506, -2.2555, -2.4136, -2.3257, -2.5089, -2.5119, -2.0553, -2.3761,\n",
      "        -2.3378, -2.4437, -2.6045, -2.5075, -2.2028, -2.0350, -2.3360, -2.0768,\n",
      "        -2.3831, -2.1312, -2.1480, -2.3739, -2.5925, -2.4557, -2.0078, -2.2038,\n",
      "        -2.0887, -2.1572, -2.1375, -2.4604, -2.1636, -2.3065, -2.1077, -2.6664,\n",
      "        -2.2263, -2.4208, -2.5081, -2.3404, -2.4841, -2.3643, -2.0218, -2.4130,\n",
      "        -2.3388, -2.1676, -1.9600, -2.5468, -2.4307, -2.1788, -2.1766, -2.1898,\n",
      "        -2.2671, -2.3432], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3247, -2.3167, -2.3297, -2.3895, -2.3155, -2.2969, -2.3359, -2.3248,\n",
      "        -2.3087, -2.3262, -2.3134, -2.2700, -2.3082, -2.3425, -2.3650, -2.3271,\n",
      "        -2.2987, -2.2725, -2.2538, -2.3331, -2.2937, -2.3123, -2.3216, -2.3285,\n",
      "        -2.2929, -2.2818, -2.3288, -2.3377, -2.2770, -2.3255, -2.3299, -2.3258,\n",
      "        -2.3019, -2.2481, -2.3287, -2.2589, -2.3272, -2.3148, -2.3254, -2.2780,\n",
      "        -2.3312, -2.2738, -2.3283, -2.3151, -2.3291, -2.3321, -2.2924, -2.3277,\n",
      "        -2.3313, -2.3133], device='mps:0')\n",
      "mean: tensor(-2.3133, device='mps:0')\n",
      "iter_dt 1.05s; iter 84: train loss 0.41390 temperature: 9.200000000000006\n",
      "mean_logits tensor([-2.3252, -2.4571, -2.1271, -2.4224, -2.2844, -2.4675, -2.1641, -2.4367,\n",
      "        -1.9924, -2.2002, -2.3345, -2.3440, -2.5007, -2.3715, -2.2646, -2.6005,\n",
      "        -2.3063, -2.2023, -2.3941, -1.9776, -2.3491, -2.2065, -2.3593, -2.4989,\n",
      "        -2.2656, -2.4124, -2.5124, -2.1813, -2.3348, -2.0514, -2.4510, -2.2863,\n",
      "        -1.9625, -2.3451, -2.1587, -2.2229, -2.2614, -2.4552, -2.7264, -2.3380,\n",
      "        -2.3232, -2.5024, -2.2660, -2.4992, -2.1864, -2.5853, -2.4085, -2.3691,\n",
      "        -2.6239, -2.5414], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3063, -2.3261, -2.2947, -2.3297, -2.3047, -2.2973, -2.3351, -2.3309,\n",
      "        -2.3306, -2.3042, -2.3207, -2.3049, -2.3288, -2.3208, -2.3150, -2.3372,\n",
      "        -2.3302, -2.3331, -2.3298, -2.2621, -2.3230, -2.3325, -2.3021, -2.2764,\n",
      "        -2.3318, -2.3291, -2.3203, -2.3282, -2.3259, -2.2898, -2.2789, -2.3357,\n",
      "        -2.3386, -2.2950, -2.3270, -2.3042, -2.3269, -2.2858, -2.3494, -2.3269,\n",
      "        -2.2729, -2.2984, -2.3163, -2.3115, -2.3205, -2.3283, -2.2832, -2.3306,\n",
      "        -2.3278, -2.2691], device='mps:0')\n",
      "mean: tensor(-2.3146, device='mps:0')\n",
      "iter_dt 1.05s; iter 85: train loss 0.49913 temperature: 9.250000000000007\n",
      "mean_logits tensor([-2.3894, -2.6929, -2.3058, -1.9931, -2.0564, -2.4794, -2.5892, -2.0813,\n",
      "        -2.3746, -2.2965, -2.4525, -2.2068, -2.1897, -2.1425, -1.9787, -2.4576,\n",
      "        -2.5287, -2.2012, -2.5265, -2.1509, -2.2857, -2.5914, -2.4673, -2.2926,\n",
      "        -2.3583, -2.1091, -2.1217, -2.0642, -2.6171, -2.1703, -2.3375, -2.3933,\n",
      "        -2.2781, -2.2923, -2.3617, -2.0716, -2.2916, -2.4401, -2.1109, -2.0308,\n",
      "        -2.3139, -2.1744, -2.4339, -2.2088, -2.0371, -2.5843, -2.4391, -2.1138,\n",
      "        -2.0934, -2.5385], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2968, -2.3178, -2.3302, -2.3316, -2.3368, -2.3060, -2.2956, -2.3216,\n",
      "        -2.3048, -2.3008, -2.3482, -2.3296, -2.3233, -2.3443, -2.3031, -2.3006,\n",
      "        -2.3226, -2.3048, -2.2782, -2.3161, -2.3612, -2.3259, -2.3370, -2.3059,\n",
      "        -2.3328, -2.2954, -2.3030, -2.3027, -2.2751, -2.3502, -2.3291, -2.3253,\n",
      "        -2.3088, -2.3100, -2.3177, -2.2611, -2.3233, -2.3324, -2.3169, -2.3289,\n",
      "        -2.2889, -2.3429, -2.3278, -2.3114, -2.3016, -2.3319, -2.3107, -2.3194,\n",
      "        -2.3234, -2.3283], device='mps:0')\n",
      "mean: tensor(-2.3168, device='mps:0')\n",
      "iter_dt 1.06s; iter 86: train loss 0.28636 temperature: 9.300000000000008\n",
      "mean_logits tensor([-2.3282, -2.2203, -2.3866, -2.2412, -2.3938, -2.1030, -2.5540, -2.2320,\n",
      "        -2.3007, -2.1636, -2.1330, -2.1640, -2.1322, -2.1270, -2.3611, -2.2356,\n",
      "        -2.4381, -2.1938, -2.2376, -2.1197, -2.4538, -2.4250, -2.3810, -2.5313,\n",
      "        -2.3068, -2.1552, -2.1807, -2.3980, -2.6558, -2.3283, -2.2600, -2.2864,\n",
      "        -2.0000, -2.3677, -1.9071, -2.2469, -2.1702, -2.1883, -2.3543, -2.1780,\n",
      "        -2.2124, -2.1513, -2.5167, -2.3476, -2.4261, -2.4284, -2.1327, -2.4994,\n",
      "        -2.2722, -2.3861], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3158, -2.3289, -2.3229, -2.3054, -2.2859, -2.3118, -2.3221, -2.2861,\n",
      "        -2.3292, -2.3099, -2.3142, -2.3334, -2.3083, -2.3198, -2.3009, -2.3268,\n",
      "        -2.3254, -2.2958, -2.3318, -2.2141, -2.3283, -2.3318, -2.3263, -2.3415,\n",
      "        -2.2927, -2.2492, -2.2930, -2.2687, -2.3364, -2.3651, -2.2880, -2.3102,\n",
      "        -2.3243, -2.3207, -2.3303, -2.3272, -2.3399, -2.2270, -2.3347, -2.3045,\n",
      "        -2.3379, -2.3276, -2.3109, -2.3260, -2.3285, -2.3175, -2.2970, -2.3106,\n",
      "        -2.3238, -2.2639], device='mps:0')\n",
      "mean: tensor(-2.3114, device='mps:0')\n",
      "iter_dt 1.05s; iter 87: train loss 0.34815 temperature: 9.350000000000009\n",
      "mean_logits tensor([-2.2047, -2.3262, -2.1737, -1.9590, -2.0704, -2.0673, -2.0619, -1.9673,\n",
      "        -2.2902, -2.3659, -2.4584, -2.3569, -2.3449, -2.3928, -2.1652, -2.2302,\n",
      "        -2.1611, -2.4574, -2.1081, -2.0329, -2.3831, -2.2068, -2.0964, -2.2842,\n",
      "        -2.3165, -2.3518, -1.9998, -2.1201, -2.2726, -1.9042, -2.2670, -2.1406,\n",
      "        -2.2806, -2.4817, -2.3516, -2.3243, -2.3455, -2.0616, -2.3161, -2.1055,\n",
      "        -2.0942, -2.5141, -2.4561, -1.8891, -2.1758, -2.0922, -2.2810, -2.2148,\n",
      "        -2.5967, -2.3004], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3267, -2.3224, -2.2776, -2.3252, -2.3085, -2.3242, -2.3292, -2.2933,\n",
      "        -2.2977, -2.3079, -2.3205, -2.3160, -2.3311, -2.3278, -2.2686, -2.3139,\n",
      "        -2.2855, -2.3210, -2.3068, -2.2670, -2.3306, -2.3279, -2.2951, -2.3310,\n",
      "        -2.3279, -2.3287, -2.3177, -2.3259, -2.2759, -2.2921, -2.3311, -2.2997,\n",
      "        -2.3343, -2.3143, -2.2936, -2.2852, -2.3227, -2.2715, -2.2985, -2.2889,\n",
      "        -2.3326, -2.3439, -2.3512, -2.2958, -2.2918, -2.3173, -2.3284, -2.3390,\n",
      "        -2.3283, -2.3179], device='mps:0')\n",
      "mean: tensor(-2.3122, device='mps:0')\n",
      "iter_dt 1.04s; iter 88: train loss 0.45434 temperature: 9.40000000000001\n",
      "mean_logits tensor([-2.3105, -2.1653, -2.4191, -2.3828, -2.1720, -2.3042, -1.9667, -2.0070,\n",
      "        -2.6068, -2.3438, -2.1696, -1.9180, -2.5924, -2.3820, -2.4129, -2.1095,\n",
      "        -2.4707, -1.8632, -2.2543, -2.4745, -2.4500, -2.3747, -2.4139, -2.3725,\n",
      "        -2.2265, -2.1779, -2.0917, -2.2283, -2.2673, -2.4771, -2.3770, -2.1991,\n",
      "        -1.8646, -2.3367, -2.0800, -2.3903, -2.1838, -2.6247, -2.2273, -2.3109,\n",
      "        -2.3423, -2.3948, -2.6561, -2.1383, -2.3500, -2.1254, -2.4710, -2.3811,\n",
      "        -2.4225, -2.1739], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2874, -2.3314, -2.3268, -2.3150, -2.3332, -2.3150, -2.2705, -2.3065,\n",
      "        -2.3248, -2.3318, -2.3198, -2.3293, -2.3291, -2.3182, -2.3191, -2.3291,\n",
      "        -2.3220, -2.3225, -2.3195, -2.2919, -2.3177, -2.2978, -2.2929, -2.3097,\n",
      "        -2.3315, -2.2930, -2.3259, -2.3160, -2.2828, -2.3324, -2.3270, -2.3213,\n",
      "        -2.3231, -2.3285, -2.3019, -2.3260, -2.3259, -2.3009, -2.3310, -2.3329,\n",
      "        -2.3180, -2.3227, -2.3042, -2.3079, -2.2531, -2.3146, -2.2400, -2.2896,\n",
      "        -2.3111, -2.2930], device='mps:0')\n",
      "mean: tensor(-2.3123, device='mps:0')\n",
      "iter_dt 1.05s; iter 89: train loss 0.44887 temperature: 9.45000000000001\n",
      "mean_logits tensor([-2.3218, -2.1579, -2.0398, -2.4333, -2.2500, -2.0123, -2.4285, -2.4471,\n",
      "        -2.3716, -2.3516, -2.4930, -2.3275, -2.4122, -2.3204, -2.1510, -2.4014,\n",
      "        -2.2070, -2.5595, -2.2836, -2.2581, -2.3326, -2.5788, -1.7676, -2.3305,\n",
      "        -2.3442, -2.2124, -2.1253, -2.3598, -2.2799, -2.0391, -2.6011, -2.5507,\n",
      "        -2.1381, -2.1192, -2.5973, -2.2287, -2.1193, -2.4076, -2.2871, -2.3616,\n",
      "        -2.4009, -2.3628, -2.2446, -1.8912, -2.2948, -2.0376, -2.5061, -2.4820,\n",
      "        -2.1668, -2.0088], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3299, -2.3083, -2.3895, -2.2960, -2.2855, -2.3277, -2.3299, -2.3231,\n",
      "        -2.3058, -2.3165, -2.3182, -2.3378, -2.3048, -2.3264, -2.2941, -2.3124,\n",
      "        -2.3245, -2.3290, -2.2502, -2.3323, -2.2832, -2.3290, -2.3050, -2.2909,\n",
      "        -2.3056, -2.3050, -2.3248, -2.2419, -2.3347, -2.3295, -2.3274, -2.2875,\n",
      "        -2.3287, -2.3290, -2.3149, -2.3293, -2.3334, -2.3104, -2.3286, -2.3314,\n",
      "        -2.3048, -2.3115, -2.3332, -2.3105, -2.3291, -2.3325, -2.3174, -2.2898,\n",
      "        -2.3245, -2.3451], device='mps:0')\n",
      "mean: tensor(-2.3162, device='mps:0')\n",
      "iter_dt 1.04s; iter 90: train loss 0.31172 temperature: 9.50000000000001\n",
      "mean_logits tensor([-2.3067, -2.2830, -2.4066, -2.1833, -2.4704, -2.2626, -2.1678, -1.9519,\n",
      "        -2.3779, -2.5130, -2.2671, -2.2867, -2.4405, -2.0334, -2.1941, -2.1622,\n",
      "        -2.5529, -2.4449, -2.3191, -1.8432, -2.1888, -2.3430, -1.9473, -2.4296,\n",
      "        -2.1653, -2.1879, -2.0487, -2.2790, -2.1112, -2.0836, -2.3806, -2.1860,\n",
      "        -2.1443, -2.1189, -1.9787, -2.2843, -2.4157, -2.1735, -2.3790, -2.2522,\n",
      "        -2.3526, -2.1689, -2.3955, -2.3061, -2.4590, -2.3626, -2.3105, -2.3868,\n",
      "        -2.3273, -2.2412], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3499, -2.2649, -2.3306, -2.3655, -2.3013, -2.3322, -2.3154, -2.3233,\n",
      "        -2.3105, -2.3103, -2.3327, -2.2815, -2.2431, -2.3090, -2.3126, -2.3265,\n",
      "        -2.3368, -2.3284, -2.3281, -2.2741, -2.3265, -2.3314, -2.3293, -2.2624,\n",
      "        -2.3147, -2.3382, -2.3093, -2.3351, -2.3171, -2.3282, -2.3491, -2.3289,\n",
      "        -2.2701, -2.2635, -2.2910, -2.3292, -2.3302, -2.2990, -2.3307, -2.2634,\n",
      "        -2.3111, -2.3249, -2.3112, -2.3376, -2.3124, -2.3397, -2.3384, -2.3115,\n",
      "        -2.2688, -2.3302], device='mps:0')\n",
      "mean: tensor(-2.3142, device='mps:0')\n",
      "iter_dt 1.06s; iter 91: train loss 0.39421 temperature: 9.550000000000011\n",
      "mean_logits tensor([-2.1530, -2.0182, -2.1935, -2.2533, -2.2647, -2.4827, -2.1505, -2.3443,\n",
      "        -2.3064, -2.3180, -1.9282, -2.3889, -2.0630, -2.3677, -2.3337, -2.4997,\n",
      "        -2.2087, -2.4709, -2.2459, -2.2132, -2.3608, -2.4789, -2.5252, -2.5172,\n",
      "        -2.2917, -2.1970, -2.2099, -2.1849, -2.4173, -2.3618, -2.4090, -1.9778,\n",
      "        -2.5225, -1.9928, -2.3836, -2.3773, -2.4269, -2.4460, -2.2130, -2.1348,\n",
      "        -2.6979, -2.4039, -2.1487, -2.2385, -2.1823, -2.6662, -2.1621, -2.3788,\n",
      "        -2.1298, -2.1892], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2409, -2.3062, -2.3097, -2.3052, -2.2683, -2.3204, -2.3270, -2.2872,\n",
      "        -2.2850, -2.2868, -2.3290, -2.3202, -2.3419, -2.3375, -2.3095, -2.3295,\n",
      "        -2.3172, -2.3250, -2.3308, -2.3079, -2.3100, -2.3271, -2.2558, -2.3220,\n",
      "        -2.2708, -2.3311, -2.3109, -2.2908, -2.3353, -2.3057, -2.3450, -2.3277,\n",
      "        -2.3551, -2.3370, -2.2682, -2.2795, -2.3330, -2.2713, -2.3145, -2.2676,\n",
      "        -2.3387, -2.3317, -2.3555, -2.3272, -2.3364, -2.3305, -2.3207, -2.3294,\n",
      "        -2.3136, -2.2732], device='mps:0')\n",
      "mean: tensor(-2.3120, device='mps:0')\n",
      "iter_dt 1.06s; iter 92: train loss 0.37654 temperature: 9.600000000000012\n",
      "mean_logits tensor([-2.3103, -2.0723, -2.2877, -2.5337, -2.2827, -2.2937, -2.1455, -2.3123,\n",
      "        -2.3967, -2.3975, -2.1388, -2.4989, -2.3355, -2.0733, -2.1495, -2.2252,\n",
      "        -2.1716, -2.2810, -2.1578, -2.1710, -2.1412, -2.4651, -2.7920, -2.2992,\n",
      "        -2.3805, -2.3808, -2.1834, -2.2499, -2.1967, -1.8554, -2.2975, -2.4377,\n",
      "        -2.1378, -2.2651, -2.4962, -2.1488, -2.2034, -2.1719, -2.2227, -2.6433,\n",
      "        -2.4612, -2.2696, -2.5936, -2.3011, -2.1917, -2.3050, -2.3209, -2.3039,\n",
      "        -2.4635, -2.2892], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2370, -2.3250, -2.2902, -2.3215, -2.3325, -2.2881, -2.2968, -2.3309,\n",
      "        -2.2798, -2.2868, -2.3295, -2.2735, -2.3089, -2.2928, -2.1635, -2.3231,\n",
      "        -2.2620, -2.3215, -2.3161, -2.2570, -2.3090, -2.3280, -2.3262, -2.3103,\n",
      "        -2.2938, -2.2758, -2.3311, -2.2840, -2.3140, -2.2974, -2.3253, -2.3111,\n",
      "        -2.3537, -2.3285, -2.3305, -2.2680, -2.3292, -2.3316, -2.3140, -2.3231,\n",
      "        -2.3380, -2.3299, -2.3259, -2.3209, -2.2886, -2.3088, -2.3118, -2.3316,\n",
      "        -2.3461, -2.3094], device='mps:0')\n",
      "mean: tensor(-2.3066, device='mps:0')\n",
      "iter_dt 1.05s; iter 93: train loss 0.27389 temperature: 9.650000000000013\n",
      "mean_logits tensor([-2.2772, -2.2775, -2.3842, -2.1616, -2.2060, -2.2410, -2.4889, -2.3006,\n",
      "        -2.4515, -2.4785, -2.4801, -2.0497, -2.0935, -2.2359, -2.2995, -2.3756,\n",
      "        -2.4033, -2.3609, -2.3711, -2.1428, -2.1748, -2.4979, -2.3587, -2.3059,\n",
      "        -2.2926, -2.5228, -2.4567, -2.3377, -2.0108, -2.2822, -2.2438, -2.0911,\n",
      "        -2.4575, -2.2876, -2.2509, -2.1042, -2.2004, -2.3321, -2.3345, -2.3641,\n",
      "        -2.0259, -2.1994, -2.0367, -2.4476, -2.1783, -2.2202, -2.1443, -2.2403,\n",
      "        -2.5119, -1.9546], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3293, -2.3330, -2.2885, -2.3241, -2.3232, -2.3325, -2.3452, -2.2513,\n",
      "        -2.3312, -2.2725, -2.2705, -2.3582, -2.2773, -2.3000, -2.3242, -2.3232,\n",
      "        -2.3128, -2.2979, -2.3086, -2.2863, -2.3141, -2.3345, -2.2961, -2.3428,\n",
      "        -2.3372, -2.3078, -2.3229, -2.3213, -2.3205, -2.3285, -2.3583, -2.3341,\n",
      "        -2.3226, -2.2984, -2.3253, -2.2730, -2.2698, -2.3292, -2.3286, -2.3158,\n",
      "        -2.2663, -2.3084, -2.2871, -2.2734, -2.2570, -2.3152, -2.3308, -2.3175,\n",
      "        -2.3419, -2.3290], device='mps:0')\n",
      "mean: tensor(-2.3119, device='mps:0')\n",
      "iter_dt 1.04s; iter 94: train loss 0.27373 temperature: 9.700000000000014\n",
      "mean_logits tensor([-2.1071, -2.3131, -2.1367, -1.9872, -2.4547, -2.2590, -2.1418, -2.2858,\n",
      "        -2.3395, -2.4257, -2.3839, -2.3945, -2.2985, -2.2579, -2.2196, -2.1296,\n",
      "        -2.5354, -2.3823, -2.2355, -2.5777, -2.3226, -2.3779, -2.3480, -2.3413,\n",
      "        -2.2661, -2.1824, -2.3988, -2.2669, -2.2653, -2.5177, -2.2745, -2.4167,\n",
      "        -2.1673, -2.1602, -2.5011, -2.2797, -2.2003, -2.0286, -2.3810, -2.3874,\n",
      "        -2.5245, -2.5870, -2.5344, -2.5512, -2.3243, -2.1665, -2.2778, -2.0689,\n",
      "        -2.2636, -2.3788], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.2650, -2.2940, -2.2832, -2.2783, -2.2946, -2.3290, -2.3219, -2.3115,\n",
      "        -2.3240, -2.2585, -2.3280, -2.3276, -2.3191, -2.3294, -2.2656, -2.2714,\n",
      "        -2.3250, -2.3169, -2.2884, -2.3040, -2.3315, -2.3311, -2.2927, -2.3061,\n",
      "        -2.3289, -2.3204, -2.2898, -2.3292, -2.2910, -2.3174, -2.2597, -2.3309,\n",
      "        -2.3274, -2.3107, -2.2742, -2.3234, -2.2499, -2.2784, -2.3364, -2.3208,\n",
      "        -2.3298, -2.3069, -2.3254, -2.3113, -2.3551, -2.2942, -2.3264, -2.3096,\n",
      "        -2.3127, -2.3207], device='mps:0')\n",
      "mean: tensor(-2.3075, device='mps:0')\n",
      "iter_dt 1.05s; iter 95: train loss 0.40078 temperature: 9.750000000000014\n",
      "mean_logits tensor([-2.2463, -2.5449, -2.3220, -2.3325, -2.1283, -2.2322, -2.5338, -2.2862,\n",
      "        -2.4171, -2.5934, -2.5408, -2.2592, -2.2680, -2.3071, -2.4020, -2.1045,\n",
      "        -2.1789, -2.4010, -2.1768, -2.3109, -2.4980, -2.3501, -2.2532, -2.4783,\n",
      "        -2.5720, -2.2543, -2.3063, -2.1348, -2.3641, -2.3723, -2.2852, -2.3049,\n",
      "        -2.2343, -2.1642, -2.4540, -1.9427, -2.2005, -2.1695, -1.9495, -2.5398,\n",
      "        -2.1388, -2.2909, -2.4916, -2.6983, -2.3926, -2.3188, -2.2126, -2.2447,\n",
      "        -2.1919, -2.6256], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3202, -2.3286, -2.3034, -2.2931, -2.2830, -2.3001, -2.3217, -2.3087,\n",
      "        -2.2965, -2.2604, -2.3113, -2.3191, -2.3263, -2.3297, -2.3195, -2.3115,\n",
      "        -2.3224, -2.2757, -2.3189, -2.3284, -2.3099, -2.3161, -2.3355, -2.2950,\n",
      "        -2.3209, -2.3009, -2.2777, -2.3220, -2.3256, -2.2704, -2.3226, -2.3139,\n",
      "        -2.3304, -2.3283, -2.2912, -2.3297, -2.3746, -2.3292, -2.3239, -2.3320,\n",
      "        -2.2800, -2.2824, -2.3385, -2.3373, -2.3466, -2.3283, -2.3199, -2.2958,\n",
      "        -2.2199, -2.3275], device='mps:0')\n",
      "mean: tensor(-2.3121, device='mps:0')\n",
      "iter_dt 1.04s; iter 96: train loss 0.25110 temperature: 9.800000000000015\n",
      "mean_logits tensor([-2.0999, -2.1932, -2.4114, -2.2898, -2.5215, -2.1043, -2.1942, -2.3046,\n",
      "        -2.2490, -2.2920, -2.1768, -2.2294, -2.2579, -2.5133, -2.2661, -2.3881,\n",
      "        -2.3955, -2.2397, -2.1357, -2.0824, -2.3333, -2.3417, -2.3600, -2.0787,\n",
      "        -2.3931, -2.1456, -2.2511, -2.0485, -2.3152, -2.3555, -2.2812, -2.3685,\n",
      "        -2.0771, -2.3299, -2.2333, -2.4211, -2.1523, -2.2241, -2.3886, -2.3574,\n",
      "        -2.3979, -2.2022, -2.3839, -2.5414, -2.3019, -2.4998, -2.2221, -2.3399,\n",
      "        -2.3331, -2.6681], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3134, -2.3030, -2.2679, -2.3250, -2.3163, -2.3241, -2.2765, -2.3292,\n",
      "        -2.3316, -2.3757, -2.3297, -2.2846, -2.3223, -2.3032, -2.3300, -2.2789,\n",
      "        -2.2762, -2.3279, -2.3336, -2.2883, -2.3251, -2.3008, -2.3368, -2.3065,\n",
      "        -2.2962, -2.3268, -2.3129, -2.2747, -2.3198, -2.3331, -2.3318, -2.3309,\n",
      "        -2.3266, -2.3316, -2.2985, -2.3259, -2.3178, -2.3161, -2.3237, -2.3006,\n",
      "        -2.3178, -2.3176, -2.3590, -2.3238, -2.2953, -2.3143, -2.3042, -2.3014,\n",
      "        -2.2384, -2.3264], device='mps:0')\n",
      "mean: tensor(-2.3134, device='mps:0')\n",
      "iter_dt 1.07s; iter 97: train loss 0.32374 temperature: 9.850000000000016\n",
      "mean_logits tensor([-2.0376, -2.1066, -2.2894, -2.5304, -2.2105, -2.4719, -2.4008, -2.3371,\n",
      "        -2.2109, -2.4216, -2.4142, -2.2418, -2.4482, -2.2091, -2.4356, -2.3010,\n",
      "        -2.3063, -2.4116, -1.9698, -2.2571, -2.0989, -2.3045, -2.2802, -2.4548,\n",
      "        -2.2446, -2.3908, -2.5147, -2.5383, -2.4007, -2.2417, -2.2126, -2.3210,\n",
      "        -2.3815, -2.2869, -2.5999, -2.2199, -2.0649, -2.1745, -2.1187, -2.3819,\n",
      "        -2.2198, -2.3966, -2.1959, -2.0302, -2.2969, -2.5544, -1.9346, -2.0018,\n",
      "        -2.5013, -2.2226], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3018, -2.3260, -2.2860, -2.3380, -2.3315, -2.3292, -2.3253, -2.2884,\n",
      "        -2.2568, -2.3300, -2.3208, -2.3022, -2.3266, -2.3083, -2.3318, -2.3302,\n",
      "        -2.3113, -2.2694, -2.2766, -2.3294, -2.2716, -2.2149, -2.3889, -2.2451,\n",
      "        -2.3146, -2.3108, -2.3258, -2.3207, -2.3014, -2.3244, -2.2619, -2.2922,\n",
      "        -2.3325, -2.3332, -2.3200, -2.2711, -2.3856, -2.3184, -2.2748, -2.3081,\n",
      "        -2.2919, -2.3246, -2.3076, -2.3267, -2.3278, -2.2931, -2.2672, -2.2935,\n",
      "        -2.3286, -2.3434], device='mps:0')\n",
      "mean: tensor(-2.3088, device='mps:0')\n",
      "iter_dt 1.05s; iter 98: train loss 0.31202 temperature: 9.900000000000016\n",
      "mean_logits tensor([-2.2205, -2.2031, -2.2224, -2.3150, -2.0127, -2.2157, -2.4547, -2.4117,\n",
      "        -2.1964, -2.3219, -2.2520, -2.1006, -2.1203, -2.1932, -2.2433, -2.2839,\n",
      "        -2.1914, -2.0705, -2.3700, -2.2443, -2.0392, -2.0749, -2.1109, -2.4262,\n",
      "        -2.3619, -2.4663, -2.5113, -2.5066, -2.1891, -2.3620, -2.1063, -2.3378,\n",
      "        -2.2325, -2.2141, -2.4201, -2.2535, -2.5477, -2.1437, -2.4075, -2.3226,\n",
      "        -2.2819, -2.2183, -2.2463, -2.2969, -2.5341, -2.1107, -2.3466, -2.0760,\n",
      "        -2.2029, -2.5625], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3246, -2.3204, -2.3076, -2.2675, -2.3312, -2.3313, -2.3305, -2.3243,\n",
      "        -2.3197, -2.3770, -2.3590, -2.3289, -2.2664, -2.3073, -2.2708, -2.2989,\n",
      "        -2.3235, -2.3299, -2.3233, -2.3224, -2.3268, -2.3299, -2.3124, -2.3251,\n",
      "        -2.3224, -2.3293, -2.2828, -2.3322, -2.3306, -2.3268, -2.2913, -2.3091,\n",
      "        -2.3154, -2.3244, -2.3314, -2.3537, -2.3306, -2.3337, -2.3504, -2.3522,\n",
      "        -2.3869, -2.2803, -2.3392, -2.3036, -2.3085, -2.3221, -2.2856, -2.2527,\n",
      "        -2.3289, -2.1714], device='mps:0')\n",
      "mean: tensor(-2.3171, device='mps:0')\n",
      "iter_dt 1.07s; iter 99: train loss 0.28995 temperature: 9.950000000000017\n",
      "mean_logits tensor([-2.1794, -2.3799, -2.4715, -2.3097, -2.4697, -2.3937, -2.3286, -2.2645,\n",
      "        -2.2219, -2.0273, -2.1508, -2.2664, -2.4737, -2.2587, -2.4744, -2.2441,\n",
      "        -2.3977, -2.3235, -2.2647, -2.2984, -2.2053, -2.5375, -2.3181, -2.2053,\n",
      "        -2.1889, -2.4747, -2.0642, -2.1508, -2.3200, -2.1184, -2.3991, -2.3205,\n",
      "        -2.6782, -2.3428, -2.1473, -2.1238, -2.2951, -2.3630, -2.2052, -2.3233,\n",
      "        -2.2155, -2.4389, -2.4207, -2.3657, -2.5201, -2.5494, -2.4285, -2.5523,\n",
      "        -2.2112, -2.1182], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3258, -2.3130, -2.3288, -2.3308, -2.3196, -2.3426, -2.3067, -2.2898,\n",
      "        -2.3106, -2.3327, -2.3172, -2.3006, -2.3287, -2.2706, -2.2926, -2.3035,\n",
      "        -2.3295, -2.3021, -2.3333, -2.3122, -2.3118, -2.3277, -2.3286, -2.3193,\n",
      "        -2.3287, -2.3242, -2.3290, -2.3264, -2.3404, -2.3074, -2.3309, -2.3109,\n",
      "        -2.3323, -2.3176, -2.3232, -2.3314, -2.3126, -2.3239, -2.3481, -2.3257,\n",
      "        -2.3317, -2.3237, -2.3313, -2.3036, -2.2977, -2.3374, -2.3284, -2.3331,\n",
      "        -2.3047, -2.3482], device='mps:0')\n",
      "mean: tensor(-2.3206, device='mps:0')\n",
      "current_prefixes: [7278 4037 5557 4534 4632 6985  380 4805 4101 4404 4883  611  346 1045\n",
      " 2273 6235 5773 2879  256  465]\n",
      "layer: 5 starts running\n",
      "number of parameters: 91.99M\n",
      "running on device mps\n",
      "iter_dt 0.00s; iter 0: train loss 2.65248 temperature: 5\n",
      "mean_logits tensor([-2.2109, -1.9567, -1.7593, -1.5956, -2.0445, -1.8089, -1.6233, -1.6997,\n",
      "        -1.9273, -1.5091, -1.7500, -1.9846, -1.6434, -1.9335, -1.6165, -2.0602,\n",
      "        -1.8354, -1.9879, -1.9118, -1.7707, -1.7341, -1.8182, -1.6414, -1.7454,\n",
      "        -1.8030, -1.8635, -2.1624, -1.8909, -1.9737, -1.9673, -2.1011, -2.0223,\n",
      "        -2.0846, -2.0457, -2.0483, -2.2252, -2.0716, -1.7243, -2.0522, -1.9354,\n",
      "        -1.8587, -2.0613, -2.3501, -1.8985, -1.5785, -1.7183, -2.2924, -1.8910,\n",
      "        -1.8740, -1.8381], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4205, -2.4223, -2.3932, -2.3803, -2.4193, -2.3990, -2.4511, -2.3620,\n",
      "        -2.4173, -2.3963, -2.4161, -2.4085, -2.3851, -2.3910, -2.3687, -2.3303,\n",
      "        -2.4205, -2.4185, -2.3480, -2.4146, -2.4066, -2.4127, -2.3807, -2.3941,\n",
      "        -2.4190, -2.3953, -2.4126, -2.4223, -2.4049, -2.3722, -2.3743, -2.3997,\n",
      "        -2.4010, -2.4185, -2.4072, -2.4184, -2.4257, -2.3700, -2.4168, -2.3446,\n",
      "        -2.4169, -2.4093, -2.3843, -2.3947, -2.4206, -2.3812, -2.4098, -2.4178,\n",
      "        -2.4085, -2.3831], device='mps:0')\n",
      "mean: tensor(-2.3997, device='mps:0')\n",
      "iter_dt 1695864187.42s; iter 1: train loss 2.59058 temperature: 5.05\n",
      "mean_logits tensor([-2.0401, -1.8837, -2.0835, -2.1024, -1.6616, -1.6801, -2.2115, -1.7600,\n",
      "        -1.3801, -1.9789, -1.7007, -1.9378, -2.0192, -2.1479, -1.9942, -1.8498,\n",
      "        -2.0017, -1.9123, -1.9673, -2.0695, -1.5806, -1.8686, -1.9515, -2.1184,\n",
      "        -2.1083, -1.9680, -1.8182, -1.9429, -1.6225, -1.6806, -1.8314, -1.7597,\n",
      "        -1.9657, -1.8489, -1.7254, -2.3238, -2.3268, -2.1631, -2.0150, -1.9792,\n",
      "        -1.7638, -1.8471, -1.8147, -1.8712, -2.1468, -1.7213, -1.7942, -1.8937,\n",
      "        -2.3330, -1.6775], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4193, -2.4192, -2.3636, -2.4175, -2.3957, -2.4203, -2.3983, -2.4180,\n",
      "        -2.4017, -2.4336, -2.4240, -2.4274, -2.4183, -2.4132, -2.4312, -2.4134,\n",
      "        -2.4238, -2.4188, -2.4125, -2.4261, -2.3910, -2.4225, -2.3822, -2.3843,\n",
      "        -2.4094, -2.3181, -2.3605, -2.4190, -2.4213, -2.4065, -2.4258, -2.2856,\n",
      "        -2.3681, -2.4173, -2.4223, -2.4343, -2.4238, -2.4173, -2.4127, -2.4184,\n",
      "        -2.3580, -2.3937, -2.3847, -2.4180, -2.4077, -2.4226, -2.3993, -2.4217,\n",
      "        -2.4193, -2.4197], device='mps:0')\n",
      "mean: tensor(-2.4056, device='mps:0')\n",
      "iter_dt 1.11s; iter 2: train loss 2.40617 temperature: 5.1\n",
      "mean_logits tensor([-2.0022, -2.1347, -1.6977, -1.8476, -2.1439, -1.7955, -1.8262, -2.1213,\n",
      "        -2.1320, -1.9766, -1.6960, -1.9605, -2.1324, -1.7723, -1.7784, -2.0515,\n",
      "        -1.8578, -1.5883, -1.7528, -2.2492, -2.0447, -1.7073, -1.7291, -1.8650,\n",
      "        -1.7802, -1.5149, -1.7385, -2.1903, -1.9856, -2.0322, -1.7957, -2.0281,\n",
      "        -1.4979, -1.8926, -2.1883, -1.8649, -1.9399, -1.7430, -2.4218, -1.8303,\n",
      "        -2.1346, -2.3792, -2.2548, -1.8323, -1.8196, -1.7993, -2.3391, -2.0070,\n",
      "        -1.6099, -2.2252], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4138, -2.4272, -2.4017, -2.4203, -2.3733, -2.4124, -2.4189, -2.4333,\n",
      "        -2.4535, -2.4363, -2.4002, -2.4373, -2.4014, -2.4168, -2.4337, -2.3935,\n",
      "        -2.3785, -2.3734, -2.4114, -2.4237, -2.4035, -2.3828, -2.4162, -2.3774,\n",
      "        -2.3964, -2.3359, -2.3510, -2.3762, -2.4198, -2.3855, -2.3951, -2.2863,\n",
      "        -2.3010, -2.3928, -2.4185, -2.4111, -2.3994, -2.4095, -2.3804, -2.4151,\n",
      "        -2.4198, -2.4262, -2.3662, -2.4160, -2.3568, -2.4128, -2.3645, -2.4075,\n",
      "        -2.3882, -2.3797], device='mps:0')\n",
      "mean: tensor(-2.3970, device='mps:0')\n",
      "iter_dt 1.05s; iter 3: train loss 2.17093 temperature: 5.1499999999999995\n",
      "mean_logits tensor([-1.5864, -2.1030, -1.5985, -1.9125, -2.0652, -1.8993, -2.0842, -1.9926,\n",
      "        -2.4002, -2.3474, -1.9118, -1.7581, -2.3129, -2.2366, -2.1383, -1.7492,\n",
      "        -1.6988, -2.0458, -1.8511, -2.0988, -1.9659, -1.7250, -2.1267, -1.6844,\n",
      "        -1.6955, -1.8379, -2.0328, -2.1897, -2.0419, -1.6309, -1.7234, -1.7196,\n",
      "        -2.0522, -1.9111, -2.1817, -2.1362, -1.7622, -2.0111, -2.3481, -2.2051,\n",
      "        -2.2643, -2.1461, -1.9066, -2.0036, -2.1411, -2.2756, -1.7341, -1.5723,\n",
      "        -1.7476, -2.1873], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3678, -2.3827, -2.4005, -2.4069, -2.3875, -2.3968, -2.4324, -2.4197,\n",
      "        -2.4192, -2.3743, -2.4245, -2.4117, -2.4278, -2.3944, -2.3905, -2.3895,\n",
      "        -2.4221, -2.3835, -2.3530, -2.3973, -2.4185, -2.3855, -2.3771, -2.3893,\n",
      "        -2.3592, -2.4095, -2.4255, -2.4170, -2.4171, -2.4129, -2.4152, -2.4010,\n",
      "        -2.4417, -2.4177, -2.4140, -2.4031, -2.4308, -2.3161, -2.4093, -2.3958,\n",
      "        -2.4323, -2.4246, -2.3740, -2.4147, -2.4183, -2.3855, -2.4466, -2.4040,\n",
      "        -2.3435, -2.4236], device='mps:0')\n",
      "mean: tensor(-2.4021, device='mps:0')\n",
      "iter_dt 1.06s; iter 4: train loss 1.83220 temperature: 5.199999999999999\n",
      "mean_logits tensor([-1.9985, -2.1137, -1.8005, -2.1414, -1.7386, -1.8320, -1.9576, -2.0430,\n",
      "        -1.9677, -1.7251, -2.0045, -1.5234, -1.8027, -2.0017, -2.1539, -1.8584,\n",
      "        -1.8876, -2.1396, -2.0736, -1.7031, -2.0865, -1.9350, -1.8169, -2.0416,\n",
      "        -2.2289, -2.4074, -2.1021, -2.3944, -2.4290, -2.2862, -2.1874, -2.2700,\n",
      "        -1.7653, -2.0806, -2.1973, -1.7829, -1.8873, -1.7121, -1.9313, -1.8552,\n",
      "        -2.4160, -2.0425, -2.3548, -2.1479, -2.1239, -1.7887, -2.1585, -1.9373,\n",
      "        -1.9701, -2.4932], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4129, -2.4179, -2.4124, -2.3957, -2.3911, -2.4155, -2.3905, -2.3986,\n",
      "        -2.3434, -2.4001, -2.4006, -2.3896, -2.3896, -2.3894, -2.3522, -2.3947,\n",
      "        -2.4258, -2.3816, -2.3648, -2.4215, -2.4257, -2.3724, -2.3932, -2.4215,\n",
      "        -2.4195, -2.4105, -2.3759, -2.4030, -2.3809, -2.3981, -2.3705, -2.3715,\n",
      "        -2.4061, -2.4002, -2.4157, -2.4299, -2.3850, -2.3977, -2.4201, -2.3765,\n",
      "        -2.4179, -2.3702, -2.3795, -2.3936, -2.4101, -2.4131, -2.3949, -2.4029,\n",
      "        -2.4166, -2.3834], device='mps:0')\n",
      "mean: tensor(-2.3969, device='mps:0')\n",
      "iter_dt 1.04s; iter 5: train loss 2.10816 temperature: 5.249999999999999\n",
      "mean_logits tensor([-2.1571, -2.5022, -1.9244, -1.8616, -1.7510, -1.8290, -2.0803, -1.7896,\n",
      "        -2.0734, -1.7821, -1.8392, -1.7491, -1.9754, -2.3559, -2.0968, -2.1689,\n",
      "        -2.1178, -1.6024, -1.9963, -2.1096, -1.9196, -1.6701, -1.8089, -2.3267,\n",
      "        -2.2758, -1.7789, -1.8421, -2.2056, -1.9066, -1.6956, -1.9756, -1.8009,\n",
      "        -1.8856, -1.8883, -1.7401, -2.2134, -2.3318, -2.0968, -2.1882, -1.9310,\n",
      "        -1.8991, -1.8456, -1.9602, -2.1502, -2.3254, -1.9221, -2.0631, -2.4066,\n",
      "        -1.5708, -2.0879], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4088, -2.4183, -2.3094, -2.4241, -2.4262, -2.3955, -2.3922, -2.4103,\n",
      "        -2.4003, -2.3752, -2.4164, -2.3988, -2.4190, -2.3775, -2.3666, -2.4186,\n",
      "        -2.4341, -2.3740, -2.4120, -2.3886, -2.3958, -2.4201, -2.3544, -2.4049,\n",
      "        -2.4005, -2.3797, -2.4109, -2.4289, -2.3936, -2.4180, -2.4128, -2.4208,\n",
      "        -2.4691, -2.3502, -2.4308, -2.4181, -2.3437, -2.4116, -2.4121, -2.3961,\n",
      "        -2.4184, -2.4179, -2.3905, -2.3547, -2.4138, -2.4197, -2.4544, -2.4078,\n",
      "        -2.3674, -2.4147], device='mps:0')\n",
      "mean: tensor(-2.4019, device='mps:0')\n",
      "iter_dt 1.07s; iter 6: train loss 1.62373 temperature: 5.299999999999999\n",
      "mean_logits tensor([-2.3657, -1.9613, -2.3900, -1.9854, -1.9830, -1.8367, -2.2870, -2.1129,\n",
      "        -2.1277, -1.8232, -2.5302, -2.1340, -1.8732, -2.2097, -2.0520, -2.0727,\n",
      "        -2.1122, -2.1930, -1.7961, -1.7980, -2.2517, -1.7942, -1.8731, -1.9730,\n",
      "        -2.0049, -2.2289, -1.8401, -2.4465, -2.0804, -1.5930, -2.2082, -2.3462,\n",
      "        -2.5598, -2.2840, -1.9278, -2.3324, -1.9025, -2.2204, -2.4002, -2.7532,\n",
      "        -1.7948, -1.9555, -2.1879, -1.6791, -2.1152, -1.6376, -1.9466, -2.3803,\n",
      "        -1.6505, -1.7774], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4398, -2.3732, -2.4279, -2.3618, -2.4169, -2.3707, -2.4184, -2.4174,\n",
      "        -2.3863, -2.3003, -2.4166, -2.3931, -2.4126, -2.4191, -2.4317, -2.3101,\n",
      "        -2.3978, -2.4175, -2.3292, -2.4167, -2.4107, -2.3930, -2.4195, -2.2848,\n",
      "        -2.3464, -2.3817, -2.4091, -2.3831, -2.3645, -2.4046, -2.4367, -2.4228,\n",
      "        -2.4429, -2.4156, -2.4498, -2.4129, -2.3648, -2.3748, -2.3514, -2.4184,\n",
      "        -2.4008, -2.4171, -2.4193, -2.3538, -2.3865, -2.4169, -2.3868, -2.4212,\n",
      "        -2.4096, -2.3801], device='mps:0')\n",
      "mean: tensor(-2.3947, device='mps:0')\n",
      "iter_dt 1.05s; iter 7: train loss 1.60026 temperature: 5.349999999999999\n",
      "mean_logits tensor([-1.9973, -2.1414, -2.1039, -2.5048, -2.1173, -2.0148, -1.9572, -1.7992,\n",
      "        -2.3026, -2.4569, -2.0508, -2.2163, -2.1317, -1.7110, -2.1490, -1.8284,\n",
      "        -2.0754, -2.2055, -2.3203, -1.9803, -2.0443, -2.1801, -2.0898, -2.0267,\n",
      "        -1.9944, -2.2026, -1.7025, -2.0421, -1.9750, -2.2532, -2.0761, -2.0633,\n",
      "        -1.8101, -2.4305, -2.1998, -2.2799, -1.7673, -2.1954, -2.4847, -1.5465,\n",
      "        -2.2616, -1.9731, -1.8900, -1.8767, -2.0607, -1.6115, -2.2009, -2.2374,\n",
      "        -1.8732, -1.7298], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4426, -2.4030, -2.4168, -2.4418, -2.3545, -2.4151, -2.4245, -2.4442,\n",
      "        -2.4178, -2.3558, -2.4305, -2.4120, -2.4314, -2.3484, -2.3955, -2.4062,\n",
      "        -2.4224, -2.3918, -2.4012, -2.4176, -2.4327, -2.4467, -2.3450, -2.3483,\n",
      "        -2.3729, -2.3903, -2.3846, -2.3978, -2.3847, -2.4160, -2.4388, -2.3871,\n",
      "        -2.4188, -2.3657, -2.3882, -2.4178, -2.3318, -2.3996, -2.4168, -2.3984,\n",
      "        -2.4185, -2.4131, -2.3689, -2.4183, -2.4289, -2.3579, -2.4110, -2.3584,\n",
      "        -2.4192, -2.3847], device='mps:0')\n",
      "mean: tensor(-2.4007, device='mps:0')\n",
      "iter_dt 1.06s; iter 8: train loss 1.45657 temperature: 5.399999999999999\n",
      "mean_logits tensor([-2.0428, -2.0491, -2.2137, -2.5971, -1.5029, -1.9211, -2.0777, -1.9950,\n",
      "        -2.1077, -2.3359, -2.6165, -2.2062, -2.5162, -2.1505, -1.9924, -1.8015,\n",
      "        -2.0720, -2.5561, -1.9483, -1.4426, -2.0112, -2.2924, -1.8786, -2.7642,\n",
      "        -1.9258, -2.0471, -2.2196, -2.0817, -2.1101, -2.0322, -2.2601, -2.1202,\n",
      "        -2.1844, -2.2706, -2.0869, -1.8349, -2.0654, -2.1515, -2.2409, -1.9652,\n",
      "        -2.1413, -2.2831, -2.2062, -2.0270, -1.9510, -1.9790, -1.9138, -2.5664,\n",
      "        -2.1118, -2.4442], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3911, -2.3973, -2.4102, -2.4332, -2.3408, -2.4129, -2.4299, -2.3653,\n",
      "        -2.3685, -2.3944, -2.4211, -2.4186, -2.4114, -2.4192, -2.4083, -2.4069,\n",
      "        -2.4154, -2.4076, -2.3398, -2.3369, -2.4165, -2.4073, -2.4293, -2.3831,\n",
      "        -2.3626, -2.4134, -2.4165, -2.4139, -2.4187, -2.4033, -2.4220, -2.4279,\n",
      "        -2.4115, -2.4303, -2.4125, -2.4090, -2.4735, -2.4230, -2.4043, -2.4354,\n",
      "        -2.4174, -2.4134, -2.4096, -2.4122, -2.4128, -2.4093, -2.3825, -2.4097,\n",
      "        -2.3703, -2.4049], device='mps:0')\n",
      "mean: tensor(-2.4057, device='mps:0')\n",
      "iter_dt 1.08s; iter 9: train loss 1.23244 temperature: 5.449999999999998\n",
      "mean_logits tensor([-2.3467, -2.4592, -1.8231, -2.1874, -2.3297, -2.4654, -1.8958, -2.3893,\n",
      "        -1.9556, -1.8143, -2.0957, -2.0368, -2.6466, -2.3043, -2.5019, -2.2447,\n",
      "        -2.3117, -1.7890, -2.0279, -2.1150, -2.0624, -2.2112, -2.2846, -2.1816,\n",
      "        -1.9594, -1.7698, -2.4894, -2.4189, -2.1608, -2.3211, -2.3618, -2.3988,\n",
      "        -1.6936, -2.2126, -2.0195, -1.7341, -2.0115, -2.2183, -2.1516, -2.2568,\n",
      "        -2.1534, -1.8669, -2.5485, -2.1916, -1.7969, -2.1461, -1.8646, -2.2390,\n",
      "        -2.1543, -2.0335], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4208, -2.4225, -2.3647, -2.3943, -2.3298, -2.4066, -2.4186, -2.4197,\n",
      "        -2.4398, -2.4201, -2.4220, -2.4195, -2.3806, -2.4204, -2.4339, -2.4031,\n",
      "        -2.4193, -2.3849, -2.4018, -2.4128, -2.4272, -2.4012, -2.4155, -2.4280,\n",
      "        -2.4185, -2.3906, -2.4141, -2.4191, -2.4098, -2.4348, -2.3711, -2.3884,\n",
      "        -2.4235, -2.3565, -2.4138, -2.3801, -2.3938, -2.4233, -2.4231, -2.4099,\n",
      "        -2.4004, -2.4041, -2.4233, -2.4270, -2.4013, -2.3781, -2.3810, -2.4011,\n",
      "        -2.4220, -2.3756], device='mps:0')\n",
      "mean: tensor(-2.4058, device='mps:0')\n",
      "iter_dt 1.04s; iter 10: train loss 1.43568 temperature: 5.499999999999998\n",
      "mean_logits tensor([-1.7795, -2.0256, -2.4175, -2.1424, -1.8393, -2.3290, -2.7421, -1.8784,\n",
      "        -2.4181, -1.9367, -2.5390, -1.9470, -2.0546, -1.9062, -2.1863, -2.0489,\n",
      "        -2.0093, -2.0293, -2.3214, -2.2387, -1.9319, -1.8423, -2.6278, -2.4835,\n",
      "        -2.2533, -2.1404, -2.1046, -2.0728, -2.1957, -1.8227, -2.4086, -2.0283,\n",
      "        -2.2951, -2.2637, -2.0656, -2.2139, -1.8770, -2.1017, -1.6619, -2.5222,\n",
      "        -2.1710, -1.6495, -2.5525, -2.0616, -2.1865, -2.2898, -1.9761, -2.1735,\n",
      "        -2.0324, -1.7697], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4160, -2.3954, -2.3799, -2.4461, -2.3554, -2.3857, -2.4182, -2.4649,\n",
      "        -2.4261, -2.4039, -2.3671, -2.4192, -2.4027, -2.4165, -2.3851, -2.3984,\n",
      "        -2.4241, -2.4311, -2.4024, -2.4442, -2.3974, -2.4120, -2.4273, -2.4219,\n",
      "        -2.4197, -2.4013, -2.3685, -2.4207, -2.3937, -2.4142, -2.4161, -2.4075,\n",
      "        -2.3354, -2.3235, -2.3841, -2.4169, -2.4073, -2.4015, -2.3861, -2.4282,\n",
      "        -2.4246, -2.4308, -2.4004, -2.3530, -2.3518, -2.4234, -2.4060, -2.3906,\n",
      "        -2.3868, -2.3398], device='mps:0')\n",
      "mean: tensor(-2.4015, device='mps:0')\n",
      "iter_dt 1.05s; iter 11: train loss 1.12709 temperature: 5.549999999999998\n",
      "mean_logits tensor([-2.1990, -2.2995, -1.9153, -1.4629, -2.5340, -2.3842, -2.8591, -2.5012,\n",
      "        -2.2986, -1.9403, -2.4811, -2.2102, -2.1618, -2.2220, -2.1216, -1.8991,\n",
      "        -2.0287, -1.8970, -2.2692, -2.2238, -2.4423, -2.3559, -2.2794, -1.6708,\n",
      "        -2.1644, -1.9987, -1.9778, -2.4529, -1.9619, -2.4013, -2.0049, -2.3320,\n",
      "        -2.2704, -2.0936, -2.1805, -2.2698, -2.4174, -2.6910, -2.2235, -2.7053,\n",
      "        -2.4376, -2.5281, -2.0428, -1.7780, -2.4797, -2.4995, -2.2359, -2.2438,\n",
      "        -2.2548, -1.9540], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3815, -2.4069, -2.4100, -2.3559, -2.3984, -2.4050, -2.4302, -2.4323,\n",
      "        -2.4160, -2.4052, -2.4173, -2.4163, -2.4315, -2.3855, -2.3970, -2.3814,\n",
      "        -2.4160, -2.4680, -2.4098, -2.3890, -2.4255, -2.4191, -2.4118, -2.4370,\n",
      "        -2.4195, -2.3925, -2.3921, -2.4207, -2.4045, -2.4100, -2.4108, -2.4191,\n",
      "        -2.4748, -2.3873, -2.3870, -2.4318, -2.4276, -2.4330, -2.3878, -2.4460,\n",
      "        -2.4331, -2.4224, -2.4186, -2.3535, -2.4210, -2.3728, -2.3524, -2.4184,\n",
      "        -2.4344, -2.4249], device='mps:0')\n",
      "mean: tensor(-2.4108, device='mps:0')\n",
      "iter_dt 1.01s; iter 12: train loss 0.91918 temperature: 5.599999999999998\n",
      "mean_logits tensor([-2.3568, -2.5863, -1.9191, -2.2409, -2.4468, -2.5074, -2.3498, -2.1167,\n",
      "        -2.2670, -2.5599, -2.2943, -2.1373, -2.6332, -2.0403, -1.8593, -2.2885,\n",
      "        -2.4229, -2.1490, -2.2698, -2.2322, -2.3450, -2.1468, -2.0975, -2.4689,\n",
      "        -2.4367, -2.4894, -2.0677, -2.2554, -2.2587, -2.7768, -2.3630, -1.9961,\n",
      "        -2.1492, -2.1598, -2.0187, -2.1918, -2.0330, -2.4713, -2.1941, -2.2294,\n",
      "        -2.1427, -1.9080, -2.5872, -2.3608, -2.5020, -2.7116, -1.8946, -2.3724,\n",
      "        -1.9804, -1.7435], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3964, -2.4328, -2.4328, -2.4132, -2.3486, -2.4293, -2.4192, -2.4153,\n",
      "        -2.4288, -2.3958, -2.3952, -2.4202, -2.4028, -2.4153, -2.4164, -2.3315,\n",
      "        -2.3784, -2.4404, -2.3871, -2.4351, -2.4367, -2.3591, -2.3951, -2.4205,\n",
      "        -2.4409, -2.4389, -2.3808, -2.4029, -2.4233, -2.3904, -2.4191, -2.4174,\n",
      "        -2.3956, -2.4235, -2.3613, -2.4340, -2.3890, -2.3664, -2.4332, -2.3906,\n",
      "        -2.3728, -2.4158, -2.3824, -2.4204, -2.4008, -2.4295, -2.4064, -2.4305,\n",
      "        -2.4168, -2.3926], device='mps:0')\n",
      "mean: tensor(-2.4064, device='mps:0')\n",
      "iter_dt 1.00s; iter 13: train loss 0.82267 temperature: 5.649999999999998\n",
      "mean_logits tensor([-2.1151, -2.4924, -2.6534, -2.0386, -2.7856, -2.5232, -2.7194, -2.2943,\n",
      "        -2.1803, -2.5045, -2.0969, -2.3522, -2.4081, -2.3898, -2.3186, -2.0717,\n",
      "        -2.7844, -2.3372, -2.5281, -2.2720, -2.0836, -2.5508, -2.5017, -2.0432,\n",
      "        -2.2877, -2.4818, -2.3204, -2.5150, -2.4363, -2.3464, -2.4316, -2.1458,\n",
      "        -1.9988, -2.2430, -2.4606, -2.7384, -2.2532, -2.4175, -2.2169, -2.0987,\n",
      "        -2.0388, -2.7523, -2.2338, -2.3847, -2.6794, -2.6372, -2.7630, -2.3655,\n",
      "        -2.5671, -2.1231], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3797, -2.4131, -2.4253, -2.4317, -2.4148, -2.3969, -2.4102, -2.4344,\n",
      "        -2.3820, -2.3693, -2.4122, -2.4253, -2.4262, -2.3970, -2.4055, -2.3990,\n",
      "        -2.4263, -2.4053, -2.3287, -2.4176, -2.4039, -2.4324, -2.3911, -2.4069,\n",
      "        -2.3612, -2.4307, -2.4173, -2.4187, -2.4271, -2.3980, -2.4324, -2.4205,\n",
      "        -2.4226, -2.4492, -2.4187, -2.4203, -2.4003, -2.3791, -2.4184, -2.4032,\n",
      "        -2.3791, -2.4413, -2.4288, -2.3903, -2.4140, -2.4336, -2.4189, -2.4094,\n",
      "        -2.4078, -2.4124], device='mps:0')\n",
      "mean: tensor(-2.4098, device='mps:0')\n",
      "iter_dt 1.01s; iter 14: train loss 0.97990 temperature: 5.6999999999999975\n",
      "mean_logits tensor([-2.4914, -2.6065, -2.6207, -2.2460, -2.3878, -1.9001, -1.8126, -1.6329,\n",
      "        -2.1462, -2.5910, -2.3051, -2.6974, -2.1909, -2.1837, -1.9230, -2.5218,\n",
      "        -1.9872, -2.7161, -2.2871, -2.3744, -2.6807, -2.4162, -2.0036, -2.1232,\n",
      "        -2.6904, -2.2153, -2.6487, -2.3663, -2.3423, -1.9301, -2.7168, -2.2886,\n",
      "        -2.3932, -2.7805, -2.2322, -2.2173, -2.3921, -2.3273, -2.3779, -2.4454,\n",
      "        -2.2500, -2.0562, -2.2885, -2.3503, -2.7646, -2.3159, -2.2237, -1.8414,\n",
      "        -2.4688, -2.2665], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4077, -2.4196, -2.4134, -2.4021, -2.4205, -2.4216, -2.4020, -2.4294,\n",
      "        -2.4337, -2.4255, -2.3959, -2.4445, -2.3921, -2.4179, -2.3238, -2.4396,\n",
      "        -2.3748, -2.4237, -2.3590, -2.4094, -2.4458, -2.4215, -2.4400, -2.3627,\n",
      "        -2.4091, -2.3916, -2.4179, -2.3836, -2.4336, -2.4148, -2.4203, -2.4070,\n",
      "        -2.4206, -2.4231, -2.4181, -2.4192, -2.3623, -2.3922, -2.4343, -2.4217,\n",
      "        -2.4182, -2.3800, -2.3637, -2.4179, -2.4314, -2.3850, -2.4002, -2.4180,\n",
      "        -2.4175, -2.4431], device='mps:0')\n",
      "mean: tensor(-2.4094, device='mps:0')\n",
      "iter_dt 1.08s; iter 15: train loss 0.91468 temperature: 5.749999999999997\n",
      "mean_logits tensor([-2.7064, -2.6875, -2.8314, -2.1001, -1.9375, -2.2028, -2.6749, -2.4981,\n",
      "        -2.4355, -2.5422, -1.9511, -2.4510, -2.3089, -2.4083, -2.6662, -2.0597,\n",
      "        -2.4412, -2.7204, -2.5625, -2.7747, -2.6490, -2.3071, -2.4789, -2.0513,\n",
      "        -2.3562, -2.3465, -2.5155, -2.1615, -2.0929, -2.5144, -2.2814, -2.1251,\n",
      "        -2.6076, -2.1432, -2.0485, -2.5789, -2.3542, -2.0222, -2.6162, -2.6136,\n",
      "        -2.1331, -2.1884, -2.2245, -2.3249, -2.2823, -2.5610, -2.2151, -2.6220,\n",
      "        -1.9428, -2.5793], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4440, -2.3948, -2.4580, -2.4177, -2.3668, -2.3910, -2.3856, -2.4399,\n",
      "        -2.4254, -2.4436, -2.3975, -2.4092, -2.4320, -2.4093, -2.3812, -2.4147,\n",
      "        -2.3874, -2.4175, -2.3747, -2.4429, -2.4211, -2.3449, -2.4147, -2.3536,\n",
      "        -2.4459, -2.4165, -2.4011, -2.4128, -2.4207, -2.4152, -2.4556, -2.4101,\n",
      "        -2.4314, -2.3955, -2.4442, -2.4104, -2.3975, -2.4224, -2.4227, -2.3885,\n",
      "        -2.3854, -2.4126, -2.4177, -2.4114, -2.4157, -2.4382, -2.3990, -2.3756,\n",
      "        -2.4185, -2.4176], device='mps:0')\n",
      "mean: tensor(-2.4110, device='mps:0')\n",
      "iter_dt 1.07s; iter 16: train loss 1.02825 temperature: 5.799999999999997\n",
      "mean_logits tensor([-2.2559, -1.9318, -1.8585, -2.0535, -2.6514, -2.2094, -1.8292, -2.3967,\n",
      "        -2.1726, -2.7608, -2.4608, -2.4257, -2.7364, -2.3167, -2.3702, -2.2643,\n",
      "        -2.4943, -2.0247, -2.4451, -2.1343, -2.0411, -2.7174, -2.2228, -2.0758,\n",
      "        -2.2109, -2.7670, -2.5493, -2.2497, -2.2526, -1.9569, -2.5540, -2.0990,\n",
      "        -2.5183, -2.5138, -2.6067, -2.8074, -2.3532, -2.1004, -2.5873, -2.6478,\n",
      "        -2.2587, -2.3984, -2.1240, -2.3354, -1.6971, -2.1802, -2.2075, -2.3366,\n",
      "        -2.1596, -2.2824], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3870, -2.4330, -2.3791, -2.4156, -2.4528, -2.3933, -2.4203, -2.3481,\n",
      "        -2.4309, -2.4330, -2.3651, -2.4148, -2.3770, -2.3541, -2.4185, -2.3926,\n",
      "        -2.4062, -2.4162, -2.4101, -2.4127, -2.4152, -2.3611, -2.4256, -2.4153,\n",
      "        -2.4004, -2.4320, -2.4335, -2.4102, -2.4231, -2.3850, -2.4486, -2.3100,\n",
      "        -2.4263, -2.4340, -2.4241, -2.4126, -2.3980, -2.3761, -2.4261, -2.4318,\n",
      "        -2.4140, -2.4286, -2.4228, -2.4204, -2.4106, -2.4218, -2.4255, -2.4336,\n",
      "        -2.4117, -2.4339], device='mps:0')\n",
      "mean: tensor(-2.4094, device='mps:0')\n",
      "iter_dt 1.07s; iter 17: train loss 0.86158 temperature: 5.849999999999997\n",
      "mean_logits tensor([-2.2278, -2.2980, -1.8827, -2.3489, -2.7883, -2.5397, -1.6614, -2.2605,\n",
      "        -2.4493, -2.2604, -2.7842, -2.4314, -1.6988, -2.4486, -2.0939, -2.3411,\n",
      "        -2.4403, -2.3332, -2.3197, -2.5779, -2.3913, -2.5396, -2.2219, -2.1981,\n",
      "        -2.2288, -2.1130, -2.0328, -2.2942, -2.1438, -2.5735, -2.4214, -2.3054,\n",
      "        -2.1908, -2.4053, -2.3235, -1.7708, -2.2461, -2.2819, -2.1889, -2.2121,\n",
      "        -2.6126, -2.0439, -2.1278, -2.3232, -2.0209, -2.2233, -2.2545, -1.9675,\n",
      "        -2.2712, -2.4287], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3818, -2.3999, -2.3956, -2.4127, -2.3955, -2.4209, -2.3996, -2.4028,\n",
      "        -2.3904, -2.4337, -2.4472, -2.4244, -2.3988, -2.4196, -2.3878, -2.4190,\n",
      "        -2.4064, -2.4029, -2.3692, -2.4171, -2.4338, -2.3875, -2.4202, -2.4105,\n",
      "        -2.3871, -2.3878, -2.4343, -2.3446, -2.4185, -2.3922, -2.4256, -2.4228,\n",
      "        -2.4201, -2.4342, -2.4456, -2.4041, -2.4165, -2.3788, -2.4166, -2.4275,\n",
      "        -2.4163, -2.3629, -2.4148, -2.4010, -2.4171, -2.4227, -2.4673, -2.3995,\n",
      "        -2.4187, -2.4153], device='mps:0')\n",
      "mean: tensor(-2.4094, device='mps:0')\n",
      "iter_dt 1.07s; iter 18: train loss 0.79885 temperature: 5.899999999999997\n",
      "mean_logits tensor([-2.3341, -1.9158, -2.1881, -2.3317, -2.6381, -2.6225, -1.9198, -2.3588,\n",
      "        -1.9847, -2.7742, -2.0592, -2.3389, -1.9586, -2.3564, -2.6627, -2.4342,\n",
      "        -2.2293, -2.3722, -2.3333, -1.9178, -2.3046, -2.4253, -2.5006, -2.0770,\n",
      "        -1.7860, -2.4061, -2.4941, -2.1921, -2.4654, -2.6138, -2.3765, -2.6345,\n",
      "        -2.5268, -1.9646, -2.2747, -2.4803, -2.2289, -2.3304, -2.3763, -2.1557,\n",
      "        -2.0372, -1.9749, -2.2754, -2.4978, -2.4344, -2.3919, -2.0678, -2.2845,\n",
      "        -2.1252, -2.1800], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4195, -2.3718, -2.3653, -2.3887, -2.3732, -2.3610, -2.4187, -2.4187,\n",
      "        -2.4437, -2.4589, -2.3985, -2.4051, -2.4185, -2.4461, -2.4095, -2.4312,\n",
      "        -2.4060, -2.3696, -2.3982, -2.3930, -2.3933, -2.3606, -2.4187, -2.4045,\n",
      "        -2.4115, -2.3742, -2.4151, -2.4175, -2.4115, -2.4133, -2.4069, -2.3925,\n",
      "        -2.4185, -2.3633, -2.4187, -2.3971, -2.4216, -2.4252, -2.4155, -2.3692,\n",
      "        -2.4068, -2.3756, -2.4395, -2.4099, -2.3542, -2.4178, -2.4244, -2.4059,\n",
      "        -2.4089, -2.3179], device='mps:0')\n",
      "mean: tensor(-2.4021, device='mps:0')\n",
      "iter_dt 1.05s; iter 19: train loss 0.71637 temperature: 5.949999999999997\n",
      "mean_logits tensor([-1.7740, -2.2982, -1.9749, -1.8969, -2.4561, -1.9901, -2.5943, -2.5314,\n",
      "        -2.4169, -2.0920, -2.2568, -2.2759, -2.1616, -2.3141, -2.1162, -2.2166,\n",
      "        -2.0868, -2.3022, -2.6157, -2.4169, -2.4611, -2.5159, -2.3412, -2.1827,\n",
      "        -2.1213, -2.4203, -2.0668, -2.5543, -2.2561, -2.1136, -2.5160, -2.4979,\n",
      "        -1.9876, -2.4300, -2.1126, -2.2271, -2.2868, -2.4579, -2.3198, -2.6141,\n",
      "        -2.3342, -2.5085, -2.5449, -2.4392, -2.0036, -2.3586, -2.3656, -1.7483,\n",
      "        -2.4175, -2.1894], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4036, -2.4153, -2.3326, -2.4196, -2.4017, -2.4253, -2.4405, -2.3725,\n",
      "        -2.3367, -2.4074, -2.4200, -2.4331, -2.4162, -2.4105, -2.4011, -2.4342,\n",
      "        -2.4180, -2.4205, -2.4487, -2.4187, -2.4194, -2.4319, -2.4179, -2.3617,\n",
      "        -2.3743, -2.4331, -2.4145, -2.4203, -2.3983, -2.4166, -2.3922, -2.3788,\n",
      "        -2.4121, -2.3658, -2.3778, -2.4229, -2.3775, -2.4297, -2.3673, -2.4141,\n",
      "        -2.4208, -2.3862, -2.3544, -2.4185, -2.4155, -2.3698, -2.4012, -2.4651,\n",
      "        -2.4609, -2.2793], device='mps:0')\n",
      "mean: tensor(-2.4035, device='mps:0')\n",
      "iter_dt 1.06s; iter 20: train loss 0.98658 temperature: 5.9999999999999964\n",
      "mean_logits tensor([-1.7992, -2.0983, -2.3815, -2.2521, -1.6761, -2.2169, -2.1454, -2.0663,\n",
      "        -2.5808, -2.2727, -2.3692, -2.4203, -2.4796, -2.3007, -2.4559, -2.0559,\n",
      "        -2.3589, -2.0952, -2.2051, -2.3454, -1.6653, -2.1632, -2.4354, -2.6490,\n",
      "        -2.5148, -2.1237, -2.0220, -2.4733, -2.6173, -2.8385, -2.3564, -2.4792,\n",
      "        -2.1139, -2.1051, -2.6414, -2.5385, -2.5983, -2.1562, -2.1073, -2.3507,\n",
      "        -2.7701, -2.2008, -2.3304, -2.5446, -2.5217, -2.2776, -2.0553, -2.2157,\n",
      "        -1.9589, -2.2363], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3900, -2.4151, -2.4567, -2.3834, -2.4238, -2.4208, -2.4085, -2.4081,\n",
      "        -2.4035, -2.4054, -2.4122, -2.4463, -2.4182, -2.3827, -2.3522, -2.4190,\n",
      "        -2.4345, -2.4149, -2.4195, -2.4005, -2.3687, -2.3599, -2.3749, -2.3301,\n",
      "        -2.4137, -2.3740, -2.3453, -2.4007, -2.4111, -2.3911, -2.4112, -2.3895,\n",
      "        -2.4454, -2.4624, -2.4231, -2.3920, -2.4184, -2.4114, -2.4194, -2.4138,\n",
      "        -2.4146, -2.3986, -2.4100, -2.4171, -2.4024, -2.4030, -2.4325, -2.4363,\n",
      "        -2.4192, -2.4151], device='mps:0')\n",
      "mean: tensor(-2.4064, device='mps:0')\n",
      "iter_dt 1.11s; iter 21: train loss 0.95152 temperature: 6.049999999999996\n",
      "mean_logits tensor([-2.1147, -2.5289, -2.1843, -2.0158, -2.3086, -2.2514, -2.2942, -2.2750,\n",
      "        -2.7311, -2.4196, -1.8748, -2.0211, -1.7389, -1.9157, -2.3254, -2.3096,\n",
      "        -2.0658, -2.1178, -2.4380, -2.3617, -2.4387, -2.2712, -2.3301, -2.2234,\n",
      "        -2.3451, -1.7570, -2.2572, -2.4695, -1.8038, -2.3139, -1.9504, -1.9295,\n",
      "        -2.1848, -2.0911, -2.0875, -2.1511, -2.4086, -2.3847, -2.3458, -2.0181,\n",
      "        -2.0638, -2.2919, -1.8191, -2.4078, -2.1090, -2.3268, -2.4026, -2.2434,\n",
      "        -2.3815, -2.0029], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4002, -2.4242, -2.4133, -2.4194, -2.4104, -2.4161, -2.4196, -2.3733,\n",
      "        -2.3884, -2.4139, -2.4010, -2.4190, -2.4354, -2.4224, -2.4110, -2.4438,\n",
      "        -2.3617, -2.3540, -2.4014, -2.3746, -2.4114, -2.3873, -2.4205, -2.3939,\n",
      "        -2.4173, -2.4031, -2.3578, -2.3417, -2.4130, -2.3962, -2.3769, -2.4140,\n",
      "        -2.4100, -2.3753, -2.3342, -2.4285, -2.3755, -2.4040, -2.4172, -2.3571,\n",
      "        -2.3740, -2.4140, -2.4290, -2.4221, -2.4173, -2.4206, -2.4001, -2.4173,\n",
      "        -2.4115, -2.4098], device='mps:0')\n",
      "mean: tensor(-2.4011, device='mps:0')\n",
      "iter_dt 1.07s; iter 22: train loss 0.92269 temperature: 6.099999999999996\n",
      "mean_logits tensor([-2.4584, -2.2314, -2.3152, -2.7300, -1.9344, -2.1928, -2.2352, -2.4084,\n",
      "        -2.3436, -2.3718, -2.2229, -2.1864, -2.2768, -2.5226, -2.6936, -2.0528,\n",
      "        -1.9239, -2.3858, -2.5417, -2.2874, -2.1549, -2.2390, -2.0965, -2.5509,\n",
      "        -1.9132, -2.0274, -2.2530, -2.5601, -2.1347, -2.5317, -2.0783, -2.0571,\n",
      "        -2.2761, -1.4775, -2.3527, -2.1822, -2.3894, -2.6251, -2.6322, -2.3086,\n",
      "        -1.9751, -2.0582, -2.4385, -2.6725, -2.7203, -2.2296, -2.1915, -1.9470,\n",
      "        -2.4522, -2.4553], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3986, -2.3937, -2.4187, -2.4102, -2.3557, -2.4198, -2.4161, -2.4332,\n",
      "        -2.3894, -2.3928, -2.4348, -2.4110, -2.4257, -2.4106, -2.4286, -2.3740,\n",
      "        -2.4112, -2.3802, -2.4078, -2.4336, -2.4181, -2.3812, -2.4169, -2.4011,\n",
      "        -2.3586, -2.4131, -2.4254, -2.4034, -2.4044, -2.4339, -2.4166, -2.4191,\n",
      "        -2.4033, -2.4233, -2.4122, -2.4142, -2.4076, -2.3917, -2.4169, -2.4118,\n",
      "        -2.4135, -2.4207, -2.4131, -2.4124, -2.4199, -2.4209, -2.4081, -2.4215,\n",
      "        -2.4126, -2.3963], device='mps:0')\n",
      "mean: tensor(-2.4091, device='mps:0')\n",
      "iter_dt 1.09s; iter 23: train loss 0.82310 temperature: 6.149999999999996\n",
      "mean_logits tensor([-2.5147, -2.3244, -2.2182, -2.1215, -2.1057, -2.1070, -2.5806, -2.0750,\n",
      "        -2.2669, -2.3281, -2.4409, -2.4586, -2.1951, -2.3200, -2.3742, -2.2466,\n",
      "        -2.0128, -2.3646, -1.9805, -2.3452, -2.1362, -1.7521, -2.0842, -2.3031,\n",
      "        -2.0850, -2.0938, -2.1231, -2.5710, -2.5913, -2.1331, -2.6188, -2.2755,\n",
      "        -2.4944, -2.3825, -2.0490, -2.4434, -2.2361, -1.7150, -2.6924, -2.5914,\n",
      "        -2.2472, -2.0414, -2.1299, -2.1476, -2.3077, -2.2641, -2.6605, -2.0840,\n",
      "        -2.5401, -2.5049], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3567, -2.3729, -2.3942, -2.4195, -2.4005, -2.3804, -2.4106, -2.4150,\n",
      "        -2.4257, -2.3586, -2.4032, -2.4185, -2.3216, -2.3860, -2.4081, -2.4045,\n",
      "        -2.4013, -2.3972, -2.3583, -2.4213, -2.4190, -2.4451, -2.4119, -2.4243,\n",
      "        -2.4178, -2.4187, -2.3836, -2.4035, -2.3917, -2.4190, -2.3791, -2.4108,\n",
      "        -2.4319, -2.4164, -2.3947, -2.4189, -2.3636, -2.4177, -2.3635, -2.3996,\n",
      "        -2.3652, -2.3949, -2.4141, -2.3928, -2.4041, -2.3893, -2.4103, -2.4173,\n",
      "        -2.3713, -2.4000], device='mps:0')\n",
      "mean: tensor(-2.3989, device='mps:0')\n",
      "iter_dt 1.05s; iter 24: train loss 1.10037 temperature: 6.199999999999996\n",
      "mean_logits tensor([-1.8775, -2.1235, -2.1276, -2.2515, -1.8247, -2.5807, -2.1535, -2.1711,\n",
      "        -2.0716, -2.1395, -2.1951, -2.3596, -2.3445, -2.3675, -2.1725, -2.1927,\n",
      "        -2.7619, -1.9530, -2.0392, -2.0532, -2.5819, -2.6593, -2.4005, -2.3378,\n",
      "        -2.4093, -2.6792, -2.7202, -2.0415, -2.3974, -2.2315, -1.9471, -2.3720,\n",
      "        -2.3515, -2.0977, -1.7564, -1.9314, -2.4813, -2.0920, -2.2003, -2.1559,\n",
      "        -1.9037, -2.6671, -2.0465, -2.4686, -2.2457, -2.4395, -2.4035, -1.9414,\n",
      "        -2.4744, -2.3113], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4547, -2.3853, -2.4277, -2.3293, -2.3885, -2.3881, -2.4161, -2.4216,\n",
      "        -2.3906, -2.4250, -2.4379, -2.4447, -2.4166, -2.4176, -2.3815, -2.4357,\n",
      "        -2.4139, -2.4193, -2.4189, -2.4127, -2.4256, -2.4041, -2.3985, -2.3871,\n",
      "        -2.4276, -2.3127, -2.4315, -2.4061, -2.4000, -2.4235, -2.4176, -2.3983,\n",
      "        -2.4175, -2.4101, -2.4258, -2.4164, -2.4329, -2.4268, -2.3922, -2.3951,\n",
      "        -2.3847, -2.4002, -2.4379, -2.3892, -2.3719, -2.4136, -2.4206, -2.4428,\n",
      "        -2.4319, -2.3900], device='mps:0')\n",
      "mean: tensor(-2.4092, device='mps:0')\n",
      "iter_dt 1.10s; iter 25: train loss 0.72486 temperature: 6.249999999999996\n",
      "mean_logits tensor([-2.2853, -2.8823, -2.5494, -2.4986, -2.1939, -2.4803, -2.4889, -2.6084,\n",
      "        -2.1582, -2.4413, -1.8563, -2.1313, -2.3672, -2.4831, -2.6254, -1.9052,\n",
      "        -2.1991, -2.2155, -2.4339, -2.0697, -2.2919, -2.2452, -2.2803, -2.5606,\n",
      "        -2.2875, -2.2675, -2.6093, -2.5552, -2.2256, -2.0762, -2.1240, -2.2721,\n",
      "        -2.3936, -2.3508, -2.3987, -2.0630, -2.3846, -2.4205, -2.3855, -2.4104,\n",
      "        -2.2021, -2.3770, -2.7043, -2.1699, -2.3027, -1.8935, -2.4240, -1.9560,\n",
      "        -2.4842, -2.5079], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4139, -2.3894, -2.4062, -2.4146, -2.4173, -2.4162, -2.4270, -2.4185,\n",
      "        -2.4198, -2.4225, -2.4003, -2.4063, -2.4080, -2.3728, -2.3907, -2.3364,\n",
      "        -2.4266, -2.4419, -2.4094, -2.4201, -2.3778, -2.4013, -2.4322, -2.4165,\n",
      "        -2.4064, -2.4200, -2.4006, -2.4317, -2.4238, -2.4026, -2.4265, -2.4574,\n",
      "        -2.4026, -2.4085, -2.4040, -2.3847, -2.3652, -2.4200, -2.4374, -2.4051,\n",
      "        -2.4190, -2.4206, -2.4095, -2.4195, -2.3585, -2.4141, -2.4266, -2.3752,\n",
      "        -2.3950, -2.3597], device='mps:0')\n",
      "mean: tensor(-2.4076, device='mps:0')\n",
      "iter_dt 1.13s; iter 26: train loss 0.75071 temperature: 6.299999999999995\n",
      "mean_logits tensor([-2.2484, -2.4139, -2.1479, -1.7043, -2.6199, -2.3969, -2.0310, -2.4128,\n",
      "        -2.5415, -2.3762, -2.1425, -2.5540, -2.3572, -2.0515, -2.3218, -2.4459,\n",
      "        -2.3229, -2.0021, -2.1309, -2.3124, -2.5376, -2.1528, -2.4706, -2.4804,\n",
      "        -2.3214, -2.8107, -2.4808, -2.5195, -2.1786, -2.3192, -2.2131, -2.5856,\n",
      "        -2.5233, -2.0431, -2.3344, -2.1884, -2.0263, -1.9249, -2.5104, -2.5276,\n",
      "        -1.8057, -2.4382, -2.4269, -2.3985, -2.6398, -1.9474, -2.1460, -2.7620,\n",
      "        -2.4255, -2.2614], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3972, -2.4160, -2.4220, -2.4077, -2.4070, -2.3974, -2.4130, -2.4102,\n",
      "        -2.4339, -2.3591, -2.4010, -2.3930, -2.4207, -2.3137, -2.4188, -2.4498,\n",
      "        -2.3809, -2.3990, -2.4344, -2.4011, -2.4135, -2.4012, -2.4205, -2.4247,\n",
      "        -2.4350, -2.4043, -2.4141, -2.4147, -2.4178, -2.4071, -2.4215, -2.4170,\n",
      "        -2.4299, -2.3844, -2.4030, -2.3344, -2.3913, -2.3549, -2.4396, -2.4179,\n",
      "        -2.3832, -2.4158, -2.4194, -2.3732, -2.4085, -2.4066, -2.3419, -2.4171,\n",
      "        -2.4484, -2.4265], device='mps:0')\n",
      "mean: tensor(-2.4053, device='mps:0')\n",
      "iter_dt 1.16s; iter 27: train loss 0.73283 temperature: 6.349999999999995\n",
      "mean_logits tensor([-2.6931, -2.1652, -2.5859, -2.3700, -2.1077, -2.1987, -2.3959, -2.4500,\n",
      "        -2.1902, -2.4309, -2.1944, -2.3455, -2.1031, -2.4631, -2.1790, -1.8929,\n",
      "        -2.2768, -2.2266, -2.4667, -2.2881, -2.4861, -2.4371, -2.3825, -2.2144,\n",
      "        -2.5370, -2.5116, -2.2379, -1.7842, -2.6077, -2.6466, -2.4701, -2.1022,\n",
      "        -2.6404, -2.0908, -2.3465, -2.5262, -1.9366, -2.3964, -2.4622, -2.3376,\n",
      "        -2.0813, -2.6564, -1.9471, -1.9479, -2.3801, -1.9558, -2.3544, -2.1529,\n",
      "        -2.2602, -2.6388], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4098, -2.3969, -2.4135, -2.3972, -2.4094, -2.4179, -2.4011, -2.3799,\n",
      "        -2.4526, -2.4030, -2.3807, -2.4079, -2.4124, -2.4106, -2.3904, -2.3861,\n",
      "        -2.3698, -2.3951, -2.3567, -2.4085, -2.4313, -2.3802, -2.4300, -2.4170,\n",
      "        -2.4329, -2.3927, -2.3757, -2.3820, -2.4170, -2.4201, -2.3935, -2.4037,\n",
      "        -2.4155, -2.3946, -2.3627, -2.4016, -2.4173, -2.4138, -2.3971, -2.4090,\n",
      "        -2.4223, -2.3970, -2.3972, -2.4329, -2.3942, -2.4097, -2.3983, -2.4184,\n",
      "        -2.4044, -2.4241], device='mps:0')\n",
      "mean: tensor(-2.4037, device='mps:0')\n",
      "iter_dt 1.10s; iter 28: train loss 0.77670 temperature: 6.399999999999995\n",
      "mean_logits tensor([-2.7176, -2.4029, -2.3457, -2.8731, -2.3681, -2.0770, -2.5530, -2.4382,\n",
      "        -2.5348, -2.3396, -2.4032, -1.9055, -2.2890, -2.2030, -2.4379, -2.1217,\n",
      "        -2.7571, -2.4678, -2.3460, -2.7026, -2.1336, -2.2958, -2.3162, -2.0345,\n",
      "        -2.2683, -2.2195, -2.1504, -2.4629, -2.5526, -2.2425, -2.5782, -2.0424,\n",
      "        -2.4802, -2.1204, -2.2275, -2.6141, -2.7027, -2.3363, -2.3633, -2.2561,\n",
      "        -2.3762, -2.4916, -2.3516, -2.2473, -2.3321, -2.5746, -2.0793, -2.7376,\n",
      "        -2.5664, -2.2748], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3997, -2.4437, -2.3557, -2.4042, -2.3576, -2.4208, -2.3618, -2.3988,\n",
      "        -2.3620, -2.4334, -2.4053, -2.4177, -2.4324, -2.4130, -2.4194, -2.4190,\n",
      "        -2.4179, -2.4191, -2.4197, -2.4129, -2.4205, -2.3932, -2.4175, -2.4035,\n",
      "        -2.3955, -2.3996, -2.3288, -2.3912, -2.4015, -2.3909, -2.3983, -2.3983,\n",
      "        -2.4184, -2.4117, -2.4236, -2.4132, -2.3733, -2.3573, -2.4104, -2.4156,\n",
      "        -2.4168, -2.3993, -2.4221, -2.3571, -2.4123, -2.4207, -2.4192, -2.3950,\n",
      "        -2.4128, -2.4101], device='mps:0')\n",
      "mean: tensor(-2.4028, device='mps:0')\n",
      "iter_dt 1.06s; iter 29: train loss 0.62752 temperature: 6.449999999999995\n",
      "mean_logits tensor([-2.2935, -2.4389, -2.3944, -2.2169, -2.8606, -2.0779, -2.5917, -2.2898,\n",
      "        -2.6422, -2.4725, -2.6595, -2.3851, -2.4115, -2.2298, -1.7445, -2.4410,\n",
      "        -2.2582, -2.4568, -2.4641, -2.4359, -2.4141, -2.2947, -2.4096, -2.4439,\n",
      "        -2.2763, -2.4100, -2.0810, -2.6025, -2.2064, -2.2672, -2.2798, -2.3200,\n",
      "        -2.2098, -2.5572, -2.4679, -2.2746, -2.5968, -2.3983, -2.3077, -2.1812,\n",
      "        -2.1261, -2.1909, -2.4251, -2.6553, -2.7602, -2.3142, -2.6642, -2.2500,\n",
      "        -1.9725, -2.2582], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4141, -2.4087, -2.4206, -2.3461, -2.4135, -2.3848, -2.3969, -2.4148,\n",
      "        -2.4270, -2.3988, -2.4370, -2.3935, -2.4093, -2.3618, -2.4142, -2.3841,\n",
      "        -2.4076, -2.4205, -2.4190, -2.3920, -2.4174, -2.3606, -2.4188, -2.3960,\n",
      "        -2.4206, -2.4041, -2.4251, -2.4026, -2.4550, -2.3745, -2.4178, -2.3904,\n",
      "        -2.4105, -2.3869, -2.4241, -2.3925, -2.4169, -2.3904, -2.4133, -2.4080,\n",
      "        -2.3643, -2.4033, -2.3998, -2.4202, -2.4185, -2.4397, -2.4247, -2.4164,\n",
      "        -2.4142, -2.3604], device='mps:0')\n",
      "mean: tensor(-2.4050, device='mps:0')\n",
      "iter_dt 1.09s; iter 30: train loss 0.53592 temperature: 6.499999999999995\n",
      "mean_logits tensor([-2.1738, -2.3101, -2.4498, -2.2041, -2.4235, -2.2467, -2.0656, -2.2935,\n",
      "        -2.6917, -2.3386, -2.2017, -2.1125, -2.5276, -2.2858, -2.3915, -2.2550,\n",
      "        -2.1996, -2.3979, -2.4750, -2.2716, -2.4877, -2.2609, -2.6001, -2.5404,\n",
      "        -2.7233, -2.3658, -2.1299, -2.3885, -2.7429, -2.3974, -2.4609, -2.0897,\n",
      "        -2.3672, -2.1668, -2.5167, -2.5616, -2.2453, -2.4669, -2.3476, -2.4757,\n",
      "        -2.5779, -2.1621, -2.3190, -2.6351, -1.9563, -1.9983, -2.2603, -2.4198,\n",
      "        -2.3267, -2.4906], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4049, -2.3772, -2.3779, -2.3677, -2.4005, -2.3403, -2.4170, -2.3837,\n",
      "        -2.3995, -2.3936, -2.4162, -2.4177, -2.4224, -2.4019, -2.3903, -2.4198,\n",
      "        -2.4195, -2.3940, -2.3483, -2.4476, -2.4053, -2.3516, -2.4261, -2.3949,\n",
      "        -2.4102, -2.4082, -2.4204, -2.4185, -2.3820, -2.4123, -2.4188, -2.3626,\n",
      "        -2.4121, -2.3686, -2.4163, -2.3821, -2.4210, -2.4154, -2.3784, -2.4132,\n",
      "        -2.4266, -2.4481, -2.4190, -2.4105, -2.4173, -2.3688, -2.4192, -2.4343,\n",
      "        -2.4572, -2.4038], device='mps:0')\n",
      "mean: tensor(-2.4033, device='mps:0')\n",
      "iter_dt 1.07s; iter 31: train loss 0.50618 temperature: 6.5499999999999945\n",
      "mean_logits tensor([-2.5120, -2.2341, -2.3005, -2.3350, -2.4138, -2.1935, -2.3822, -2.3777,\n",
      "        -2.2517, -2.4056, -2.1716, -2.3129, -2.0989, -2.2492, -2.1492, -2.5369,\n",
      "        -2.2572, -2.1902, -2.6468, -2.2875, -2.3932, -2.3299, -2.0840, -2.5592,\n",
      "        -2.2027, -2.2584, -2.1994, -2.0057, -2.3600, -2.3628, -2.0081, -2.4555,\n",
      "        -2.3375, -2.3463, -2.2884, -2.1151, -2.1835, -2.2710, -2.2053, -2.3320,\n",
      "        -2.5220, -2.0910, -1.6941, -2.1650, -2.0030, -2.2929, -2.3000, -2.0682,\n",
      "        -2.4022, -2.3955], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4214, -2.4131, -2.4344, -2.3767, -2.4356, -2.4189, -2.4137, -2.4114,\n",
      "        -2.4171, -2.4116, -2.3986, -2.4018, -2.3960, -2.3773, -2.3946, -2.4172,\n",
      "        -2.4169, -2.3697, -2.4190, -2.4239, -2.4310, -2.4022, -2.3183, -2.4122,\n",
      "        -2.3808, -2.4327, -2.4262, -2.4045, -2.4166, -2.4090, -2.3085, -2.4328,\n",
      "        -2.4351, -2.3721, -2.3917, -2.4052, -2.3928, -2.4219, -2.4175, -2.3901,\n",
      "        -2.4453, -2.2970, -2.4160, -2.4126, -2.3941, -2.4044, -2.4159, -2.4156,\n",
      "        -2.4170, -2.4139], device='mps:0')\n",
      "mean: tensor(-2.4040, device='mps:0')\n",
      "iter_dt 1.06s; iter 32: train loss 0.53556 temperature: 6.599999999999994\n",
      "mean_logits tensor([-2.2153, -1.9181, -2.3979, -2.2795, -2.2836, -2.3748, -2.3805, -2.3116,\n",
      "        -2.5725, -2.0294, -2.5051, -2.4191, -1.9757, -2.2263, -2.6773, -1.9675,\n",
      "        -2.4531, -2.1711, -2.4759, -2.3376, -2.1253, -2.4629, -2.2972, -2.6528,\n",
      "        -2.4016, -2.5012, -2.4467, -2.4546, -2.2411, -2.4370, -2.2381, -2.3025,\n",
      "        -2.5300, -2.2317, -2.1635, -2.5376, -2.4626, -2.2417, -2.3193, -2.3589,\n",
      "        -2.0056, -2.5716, -2.2911, -2.7743, -2.2162, -2.4186, -2.2822, -2.3989,\n",
      "        -2.1764, -2.4220], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4169, -2.4134, -2.3953, -2.4083, -2.4190, -2.4167, -2.3899, -2.4132,\n",
      "        -2.4104, -2.4213, -2.4178, -2.4127, -2.4170, -2.4077, -2.4146, -2.3913,\n",
      "        -2.3398, -2.4173, -2.3855, -2.4171, -2.4178, -2.4199, -2.4052, -2.4180,\n",
      "        -2.3182, -2.4034, -2.3374, -2.4459, -2.4106, -2.3925, -2.4065, -2.3928,\n",
      "        -2.4279, -2.3818, -2.3975, -2.4036, -2.4369, -2.4143, -2.4213, -2.4234,\n",
      "        -2.4184, -2.4207, -2.3909, -2.4105, -2.3778, -2.3843, -2.4087, -2.4128,\n",
      "        -2.3837, -2.4207], device='mps:0')\n",
      "mean: tensor(-2.4046, device='mps:0')\n",
      "iter_dt 1.09s; iter 33: train loss 0.85555 temperature: 6.649999999999994\n",
      "mean_logits tensor([-2.7044, -2.5649, -2.4127, -2.0471, -2.1832, -2.6440, -2.2880, -1.8663,\n",
      "        -2.4130, -2.4005, -2.5065, -2.1886, -2.3210, -2.5094, -2.5292, -1.9582,\n",
      "        -2.0487, -2.0198, -2.0814, -2.1751, -2.6383, -2.1983, -2.6465, -2.1361,\n",
      "        -2.1552, -1.9995, -2.2211, -2.0585, -2.2237, -2.2853, -2.3305, -2.1080,\n",
      "        -2.3709, -2.0016, -2.1509, -2.6179, -2.1453, -2.1423, -2.7677, -2.1431,\n",
      "        -2.5090, -2.3253, -2.0514, -2.3300, -2.5544, -2.4404, -2.3533, -2.6509,\n",
      "        -2.5278, -2.4276], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4137, -2.3240, -2.3920, -2.4415, -2.3931, -2.3910, -2.4180, -2.4201,\n",
      "        -2.3759, -2.4414, -2.4077, -2.4367, -2.3973, -2.3713, -2.4189, -2.3793,\n",
      "        -2.4227, -2.4114, -2.4229, -2.3815, -2.4227, -2.4134, -2.3910, -2.3809,\n",
      "        -2.4172, -2.4205, -2.4189, -2.3609, -2.3851, -2.4174, -2.3947, -2.3890,\n",
      "        -2.3926, -2.4013, -2.3808, -2.3636, -2.4129, -2.3801, -2.4087, -2.4155,\n",
      "        -2.3947, -2.3558, -2.3713, -2.4084, -2.3989, -2.4515, -2.4166, -2.3584,\n",
      "        -2.4045, -2.3316], device='mps:0')\n",
      "mean: tensor(-2.3984, device='mps:0')\n",
      "iter_dt 1.16s; iter 34: train loss 0.83093 temperature: 6.699999999999994\n",
      "mean_logits tensor([-2.7963, -2.3184, -2.5328, -2.2650, -2.4617, -2.4691, -2.2046, -2.3491,\n",
      "        -2.3446, -2.4387, -2.0803, -2.3034, -1.8465, -2.1739, -2.4572, -2.5864,\n",
      "        -2.0500, -1.9701, -2.4499, -2.3027, -2.4183, -2.3355, -2.6317, -2.7403,\n",
      "        -2.3504, -2.4548, -2.4881, -2.1307, -2.3272, -2.4082, -2.2932, -2.9056,\n",
      "        -1.9945, -2.6044, -2.2553, -2.3915, -2.5859, -2.3151, -2.2487, -2.1240,\n",
      "        -2.2144, -1.9526, -2.2111, -2.1914, -2.6364, -2.4519, -2.4713, -2.5004,\n",
      "        -2.8212, -2.3638], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4042, -2.3952, -2.3854, -2.4039, -2.4199, -2.4149, -2.4082, -2.3638,\n",
      "        -2.4107, -2.4146, -2.4146, -2.4196, -2.3823, -2.3594, -2.4167, -2.3193,\n",
      "        -2.4101, -2.4193, -2.4192, -2.4217, -2.3634, -2.3928, -2.4191, -2.4255,\n",
      "        -2.4260, -2.4518, -2.4232, -2.3992, -2.4224, -2.4453, -2.4073, -2.3880,\n",
      "        -2.3958, -2.4198, -2.3980, -2.3824, -2.4113, -2.3702, -2.4326, -2.3938,\n",
      "        -2.3585, -2.3961, -2.4122, -2.4061, -2.4200, -2.3790, -2.4192, -2.4730,\n",
      "        -2.4094, -2.3765], device='mps:0')\n",
      "mean: tensor(-2.4044, device='mps:0')\n",
      "iter_dt 1.05s; iter 35: train loss 0.55426 temperature: 6.749999999999994\n",
      "mean_logits tensor([-2.3574, -2.1720, -2.1908, -2.2903, -2.5334, -2.3979, -2.4866, -2.5092,\n",
      "        -2.7852, -2.1823, -2.3478, -2.4267, -2.4798, -2.3495, -2.4682, -2.2633,\n",
      "        -2.2925, -2.5330, -2.3084, -2.3958, -2.0620, -2.0167, -2.0016, -2.1796,\n",
      "        -2.0547, -1.9968, -2.3839, -2.6667, -2.4105, -2.4506, -2.1721, -2.6114,\n",
      "        -2.1877, -2.2814, -1.9592, -2.5179, -2.0620, -2.2204, -2.3539, -2.5414,\n",
      "        -2.2716, -2.2749, -2.5309, -2.6094, -2.4907, -2.2518, -2.3298, -2.2666,\n",
      "        -2.4051, -2.5866], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4088, -2.4149, -2.3707, -2.4640, -2.3791, -2.4164, -2.4190, -2.3998,\n",
      "        -2.4109, -2.4196, -2.3958, -2.3548, -2.4122, -2.4204, -2.4170, -2.3649,\n",
      "        -2.4191, -2.4140, -2.3966, -2.4200, -2.3702, -2.4120, -2.3626, -2.4006,\n",
      "        -2.3938, -2.4089, -2.4232, -2.4191, -2.4137, -2.3984, -2.4112, -2.4170,\n",
      "        -2.3764, -2.4098, -2.3924, -2.4257, -2.3985, -2.4110, -2.3485, -2.3929,\n",
      "        -2.4081, -2.3920, -2.3596, -2.4187, -2.3929, -2.4051, -2.4218, -2.4073,\n",
      "        -2.4222, -2.3662], device='mps:0')\n",
      "mean: tensor(-2.4020, device='mps:0')\n",
      "iter_dt 1.10s; iter 36: train loss 0.48086 temperature: 6.799999999999994\n",
      "mean_logits tensor([-2.0255, -2.6177, -2.0297, -2.2655, -2.3485, -2.2760, -2.2873, -2.3877,\n",
      "        -2.5197, -1.9132, -2.4248, -2.5157, -2.4125, -2.3542, -2.0512, -2.2671,\n",
      "        -2.3835, -2.3908, -2.4323, -2.2460, -2.6121, -2.5189, -2.4017, -1.9883,\n",
      "        -2.3028, -2.3927, -2.1942, -2.4484, -2.2688, -2.3305, -2.2991, -2.2484,\n",
      "        -2.3727, -2.3837, -2.6576, -2.2740, -2.3836, -2.0632, -2.4454, -2.5833,\n",
      "        -2.1734, -2.1739, -2.3428, -2.2849, -2.2144, -2.2365, -2.2304, -1.9848,\n",
      "        -2.2404, -2.2016], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3710, -2.4176, -2.3575, -2.4171, -2.4013, -2.3931, -2.4154, -2.4295,\n",
      "        -2.3898, -2.4007, -2.3559, -2.4268, -2.4185, -2.4167, -2.4163, -2.4023,\n",
      "        -2.4303, -2.4144, -2.3770, -2.4005, -2.3973, -2.4026, -2.4160, -2.3961,\n",
      "        -2.4460, -2.4093, -2.3632, -2.4024, -2.4257, -2.3920, -2.4319, -2.3665,\n",
      "        -2.4207, -2.4102, -2.4188, -2.4187, -2.4503, -2.3492, -2.4188, -2.3939,\n",
      "        -2.4271, -2.4176, -2.4165, -2.3842, -2.4289, -2.4188, -2.4048, -2.4165,\n",
      "        -2.4064, -2.4161], device='mps:0')\n",
      "mean: tensor(-2.4064, device='mps:0')\n",
      "iter_dt 1.15s; iter 37: train loss 0.74993 temperature: 6.849999999999993\n",
      "mean_logits tensor([-1.9680, -2.3180, -2.1360, -2.1724, -2.2638, -2.6553, -2.6277, -1.6848,\n",
      "        -2.6855, -2.1699, -2.3674, -2.6857, -2.2385, -2.4179, -2.5787, -2.1964,\n",
      "        -2.4179, -2.5157, -2.3354, -2.3750, -2.4236, -2.0493, -2.2647, -2.1687,\n",
      "        -2.1188, -2.6145, -2.3735, -2.4917, -2.5226, -1.6490, -2.1009, -2.0835,\n",
      "        -2.4215, -2.3718, -2.1946, -2.1557, -2.0708, -2.2313, -2.4818, -2.1891,\n",
      "        -2.3615, -2.1273, -2.4111, -2.4709, -2.2319, -2.5483, -2.1345, -2.3501,\n",
      "        -2.4911, -2.6319], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4216, -2.3625, -2.4051, -2.3543, -2.3125, -2.4008, -2.4189, -2.4002,\n",
      "        -2.3628, -2.3778, -2.4192, -2.4123, -2.4165, -2.3433, -2.4144, -2.4141,\n",
      "        -2.3526, -2.3562, -2.3607, -2.3728, -2.3536, -2.3662, -2.4188, -2.3682,\n",
      "        -2.3724, -2.4118, -2.4091, -2.4672, -2.4020, -2.4187, -2.4395, -2.4138,\n",
      "        -2.4184, -2.4113, -2.4193, -2.4193, -2.3980, -2.4156, -2.4109, -2.4183,\n",
      "        -2.4080, -2.3569, -2.4398, -2.3964, -2.4092, -2.4159, -2.4417, -2.4363,\n",
      "        -2.4314, -2.3525], device='mps:0')\n",
      "mean: tensor(-2.3984, device='mps:0')\n",
      "iter_dt 1.03s; iter 38: train loss 0.61682 temperature: 6.899999999999993\n",
      "mean_logits tensor([-2.4838, -2.2733, -2.1560, -2.0285, -2.3136, -2.4109, -2.5327, -2.5374,\n",
      "        -2.5518, -2.2441, -2.5146, -2.4278, -2.3476, -1.9733, -2.8258, -2.3967,\n",
      "        -2.3907, -2.3350, -2.1745, -1.6365, -2.3212, -2.1808, -2.0948, -2.3554,\n",
      "        -2.0171, -2.4067, -2.4024, -2.3270, -2.0643, -2.4355, -2.1172, -2.0953,\n",
      "        -2.5301, -2.4719, -2.3383, -2.4093, -2.0612, -2.3511, -2.3375, -2.3889,\n",
      "        -2.7038, -2.4913, -2.5671, -2.2103, -2.4780, -2.0417, -2.5355, -2.3101,\n",
      "        -2.5958, -2.2827], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4256, -2.4187, -2.4202, -2.3539, -2.4090, -2.4191, -2.4183, -2.4609,\n",
      "        -2.4185, -2.4000, -2.4321, -2.3634, -2.4174, -2.4044, -2.4041, -2.3775,\n",
      "        -2.4397, -2.4093, -2.4196, -2.3988, -2.4176, -2.3599, -2.4192, -2.3741,\n",
      "        -2.3447, -2.4213, -2.4189, -2.4188, -2.3755, -2.4163, -2.4136, -2.4026,\n",
      "        -2.4176, -2.4150, -2.4229, -2.4179, -2.4126, -2.4115, -2.4097, -2.4241,\n",
      "        -2.4196, -2.4317, -2.4198, -2.4158, -2.4076, -2.4062, -2.4141, -2.4166,\n",
      "        -2.3860, -2.4008], device='mps:0')\n",
      "mean: tensor(-2.4088, device='mps:0')\n",
      "iter_dt 1.07s; iter 39: train loss 0.57331 temperature: 6.949999999999993\n",
      "mean_logits tensor([-2.2837, -2.2333, -2.1587, -2.6167, -2.0169, -2.4723, -2.7267, -2.4589,\n",
      "        -2.1270, -1.8110, -2.2704, -2.2700, -2.2771, -2.2754, -2.4893, -2.6272,\n",
      "        -2.3898, -2.4104, -2.1433, -2.1424, -2.3338, -2.3671, -2.4709, -2.5445,\n",
      "        -2.1329, -2.4494, -2.3189, -2.1460, -2.2576, -2.3684, -2.1707, -2.5597,\n",
      "        -2.0986, -2.0248, -2.2718, -2.3611, -2.2179, -2.2785, -2.5728, -1.9211,\n",
      "        -2.3403, -2.5443, -2.6316, -2.1537, -2.4600, -2.2738, -2.1413, -2.2100,\n",
      "        -2.1080, -2.4756], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4202, -2.3551, -2.3438, -2.4169, -2.3699, -2.4092, -2.4086, -2.3971,\n",
      "        -2.4205, -2.4182, -2.3419, -2.4191, -2.3837, -2.3943, -2.4154, -2.3720,\n",
      "        -2.4055, -2.4266, -2.4109, -2.3700, -2.4167, -2.4142, -2.3733, -2.4195,\n",
      "        -2.3725, -2.4121, -2.4178, -2.3570, -2.4091, -2.4272, -2.4043, -2.4408,\n",
      "        -2.3162, -2.3525, -2.4098, -2.4148, -2.3932, -2.3736, -2.3135, -2.4119,\n",
      "        -2.4286, -2.3937, -2.4264, -2.4142, -2.4069, -2.3533, -2.3801, -2.4125,\n",
      "        -2.4016, -2.3955], device='mps:0')\n",
      "mean: tensor(-2.3952, device='mps:0')\n",
      "iter_dt 1.12s; iter 40: train loss 0.78017 temperature: 6.999999999999993\n",
      "mean_logits tensor([-2.3092, -2.2500, -1.8576, -2.8094, -2.3482, -2.1382, -2.3034, -2.3040,\n",
      "        -2.2140, -2.2009, -2.7625, -2.3000, -2.3613, -2.1418, -2.1363, -2.0628,\n",
      "        -2.0590, -2.3924, -2.6769, -2.3675, -2.4504, -2.5507, -2.3852, -2.0740,\n",
      "        -2.3848, -2.2686, -2.3300, -2.4831, -2.2763, -2.4195, -2.2745, -2.6879,\n",
      "        -1.8694, -2.1661, -2.1259, -2.2396, -2.1047, -2.1573, -2.3376, -2.1233,\n",
      "        -2.4322, -2.6533, -2.0888, -2.2589, -2.1603, -2.4887, -2.4848, -1.9401,\n",
      "        -2.4261, -2.1759], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4191, -2.3966, -2.3394, -2.3055, -2.3713, -2.4134, -2.4325, -2.3784,\n",
      "        -2.4264, -2.4187, -2.4047, -2.3710, -2.4188, -2.4151, -2.4193, -2.3692,\n",
      "        -2.3558, -2.4357, -2.3789, -2.3761, -2.4470, -2.4086, -2.4006, -2.3715,\n",
      "        -2.4089, -2.4184, -2.4252, -2.3770, -2.4310, -2.4326, -2.3998, -2.4184,\n",
      "        -2.3571, -2.4092, -2.3567, -2.4168, -2.4033, -2.3881, -2.3629, -2.4043,\n",
      "        -2.4172, -2.3654, -2.3799, -2.4229, -2.3986, -2.3868, -2.4122, -2.4371,\n",
      "        -2.4220, -2.3976], device='mps:0')\n",
      "mean: tensor(-2.3985, device='mps:0')\n",
      "iter_dt 1.07s; iter 41: train loss 0.49851 temperature: 7.049999999999993\n",
      "mean_logits tensor([-2.0265, -2.3500, -2.1015, -2.5797, -2.2583, -2.5321, -2.4925, -2.4049,\n",
      "        -2.3751, -2.1094, -2.6046, -2.3115, -2.4854, -2.3719, -2.3443, -2.5104,\n",
      "        -2.2798, -2.4660, -2.0374, -2.6569, -2.3360, -2.1906, -2.2914, -2.0493,\n",
      "        -2.3889, -2.4590, -2.1391, -2.6481, -2.4109, -2.2345, -2.3315, -2.2216,\n",
      "        -2.6410, -2.1179, -2.3211, -2.0739, -2.4422, -2.2990, -2.2438, -2.5615,\n",
      "        -2.3094, -2.4303, -2.2428, -2.0740, -2.3388, -2.4103, -2.3267, -2.0332,\n",
      "        -2.2459, -2.1233], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3937, -2.4183, -2.3374, -2.3970, -2.4377, -2.4132, -2.3922, -2.3698,\n",
      "        -2.4065, -2.4184, -2.4225, -2.4130, -2.3805, -2.4210, -2.4477, -2.4012,\n",
      "        -2.4282, -2.4121, -2.4135, -2.4074, -2.4068, -2.4184, -2.4091, -2.4135,\n",
      "        -2.4042, -2.4212, -2.3737, -2.4332, -2.4166, -2.4192, -2.4280, -2.4423,\n",
      "        -2.4498, -2.4017, -2.4168, -2.4195, -2.4191, -2.4110, -2.3920, -2.3556,\n",
      "        -2.4175, -2.3913, -2.4228, -2.3581, -2.4181, -2.4105, -2.4225, -2.3796,\n",
      "        -2.3927, -2.4253], device='mps:0')\n",
      "mean: tensor(-2.4084, device='mps:0')\n",
      "iter_dt 1.06s; iter 42: train loss 0.70332 temperature: 7.0999999999999925\n",
      "mean_logits tensor([-2.7316, -1.7893, -2.4188, -2.1618, -2.4794, -2.4636, -2.5477, -2.2857,\n",
      "        -1.8322, -1.9076, -2.4087, -2.5022, -2.3921, -1.9406, -2.4493, -2.3234,\n",
      "        -2.5973, -2.3393, -2.4097, -2.6975, -2.4062, -2.6807, -1.8751, -2.3875,\n",
      "        -2.4131, -2.2637, -2.4418, -2.5826, -2.3907, -2.1934, -2.4792, -2.4028,\n",
      "        -2.2254, -2.2810, -2.4877, -2.4836, -2.3198, -2.3879, -1.8601, -2.0724,\n",
      "        -2.3682, -2.5235, -2.5168, -2.1157, -2.4792, -2.3501, -2.0403, -2.4128,\n",
      "        -2.6390, -2.6539], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4153, -2.4190, -2.4259, -2.4141, -2.3870, -2.4173, -2.3928, -2.4405,\n",
      "        -2.3998, -2.4223, -2.4304, -2.4134, -2.4203, -2.3434, -2.3936, -2.3635,\n",
      "        -2.3981, -2.3570, -2.4069, -2.4187, -2.4428, -2.4243, -2.3959, -2.4110,\n",
      "        -2.4213, -2.4078, -2.4248, -2.4129, -2.4019, -2.4193, -2.4199, -2.4000,\n",
      "        -2.3948, -2.3905, -2.4213, -2.3906, -2.3930, -2.4198, -2.4056, -2.4160,\n",
      "        -2.3843, -2.4129, -2.4289, -2.4028, -2.3936, -2.4212, -2.4077, -2.4102,\n",
      "        -2.4116, -2.3841], device='mps:0')\n",
      "mean: tensor(-2.4070, device='mps:0')\n",
      "iter_dt 1.05s; iter 43: train loss 0.43001 temperature: 7.149999999999992\n",
      "mean_logits tensor([-2.3070, -2.2338, -2.2107, -2.2254, -2.3699, -2.4328, -2.6064, -2.4481,\n",
      "        -2.2649, -2.2136, -1.9264, -2.2020, -2.6423, -2.2142, -2.4594, -2.4694,\n",
      "        -2.7439, -2.5016, -2.4595, -2.2578, -2.2082, -2.0308, -2.3551, -2.4439,\n",
      "        -2.5874, -2.5456, -2.3527, -2.2566, -2.5854, -2.3433, -2.5157, -2.4877,\n",
      "        -2.2599, -2.2064, -2.0403, -2.3392, -2.3591, -2.2912, -2.3371, -2.3181,\n",
      "        -2.3367, -2.1566, -2.3714, -2.4149, -2.3226, -2.5639, -2.6083, -2.3364,\n",
      "        -2.4298, -2.1854], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4243, -2.4126, -2.4191, -2.4291, -2.4069, -2.4361, -2.4082, -2.4097,\n",
      "        -2.4064, -2.3874, -2.4110, -2.4259, -2.4134, -2.4084, -2.4168, -2.4509,\n",
      "        -2.3921, -2.3655, -2.4096, -2.4169, -2.4061, -2.3573, -2.4187, -2.4040,\n",
      "        -2.3945, -2.4429, -2.4008, -2.3751, -2.4227, -2.3587, -2.4120, -2.4106,\n",
      "        -2.4197, -2.4341, -2.3908, -2.4081, -2.4214, -2.3687, -2.4169, -2.4164,\n",
      "        -2.4023, -2.3787, -2.4209, -2.4125, -2.4002, -2.4043, -2.3933, -2.4168,\n",
      "        -2.4415, -2.3725], device='mps:0')\n",
      "mean: tensor(-2.4074, device='mps:0')\n",
      "iter_dt 1.05s; iter 44: train loss 0.60536 temperature: 7.199999999999992\n",
      "mean_logits tensor([-2.2641, -2.3533, -2.3739, -2.1692, -2.4479, -2.1993, -1.9500, -2.2792,\n",
      "        -2.7169, -2.2344, -2.1215, -2.4302, -2.1159, -2.4330, -2.3797, -2.5636,\n",
      "        -2.0621, -2.5772, -2.4897, -2.3854, -2.1893, -2.2274, -1.9237, -2.3466,\n",
      "        -2.4642, -2.4859, -2.1944, -2.1084, -2.0825, -2.3618, -2.3759, -2.5369,\n",
      "        -2.4098, -2.0837, -2.3350, -2.1902, -2.2162, -2.4284, -2.2515, -2.2092,\n",
      "        -2.1867, -2.1217, -2.5088, -2.3414, -2.2958, -2.5037, -2.0963, -2.2064,\n",
      "        -1.9498, -2.4392], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4071, -2.4175, -2.4194, -2.4176, -2.4352, -2.4415, -2.4036, -2.4252,\n",
      "        -2.3974, -2.4208, -2.4058, -2.4042, -2.4195, -2.4275, -2.4025, -2.4187,\n",
      "        -2.4227, -2.3936, -2.4009, -2.4184, -2.4577, -2.4022, -2.4233, -2.3899,\n",
      "        -2.4317, -2.4106, -2.4377, -2.3725, -2.4444, -2.4586, -2.4161, -2.4053,\n",
      "        -2.4167, -2.3262, -2.4228, -2.4062, -2.4177, -2.4282, -2.4183, -2.3821,\n",
      "        -2.4177, -2.4205, -2.3925, -2.3981, -2.4081, -2.3650, -2.4445, -2.3975,\n",
      "        -2.4067, -2.4342], device='mps:0')\n",
      "mean: tensor(-2.4130, device='mps:0')\n",
      "iter_dt 1.04s; iter 45: train loss 0.53013 temperature: 7.249999999999992\n",
      "mean_logits tensor([-2.3594, -2.4970, -2.4384, -2.0579, -2.1959, -2.1619, -1.9823, -2.2320,\n",
      "        -2.4932, -2.1361, -2.3742, -2.3250, -1.9667, -2.3109, -2.3183, -2.4782,\n",
      "        -2.6752, -2.5081, -2.3341, -1.9336, -2.5185, -2.2478, -2.4551, -2.3694,\n",
      "        -2.5569, -2.4494, -2.4662, -2.2360, -2.2599, -2.5360, -2.4787, -2.3055,\n",
      "        -2.3772, -2.2310, -2.4070, -2.6355, -2.0766, -2.1856, -2.5103, -2.3425,\n",
      "        -2.5166, -2.1150, -2.3248, -2.5886, -2.6883, -2.4400, -2.1412, -2.3783,\n",
      "        -2.3606, -2.1532], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3655, -2.4306, -2.4291, -2.4094, -2.4178, -2.3824, -2.4047, -2.4117,\n",
      "        -2.4194, -2.4227, -2.4357, -2.3943, -2.3996, -2.4240, -2.3998, -2.3575,\n",
      "        -2.3756, -2.4004, -2.4274, -2.4600, -2.4107, -2.3577, -2.4172, -2.4141,\n",
      "        -2.3839, -2.4269, -2.4128, -2.3260, -2.4067, -2.4325, -2.4099, -2.3956,\n",
      "        -2.4075, -2.3856, -2.4075, -2.4190, -2.4208, -2.4111, -2.4147, -2.4522,\n",
      "        -2.4028, -2.3972, -2.4129, -2.4119, -2.3667, -2.4171, -2.4334, -2.4064,\n",
      "        -2.4124, -2.4086], device='mps:0')\n",
      "mean: tensor(-2.4070, device='mps:0')\n",
      "iter_dt 1.05s; iter 46: train loss 0.44361 temperature: 7.299999999999992\n",
      "mean_logits tensor([-2.2607, -2.1069, -2.4440, -2.4286, -2.3262, -2.4531, -2.2308, -2.2789,\n",
      "        -2.3235, -2.2477, -2.3056, -2.2934, -2.4976, -2.1903, -2.4701, -2.4786,\n",
      "        -2.3147, -2.0960, -2.4064, -2.4910, -2.6252, -2.4728, -2.3748, -2.3911,\n",
      "        -2.5398, -2.5293, -2.2276, -2.2780, -2.5023, -2.3319, -2.2002, -2.2194,\n",
      "        -2.4204, -2.6333, -2.2738, -2.1288, -2.6612, -2.1664, -2.7785, -2.2819,\n",
      "        -2.3299, -2.0549, -2.5106, -2.2148, -2.5575, -2.3939, -2.3077, -2.2051,\n",
      "        -2.5569, -2.6568], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4061, -2.4202, -2.4070, -2.4377, -2.4115, -2.4189, -2.4181, -2.4507,\n",
      "        -2.4195, -2.3558, -2.4338, -2.4122, -2.4188, -2.3915, -2.4155, -2.4159,\n",
      "        -2.4261, -2.4217, -2.3789, -2.4225, -2.3958, -2.4186, -2.4292, -2.4238,\n",
      "        -2.4141, -2.3488, -2.4146, -2.3985, -2.3924, -2.4173, -2.3452, -2.4067,\n",
      "        -2.4028, -2.4164, -2.4190, -2.4059, -2.4347, -2.4021, -2.4140, -2.3727,\n",
      "        -2.4308, -2.3946, -2.4512, -2.3995, -2.3712, -2.4050, -2.3408, -2.4185,\n",
      "        -2.4378, -2.4103], device='mps:0')\n",
      "mean: tensor(-2.4083, device='mps:0')\n",
      "iter_dt 1.06s; iter 47: train loss 0.52325 temperature: 7.349999999999992\n",
      "mean_logits tensor([-2.4878, -2.1827, -2.4687, -2.2374, -2.2947, -2.6504, -2.4942, -2.5057,\n",
      "        -2.4469, -2.3262, -2.5883, -2.4337, -1.9997, -2.2954, -2.3234, -2.6675,\n",
      "        -2.4430, -2.0035, -2.1679, -2.0466, -2.1202, -2.4986, -2.6471, -2.5854,\n",
      "        -2.3495, -2.4059, -2.4332, -2.2591, -2.1721, -2.4220, -2.5004, -2.4573,\n",
      "        -2.0916, -2.3865, -2.1397, -2.4479, -2.6315, -2.5311, -2.0416, -2.4001,\n",
      "        -2.2865, -1.9642, -2.2228, -2.4757, -2.7353, -2.2943, -2.2774, -2.1105,\n",
      "        -2.2167, -2.4282], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4514, -2.4217, -2.4089, -2.4145, -2.4150, -2.4061, -2.3986, -2.4193,\n",
      "        -2.4268, -2.4178, -2.4250, -2.4412, -2.3510, -2.4085, -2.4009, -2.3905,\n",
      "        -2.4047, -2.4141, -2.3624, -2.4014, -2.4095, -2.4172, -2.4205, -2.4200,\n",
      "        -2.3734, -2.4095, -2.4097, -2.3572, -2.4234, -2.4004, -2.4089, -2.4439,\n",
      "        -2.3911, -2.4267, -2.4200, -2.4295, -2.4404, -2.3936, -2.3625, -2.3868,\n",
      "        -2.4007, -2.3506, -2.4194, -2.4125, -2.4138, -2.3570, -2.3926, -2.4174,\n",
      "        -2.4229, -2.4305], device='mps:0')\n",
      "mean: tensor(-2.4068, device='mps:0')\n",
      "iter_dt 1.05s; iter 48: train loss 0.48130 temperature: 7.3999999999999915\n",
      "mean_logits tensor([-2.5200, -2.4469, -2.2553, -2.1091, -2.1468, -2.3558, -2.2953, -2.1458,\n",
      "        -2.6781, -2.4889, -2.3903, -2.4566, -2.0453, -2.3192, -2.2836, -2.5519,\n",
      "        -2.0909, -2.5305, -2.2456, -2.1183, -2.3829, -2.2081, -2.4652, -2.5381,\n",
      "        -2.5918, -2.5063, -2.0879, -2.0584, -2.2727, -2.4311, -1.9696, -2.4285,\n",
      "        -2.2917, -2.4387, -2.3019, -2.4584, -2.6640, -2.1584, -2.4019, -2.2560,\n",
      "        -2.5094, -2.7212, -2.2482, -2.3351, -2.3379, -2.5170, -2.4698, -2.3327,\n",
      "        -2.4272, -2.3979], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4184, -2.4202, -2.4120, -2.4125, -2.3984, -2.4141, -2.4125, -2.4212,\n",
      "        -2.4212, -2.4075, -2.4029, -2.3821, -2.4162, -2.4213, -2.3686, -2.3940,\n",
      "        -2.4134, -2.4127, -2.4214, -2.3915, -2.4113, -2.4348, -2.4112, -2.4217,\n",
      "        -2.4125, -2.4174, -2.4174, -2.3643, -2.4144, -2.4397, -2.3941, -2.4114,\n",
      "        -2.4351, -2.4191, -2.4088, -2.3506, -2.4372, -2.4181, -2.4231, -2.4445,\n",
      "        -2.3377, -2.4151, -2.3652, -2.4413, -2.3936, -2.3903, -2.4170, -2.4076,\n",
      "        -2.4157, -2.4190], device='mps:0')\n",
      "mean: tensor(-2.4090, device='mps:0')\n",
      "iter_dt 1.06s; iter 49: train loss 0.48408 temperature: 7.449999999999991\n",
      "mean_logits tensor([-2.4021, -2.2837, -2.1317, -2.6013, -2.3349, -1.9072, -2.2716, -2.2085,\n",
      "        -2.3235, -2.2724, -2.1308, -2.1995, -2.0658, -2.4808, -1.9924, -2.3747,\n",
      "        -2.1625, -2.4270, -2.4608, -2.5496, -2.3817, -2.1146, -2.5911, -2.4018,\n",
      "        -2.2881, -1.9401, -2.3767, -2.2475, -2.4174, -2.2261, -2.5029, -2.2482,\n",
      "        -2.4572, -2.1639, -2.7018, -2.4786, -2.3641, -2.1240, -2.4662, -2.4292,\n",
      "        -2.4492, -2.2057, -2.1709, -2.5840, -2.2606, -2.2606, -2.0641, -2.5709,\n",
      "        -2.5073, -2.2373], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4159, -2.3909, -2.4117, -2.4077, -2.4235, -2.3998, -2.4430, -2.4018,\n",
      "        -2.4135, -2.4252, -2.3530, -2.4004, -2.3304, -2.4267, -2.3530, -2.4222,\n",
      "        -2.4132, -2.4376, -2.4182, -2.4121, -2.4212, -2.3658, -2.4238, -2.3936,\n",
      "        -2.4198, -2.3603, -2.4208, -2.4243, -2.4101, -2.4213, -2.4064, -2.4262,\n",
      "        -2.3829, -2.4110, -2.4269, -2.4274, -2.3954, -2.4522, -2.4012, -2.4111,\n",
      "        -2.4175, -2.3349, -2.3568, -2.3936, -2.4306, -2.3724, -2.3679, -2.3588,\n",
      "        -2.4198, -2.3901], device='mps:0')\n",
      "mean: tensor(-2.4029, device='mps:0')\n",
      "iter_dt 1.03s; iter 50: train loss 0.59787 temperature: 7.499999999999991\n",
      "mean_logits tensor([-2.5063, -2.7673, -2.4633, -2.2169, -2.2370, -2.5325, -2.1691, -2.2237,\n",
      "        -2.1353, -2.5221, -1.8946, -2.0582, -2.4503, -2.1051, -2.6936, -2.2833,\n",
      "        -2.2468, -2.1809, -2.3814, -2.2879, -2.5841, -2.5893, -2.5549, -2.4507,\n",
      "        -2.5425, -2.3688, -2.4042, -2.4056, -2.3217, -2.2884, -2.2458, -2.1713,\n",
      "        -2.5239, -2.1936, -2.4310, -2.3967, -2.5683, -2.4197, -2.0052, -2.3143,\n",
      "        -2.3622, -2.4795, -2.2830, -2.4298, -2.0271, -2.7406, -2.7527, -2.3401,\n",
      "        -2.3154, -2.4383], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4153, -2.4229, -2.3855, -2.4122, -2.4211, -2.4120, -2.3953, -2.3675,\n",
      "        -2.3988, -2.4260, -2.3846, -2.4282, -2.4200, -2.4201, -2.4179, -2.4067,\n",
      "        -2.4006, -2.4171, -2.4165, -2.3930, -2.4441, -2.4120, -2.4285, -2.4282,\n",
      "        -2.4197, -2.3873, -2.4092, -2.3913, -2.3934, -2.4191, -2.4552, -2.3795,\n",
      "        -2.4237, -2.4081, -2.3321, -2.3377, -2.3638, -2.3350, -2.4129, -2.4193,\n",
      "        -2.3577, -2.4105, -2.4189, -2.4225, -2.4194, -2.4172, -2.4102, -2.4206,\n",
      "        -2.4161, -2.4380], device='mps:0')\n",
      "mean: tensor(-2.4059, device='mps:0')\n",
      "iter_dt 1.04s; iter 51: train loss 0.66072 temperature: 7.549999999999991\n",
      "mean_logits tensor([-2.5041, -2.5542, -2.5319, -2.4593, -2.1888, -2.4044, -2.4238, -2.5097,\n",
      "        -2.3199, -2.1690, -2.5757, -2.4197, -2.3580, -1.8358, -1.9211, -2.5924,\n",
      "        -2.5182, -2.4773, -2.5027, -2.6636, -2.3398, -2.2956, -2.1908, -2.2394,\n",
      "        -2.3677, -2.3575, -2.2599, -2.2562, -2.2653, -1.8776, -2.8085, -2.2226,\n",
      "        -2.1855, -2.0536, -2.0881, -2.4441, -2.2952, -2.3158, -1.9829, -2.0246,\n",
      "        -2.5798, -2.3503, -2.5675, -2.2585, -2.5243, -2.2995, -2.3701, -2.1925,\n",
      "        -2.2116, -2.6757], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4190, -2.4104, -2.4316, -2.4194, -2.4001, -2.4120, -2.4180, -2.3807,\n",
      "        -2.3878, -2.4267, -2.4222, -2.3980, -2.4086, -2.3454, -2.4237, -2.4612,\n",
      "        -2.3908, -2.3689, -2.4022, -2.4366, -2.3495, -2.4199, -2.4236, -2.3900,\n",
      "        -2.3534, -2.5009, -2.4435, -2.4007, -2.3902, -2.4064, -2.3913, -2.4269,\n",
      "        -2.4125, -2.4397, -2.4203, -2.4201, -2.3878, -2.4041, -2.4460, -2.3554,\n",
      "        -2.4296, -2.3792, -2.3610, -2.4268, -2.3902, -2.3965, -2.4177, -2.3059,\n",
      "        -2.4194, -2.4185], device='mps:0')\n",
      "mean: tensor(-2.4058, device='mps:0')\n",
      "iter_dt 1.05s; iter 52: train loss 0.60421 temperature: 7.599999999999991\n",
      "mean_logits tensor([-2.0993, -2.4688, -2.5403, -2.2992, -2.7091, -2.1203, -2.4725, -2.6548,\n",
      "        -2.4035, -2.3775, -2.6551, -2.5373, -2.0463, -2.3969, -2.6231, -2.4971,\n",
      "        -2.6763, -2.3926, -2.2831, -2.3832, -2.5291, -2.1917, -2.3323, -2.6674,\n",
      "        -1.8649, -2.4685, -2.4933, -2.4832, -2.3080, -2.2959, -2.6678, -2.3347,\n",
      "        -2.5133, -2.4886, -2.5577, -2.7524, -2.2517, -2.5089, -2.3841, -2.5768,\n",
      "        -2.3520, -2.1516, -2.3221, -2.2598, -2.5872, -2.4081, -2.3636, -2.1166,\n",
      "        -2.4553, -2.4616], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4091, -2.4261, -2.3831, -2.4157, -2.3501, -2.4201, -2.4197, -2.3957,\n",
      "        -2.3798, -2.4161, -2.4487, -2.4192, -2.4149, -2.4008, -2.4150, -2.4216,\n",
      "        -2.4214, -2.3998, -2.4302, -2.4171, -2.3942, -2.3838, -2.4190, -2.3498,\n",
      "        -2.4439, -2.4186, -2.4342, -2.3931, -2.4430, -2.3826, -2.4192, -2.4243,\n",
      "        -2.4106, -2.4248, -2.4040, -2.3588, -2.4069, -2.4015, -2.4145, -2.4181,\n",
      "        -2.4562, -2.3824, -2.4117, -2.4529, -2.4108, -2.4319, -2.3955, -2.4117,\n",
      "        -2.4451, -2.4531], device='mps:0')\n",
      "mean: tensor(-2.4120, device='mps:0')\n",
      "iter_dt 1.04s; iter 53: train loss 0.59683 temperature: 7.649999999999991\n",
      "mean_logits tensor([-2.6151, -2.0481, -2.4699, -2.4273, -2.3923, -2.4213, -2.4388, -2.6062,\n",
      "        -2.5066, -2.1356, -2.7913, -2.3061, -2.3061, -2.3423, -2.2150, -2.4640,\n",
      "        -2.6870, -2.7970, -2.3094, -2.1634, -2.5122, -2.3433, -2.4321, -2.4439,\n",
      "        -2.4312, -2.1046, -2.2361, -2.3485, -2.5349, -2.6051, -2.2082, -2.6777,\n",
      "        -2.4434, -2.3478, -2.2997, -2.5453, -2.2659, -2.3394, -2.2727, -2.4035,\n",
      "        -2.5621, -2.6635, -2.3327, -2.6163, -2.3352, -2.4375, -2.5100, -2.7724,\n",
      "        -2.2650, -2.0695], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3988, -2.4153, -2.4116, -2.4114, -2.4159, -2.3769, -2.3630, -2.4436,\n",
      "        -2.4046, -2.4189, -2.3754, -2.4197, -2.4139, -2.4062, -2.4196, -2.4468,\n",
      "        -2.4249, -2.4172, -2.4265, -2.3859, -2.4123, -2.4048, -2.4438, -2.4085,\n",
      "        -2.3836, -2.4165, -2.4576, -2.4273, -2.4166, -2.3862, -2.4081, -2.3979,\n",
      "        -2.4056, -2.4624, -2.4248, -2.4024, -2.3961, -2.3681, -2.3846, -2.3905,\n",
      "        -2.4256, -2.4590, -2.4135, -2.4346, -2.4211, -2.4349, -2.3924, -2.3952,\n",
      "        -2.3842, -2.3383], device='mps:0')\n",
      "mean: tensor(-2.4098, device='mps:0')\n",
      "iter_dt 1.04s; iter 54: train loss 0.46212 temperature: 7.69999999999999\n",
      "mean_logits tensor([-2.4697, -2.4510, -2.0551, -1.8760, -2.1150, -2.2968, -2.1536, -2.4357,\n",
      "        -2.2726, -2.0841, -2.5021, -2.5253, -2.5116, -2.2980, -2.5392, -2.5221,\n",
      "        -2.3169, -2.1997, -2.6257, -2.4614, -2.4540, -2.3614, -2.5224, -2.5290,\n",
      "        -2.1638, -2.5814, -2.0491, -2.6513, -2.2841, -2.0921, -2.6049, -2.4394,\n",
      "        -2.4313, -2.4001, -2.5050, -2.3688, -2.6934, -2.2156, -2.3045, -2.2296,\n",
      "        -2.3782, -2.5014, -2.3650, -2.5632, -2.3414, -2.5184, -2.2677, -2.1455,\n",
      "        -2.4750, -2.1764], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4099, -2.4155, -2.3788, -2.4035, -2.4136, -2.4246, -2.3623, -2.3772,\n",
      "        -2.3873, -2.4189, -2.4189, -2.4050, -2.4085, -2.3640, -2.3785, -2.4196,\n",
      "        -2.3986, -2.4094, -2.4120, -2.4180, -2.3755, -2.4212, -2.3897, -2.4106,\n",
      "        -2.3628, -2.4213, -2.4123, -2.4105, -2.4333, -2.4061, -2.4374, -2.4122,\n",
      "        -2.4120, -2.4170, -2.4134, -2.3717, -2.4441, -2.4262, -2.3201, -2.4249,\n",
      "        -2.3717, -2.4026, -2.4072, -2.4224, -2.4018, -2.4181, -2.3817, -2.4201,\n",
      "        -2.4303, -2.4332], device='mps:0')\n",
      "mean: tensor(-2.4047, device='mps:0')\n",
      "iter_dt 1.05s; iter 55: train loss 0.56851 temperature: 7.74999999999999\n",
      "mean_logits tensor([-2.4459, -2.2110, -2.2683, -2.4745, -2.3263, -2.5523, -2.3145, -2.2434,\n",
      "        -2.1589, -2.3452, -2.2658, -2.2126, -2.0334, -2.6460, -2.3505, -2.3333,\n",
      "        -2.2198, -2.5331, -2.3478, -2.1481, -2.4833, -2.2672, -2.5250, -2.6031,\n",
      "        -2.1858, -2.5637, -2.5020, -2.4221, -2.7052, -1.9969, -2.0405, -2.0893,\n",
      "        -2.3994, -2.1644, -2.2572, -2.0860, -2.5129, -2.2886, -2.2292, -2.2576,\n",
      "        -2.2952, -2.5758, -2.7860, -2.6779, -2.3575, -2.1666, -2.5959, -2.4814,\n",
      "        -2.3316, -2.5389], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4287, -2.4145, -2.3872, -2.4192, -2.4149, -2.4018, -2.4160, -2.3972,\n",
      "        -2.3709, -2.4199, -2.4175, -2.4207, -2.4346, -2.4343, -2.3614, -2.4249,\n",
      "        -2.4196, -2.4310, -2.4147, -2.3687, -2.4125, -2.4169, -2.4530, -2.4410,\n",
      "        -2.4033, -2.3770, -2.3864, -2.4141, -2.4438, -2.3764, -2.4276, -2.4159,\n",
      "        -2.4242, -2.4333, -2.4010, -2.4548, -2.4155, -2.4171, -2.3746, -2.4092,\n",
      "        -2.4159, -2.4107, -2.4038, -2.4266, -2.4294, -2.4148, -2.4431, -2.4016,\n",
      "        -2.3754, -2.4359], device='mps:0')\n",
      "mean: tensor(-2.4131, device='mps:0')\n",
      "iter_dt 1.09s; iter 56: train loss 0.48648 temperature: 7.79999999999999\n",
      "mean_logits tensor([-2.2777, -2.2617, -2.6252, -2.3543, -2.2887, -2.1999, -2.5979, -2.3326,\n",
      "        -2.4178, -1.9945, -2.1239, -2.3570, -2.6685, -1.9330, -2.2724, -2.2337,\n",
      "        -2.2658, -2.4135, -2.2805, -2.3884, -2.1862, -2.3424, -2.4140, -2.6065,\n",
      "        -2.4956, -2.3010, -2.5196, -2.3682, -2.4813, -2.3065, -2.4030, -2.1551,\n",
      "        -2.4208, -2.5561, -2.3816, -2.5133, -2.4049, -2.5593, -2.4135, -2.6577,\n",
      "        -2.4202, -2.0160, -2.5751, -2.5691, -2.4662, -2.0274, -1.9457, -2.5109,\n",
      "        -2.1075, -2.4354], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4140, -2.4238, -2.4190, -2.4036, -2.4555, -2.3556, -2.4139, -2.3891,\n",
      "        -2.4199, -2.4448, -2.4169, -2.4055, -2.4227, -2.3532, -2.4040, -2.4295,\n",
      "        -2.4187, -2.3867, -2.3418, -2.4617, -2.3796, -2.4290, -2.3728, -2.4382,\n",
      "        -2.3650, -2.3958, -2.3668, -2.4049, -2.4100, -2.4145, -2.4113, -2.4037,\n",
      "        -2.4186, -2.3949, -2.4042, -2.4162, -2.4000, -2.3706, -2.4241, -2.4212,\n",
      "        -2.4349, -2.3877, -2.4206, -2.4065, -2.4176, -2.3665, -2.4161, -2.4189,\n",
      "        -2.4131, -2.4120], device='mps:0')\n",
      "mean: tensor(-2.4063, device='mps:0')\n",
      "iter_dt 1.05s; iter 57: train loss 0.41047 temperature: 7.84999999999999\n",
      "mean_logits tensor([-2.5888, -2.2823, -2.4984, -2.4171, -2.3305, -2.2809, -2.3321, -2.1188,\n",
      "        -2.6059, -2.2696, -2.4051, -2.3740, -2.4159, -2.5173, -2.4051, -2.2890,\n",
      "        -2.5632, -2.3030, -2.4800, -2.3259, -2.2070, -2.5635, -2.2470, -2.2616,\n",
      "        -2.4068, -2.4434, -2.0030, -2.5499, -2.3235, -2.2685, -2.3029, -2.4724,\n",
      "        -2.2365, -2.4440, -2.0652, -2.4330, -2.3182, -1.9900, -2.4775, -2.0859,\n",
      "        -2.1005, -2.2322, -2.2400, -2.2842, -2.4993, -2.1454, -2.6526, -2.3030,\n",
      "        -2.5739, -2.3514], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4156, -2.4144, -2.4058, -2.4133, -2.3529, -2.4179, -2.4019, -2.4191,\n",
      "        -2.3722, -2.4091, -2.3707, -2.3958, -2.4048, -2.4121, -2.4161, -2.4328,\n",
      "        -2.4040, -2.3893, -2.4146, -2.4142, -2.4133, -2.4228, -2.4119, -2.4122,\n",
      "        -2.4260, -2.3947, -2.4336, -2.4020, -2.4320, -2.4210, -2.4250, -2.4197,\n",
      "        -2.4148, -2.4120, -2.4112, -2.4134, -2.4279, -2.3734, -2.4260, -2.3909,\n",
      "        -2.3986, -2.4079, -2.4151, -2.3994, -2.4176, -2.4193, -2.3995, -2.4132,\n",
      "        -2.4203, -2.3894], device='mps:0')\n",
      "mean: tensor(-2.4088, device='mps:0')\n",
      "iter_dt 1.05s; iter 58: train loss 0.61618 temperature: 7.89999999999999\n",
      "mean_logits tensor([-2.4211, -2.1760, -2.3612, -2.0453, -2.3750, -2.4100, -2.3012, -2.4914,\n",
      "        -2.6051, -1.9718, -2.3898, -2.0737, -2.2433, -2.5484, -1.9544, -2.3310,\n",
      "        -2.4091, -2.5573, -2.4095, -2.2407, -2.4059, -2.1487, -2.3499, -2.3668,\n",
      "        -2.2021, -2.1530, -1.9851, -2.5043, -2.3795, -2.0928, -2.1935, -2.4186,\n",
      "        -1.9308, -2.4572, -1.9837, -2.5716, -2.4483, -2.7480, -2.4736, -1.8161,\n",
      "        -2.3031, -2.5234, -2.4558, -2.5201, -2.4716, -2.2992, -2.2094, -2.5773,\n",
      "        -2.2622, -2.2613], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4064, -2.4127, -2.4039, -2.3722, -2.4191, -2.3884, -2.3763, -2.3644,\n",
      "        -2.3952, -2.3819, -2.4189, -2.4248, -2.4156, -2.4263, -2.3946, -2.4252,\n",
      "        -2.3721, -2.4157, -2.4196, -2.3776, -2.4072, -2.3930, -2.4142, -2.4302,\n",
      "        -2.4044, -2.4054, -2.4068, -2.4008, -2.4169, -2.4139, -2.4004, -2.3927,\n",
      "        -2.4183, -2.3757, -2.4204, -2.4155, -2.3817, -2.4210, -2.3702, -2.4177,\n",
      "        -2.4022, -2.4246, -2.4071, -2.4059, -2.3891, -2.3586, -2.4074, -2.3664,\n",
      "        -2.3876, -2.4044], device='mps:0')\n",
      "mean: tensor(-2.4014, device='mps:0')\n",
      "iter_dt 1.05s; iter 59: train loss 0.45616 temperature: 7.9499999999999895\n",
      "mean_logits tensor([-2.1407, -2.5394, -2.2907, -2.4140, -2.3165, -2.4566, -2.2995, -2.4919,\n",
      "        -2.1950, -2.4905, -2.0985, -2.4928, -1.9704, -2.4113, -2.6199, -2.3901,\n",
      "        -2.3474, -2.3837, -2.4736, -2.5202, -2.6707, -2.5621, -2.2294, -2.4971,\n",
      "        -2.3866, -2.2862, -2.3845, -2.4063, -2.5935, -2.7322, -2.1713, -1.9723,\n",
      "        -2.4530, -2.3034, -2.2885, -2.6237, -2.4332, -2.2577, -2.5252, -2.4638,\n",
      "        -2.4399, -2.7297, -2.2982, -2.3651, -2.2609, -2.6930, -2.1398, -2.4011,\n",
      "        -2.3776, -2.1656], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4199, -2.4007, -2.4267, -2.4099, -2.4182, -2.3900, -2.3756, -2.4152,\n",
      "        -2.4359, -2.4425, -2.4087, -2.4150, -2.3539, -2.4035, -2.3922, -2.3999,\n",
      "        -2.3594, -2.4017, -2.4286, -2.4188, -2.4674, -2.3960, -2.3750, -2.4468,\n",
      "        -2.4343, -2.4021, -2.4387, -2.3938, -2.3923, -2.3977, -2.4010, -2.4185,\n",
      "        -2.4118, -2.3906, -2.4210, -2.4653, -2.4280, -2.4128, -2.3950, -2.3498,\n",
      "        -2.4240, -2.4095, -2.2507, -2.4190, -2.3667, -2.4524, -2.4203, -2.4170,\n",
      "        -2.4187, -2.3591], device='mps:0')\n",
      "mean: tensor(-2.4058, device='mps:0')\n",
      "iter_dt 1.04s; iter 60: train loss 0.59789 temperature: 7.999999999999989\n",
      "mean_logits tensor([-2.3122, -2.1528, -2.4221, -2.6107, -2.3076, -2.6758, -2.3145, -2.2280,\n",
      "        -2.5002, -2.4913, -2.3698, -2.2040, -2.4195, -2.5176, -2.5162, -2.3894,\n",
      "        -2.3133, -2.0992, -1.9671, -2.2163, -2.3570, -2.4519, -2.4613, -2.4773,\n",
      "        -2.0375, -2.6364, -2.2086, -2.3171, -1.9999, -2.2421, -2.5330, -2.1402,\n",
      "        -2.6142, -2.0561, -2.4367, -2.5862, -2.1642, -2.5579, -2.1650, -2.4607,\n",
      "        -2.1231, -2.3916, -2.4705, -2.0869, -2.0807, -2.4598, -2.3713, -2.2866,\n",
      "        -2.8131, -2.4571], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4134, -2.4151, -2.4192, -2.4171, -2.4196, -2.4138, -2.3877, -2.4181,\n",
      "        -2.4179, -2.4028, -2.4215, -2.4225, -2.4197, -2.4283, -2.3717, -2.4174,\n",
      "        -2.3852, -2.3937, -2.4165, -2.3945, -2.4142, -2.3590, -2.4557, -2.4543,\n",
      "        -2.3959, -2.4196, -2.4000, -2.4355, -2.3989, -2.3948, -2.4202, -2.4085,\n",
      "        -2.4058, -2.3804, -2.4066, -2.3402, -2.4456, -2.4437, -2.4188, -2.3889,\n",
      "        -2.4007, -2.3653, -2.4464, -2.4189, -2.4043, -2.3453, -2.4331, -2.4118,\n",
      "        -2.4162, -2.4000], device='mps:0')\n",
      "mean: tensor(-2.4085, device='mps:0')\n",
      "iter_dt 1.03s; iter 61: train loss 0.33924 temperature: 8.04999999999999\n",
      "mean_logits tensor([-2.5662, -2.1088, -2.2100, -2.3698, -2.3884, -2.4600, -2.6170, -2.2733,\n",
      "        -2.3172, -2.2610, -2.3240, -2.4663, -2.6752, -2.5738, -2.4933, -2.3194,\n",
      "        -2.1538, -2.5133, -2.4667, -2.4255, -2.4618, -2.6138, -2.2358, -2.3769,\n",
      "        -2.2521, -2.1426, -2.1824, -2.6425, -2.4638, -2.4072, -2.3715, -2.1890,\n",
      "        -2.4085, -2.3730, -2.5641, -2.3377, -2.3407, -2.5124, -2.4045, -2.3939,\n",
      "        -2.2606, -2.4330, -2.3026, -2.3358, -2.1363, -2.2377, -2.2663, -2.2516,\n",
      "        -2.3454, -2.6082], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4200, -2.3961, -2.3801, -2.4157, -2.4227, -2.4107, -2.4194, -2.4184,\n",
      "        -2.4436, -2.4224, -2.4219, -2.4109, -2.4168, -2.4215, -2.4195, -2.4603,\n",
      "        -2.4127, -2.4100, -2.4168, -2.4199, -2.3947, -2.4107, -2.4081, -2.3541,\n",
      "        -2.4431, -2.4069, -2.4092, -2.4155, -2.3974, -2.4202, -2.3939, -2.4196,\n",
      "        -2.4054, -2.4138, -2.3317, -2.3350, -2.4591, -2.4124, -2.4459, -2.4375,\n",
      "        -2.3406, -2.4265, -2.2628, -2.3807, -2.3518, -2.4156, -2.4239, -2.4184,\n",
      "        -2.4090, -2.4233], device='mps:0')\n",
      "mean: tensor(-2.4065, device='mps:0')\n",
      "iter_dt 1.07s; iter 62: train loss 0.54999 temperature: 8.09999999999999\n",
      "mean_logits tensor([-2.6025, -2.1800, -2.3844, -2.4283, -2.1113, -2.0656, -2.5995, -2.2083,\n",
      "        -2.5148, -2.0103, -2.4228, -2.4067, -2.6432, -2.5302, -2.2081, -2.7487,\n",
      "        -2.4904, -2.3727, -2.5736, -2.1826, -2.2490, -2.5372, -2.3148, -2.2868,\n",
      "        -2.1938, -2.2638, -2.4016, -2.2513, -2.2642, -2.3375, -2.3983, -2.3742,\n",
      "        -2.2311, -2.7205, -2.2216, -2.4172, -2.7670, -2.3910, -2.4886, -2.1060,\n",
      "        -2.1394, -2.5586, -2.4438, -2.5362, -2.0565, -2.4466, -2.5132, -2.5655,\n",
      "        -2.6055, -2.3462], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4212, -2.4204, -2.3776, -2.4251, -2.4067, -2.4077, -2.4289, -2.4060,\n",
      "        -2.4379, -2.4134, -2.3938, -2.4185, -2.4048, -2.4141, -2.4214, -2.4003,\n",
      "        -2.4017, -2.4190, -2.4122, -2.4057, -2.4107, -2.4076, -2.3967, -2.2878,\n",
      "        -2.4249, -2.4177, -2.4169, -2.4165, -2.3927, -2.4002, -2.4371, -2.3520,\n",
      "        -2.4060, -2.4531, -2.4003, -2.4118, -2.4183, -2.4149, -2.4175, -2.4215,\n",
      "        -2.4103, -2.3777, -2.4473, -2.4441, -2.3957, -2.4178, -2.4120, -2.4127,\n",
      "        -2.4143, -2.4216], device='mps:0')\n",
      "mean: tensor(-2.4099, device='mps:0')\n",
      "iter_dt 1.06s; iter 63: train loss 0.56317 temperature: 8.149999999999991\n",
      "mean_logits tensor([-2.5468, -2.3175, -2.6527, -2.4019, -2.2655, -2.2961, -2.1543, -2.6840,\n",
      "        -2.3827, -2.3265, -2.3096, -2.3816, -2.2754, -2.1439, -2.2742, -2.6358,\n",
      "        -2.2396, -2.1046, -1.9897, -2.4464, -2.2281, -1.8313, -2.4134, -2.4210,\n",
      "        -2.4007, -2.1813, -2.4204, -2.7144, -2.4258, -2.2694, -2.4632, -2.4784,\n",
      "        -2.1548, -2.3249, -2.2546, -2.5124, -2.2829, -2.5515, -2.2612, -1.9693,\n",
      "        -2.2465, -2.2202, -2.3759, -2.3734, -2.3176, -2.4326, -2.4209, -2.6879,\n",
      "        -2.6461, -2.1682], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4144, -2.3847, -2.4178, -2.3821, -2.4185, -2.3753, -2.4306, -2.3955,\n",
      "        -2.3693, -2.4148, -2.3572, -2.3250, -2.4296, -2.4052, -2.3469, -2.4556,\n",
      "        -2.4220, -2.4229, -2.4242, -2.4391, -2.4197, -2.3971, -2.4013, -2.3977,\n",
      "        -2.4020, -2.4238, -2.4256, -2.4141, -2.3792, -2.4217, -2.4191, -2.2944,\n",
      "        -2.4073, -2.4436, -2.4188, -2.3753, -2.3847, -2.4053, -2.3973, -2.4207,\n",
      "        -2.3991, -2.4079, -2.4247, -2.4166, -2.3835, -2.4462, -2.4084, -2.4005,\n",
      "        -2.4275, -2.4429], device='mps:0')\n",
      "mean: tensor(-2.4047, device='mps:0')\n",
      "iter_dt 1.04s; iter 64: train loss 0.56081 temperature: 8.199999999999992\n",
      "mean_logits tensor([-2.5270, -2.4612, -1.9649, -2.3130, -2.0372, -2.5503, -2.6566, -2.5431,\n",
      "        -2.4729, -2.3164, -2.2685, -1.9168, -2.3799, -2.1586, -2.5821, -2.1933,\n",
      "        -2.3195, -2.0605, -2.6375, -2.3025, -2.1305, -2.1158, -2.4161, -2.4022,\n",
      "        -2.3042, -2.2970, -2.2427, -2.3958, -2.5058, -2.3753, -2.2040, -2.5013,\n",
      "        -2.3888, -2.2810, -2.5400, -2.3140, -2.7090, -2.4916, -2.4685, -2.2877,\n",
      "        -2.3433, -2.0993, -2.1606, -2.2803, -2.2003, -2.1846, -2.2793, -2.1194,\n",
      "        -2.0088, -2.1432], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4280, -2.4045, -2.4231, -2.3857, -2.3740, -2.4095, -2.4136, -2.4403,\n",
      "        -2.3889, -2.3811, -2.3988, -2.4075, -2.4397, -2.3460, -2.3666, -2.4098,\n",
      "        -2.3805, -2.4118, -2.4297, -2.4319, -2.4112, -2.4200, -2.4190, -2.4570,\n",
      "        -2.4075, -2.4180, -2.4262, -2.3930, -2.4402, -2.4078, -2.3517, -2.4196,\n",
      "        -2.4197, -2.3657, -2.4100, -2.4214, -2.3601, -2.4130, -2.4123, -2.4175,\n",
      "        -2.3666, -2.4342, -2.4263, -2.3961, -2.4180, -2.4204, -2.3436, -2.4154,\n",
      "        -2.3705, -2.3777], device='mps:0')\n",
      "mean: tensor(-2.4046, device='mps:0')\n",
      "iter_dt 1.12s; iter 65: train loss 0.48420 temperature: 8.249999999999993\n",
      "mean_logits tensor([-2.2066, -1.8765, -2.4225, -2.3397, -2.4072, -2.0551, -2.6705, -2.5768,\n",
      "        -2.2860, -2.3375, -1.9719, -2.5005, -2.0795, -2.1954, -2.2461, -2.4651,\n",
      "        -2.4294, -2.3720, -2.3790, -2.2041, -2.3950, -2.3610, -2.5882, -2.3806,\n",
      "        -2.4427, -2.2705, -2.6320, -2.2408, -2.5623, -2.5303, -2.4550, -1.8963,\n",
      "        -2.5800, -2.1348, -1.9446, -2.2036, -2.4494, -2.5292, -2.4806, -2.2310,\n",
      "        -2.4638, -2.2988, -2.4536, -2.4721, -2.4889, -2.4610, -2.2330, -2.3589,\n",
      "        -2.3071, -2.4532], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3859, -2.4188, -2.3641, -2.3966, -2.4186, -2.4485, -2.4191, -2.3754,\n",
      "        -2.4201, -2.4080, -2.4222, -2.3840, -2.4113, -2.3452, -2.4256, -2.3654,\n",
      "        -2.3696, -2.3890, -2.4128, -2.3687, -2.4280, -2.3782, -2.4235, -2.4202,\n",
      "        -2.4186, -2.3914, -2.4186, -2.4490, -2.3348, -2.4203, -2.4351, -2.3645,\n",
      "        -2.4215, -2.4331, -2.3498, -2.3432, -2.4149, -2.4355, -2.4425, -2.3957,\n",
      "        -2.4154, -2.4269, -2.4057, -2.4360, -2.4253, -2.4102, -2.4282, -2.3886,\n",
      "        -2.3819, -2.4549], device='mps:0')\n",
      "mean: tensor(-2.4048, device='mps:0')\n",
      "iter_dt 0.98s; iter 66: train loss 0.63688 temperature: 8.299999999999994\n",
      "mean_logits tensor([-2.1952, -2.3991, -2.4940, -2.5072, -2.6037, -2.3389, -2.2645, -2.6392,\n",
      "        -2.6969, -2.6239, -2.0102, -2.4843, -2.1222, -2.3534, -2.6123, -2.1039,\n",
      "        -2.3917, -2.5361, -2.4431, -2.3843, -2.3263, -2.1854, -1.8726, -2.3780,\n",
      "        -2.4238, -2.8362, -2.1575, -2.4823, -2.1789, -2.1201, -2.2091, -2.5643,\n",
      "        -2.5626, -2.4996, -2.4941, -2.5298, -2.5466, -2.6737, -2.4604, -2.4636,\n",
      "        -2.4439, -1.9642, -2.5301, -2.7031, -2.4465, -2.5234, -2.3871, -2.4334,\n",
      "        -2.1300, -2.4747], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4170, -2.4237, -2.3949, -2.4204, -2.4113, -2.4267, -2.4276, -2.3547,\n",
      "        -2.3912, -2.4205, -2.4171, -2.4015, -2.4190, -2.4174, -2.4304, -2.3386,\n",
      "        -2.4206, -2.4076, -2.3898, -2.4070, -2.3817, -2.4195, -2.4181, -2.4270,\n",
      "        -2.3937, -2.4192, -2.4172, -2.4058, -2.3616, -2.4125, -2.3461, -2.4051,\n",
      "        -2.4135, -2.4597, -2.3971, -2.4465, -2.4185, -2.4638, -2.4196, -2.4158,\n",
      "        -2.3985, -2.4193, -2.4164, -2.3877, -2.4180, -2.4006, -2.3970, -2.4145,\n",
      "        -2.4130, -2.3938], device='mps:0')\n",
      "mean: tensor(-2.4088, device='mps:0')\n",
      "iter_dt 0.98s; iter 67: train loss 0.47334 temperature: 8.349999999999994\n",
      "mean_logits tensor([-2.6321, -2.3737, -2.1842, -2.1950, -2.5417, -2.4048, -2.2239, -2.1570,\n",
      "        -2.2700, -2.1426, -2.0514, -2.1660, -2.4951, -2.2249, -2.2368, -2.3657,\n",
      "        -2.1944, -2.2420, -1.9208, -2.3709, -2.4665, -2.4109, -2.3728, -2.5200,\n",
      "        -2.1898, -2.2177, -2.4319, -2.3457, -2.3289, -2.1944, -2.3669, -2.2114,\n",
      "        -2.6113, -2.0934, -2.4580, -2.5403, -2.4030, -2.2623, -2.4119, -2.5907,\n",
      "        -2.1638, -2.5744, -2.1999, -2.2859, -2.2453, -2.3613, -2.0766, -2.5941,\n",
      "        -2.1677, -2.3210], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4015, -2.3524, -2.4057, -2.4033, -2.4226, -2.4192, -2.3947, -2.4194,\n",
      "        -2.3637, -2.3371, -2.4128, -2.4178, -2.3619, -2.4008, -2.4210, -2.4250,\n",
      "        -2.4169, -2.4140, -2.4120, -2.4514, -2.3473, -2.4185, -2.3743, -2.3749,\n",
      "        -2.3443, -2.4085, -2.4289, -2.4163, -2.3726, -2.4270, -2.4499, -2.3993,\n",
      "        -2.3964, -2.4183, -2.4159, -2.3997, -2.4144, -2.4285, -2.3977, -2.4203,\n",
      "        -2.4073, -2.4102, -2.4181, -2.4396, -2.3780, -2.4097, -2.3733, -2.4176,\n",
      "        -2.4081, -2.4174], device='mps:0')\n",
      "mean: tensor(-2.4037, device='mps:0')\n",
      "iter_dt 1.01s; iter 68: train loss 0.30044 temperature: 8.399999999999995\n",
      "mean_logits tensor([-2.1843, -2.1928, -2.3087, -2.2654, -2.5434, -2.2553, -2.4761, -2.2788,\n",
      "        -2.4003, -2.3126, -2.5044, -2.4563, -2.3958, -2.5536, -2.2972, -2.0824,\n",
      "        -2.6921, -2.5975, -2.3843, -2.4569, -2.5724, -2.4852, -2.4955, -2.2115,\n",
      "        -2.1859, -2.4912, -2.3746, -2.2986, -2.2043, -2.3272, -2.2110, -2.1880,\n",
      "        -2.3854, -2.5066, -2.3497, -2.5513, -2.1070, -2.4996, -2.3277, -2.4798,\n",
      "        -2.5028, -2.4678, -2.4640, -2.5092, -2.3095, -2.3056, -2.3636, -2.4170,\n",
      "        -2.3934, -2.4014], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4243, -2.3905, -2.3732, -2.4202, -2.3988, -2.4260, -2.4505, -2.4165,\n",
      "        -2.3563, -2.4175, -2.4322, -2.4181, -2.3698, -2.4463, -2.3722, -2.3932,\n",
      "        -2.3617, -2.4080, -2.4211, -2.3510, -2.3792, -2.4116, -2.4558, -2.3726,\n",
      "        -2.3803, -2.3643, -2.3969, -2.3827, -2.4248, -2.3987, -2.4086, -2.4207,\n",
      "        -2.3993, -2.4198, -2.4007, -2.4230, -2.4116, -2.3642, -2.4377, -2.4123,\n",
      "        -2.3803, -2.4466, -2.4154, -2.4489, -2.4133, -2.4054, -2.4099, -2.4180,\n",
      "        -2.3918, -2.4136], device='mps:0')\n",
      "mean: tensor(-2.4051, device='mps:0')\n",
      "iter_dt 0.97s; iter 69: train loss 0.38819 temperature: 8.449999999999996\n",
      "mean_logits tensor([-2.4617, -2.5635, -2.2083, -2.4867, -2.5153, -2.5181, -2.2665, -2.5975,\n",
      "        -1.9778, -2.7623, -2.3073, -2.2230, -2.4754, -2.3147, -2.3524, -2.5224,\n",
      "        -2.5158, -2.5768, -2.3007, -2.4371, -2.5953, -2.3941, -2.2373, -2.4028,\n",
      "        -2.1723, -2.4175, -2.4288, -2.1239, -2.3179, -2.5279, -2.1037, -2.4300,\n",
      "        -2.4195, -2.3798, -2.0176, -2.3187, -2.4798, -2.2597, -2.5250, -2.4224,\n",
      "        -2.3550, -2.6616, -2.3784, -2.5542, -2.5395, -2.1956, -2.2405, -2.2613,\n",
      "        -2.4068, -2.3679], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4260, -2.4355, -2.4172, -2.4011, -2.4121, -2.3890, -2.4171, -2.4188,\n",
      "        -2.3955, -2.4243, -2.4125, -2.4121, -2.4149, -2.3873, -2.4062, -2.4060,\n",
      "        -2.3919, -2.4509, -2.3837, -2.4245, -2.4363, -2.4196, -2.4041, -2.3545,\n",
      "        -2.3821, -2.4227, -2.4138, -2.3882, -2.4293, -2.3785, -2.4009, -2.4226,\n",
      "        -2.4000, -2.3490, -2.4058, -2.4175, -2.3604, -2.4123, -2.3753, -2.3830,\n",
      "        -2.3965, -2.3846, -2.4081, -2.3952, -2.4401, -2.3594, -2.3924, -2.3943,\n",
      "        -2.4220, -2.4170], device='mps:0')\n",
      "mean: tensor(-2.4038, device='mps:0')\n",
      "iter_dt 0.98s; iter 70: train loss 0.58007 temperature: 8.499999999999996\n",
      "mean_logits tensor([-2.1037, -2.0909, -2.0966, -2.4822, -2.1029, -2.1969, -2.1808, -2.3634,\n",
      "        -2.3974, -2.5020, -2.4815, -2.4819, -2.6080, -2.0016, -2.6920, -2.2062,\n",
      "        -2.2303, -2.5590, -2.3859, -2.1163, -2.5839, -2.4208, -2.4955, -2.4108,\n",
      "        -2.6006, -2.2882, -2.1843, -2.3581, -2.5135, -2.3107, -2.5098, -2.5177,\n",
      "        -2.3076, -2.3675, -2.0033, -2.1812, -2.1659, -2.4469, -2.3448, -2.7719,\n",
      "        -2.0914, -2.4935, -2.6605, -2.2131, -2.1533, -2.4019, -2.1087, -2.2484,\n",
      "        -2.3045, -2.1277], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3802, -2.4126, -2.4103, -2.3395, -2.4166, -2.3863, -2.4000, -2.3362,\n",
      "        -2.4046, -2.4274, -2.4232, -2.3786, -2.4396, -2.4158, -2.3880, -2.4118,\n",
      "        -2.4145, -2.4252, -2.4115, -2.4057, -2.4330, -2.4140, -2.4097, -2.3736,\n",
      "        -2.4049, -2.4119, -2.4057, -2.4308, -2.4202, -2.3874, -2.4248, -2.4079,\n",
      "        -2.4156, -2.3887, -2.4109, -2.4482, -2.4144, -2.4573, -2.4380, -2.4378,\n",
      "        -2.3551, -2.3966, -2.4227, -2.4378, -2.3440, -2.4156, -2.3919, -2.3090,\n",
      "        -2.4120, -2.4196], device='mps:0')\n",
      "mean: tensor(-2.4053, device='mps:0')\n",
      "iter_dt 0.98s; iter 71: train loss 0.50394 temperature: 8.549999999999997\n",
      "mean_logits tensor([-2.2649, -2.1877, -2.6386, -2.0924, -2.1965, -2.4420, -2.4431, -2.2097,\n",
      "        -2.2592, -2.4120, -2.4649, -2.6463, -2.5637, -2.0873, -2.5727, -2.4232,\n",
      "        -2.4926, -2.3814, -2.6131, -2.2725, -2.4540, -2.1905, -2.1364, -2.3227,\n",
      "        -2.3912, -2.6454, -2.2826, -2.3532, -2.0347, -2.3841, -2.3661, -2.2532,\n",
      "        -2.0199, -2.4510, -2.2199, -1.9363, -2.4902, -2.5986, -2.4028, -2.5770,\n",
      "        -2.3835, -2.3689, -2.6565, -2.2732, -2.4119, -1.9604, -2.4083, -2.4188,\n",
      "        -2.1105, -2.4389], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4218, -2.3975, -2.4201, -2.3699, -2.3658, -2.4133, -2.4432, -2.4004,\n",
      "        -2.4108, -2.4199, -2.4020, -2.4012, -2.4142, -2.4165, -2.4336, -2.4472,\n",
      "        -2.4189, -2.3628, -2.4472, -2.3324, -2.4125, -2.4208, -2.4106, -2.4112,\n",
      "        -2.3622, -2.3844, -2.3997, -2.3706, -2.4156, -2.4015, -2.4403, -2.4136,\n",
      "        -2.4119, -2.4259, -2.4091, -2.4169, -2.4101, -2.4188, -2.4192, -2.4166,\n",
      "        -2.3946, -2.4236, -2.4213, -2.4241, -2.3839, -2.4117, -2.4617, -2.3630,\n",
      "        -2.4185, -2.4614], device='mps:0')\n",
      "mean: tensor(-2.4095, device='mps:0')\n",
      "iter_dt 0.96s; iter 72: train loss 0.34223 temperature: 8.599999999999998\n",
      "mean_logits tensor([-2.3990, -2.3422, -2.4480, -2.2627, -2.2032, -2.4892, -2.1364, -2.4467,\n",
      "        -2.4737, -2.2534, -2.2695, -2.5827, -2.2568, -2.2880, -2.2679, -2.3720,\n",
      "        -2.4594, -2.1825, -2.3430, -2.3627, -2.5019, -2.4316, -2.3611, -2.5037,\n",
      "        -2.7034, -2.4553, -2.4563, -2.2017, -2.1039, -2.0681, -2.2413, -2.3404,\n",
      "        -2.1205, -2.4394, -2.3557, -2.2571, -2.3693, -2.3471, -2.2705, -2.1837,\n",
      "        -2.2908, -2.4904, -2.6208, -2.4405, -2.3495, -2.0782, -2.3559, -2.2998,\n",
      "        -2.4455, -2.3086], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3826, -2.4002, -2.4211, -2.3959, -2.4014, -2.4518, -2.4266, -2.4163,\n",
      "        -2.3967, -2.4237, -2.4183, -2.4146, -2.4639, -2.3915, -2.4559, -2.4107,\n",
      "        -2.4017, -2.3960, -2.4215, -2.3794, -2.4104, -2.4054, -2.4553, -2.4078,\n",
      "        -2.4275, -2.4177, -2.4201, -2.4102, -2.4190, -2.4015, -2.4133, -2.4031,\n",
      "        -2.3855, -2.4234, -2.4094, -2.4259, -2.4010, -2.3976, -2.4080, -2.4175,\n",
      "        -2.4196, -2.3930, -2.4263, -2.4301, -2.4133, -2.4140, -2.4194, -2.4212,\n",
      "        -2.4198, -2.4359], device='mps:0')\n",
      "mean: tensor(-2.4144, device='mps:0')\n",
      "iter_dt 0.99s; iter 73: train loss 0.54473 temperature: 8.649999999999999\n",
      "mean_logits tensor([-2.1112, -1.9878, -2.4156, -2.3627, -2.7259, -2.3716, -2.3044, -2.2397,\n",
      "        -2.4052, -2.2948, -2.4951, -2.3367, -2.3666, -2.1645, -2.6651, -2.4743,\n",
      "        -2.5940, -2.4592, -2.1527, -2.3410, -2.7760, -2.3300, -2.6142, -2.2857,\n",
      "        -2.3254, -2.5147, -2.3291, -2.4272, -2.2099, -2.1892, -2.6613, -2.3899,\n",
      "        -2.3417, -2.1498, -2.3772, -2.5323, -2.4058, -2.3975, -1.9504, -2.3577,\n",
      "        -2.3876, -2.5480, -2.3013, -2.5480, -2.1013, -2.6631, -2.2688, -2.3861,\n",
      "        -2.3019, -1.9842], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4053, -2.3966, -2.3970, -2.4598, -2.4174, -2.3613, -2.4129, -2.4227,\n",
      "        -2.4110, -2.3781, -2.4165, -2.3899, -2.4429, -2.3947, -2.3752, -2.4033,\n",
      "        -2.4123, -2.4173, -2.4124, -2.4227, -2.4260, -2.4060, -2.3916, -2.4046,\n",
      "        -2.4185, -2.3886, -2.3923, -2.4114, -2.3742, -2.3617, -2.3402, -2.3881,\n",
      "        -2.4189, -2.4133, -2.4009, -2.4279, -2.4227, -2.4209, -2.4435, -2.3917,\n",
      "        -2.4155, -2.3976, -2.4288, -2.4125, -2.3791, -2.4609, -2.4107, -2.3175,\n",
      "        -2.4171, -2.3675], device='mps:0')\n",
      "mean: tensor(-2.4040, device='mps:0')\n",
      "iter_dt 0.97s; iter 74: train loss 0.35844 temperature: 8.7\n",
      "mean_logits tensor([-2.5880, -2.3623, -2.5203, -2.1693, -2.2139, -2.3002, -2.3077, -2.3639,\n",
      "        -2.5001, -2.2413, -2.1333, -2.1621, -2.3915, -2.1123, -2.4618, -2.4555,\n",
      "        -2.4393, -2.3055, -2.2983, -2.1572, -2.4211, -2.2998, -2.5035, -2.1821,\n",
      "        -2.4289, -2.2879, -2.5397, -2.3168, -2.4072, -2.6964, -2.2913, -2.3931,\n",
      "        -2.4281, -2.1959, -2.2696, -2.3858, -2.2350, -2.2716, -2.2980, -2.3444,\n",
      "        -2.6605, -2.5348, -2.5837, -2.5172, -2.2580, -2.4585, -2.5178, -2.5396,\n",
      "        -2.1761, -2.1000], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4172, -2.4265, -2.4108, -2.3924, -2.3829, -2.4190, -2.4090, -2.4465,\n",
      "        -2.4073, -2.4009, -2.4165, -2.3834, -2.3784, -2.4190, -2.4190, -2.4329,\n",
      "        -2.4188, -2.4112, -2.4221, -2.4242, -2.4204, -2.4438, -2.4087, -2.4215,\n",
      "        -2.4243, -2.3314, -2.4297, -2.4213, -2.3896, -2.4053, -2.4117, -2.4313,\n",
      "        -2.4123, -2.4192, -2.4257, -2.4075, -2.4612, -2.4106, -2.4192, -2.4050,\n",
      "        -2.4458, -2.4435, -2.4007, -2.4060, -2.4150, -2.4223, -2.4135, -2.4183,\n",
      "        -2.3444, -2.4127], device='mps:0')\n",
      "mean: tensor(-2.4132, device='mps:0')\n",
      "iter_dt 0.97s; iter 75: train loss 0.41020 temperature: 8.75\n",
      "mean_logits tensor([-2.4639, -2.3058, -2.2355, -2.3624, -2.5277, -2.3262, -2.3782, -2.3495,\n",
      "        -2.5911, -2.2514, -2.0571, -2.3031, -2.3865, -2.6580, -2.3922, -2.3610,\n",
      "        -2.4326, -2.3039, -2.2168, -2.4698, -2.3188, -2.2949, -2.2392, -2.4818,\n",
      "        -2.3274, -2.2711, -2.4041, -2.6217, -2.3218, -2.3541, -2.5047, -2.3445,\n",
      "        -2.3016, -2.5511, -2.1348, -2.2296, -2.1953, -2.1448, -2.3559, -2.4811,\n",
      "        -2.7519, -2.4410, -2.0210, -2.2045, -2.1698, -2.5720, -2.3028, -2.3913,\n",
      "        -2.1959, -2.4694], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4016, -2.4429, -2.4008, -2.4125, -2.3460, -2.4179, -2.3720, -2.4292,\n",
      "        -2.4188, -2.4151, -2.4319, -2.4136, -2.3505, -2.4297, -2.4120, -2.4212,\n",
      "        -2.3990, -2.4103, -2.4178, -2.4108, -2.3316, -2.4316, -2.4223, -2.4188,\n",
      "        -2.4352, -2.3957, -2.3334, -2.3710, -2.4203, -2.4194, -2.4245, -2.3894,\n",
      "        -2.4253, -2.4298, -2.4110, -2.4180, -2.3471, -2.3913, -2.3493, -2.4194,\n",
      "        -2.4007, -2.4094, -2.4327, -2.4085, -2.4099, -2.3667, -2.4237, -2.4180,\n",
      "        -2.3898, -2.4087], device='mps:0')\n",
      "mean: tensor(-2.4041, device='mps:0')\n",
      "iter_dt 0.97s; iter 76: train loss 0.39832 temperature: 8.8\n",
      "mean_logits tensor([-2.6202, -2.3819, -2.3268, -2.1484, -2.3341, -2.2582, -2.4788, -2.8185,\n",
      "        -2.3362, -2.3130, -2.6232, -2.0682, -2.6096, -2.5509, -2.3693, -2.3840,\n",
      "        -2.2375, -2.3228, -2.2642, -2.4661, -2.2371, -2.2779, -2.5441, -2.4633,\n",
      "        -2.3317, -2.1767, -2.2757, -2.5637, -2.3315, -2.4012, -2.3117, -2.4803,\n",
      "        -2.5483, -2.2350, -2.3215, -2.2640, -2.3148, -2.7480, -2.3086, -2.4245,\n",
      "        -2.4098, -2.2740, -2.5154, -2.2987, -2.3345, -2.3234, -2.4420, -2.4530,\n",
      "        -2.1643, -2.4794], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4041, -2.4163, -2.4271, -2.4129, -2.4555, -2.3931, -2.4379, -2.4069,\n",
      "        -2.4207, -2.4259, -2.4312, -2.4176, -2.4316, -2.4180, -2.3945, -2.4017,\n",
      "        -2.4144, -2.3539, -2.4193, -2.4070, -2.3416, -2.4141, -2.4135, -2.4237,\n",
      "        -2.4175, -2.4191, -2.4122, -2.4105, -2.4117, -2.4067, -2.3444, -2.3809,\n",
      "        -2.3994, -2.4310, -2.4046, -2.3980, -2.4172, -2.4101, -2.4309, -2.4143,\n",
      "        -2.4456, -2.3739, -2.4497, -2.3591, -2.3830, -2.4064, -2.3865, -2.4434,\n",
      "        -2.4092, -2.4056], device='mps:0')\n",
      "mean: tensor(-2.4091, device='mps:0')\n",
      "iter_dt 0.97s; iter 77: train loss 0.56130 temperature: 8.850000000000001\n",
      "mean_logits tensor([-2.4053, -2.0474, -2.4606, -2.5114, -2.3580, -2.5381, -2.6113, -2.3890,\n",
      "        -2.2117, -2.3228, -2.2165, -2.3559, -2.1170, -2.2819, -2.3605, -2.1545,\n",
      "        -2.3250, -2.6856, -2.4360, -2.4421, -2.2084, -2.5964, -2.3266, -2.5341,\n",
      "        -2.0766, -1.7188, -2.1901, -2.1724, -2.2076, -2.7023, -2.6877, -2.4148,\n",
      "        -2.2957, -2.4724, -2.3493, -2.3306, -2.0517, -2.3205, -2.2454, -2.4545,\n",
      "        -2.4621, -2.6029, -2.1017, -2.3559, -2.5965, -2.2157, -2.2579, -2.4823,\n",
      "        -2.4419, -2.2327], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4110, -2.4039, -2.3891, -2.3756, -2.4349, -2.4090, -2.3819, -2.4243,\n",
      "        -2.4493, -2.3605, -2.4166, -2.4276, -2.3821, -2.3421, -2.3656, -2.4317,\n",
      "        -2.4123, -2.4143, -2.4526, -2.4226, -2.4313, -2.4181, -2.4090, -2.3938,\n",
      "        -2.4130, -2.3791, -2.4131, -2.3849, -2.4152, -2.3926, -2.4049, -2.4127,\n",
      "        -2.4187, -2.4181, -2.4170, -2.4001, -2.3748, -2.4358, -2.4552, -2.4142,\n",
      "        -2.3926, -2.4059, -2.4230, -2.4218, -2.4024, -2.4164, -2.3620, -2.4140,\n",
      "        -2.4153, -2.4218], device='mps:0')\n",
      "mean: tensor(-2.4077, device='mps:0')\n",
      "iter_dt 0.98s; iter 78: train loss 0.44368 temperature: 8.900000000000002\n",
      "mean_logits tensor([-2.1123, -2.2789, -2.3079, -2.2520, -2.3893, -2.3020, -2.4199, -2.2152,\n",
      "        -2.4460, -2.5347, -2.2621, -2.4750, -2.1170, -2.3783, -2.3854, -2.4056,\n",
      "        -2.1536, -2.3244, -2.4623, -2.2957, -2.4491, -1.9883, -2.4542, -2.5361,\n",
      "        -2.1597, -2.2254, -2.3459, -2.4678, -2.6617, -2.3074, -2.3310, -2.2130,\n",
      "        -2.7418, -2.4341, -2.6244, -2.3625, -2.1006, -2.6134, -2.0301, -2.5230,\n",
      "        -2.5132, -2.2672, -2.0237, -2.5563, -2.5284, -2.4353, -2.4941, -2.2080,\n",
      "        -2.5227, -2.3238], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4350, -2.3602, -2.4090, -2.3844, -2.4030, -2.4031, -2.4477, -2.4258,\n",
      "        -2.4008, -2.4179, -2.4183, -2.4198, -2.4148, -2.4088, -2.4211, -2.4177,\n",
      "        -2.3943, -2.4173, -2.4671, -2.4205, -2.3989, -2.4160, -2.4405, -2.4387,\n",
      "        -2.4188, -2.3886, -2.4038, -2.4099, -2.4202, -2.4317, -2.3989, -2.4123,\n",
      "        -2.4057, -2.4166, -2.4181, -2.3663, -2.4214, -2.3847, -2.3703, -2.3985,\n",
      "        -2.4225, -2.4419, -2.3731, -2.4536, -2.3681, -2.4091, -2.4175, -2.3648,\n",
      "        -2.4422, -2.3967], device='mps:0')\n",
      "mean: tensor(-2.4107, device='mps:0')\n",
      "iter_dt 0.97s; iter 79: train loss 0.42476 temperature: 8.950000000000003\n",
      "mean_logits tensor([-2.2166, -2.4994, -2.1374, -2.3281, -2.3501, -2.3642, -2.1255, -2.3405,\n",
      "        -2.4235, -2.2557, -2.3907, -2.4354, -2.4473, -2.1754, -2.1963, -1.9781,\n",
      "        -2.5302, -2.4329, -2.3007, -2.6914, -2.1667, -2.3804, -2.2248, -2.1996,\n",
      "        -2.7203, -2.5268, -2.5910, -2.4320, -2.5281, -2.4747, -2.0728, -2.5311,\n",
      "        -2.5464, -2.5302, -2.1152, -2.3891, -2.4714, -2.4721, -2.3654, -2.4377,\n",
      "        -2.2940, -2.3953, -2.5456, -2.3214, -2.3789, -2.3302, -2.6075, -2.6026,\n",
      "        -2.6836, -2.4361], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4129, -2.4109, -2.3968, -2.4128, -2.4327, -2.4175, -2.4118, -2.3508,\n",
      "        -2.3779, -2.4583, -2.3570, -2.4011, -2.3802, -2.4177, -2.3991, -2.4021,\n",
      "        -2.4432, -2.4380, -2.4213, -2.4158, -2.4037, -2.4133, -2.4303, -2.3571,\n",
      "        -2.4286, -2.4160, -2.4196, -2.4047, -2.4118, -2.3800, -2.4031, -2.4184,\n",
      "        -2.4194, -2.3908, -2.4449, -2.4110, -2.4126, -2.4326, -2.3615, -2.3635,\n",
      "        -2.4186, -2.4110, -2.4456, -2.4178, -2.4227, -2.4029, -2.4214, -2.4083,\n",
      "        -2.4572, -2.3626], device='mps:0')\n",
      "mean: tensor(-2.4090, device='mps:0')\n",
      "iter_dt 0.99s; iter 80: train loss 0.35941 temperature: 9.000000000000004\n",
      "mean_logits tensor([-2.3162, -2.3911, -2.5177, -2.1915, -2.4304, -2.1057, -2.1738, -2.4335,\n",
      "        -2.2685, -2.2359, -2.5742, -2.6285, -2.2583, -2.5749, -2.4508, -2.4163,\n",
      "        -2.4422, -2.5433, -2.1779, -2.2329, -2.3735, -2.2160, -2.4999, -2.1873,\n",
      "        -2.3708, -2.4400, -2.4781, -2.1746, -2.4785, -2.4523, -2.2350, -2.2678,\n",
      "        -2.2823, -2.3639, -2.4032, -2.6434, -2.3655, -2.3331, -2.4747, -2.5283,\n",
      "        -2.1884, -2.3167, -2.6375, -2.3941, -2.6514, -2.3534, -2.3323, -2.3757,\n",
      "        -2.6583, -2.2320], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4242, -2.3788, -2.4150, -2.3990, -2.4142, -2.4025, -2.4175, -2.4121,\n",
      "        -2.4196, -2.3196, -2.4189, -2.4214, -2.3828, -2.3944, -2.4221, -2.4196,\n",
      "        -2.3607, -2.4161, -2.4403, -2.3765, -2.3796, -2.3991, -2.4134, -2.4372,\n",
      "        -2.4185, -2.4113, -2.4415, -2.4029, -2.3672, -2.4257, -2.4221, -2.4098,\n",
      "        -2.3610, -2.4069, -2.4041, -2.3925, -2.4253, -2.4098, -2.4116, -2.3586,\n",
      "        -2.3624, -2.4019, -2.4173, -2.4167, -2.3763, -2.4078, -2.4182, -2.4197,\n",
      "        -2.3709, -2.3863], device='mps:0')\n",
      "mean: tensor(-2.4026, device='mps:0')\n",
      "iter_dt 0.97s; iter 81: train loss 0.35875 temperature: 9.050000000000004\n",
      "mean_logits tensor([-2.2259, -2.5622, -2.4042, -2.3774, -2.3266, -2.3533, -2.5811, -2.4483,\n",
      "        -2.2342, -2.5620, -2.2323, -2.3107, -2.4620, -2.4492, -2.3209, -2.1976,\n",
      "        -2.2509, -2.3546, -2.5678, -2.3239, -2.4450, -2.3483, -2.2781, -2.4266,\n",
      "        -2.4080, -2.6157, -2.6078, -2.3807, -2.3315, -2.5365, -2.3582, -2.3222,\n",
      "        -2.1776, -2.3924, -2.0808, -2.2453, -2.4884, -2.2572, -2.7575, -2.4005,\n",
      "        -1.9775, -2.4503, -2.2691, -2.2941, -2.4486, -2.6346, -2.5536, -2.5129,\n",
      "        -2.4893, -2.5436], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4219, -2.4234, -2.3692, -2.3039, -2.3916, -2.3554, -2.4208, -2.4259,\n",
      "        -2.4153, -2.3735, -2.4057, -2.4347, -2.4143, -2.4431, -2.4154, -2.4445,\n",
      "        -2.4187, -2.3857, -2.4547, -2.3495, -2.4109, -2.4146, -2.4153, -2.3812,\n",
      "        -2.4199, -2.3776, -2.4697, -2.3843, -2.4205, -2.4252, -2.4197, -2.4195,\n",
      "        -2.4246, -2.4034, -2.4282, -2.4225, -2.3821, -2.3858, -2.4173, -2.4104,\n",
      "        -2.4101, -2.4110, -2.3823, -2.3559, -2.3656, -2.4557, -2.4166, -2.4046,\n",
      "        -2.4466, -2.3836], device='mps:0')\n",
      "mean: tensor(-2.4066, device='mps:0')\n",
      "iter_dt 0.97s; iter 82: train loss 0.32290 temperature: 9.100000000000005\n",
      "mean_logits tensor([-2.1147, -2.3488, -2.3557, -2.4611, -2.6395, -2.3799, -2.4252, -2.5153,\n",
      "        -2.2627, -2.3771, -2.2762, -2.4371, -2.3738, -2.4805, -2.5961, -2.3781,\n",
      "        -2.4580, -2.3783, -2.4704, -2.1774, -2.3280, -2.2941, -2.2047, -2.7094,\n",
      "        -2.4450, -2.4242, -2.5395, -2.0722, -2.3423, -2.6519, -2.2715, -2.4316,\n",
      "        -2.2760, -2.2469, -2.5018, -2.2594, -2.5094, -2.4037, -2.3032, -2.3518,\n",
      "        -2.2236, -2.2330, -2.4544, -2.0849, -2.3900, -2.5272, -2.4291, -2.3621,\n",
      "        -2.4529, -2.5123], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4191, -2.4109, -2.4290, -2.3842, -2.4067, -2.4168, -2.4034, -2.3733,\n",
      "        -2.3772, -2.4214, -2.4168, -2.4316, -2.4295, -2.4638, -2.4130, -2.4338,\n",
      "        -2.4193, -2.4307, -2.4050, -2.4241, -2.4136, -2.4180, -2.3769, -2.4022,\n",
      "        -2.4160, -2.3941, -2.4149, -2.4196, -2.4547, -2.4071, -2.4110, -2.3972,\n",
      "        -2.4215, -2.4042, -2.4067, -2.4514, -2.4473, -2.4108, -2.3957, -2.4120,\n",
      "        -2.3376, -2.3903, -2.4490, -2.4133, -2.4265, -2.4130, -2.3689, -2.3197,\n",
      "        -2.4007, -2.3335], device='mps:0')\n",
      "mean: tensor(-2.4087, device='mps:0')\n",
      "iter_dt 0.99s; iter 83: train loss 0.34449 temperature: 9.150000000000006\n",
      "mean_logits tensor([-2.4482, -2.4483, -2.3725, -2.6520, -2.2003, -2.4236, -2.3329, -2.4286,\n",
      "        -2.5125, -2.0106, -2.3182, -2.2780, -2.5095, -2.2376, -2.5423, -2.4538,\n",
      "        -2.3584, -2.4483, -2.5998, -2.5428, -2.0884, -2.2470, -2.1592, -2.3004,\n",
      "        -2.3073, -2.4337, -2.3053, -2.3742, -2.6244, -2.3420, -2.1723, -2.4327,\n",
      "        -2.4294, -2.2803, -2.5465, -2.3612, -2.7154, -2.3620, -2.0416, -2.4373,\n",
      "        -2.1936, -2.3170, -2.4719, -2.4994, -2.3268, -2.5192, -2.4584, -2.5437,\n",
      "        -2.4168, -2.2496], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4035, -2.3619, -2.4246, -2.4307, -2.4012, -2.4171, -2.4188, -2.4038,\n",
      "        -2.4186, -2.4148, -2.4030, -2.3795, -2.4213, -2.4184, -2.4180, -2.4165,\n",
      "        -2.4526, -2.4125, -2.4023, -2.4243, -2.4315, -2.4453, -2.4179, -2.3243,\n",
      "        -2.3499, -2.3627, -2.4126, -2.3532, -2.4149, -2.4020, -2.4083, -2.3556,\n",
      "        -2.3723, -2.3431, -2.4192, -2.4276, -2.4247, -2.4477, -2.4200, -2.4057,\n",
      "        -2.3949, -2.3452, -2.4547, -2.4107, -2.3867, -2.4265, -2.4363, -2.4044,\n",
      "        -2.4191, -2.3582], device='mps:0')\n",
      "mean: tensor(-2.4044, device='mps:0')\n",
      "iter_dt 0.96s; iter 84: train loss 0.47954 temperature: 9.200000000000006\n",
      "mean_logits tensor([-2.2436, -2.3095, -2.5082, -2.3323, -2.2112, -2.1739, -2.2654, -2.2500,\n",
      "        -2.1827, -2.5162, -2.5102, -2.2675, -2.3257, -2.1315, -2.3485, -2.6426,\n",
      "        -1.9936, -2.2108, -2.5893, -2.3607, -2.1745, -2.2064, -2.4052, -2.3603,\n",
      "        -2.1213, -2.3126, -2.2189, -2.5271, -2.1762, -2.4175, -2.3965, -2.4502,\n",
      "        -2.0701, -2.2640, -2.5662, -2.0597, -2.4077, -2.5533, -2.1764, -2.0492,\n",
      "        -2.4022, -2.2396, -2.2086, -2.3311, -2.2128, -2.5078, -2.4756, -2.6836,\n",
      "        -2.2148, -2.5184], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3623, -2.4079, -2.4450, -2.3362, -2.4075, -2.4079, -2.3590, -2.4214,\n",
      "        -2.4476, -2.4176, -2.4228, -2.4262, -2.4304, -2.4139, -2.3452, -2.4023,\n",
      "        -2.4177, -2.4206, -2.4322, -2.4170, -2.4124, -2.3509, -2.4086, -2.3979,\n",
      "        -2.4121, -2.4402, -2.4162, -2.4183, -2.3991, -2.4143, -2.4188, -2.4211,\n",
      "        -2.4478, -2.4194, -2.4054, -2.3838, -2.4041, -2.4136, -2.4127, -2.4156,\n",
      "        -2.4184, -2.4202, -2.4169, -2.4206, -2.4036, -2.4118, -2.3615, -2.4260,\n",
      "        -2.3561, -2.4191], device='mps:0')\n",
      "mean: tensor(-2.4081, device='mps:0')\n",
      "iter_dt 0.99s; iter 85: train loss 0.39426 temperature: 9.250000000000007\n",
      "mean_logits tensor([-2.5099, -2.4535, -2.3126, -2.1258, -2.2330, -2.4102, -2.5415, -2.3021,\n",
      "        -2.2722, -2.4978, -2.4630, -2.3777, -2.1792, -2.3491, -2.1161, -2.2781,\n",
      "        -2.0541, -2.2497, -2.2740, -2.2022, -2.2104, -2.6884, -2.3821, -2.4688,\n",
      "        -2.4776, -2.3486, -2.3885, -2.2908, -2.4924, -2.3258, -2.1859, -2.2813,\n",
      "        -2.3063, -2.5338, -2.1646, -2.3250, -2.6382, -2.2660, -2.6545, -2.5278,\n",
      "        -2.1900, -2.2463, -2.3088, -2.4072, -2.3180, -2.2033, -2.2338, -2.2115,\n",
      "        -2.2664, -2.4633], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4199, -2.4131, -2.4085, -2.4173, -2.3991, -2.4190, -2.4215, -2.4002,\n",
      "        -2.4027, -2.3511, -2.4249, -2.3873, -2.4026, -2.4062, -2.3959, -2.3948,\n",
      "        -2.4200, -2.4186, -2.4086, -2.4169, -2.3746, -2.4060, -2.4034, -2.4116,\n",
      "        -2.3955, -2.3943, -2.4006, -2.4046, -2.3678, -2.4194, -2.4187, -2.4057,\n",
      "        -2.4197, -2.3892, -2.4056, -2.4086, -2.4147, -2.3490, -2.4383, -2.3509,\n",
      "        -2.4442, -2.4237, -2.4182, -2.4175, -2.3794, -2.4294, -2.4086, -2.4432,\n",
      "        -2.4208, -2.4029], device='mps:0')\n",
      "mean: tensor(-2.4059, device='mps:0')\n",
      "iter_dt 0.96s; iter 86: train loss 0.34714 temperature: 9.300000000000008\n",
      "mean_logits tensor([-2.4421, -2.2071, -2.2827, -2.1591, -2.3800, -2.3207, -2.4193, -2.5710,\n",
      "        -2.5938, -2.2194, -2.6864, -2.5908, -2.4101, -2.2454, -2.4049, -2.4661,\n",
      "        -2.4811, -2.4183, -2.3013, -2.5724, -2.4102, -2.5209, -2.0718, -2.5290,\n",
      "        -2.4908, -2.6248, -2.3848, -2.5601, -2.6267, -2.3342, -2.2903, -2.5889,\n",
      "        -2.6021, -2.3508, -2.4633, -2.4090, -2.3387, -2.2625, -2.6107, -2.5190,\n",
      "        -2.3753, -2.6202, -2.0821, -2.3637, -2.4486, -2.5936, -2.5775, -2.4950,\n",
      "        -2.4808, -2.5176], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4286, -2.4120, -2.4087, -2.4462, -2.4175, -2.4189, -2.4262, -2.3949,\n",
      "        -2.4364, -2.4098, -2.4120, -2.4057, -2.4140, -2.4009, -2.3769, -2.3924,\n",
      "        -2.4093, -2.3602, -2.3714, -2.4302, -2.4119, -2.4476, -2.3721, -2.3690,\n",
      "        -2.4344, -2.4153, -2.4041, -2.4518, -2.4180, -2.4015, -2.3697, -2.4039,\n",
      "        -2.4235, -2.3735, -2.4398, -2.4091, -2.4121, -2.3741, -2.4371, -2.4267,\n",
      "        -2.4372, -2.4011, -2.4106, -2.4244, -2.4175, -2.4524, -2.4197, -2.4211,\n",
      "        -2.4354, -2.3808], device='mps:0')\n",
      "mean: tensor(-2.4114, device='mps:0')\n",
      "iter_dt 0.97s; iter 87: train loss 0.58320 temperature: 9.350000000000009\n",
      "mean_logits tensor([-2.2628, -2.3589, -2.1531, -2.3829, -2.5247, -2.3682, -2.6473, -2.2133,\n",
      "        -2.5471, -2.5041, -2.4324, -2.0302, -2.4486, -2.6129, -2.2317, -2.4942,\n",
      "        -2.4319, -2.2390, -2.7419, -1.8685, -2.3193, -2.4452, -2.5390, -2.0399,\n",
      "        -2.3190, -2.2465, -2.3706, -2.7196, -2.5682, -2.2517, -2.0978, -2.1251,\n",
      "        -2.4069, -2.2131, -2.4302, -2.3526, -2.0300, -2.4301, -2.4684, -2.3886,\n",
      "        -2.0522, -2.4761, -2.5167, -2.0961, -2.0741, -2.4119, -2.0536, -2.5732,\n",
      "        -2.3528, -2.3171], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3662, -2.4010, -2.4069, -2.4056, -2.3919, -2.4183, -2.4346, -2.4192,\n",
      "        -2.3348, -2.3513, -2.4115, -2.3873, -2.4235, -2.4180, -2.4218, -2.4529,\n",
      "        -2.4196, -2.3863, -2.4201, -2.4342, -2.4152, -2.4142, -2.4307, -2.3935,\n",
      "        -2.4212, -2.4406, -2.4128, -2.4185, -2.4136, -2.3514, -2.3447, -2.4208,\n",
      "        -2.4161, -2.4225, -2.4189, -2.4203, -2.4189, -2.3697, -2.4430, -2.4205,\n",
      "        -2.4194, -2.3847, -2.4073, -2.3918, -2.4113, -2.4103, -2.4129, -2.4322,\n",
      "        -2.3796, -2.3891], device='mps:0')\n",
      "mean: tensor(-2.4070, device='mps:0')\n",
      "iter_dt 0.97s; iter 88: train loss 0.36934 temperature: 9.40000000000001\n",
      "mean_logits tensor([-2.4807, -2.0672, -2.2428, -2.1958, -2.1238, -2.1885, -2.1427, -2.5070,\n",
      "        -2.6926, -2.3528, -2.3096, -2.5568, -2.6195, -2.4490, -2.3119, -2.4865,\n",
      "        -2.5348, -2.3383, -2.5822, -2.4442, -2.3422, -2.5288, -2.5129, -2.3911,\n",
      "        -2.4965, -2.3559, -2.1918, -2.3442, -2.4203, -2.3958, -2.2123, -2.2919,\n",
      "        -2.1971, -2.5071, -2.5000, -2.3478, -2.0773, -2.4345, -2.3965, -2.2317,\n",
      "        -2.4370, -2.3408, -2.3233, -2.2214, -2.4410, -2.2540, -2.0328, -2.2299,\n",
      "        -2.3654, -2.4427], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4187, -2.4013, -2.4217, -2.4006, -2.3891, -2.3676, -2.4190, -2.4166,\n",
      "        -2.4200, -2.4072, -2.3910, -2.4009, -2.4153, -2.4149, -2.3986, -2.3771,\n",
      "        -2.3655, -2.4220, -2.4376, -2.4462, -2.4188, -2.4130, -2.3624, -2.4471,\n",
      "        -2.4107, -2.4277, -2.4195, -2.4299, -2.4138, -2.4470, -2.3969, -2.3661,\n",
      "        -2.4254, -2.4154, -2.3906, -2.4021, -2.4341, -2.4112, -2.3738, -2.4035,\n",
      "        -2.3750, -2.4214, -2.3541, -2.4173, -2.4001, -2.4187, -2.4116, -2.4380,\n",
      "        -2.3674, -2.4329], device='mps:0')\n",
      "mean: tensor(-2.4075, device='mps:0')\n",
      "iter_dt 0.98s; iter 89: train loss 0.30853 temperature: 9.45000000000001\n",
      "mean_logits tensor([-2.4506, -2.4394, -2.4004, -2.5399, -2.5839, -2.3267, -2.6688, -2.4671,\n",
      "        -2.3958, -2.4542, -2.4213, -2.4654, -2.2953, -1.9866, -2.3614, -2.4867,\n",
      "        -2.0674, -2.4737, -2.1765, -2.4148, -2.3830, -2.3770, -2.3599, -2.4482,\n",
      "        -2.3990, -2.2741, -2.2639, -2.5212, -2.4879, -2.3096, -2.4561, -2.3210,\n",
      "        -2.3551, -2.2899, -2.4180, -2.3628, -2.5422, -2.7070, -2.3632, -2.6504,\n",
      "        -2.1393, -2.1777, -2.2386, -2.4677, -2.4197, -2.5321, -2.4035, -2.4689,\n",
      "        -2.4453, -2.3540], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4166, -2.4188, -2.4095, -2.4194, -2.4192, -2.4183, -2.4175, -2.4237,\n",
      "        -2.4418, -2.4112, -2.3672, -2.3721, -2.4260, -2.3968, -2.4018, -2.4131,\n",
      "        -2.3819, -2.4328, -2.4289, -2.4462, -2.4577, -2.4137, -2.4460, -2.4203,\n",
      "        -2.4306, -2.3750, -2.4125, -2.3979, -2.3938, -2.4316, -2.4316, -2.4327,\n",
      "        -2.4432, -2.4040, -2.4059, -2.4100, -2.3663, -2.3930, -2.4082, -2.4438,\n",
      "        -2.4202, -2.4204, -2.3554, -2.4095, -2.4283, -2.3746, -2.4485, -2.4066,\n",
      "        -2.4130, -2.4235], device='mps:0')\n",
      "mean: tensor(-2.4136, device='mps:0')\n",
      "iter_dt 0.98s; iter 90: train loss 0.37484 temperature: 9.50000000000001\n",
      "mean_logits tensor([-2.0995, -2.7045, -2.4085, -2.4695, -2.3364, -2.2857, -2.2861, -2.6042,\n",
      "        -2.3146, -2.4120, -2.5779, -2.5400, -2.1834, -2.0691, -2.4021, -2.2880,\n",
      "        -2.4649, -2.3771, -2.3928, -2.1924, -2.3240, -2.3336, -2.2483, -2.4223,\n",
      "        -2.6371, -2.6727, -2.5094, -2.4486, -2.1426, -2.4297, -2.4146, -2.3683,\n",
      "        -2.5999, -2.3922, -2.1654, -2.2761, -2.6287, -2.4664, -2.3398, -2.4419,\n",
      "        -2.4788, -2.3958, -2.3484, -2.4658, -2.0123, -2.3021, -2.5312, -2.3811,\n",
      "        -2.5107, -2.2789], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3456, -2.4432, -2.4010, -2.4142, -2.3720, -2.3967, -2.4203, -2.4139,\n",
      "        -2.3646, -2.3462, -2.4101, -2.4216, -2.4516, -2.4150, -2.4125, -2.4258,\n",
      "        -2.3254, -2.3844, -2.3949, -2.4552, -2.4101, -2.3713, -2.3548, -2.4055,\n",
      "        -2.4085, -2.4260, -2.3996, -2.3586, -2.4084, -2.4159, -2.3950, -2.3973,\n",
      "        -2.3755, -2.4136, -2.4264, -2.3580, -2.4131, -2.3976, -2.4109, -2.4215,\n",
      "        -2.4231, -2.3958, -2.3603, -2.4119, -2.4132, -2.4010, -2.3790, -2.4203,\n",
      "        -2.4222, -2.4205], device='mps:0')\n",
      "mean: tensor(-2.4006, device='mps:0')\n",
      "iter_dt 0.99s; iter 91: train loss 0.53160 temperature: 9.550000000000011\n",
      "mean_logits tensor([-2.3786, -2.5527, -2.5503, -2.4282, -2.2114, -2.3134, -2.2421, -2.3472,\n",
      "        -2.2080, -2.5505, -2.3604, -2.1622, -2.0622, -2.4713, -2.5922, -2.1789,\n",
      "        -2.7600, -2.5341, -2.2188, -2.6244, -2.5686, -2.4662, -2.6279, -2.3491,\n",
      "        -2.6249, -2.3000, -2.0305, -2.0828, -2.3344, -2.2004, -2.2348, -2.4127,\n",
      "        -2.2623, -2.5888, -2.5480, -2.5453, -2.2257, -2.7000, -2.4241, -2.2777,\n",
      "        -2.3865, -2.3755, -2.6813, -2.3096, -2.3870, -2.6570, -2.2728, -2.4708,\n",
      "        -2.4894, -2.4818], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4427, -2.3931, -2.4106, -2.3927, -2.4158, -2.4113, -2.4023, -2.4167,\n",
      "        -2.3823, -2.4085, -2.3768, -2.4056, -2.4048, -2.4054, -2.3915, -2.4398,\n",
      "        -2.4188, -2.4215, -2.4580, -2.4076, -2.4273, -2.3926, -2.4114, -2.4085,\n",
      "        -2.4087, -2.3639, -2.4103, -2.4388, -2.4179, -2.3898, -2.4261, -2.4112,\n",
      "        -2.4199, -2.4351, -2.4186, -2.4505, -2.4116, -2.3826, -2.3701, -2.4463,\n",
      "        -2.4326, -2.4014, -2.4126, -2.4067, -2.4333, -2.4316, -2.4076, -2.4483,\n",
      "        -2.4327, -2.4493], device='mps:0')\n",
      "mean: tensor(-2.4141, device='mps:0')\n",
      "iter_dt 0.97s; iter 92: train loss 0.40780 temperature: 9.600000000000012\n",
      "mean_logits tensor([-2.3149, -2.3133, -2.1394, -2.6208, -2.1813, -2.4476, -2.6584, -2.2362,\n",
      "        -2.5060, -2.5965, -2.4287, -2.3727, -2.5104, -1.9873, -2.2093, -2.2521,\n",
      "        -2.3809, -2.1841, -2.4459, -2.2943, -2.2160, -2.3579, -2.4630, -2.4772,\n",
      "        -2.3844, -2.3048, -2.3192, -2.2626, -2.1879, -2.3892, -2.3249, -2.1595,\n",
      "        -2.2580, -2.0079, -2.4931, -2.2590, -2.4393, -2.2795, -2.2422, -2.4978,\n",
      "        -2.3085, -2.1349, -2.3534, -2.3244, -2.5239, -2.2367, -2.3882, -2.5555,\n",
      "        -1.9310, -2.6053], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4061, -2.4241, -2.3843, -2.4298, -2.4485, -2.4302, -2.4076, -2.4088,\n",
      "        -2.4417, -2.4092, -2.4135, -2.4102, -2.3729, -2.4067, -2.3490, -2.3946,\n",
      "        -2.4139, -2.4009, -2.3842, -2.4356, -2.4096, -2.4108, -2.4217, -2.4415,\n",
      "        -2.4221, -2.4181, -2.4145, -2.4189, -2.4171, -2.4629, -2.3689, -2.4053,\n",
      "        -2.4181, -2.3529, -2.4187, -2.4131, -2.4188, -2.4415, -2.3742, -2.4188,\n",
      "        -2.4107, -2.4172, -2.4140, -2.4166, -2.4117, -2.3956, -2.4171, -2.4120,\n",
      "        -2.3907, -2.4191], device='mps:0')\n",
      "mean: tensor(-2.4109, device='mps:0')\n",
      "iter_dt 1.00s; iter 93: train loss 0.37662 temperature: 9.650000000000013\n",
      "mean_logits tensor([-2.6203, -2.5299, -2.6022, -2.6557, -2.2824, -2.4613, -2.2547, -2.3683,\n",
      "        -2.4766, -2.5723, -2.6645, -2.2679, -2.5127, -2.2476, -2.2720, -2.4108,\n",
      "        -2.2503, -2.4315, -2.4650, -2.2249, -2.1840, -2.2827, -2.3484, -2.1856,\n",
      "        -2.3290, -2.3795, -2.5173, -2.2454, -2.5459, -2.4792, -2.2071, -2.2317,\n",
      "        -2.5121, -2.5840, -2.4812, -2.2385, -2.0774, -2.5969, -2.4998, -2.4913,\n",
      "        -2.4282, -2.2321, -2.2820, -2.0303, -2.4696, -2.5588, -2.3876, -2.4925,\n",
      "        -2.5884, -2.5473], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4245, -2.3663, -2.4200, -2.3781, -2.4292, -2.4200, -2.4214, -2.4176,\n",
      "        -2.3751, -2.4290, -2.4196, -2.3735, -2.4135, -2.4102, -2.4050, -2.4214,\n",
      "        -2.3736, -2.4145, -2.4431, -2.3753, -2.4317, -2.3849, -2.4269, -2.3975,\n",
      "        -2.3711, -2.4140, -2.4053, -2.4122, -2.4009, -2.4241, -2.3970, -2.4121,\n",
      "        -2.4199, -2.4114, -2.4205, -2.3906, -2.4038, -2.4234, -2.4074, -2.3998,\n",
      "        -2.4157, -2.4310, -2.3581, -2.4195, -2.3942, -2.4195, -2.3872, -2.4101,\n",
      "        -2.4233, -2.4217], device='mps:0')\n",
      "mean: tensor(-2.4073, device='mps:0')\n",
      "iter_dt 0.98s; iter 94: train loss 0.31910 temperature: 9.700000000000014\n",
      "mean_logits tensor([-2.1965, -2.4299, -2.5920, -2.4943, -2.6631, -2.3555, -2.6484, -2.5761,\n",
      "        -2.4816, -2.4089, -2.0996, -2.3299, -2.5983, -2.4664, -2.4477, -2.3916,\n",
      "        -2.3281, -2.5188, -2.2768, -2.4689, -2.3075, -2.3943, -2.4178, -2.1428,\n",
      "        -2.2787, -2.4267, -2.3478, -2.2574, -2.4627, -2.4116, -2.5873, -2.3315,\n",
      "        -2.4058, -2.4748, -2.2860, -2.4124, -2.3392, -2.2208, -2.1418, -2.4143,\n",
      "        -2.2393, -2.4650, -2.3945, -2.4359, -2.5169, -2.3035, -2.1515, -2.1630,\n",
      "        -2.4933, -2.5843], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4189, -2.4188, -2.4209, -2.4159, -2.4443, -2.4088, -2.3936, -2.3962,\n",
      "        -2.4015, -2.4060, -2.4258, -2.3405, -2.4055, -2.4156, -2.4226, -2.3393,\n",
      "        -2.4062, -2.3689, -2.4118, -2.4156, -2.4012, -2.4213, -2.4035, -2.4130,\n",
      "        -2.4249, -2.4543, -2.4168, -2.4144, -2.4181, -2.4067, -2.4242, -2.4211,\n",
      "        -2.4307, -2.4129, -2.4388, -2.4123, -2.4046, -2.3516, -2.4469, -2.3972,\n",
      "        -2.4175, -2.4045, -2.4080, -2.4546, -2.3984, -2.4493, -2.4533, -2.3976,\n",
      "        -2.3858, -2.4299], device='mps:0')\n",
      "mean: tensor(-2.4118, device='mps:0')\n",
      "iter_dt 0.97s; iter 95: train loss 0.53025 temperature: 9.750000000000014\n",
      "mean_logits tensor([-2.6360, -2.4895, -2.3681, -2.0940, -2.5304, -2.5017, -2.7428, -2.4288,\n",
      "        -1.8955, -2.5023, -2.3865, -2.2959, -2.2788, -2.4396, -2.4122, -2.3870,\n",
      "        -2.3307, -2.2542, -2.5121, -2.4990, -2.3843, -2.3762, -2.5169, -2.6212,\n",
      "        -2.4096, -2.4616, -2.6194, -2.4468, -2.4045, -2.1737, -2.4432, -2.0015,\n",
      "        -2.2859, -2.5434, -2.6537, -2.6815, -2.4586, -2.0653, -2.4736, -2.5030,\n",
      "        -2.6347, -2.3524, -2.2313, -2.4262, -2.2979, -2.4680, -2.5026, -2.0238,\n",
      "        -2.7552, -2.6646], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4020, -2.4244, -2.4408, -2.4009, -2.4091, -2.4533, -2.4379, -2.4080,\n",
      "        -2.4136, -2.4208, -2.4370, -2.3999, -2.4187, -2.3728, -2.4154, -2.4222,\n",
      "        -2.3620, -2.3980, -2.4441, -2.3989, -2.4025, -2.4384, -2.4185, -2.4209,\n",
      "        -2.4023, -2.4192, -2.3952, -2.4032, -2.4054, -2.3791, -2.4236, -2.4139,\n",
      "        -2.4142, -2.4126, -2.3431, -2.4452, -2.4200, -2.4093, -2.4099, -2.4193,\n",
      "        -2.4299, -2.4046, -2.3673, -2.4251, -2.4206, -2.4030, -2.4001, -2.3975,\n",
      "        -2.4100, -2.4371], device='mps:0')\n",
      "mean: tensor(-2.4114, device='mps:0')\n",
      "iter_dt 0.98s; iter 96: train loss 0.44901 temperature: 9.800000000000015\n",
      "mean_logits tensor([-2.5201, -2.1381, -2.5526, -2.2419, -2.3603, -2.2050, -2.5711, -2.4989,\n",
      "        -2.3079, -2.3416, -2.2997, -2.2840, -2.4921, -2.6030, -2.5869, -1.9284,\n",
      "        -2.4528, -2.5209, -2.1561, -2.3497, -2.2547, -2.5753, -2.2518, -2.2002,\n",
      "        -2.4738, -2.3291, -2.5617, -2.0955, -2.3740, -2.6380, -2.4302, -2.2435,\n",
      "        -2.4128, -2.3792, -2.2726, -2.4762, -2.2583, -2.5449, -2.4480, -2.6455,\n",
      "        -2.1117, -2.6708, -2.2260, -2.5476, -2.1802, -2.5098, -2.1725, -2.4214,\n",
      "        -2.3352, -2.3316], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4102, -2.3954, -2.3984, -2.3853, -2.3769, -2.4307, -2.4123, -2.4215,\n",
      "        -2.3544, -2.4360, -2.4191, -2.4180, -2.4195, -2.4104, -2.3941, -2.4216,\n",
      "        -2.4053, -2.4140, -2.4178, -2.4465, -2.3871, -2.4325, -2.4332, -2.4210,\n",
      "        -2.4078, -2.4183, -2.4293, -2.4153, -2.4049, -2.4105, -2.4473, -2.4194,\n",
      "        -2.4110, -2.4499, -2.4090, -2.4210, -2.4191, -2.4233, -2.4564, -2.4010,\n",
      "        -2.3853, -2.3452, -2.3860, -2.4197, -2.4020, -2.4089, -2.4195, -2.4303,\n",
      "        -2.4243, -2.3929], device='mps:0')\n",
      "mean: tensor(-2.4124, device='mps:0')\n",
      "iter_dt 0.96s; iter 97: train loss 0.54827 temperature: 9.850000000000016\n",
      "mean_logits tensor([-2.8082, -2.6177, -2.2421, -2.5741, -2.4392, -1.9050, -2.5068, -2.3904,\n",
      "        -2.4907, -2.6236, -2.3932, -2.5569, -2.5645, -1.9901, -2.3005, -2.6268,\n",
      "        -2.0979, -2.3375, -2.0182, -2.5825, -2.5080, -2.4013, -2.3740, -2.2138,\n",
      "        -2.5554, -2.2785, -2.5146, -2.4913, -2.5378, -2.2128, -2.6191, -2.4606,\n",
      "        -2.3648, -2.6092, -2.5490, -2.3507, -2.4051, -2.2996, -2.6969, -2.4231,\n",
      "        -2.2337, -2.6572, -2.3365, -2.5853, -2.2004, -2.4155, -2.4560, -2.5120,\n",
      "        -2.4810, -2.3232], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4123, -2.4040, -2.4173, -2.4169, -2.4173, -2.3655, -2.4186, -2.4170,\n",
      "        -2.4412, -2.3480, -2.4210, -2.4194, -2.4170, -2.4120, -2.4255, -2.3545,\n",
      "        -2.4169, -2.4126, -2.4142, -2.4064, -2.4181, -2.3733, -2.3927, -2.4218,\n",
      "        -2.4237, -2.3960, -2.4552, -2.4078, -2.4117, -2.4018, -2.4298, -2.3932,\n",
      "        -2.4211, -2.4174, -2.4058, -2.4146, -2.4000, -2.4103, -2.4303, -2.3530,\n",
      "        -2.3656, -2.4048, -2.4554, -2.4339, -2.3724, -2.4562, -2.4466, -2.4055,\n",
      "        -2.4223, -2.4253], device='mps:0')\n",
      "mean: tensor(-2.4105, device='mps:0')\n",
      "iter_dt 0.96s; iter 98: train loss 0.33998 temperature: 9.900000000000016\n",
      "mean_logits tensor([-2.3499, -2.4977, -2.3807, -1.8660, -2.4291, -2.5961, -2.2523, -2.2581,\n",
      "        -2.3556, -2.2385, -2.4352, -2.4698, -2.4065, -2.3079, -2.0690, -2.3025,\n",
      "        -2.3058, -2.2189, -2.3435, -2.4161, -2.4065, -2.6313, -2.4024, -2.4072,\n",
      "        -2.4362, -2.4196, -2.6038, -2.6384, -2.3747, -2.3202, -2.4169, -2.2603,\n",
      "        -2.3982, -2.3771, -2.2767, -2.2876, -2.6618, -2.1570, -2.3258, -2.3614,\n",
      "        -2.3727, -2.5825, -2.5790, -2.3484, -2.4942, -2.4292, -2.3105, -2.1897,\n",
      "        -2.2410, -2.3959], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3756, -2.3997, -2.3162, -2.4183, -2.3815, -2.4157, -2.3999, -2.3948,\n",
      "        -2.4122, -2.3998, -2.4431, -2.4319, -2.3848, -2.4107, -2.4186, -2.3445,\n",
      "        -2.4164, -2.4750, -2.4125, -2.4472, -2.4202, -2.4169, -2.3835, -2.4208,\n",
      "        -2.3593, -2.4205, -2.4267, -2.4136, -2.4191, -2.4176, -2.3870, -2.4381,\n",
      "        -2.4074, -2.3849, -2.3639, -2.4242, -2.4246, -2.3874, -2.3545, -2.4146,\n",
      "        -2.3903, -2.4002, -2.3717, -2.4713, -2.4201, -2.4005, -2.4098, -2.4177,\n",
      "        -2.4219, -2.4190], device='mps:0')\n",
      "mean: tensor(-2.4061, device='mps:0')\n",
      "iter_dt 0.97s; iter 99: train loss 0.30382 temperature: 9.950000000000017\n",
      "mean_logits tensor([-2.3755, -2.5067, -2.1785, -2.2833, -2.2800, -2.2387, -2.4863, -2.4564,\n",
      "        -2.4857, -2.2233, -2.3830, -2.0874, -2.2580, -2.2515, -2.2208, -2.4513,\n",
      "        -2.2663, -2.0857, -2.3005, -2.1738, -2.4526, -2.2306, -2.3961, -2.4865,\n",
      "        -2.4927, -2.3702, -2.2711, -2.2957, -2.2769, -2.4969, -2.4272, -2.5316,\n",
      "        -2.5236, -2.4519, -2.5088, -2.5957, -2.2304, -2.5574, -2.5789, -2.3636,\n",
      "        -2.2283, -2.2933, -2.4451, -2.1489, -2.3626, -2.4015, -2.2291, -2.5373,\n",
      "        -2.3048, -2.5365], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3750, -2.4092, -2.3921, -2.3820, -2.4182, -2.4473, -2.4387, -2.3973,\n",
      "        -2.3900, -2.4297, -2.4206, -2.4130, -2.3846, -2.4085, -2.3984, -2.3750,\n",
      "        -2.4062, -2.3813, -2.4128, -2.4252, -2.3994, -2.4716, -2.3992, -2.3996,\n",
      "        -2.4023, -2.4206, -2.3499, -2.4557, -2.4183, -2.4186, -2.4351, -2.4462,\n",
      "        -2.4194, -2.4454, -2.4712, -2.4479, -2.4153, -2.4067, -2.4379, -2.4143,\n",
      "        -2.4195, -2.4216, -2.3719, -2.4436, -2.4065, -2.3348, -2.4147, -2.4186,\n",
      "        -2.4220, -2.4273], device='mps:0')\n",
      "mean: tensor(-2.4132, device='mps:0')\n",
      "current_prefixes: [7278 4037 5557 4534 4632 6985  380 4805 4101 4404 4883  611  346 1045\n",
      " 2273 6235 5773 2879  256  465 6084 8286  375 5500  264]\n",
      "layer: 6 starts running\n",
      "number of parameters: 91.99M\n",
      "running on device mps\n",
      "iter_dt 0.00s; iter 0: train loss 2.65563 temperature: 5\n",
      "mean_logits tensor([-2.0355, -1.7540, -2.2028, -1.9905, -1.8546, -2.1981, -1.7793, -1.9282,\n",
      "        -1.9305, -2.0875, -1.6665, -1.9812, -2.1226, -1.9632, -1.8713, -2.0563,\n",
      "        -2.3757, -1.6775, -1.6588, -2.0187, -2.3418, -2.3563, -1.9687, -1.7439,\n",
      "        -1.9956, -2.1588, -2.3504, -1.7944, -2.2738, -2.4282, -2.1638, -2.2519,\n",
      "        -1.6959, -1.5767, -1.9252, -1.7569, -1.9204, -2.0484, -1.9474, -2.0941,\n",
      "        -2.0406, -1.9717, -2.2894, -2.2138, -2.0354, -2.0189, -2.1522, -1.7944,\n",
      "        -2.1002, -2.1620], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4833, -2.3665, -2.4505, -2.4666, -2.4928, -2.4625, -2.4616, -2.5157,\n",
      "        -2.5157, -2.4497, -2.4584, -2.4864, -2.4535, -2.4980, -2.4774, -2.4521,\n",
      "        -2.4083, -2.4371, -2.5044, -2.3928, -2.4600, -2.3424, -2.4480, -2.4767,\n",
      "        -2.4456, -2.4526, -2.4826, -2.4870, -2.3446, -2.4729, -2.4921, -2.3788,\n",
      "        -2.4905, -2.4499, -2.4599, -2.4600, -2.4665, -2.4942, -2.4674, -2.4847,\n",
      "        -2.4744, -2.4546, -2.4930, -2.4489, -2.4982, -2.4613, -2.4425, -2.5092,\n",
      "        -2.5002, -2.4436], device='mps:0')\n",
      "mean: tensor(-2.4603, device='mps:0')\n",
      "iter_dt 1695864293.36s; iter 1: train loss 2.62875 temperature: 5.05\n",
      "mean_logits tensor([-2.1797, -1.8247, -2.1292, -2.2282, -1.9642, -2.0232, -2.3695, -1.8948,\n",
      "        -2.0569, -2.0027, -2.0699, -2.0202, -2.1583, -2.3271, -2.4574, -1.9050,\n",
      "        -1.8735, -1.9855, -1.9800, -1.8837, -2.0178, -1.9587, -2.0181, -2.1893,\n",
      "        -2.0612, -2.2406, -1.4962, -1.8703, -1.7895, -1.7718, -1.9497, -1.9505,\n",
      "        -2.4501, -2.3271, -2.2604, -1.9522, -2.3522, -1.9930, -1.8494, -2.2565,\n",
      "        -1.8148, -1.8979, -1.9094, -1.6086, -2.3980, -1.8367, -1.9411, -1.7424,\n",
      "        -1.9144, -2.1210], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4506, -2.5055, -2.4074, -2.5007, -2.4771, -2.3989, -2.4954, -2.4693,\n",
      "        -2.5104, -2.3998, -2.4653, -2.4375, -2.4668, -2.5023, -2.4637, -2.4774,\n",
      "        -2.4291, -2.4878, -2.4768, -2.4545, -2.5009, -2.4962, -2.4321, -2.4933,\n",
      "        -2.4220, -2.4250, -2.4994, -2.4716, -2.4306, -2.5009, -2.5008, -2.4683,\n",
      "        -2.4518, -2.4978, -2.4630, -2.4612, -2.4857, -2.4993, -2.4989, -2.4890,\n",
      "        -2.4792, -2.4420, -2.4859, -2.4276, -2.5137, -2.4981, -2.4955, -2.4275,\n",
      "        -2.5137, -2.4535], device='mps:0')\n",
      "mean: tensor(-2.4700, device='mps:0')\n",
      "iter_dt 1.07s; iter 2: train loss 2.26366 temperature: 5.1\n",
      "mean_logits tensor([-1.6038, -2.0969, -1.9072, -1.6844, -1.8934, -2.2402, -2.0989, -2.3111,\n",
      "        -1.6936, -2.1292, -1.6511, -2.1163, -2.0257, -1.8094, -2.1115, -1.7159,\n",
      "        -2.3193, -1.9392, -2.0904, -2.2329, -2.3365, -1.6765, -2.2242, -2.4378,\n",
      "        -1.9846, -2.5231, -2.0540, -2.3725, -2.0440, -2.0587, -2.3057, -2.0218,\n",
      "        -1.9593, -1.7878, -1.9968, -2.3066, -2.1698, -1.8741, -2.2481, -2.1980,\n",
      "        -2.0652, -2.1798, -1.8007, -2.0153, -1.8630, -1.9431, -2.0289, -1.8611,\n",
      "        -1.9873, -2.4400], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4788, -2.4636, -2.4087, -2.3037, -2.4846, -2.4861, -2.4620, -2.3831,\n",
      "        -2.3930, -2.4938, -2.4559, -2.4410, -2.4296, -2.4513, -2.4853, -2.4984,\n",
      "        -2.4735, -2.4924, -2.4732, -2.4972, -2.3215, -2.4908, -2.4990, -2.4331,\n",
      "        -2.4689, -2.4666, -2.4618, -2.4988, -2.4733, -2.3927, -2.4346, -2.3991,\n",
      "        -2.4937, -2.4756, -2.3945, -2.4745, -2.4571, -2.4400, -2.4515, -2.4656,\n",
      "        -2.4066, -2.4438, -2.4784, -2.4408, -2.4984, -2.3644, -2.4826, -2.4589,\n",
      "        -2.4714, -2.4979], device='mps:0')\n",
      "mean: tensor(-2.4518, device='mps:0')\n",
      "iter_dt 1.00s; iter 3: train loss 1.91081 temperature: 5.1499999999999995\n",
      "mean_logits tensor([-1.9441, -1.5352, -2.0213, -2.0331, -2.1415, -2.5077, -2.2020, -2.3696,\n",
      "        -2.1816, -1.8677, -2.0881, -2.0931, -2.0315, -2.3326, -2.0837, -1.7689,\n",
      "        -2.4311, -2.2252, -2.1203, -2.2280, -2.3106, -1.9547, -2.2742, -2.2003,\n",
      "        -1.9621, -2.1457, -2.2800, -2.2158, -2.0776, -2.2639, -2.0320, -1.8078,\n",
      "        -1.7750, -2.2070, -2.1326, -2.1498, -1.9341, -2.0878, -2.0420, -2.0214,\n",
      "        -2.0494, -2.0200, -2.3710, -2.3841, -2.1454, -2.1129, -2.0523, -2.0428,\n",
      "        -1.9095, -1.6016], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4827, -2.4572, -2.4323, -2.5038, -2.4508, -2.4896, -2.4568, -2.5032,\n",
      "        -2.4612, -2.4562, -2.4998, -2.4665, -2.3999, -2.4675, -2.4802, -2.4150,\n",
      "        -2.4368, -2.5075, -2.4859, -2.4029, -2.5465, -2.4702, -2.4693, -2.4619,\n",
      "        -2.4570, -2.4445, -2.4228, -2.4826, -2.4540, -2.4480, -2.5003, -2.4771,\n",
      "        -2.4779, -2.4824, -2.4518, -2.5014, -2.3855, -2.3300, -2.4070, -2.4082,\n",
      "        -2.4040, -2.5000, -2.5091, -2.4023, -2.4884, -2.4806, -2.4547, -2.4523,\n",
      "        -2.5011, -2.4417], device='mps:0')\n",
      "mean: tensor(-2.4594, device='mps:0')\n",
      "iter_dt 0.97s; iter 4: train loss 2.09749 temperature: 5.199999999999999\n",
      "mean_logits tensor([-1.5897, -2.4777, -1.8098, -2.1610, -2.3675, -2.1274, -1.7286, -1.8988,\n",
      "        -2.0262, -2.5753, -2.1578, -1.8117, -2.3618, -2.2939, -2.0691, -2.0637,\n",
      "        -2.3454, -2.0666, -2.1776, -2.1122, -2.0558, -2.1623, -1.8069, -1.8941,\n",
      "        -2.1673, -2.3795, -1.9174, -1.8901, -2.2753, -2.5618, -2.3192, -2.2137,\n",
      "        -2.2190, -1.5968, -1.9099, -2.1047, -1.9247, -1.7806, -2.1806, -1.9646,\n",
      "        -2.4254, -2.4241, -2.0721, -1.8558, -2.5716, -1.8649, -1.9090, -2.0797,\n",
      "        -2.3769, -1.8187], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4655, -2.4304, -2.4518, -2.4874, -2.4476, -2.4887, -2.4957, -2.4796,\n",
      "        -2.4132, -2.4995, -2.4591, -2.4509, -2.5007, -2.4735, -2.4957, -2.4250,\n",
      "        -2.4937, -2.4616, -2.4758, -2.4517, -2.5063, -2.3981, -2.5011, -2.4389,\n",
      "        -2.4995, -2.5084, -2.4312, -2.5009, -2.4582, -2.4959, -2.4727, -2.4990,\n",
      "        -2.4381, -2.5008, -2.3834, -2.4106, -2.4964, -2.4890, -2.4754, -2.3994,\n",
      "        -2.4434, -2.4078, -2.4486, -2.4604, -2.4954, -2.4509, -2.4571, -2.4436,\n",
      "        -2.4789, -2.4360], device='mps:0')\n",
      "mean: tensor(-2.4634, device='mps:0')\n",
      "iter_dt 0.97s; iter 5: train loss 2.39937 temperature: 5.249999999999999\n",
      "mean_logits tensor([-2.0379, -2.0403, -2.2233, -1.8459, -2.2097, -2.3541, -1.9820, -2.0587,\n",
      "        -2.2901, -1.8217, -2.2268, -1.9481, -1.8125, -2.3058, -1.9986, -2.4084,\n",
      "        -1.8844, -1.9901, -1.9681, -2.1733, -1.7293, -2.4711, -1.9489, -1.8896,\n",
      "        -2.2133, -2.2659, -1.8087, -1.8121, -1.7002, -1.9642, -1.9807, -1.8728,\n",
      "        -2.2560, -1.9889, -1.9714, -1.9179, -1.8358, -2.1706, -2.1608, -2.2200,\n",
      "        -2.5130, -2.0678, -2.3936, -2.1517, -1.6785, -1.8652, -2.2002, -1.9056,\n",
      "        -2.0159, -2.2781], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4523, -2.4908, -2.4920, -2.4313, -2.4864, -2.4361, -2.4366, -2.4364,\n",
      "        -2.5050, -2.5200, -2.4424, -2.4921, -2.5003, -2.4067, -2.4813, -2.4752,\n",
      "        -2.4013, -2.4926, -2.4978, -2.4988, -2.4865, -2.4728, -2.4537, -2.5039,\n",
      "        -2.5034, -2.4920, -2.4714, -2.4769, -2.4975, -2.4039, -2.4757, -2.4231,\n",
      "        -2.4982, -2.5025, -2.4921, -2.4757, -2.4654, -2.4958, -2.4917, -2.4749,\n",
      "        -2.4377, -2.4290, -2.4944, -2.4861, -2.3507, -2.4767, -2.4491, -2.4995,\n",
      "        -2.4975, -2.4742], device='mps:0')\n",
      "mean: tensor(-2.4705, device='mps:0')\n",
      "iter_dt 0.97s; iter 6: train loss 1.93422 temperature: 5.299999999999999\n",
      "mean_logits tensor([-2.0608, -2.1023, -2.2281, -2.3141, -2.2085, -2.2862, -2.6117, -2.0577,\n",
      "        -2.4990, -2.1748, -2.0376, -2.0034, -1.9063, -1.9292, -2.2305, -2.0647,\n",
      "        -2.1077, -1.8741, -2.0302, -2.0802, -2.3129, -2.0788, -1.9965, -1.9834,\n",
      "        -2.1112, -1.9967, -2.2393, -1.9642, -1.6456, -2.5963, -2.1573, -2.0063,\n",
      "        -1.9220, -1.7408, -1.9824, -2.2661, -2.0995, -2.1706, -2.5673, -2.0104,\n",
      "        -1.8919, -2.2011, -1.6637, -1.9837, -2.3105, -2.5720, -2.1814, -2.5280,\n",
      "        -2.5757, -1.8376], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5064, -2.5072, -2.4393, -2.4532, -2.4873, -2.4298, -2.4633, -2.3572,\n",
      "        -2.4771, -2.4097, -2.4199, -2.4999, -2.5039, -2.4921, -2.4946, -2.5612,\n",
      "        -2.4573, -2.4045, -2.4673, -2.4609, -2.4358, -2.3636, -2.3748, -2.4600,\n",
      "        -2.4661, -2.4184, -2.5006, -2.5008, -2.4973, -2.4443, -2.5025, -2.5058,\n",
      "        -2.4139, -2.4933, -2.4050, -2.4987, -2.3698, -2.4995, -2.4524, -2.4589,\n",
      "        -2.4301, -2.4593, -2.4662, -2.4886, -2.4221, -2.4253, -2.4689, -2.4461,\n",
      "        -2.3575, -2.4727], device='mps:0')\n",
      "mean: tensor(-2.4558, device='mps:0')\n",
      "iter_dt 0.98s; iter 7: train loss 1.83943 temperature: 5.349999999999999\n",
      "mean_logits tensor([-2.2890, -1.7055, -1.8763, -2.0305, -2.7076, -1.6391, -1.8215, -2.0863,\n",
      "        -2.0485, -1.7872, -2.3187, -1.8772, -2.0675, -2.2731, -1.9870, -2.0073,\n",
      "        -2.3554, -2.2026, -2.1402, -1.7918, -2.2225, -2.7542, -2.0474, -2.2641,\n",
      "        -2.3830, -2.3707, -1.9601, -2.3217, -2.2902, -2.3814, -2.1606, -2.4741,\n",
      "        -1.9390, -2.0807, -2.1002, -1.9930, -2.2968, -2.3021, -2.2544, -1.9102,\n",
      "        -2.4977, -2.2050, -2.0697, -1.9310, -2.1762, -2.0464, -2.3508, -2.3220,\n",
      "        -2.3197, -2.3287], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5059, -2.4701, -2.4952, -2.4931, -2.5001, -2.4998, -2.4732, -2.4924,\n",
      "        -2.4991, -2.4992, -2.5021, -2.4972, -2.4927, -2.4389, -2.4978, -2.4934,\n",
      "        -2.4371, -2.4947, -2.5033, -2.4661, -2.4989, -2.4627, -2.4464, -2.5024,\n",
      "        -2.4752, -2.4955, -2.4461, -2.5027, -2.4877, -2.4202, -2.4620, -2.5001,\n",
      "        -2.4400, -2.4165, -2.3716, -2.4444, -2.3978, -2.4492, -2.4684, -2.5001,\n",
      "        -2.4341, -2.4434, -2.4927, -2.4900, -2.4356, -2.4801, -2.4345, -2.4584,\n",
      "        -2.4357, -2.3813], device='mps:0')\n",
      "mean: tensor(-2.4685, device='mps:0')\n",
      "iter_dt 0.97s; iter 8: train loss 1.77630 temperature: 5.399999999999999\n",
      "mean_logits tensor([-2.0022, -2.2035, -1.7996, -2.2145, -1.7576, -2.2912, -2.4520, -2.4305,\n",
      "        -2.1316, -1.9079, -2.3355, -2.4988, -1.5885, -2.4756, -2.1651, -2.1023,\n",
      "        -2.0271, -2.2709, -1.9409, -1.8252, -2.2376, -2.3245, -2.2439, -2.0921,\n",
      "        -2.5978, -2.0395, -1.7313, -2.0824, -2.1348, -1.9841, -2.0944, -2.0198,\n",
      "        -2.4076, -2.2098, -1.9622, -1.6747, -2.6064, -2.5607, -2.6652, -1.9122,\n",
      "        -2.4559, -1.9425, -2.4322, -1.7562, -2.4212, -2.4055, -2.4646, -2.2641,\n",
      "        -2.1958, -2.1884], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4656, -2.4716, -2.4847, -2.4252, -2.5003, -2.5004, -2.4528, -2.4780,\n",
      "        -2.4961, -2.4943, -2.4905, -2.4558, -2.4984, -2.5027, -2.4187, -2.5044,\n",
      "        -2.4966, -2.4593, -2.4686, -2.4605, -2.4228, -2.4215, -2.4320, -2.4997,\n",
      "        -2.4145, -2.4652, -2.4856, -2.4351, -2.4454, -2.4531, -2.4848, -2.4727,\n",
      "        -2.4475, -2.4817, -2.4265, -2.4924, -2.4706, -2.4569, -2.5079, -2.4295,\n",
      "        -2.4640, -2.4731, -2.4770, -2.4930, -2.5014, -2.4772, -2.4655, -2.3745,\n",
      "        -2.5001, -2.3800], device='mps:0')\n",
      "mean: tensor(-2.4655, device='mps:0')\n",
      "iter_dt 0.99s; iter 9: train loss 1.30210 temperature: 5.449999999999998\n",
      "mean_logits tensor([-2.0321, -2.0209, -2.1313, -1.9861, -2.3117, -2.3866, -2.4072, -2.2624,\n",
      "        -2.6800, -2.2681, -2.0347, -2.2537, -2.2456, -2.4969, -2.0289, -2.0375,\n",
      "        -2.0439, -1.7474, -2.0665, -2.2002, -1.8875, -2.3473, -2.6857, -2.4584,\n",
      "        -2.1513, -2.0555, -2.5837, -2.3488, -2.4226, -1.7247, -2.3353, -2.3434,\n",
      "        -2.1905, -2.3469, -2.2821, -1.9639, -2.0773, -2.4685, -2.3312, -2.6992,\n",
      "        -2.3784, -2.2178, -2.5019, -2.2614, -2.4306, -2.3653, -2.2844, -2.1629,\n",
      "        -1.7895, -2.1033], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5144, -2.4616, -2.4758, -2.4456, -2.4366, -2.5125, -2.3459, -2.5005,\n",
      "        -2.4766, -2.5008, -2.5014, -2.4890, -2.4115, -2.4950, -2.4600, -2.4198,\n",
      "        -2.4777, -2.3702, -2.4637, -2.4852, -2.4997, -2.4924, -2.4701, -2.3368,\n",
      "        -2.4435, -2.4409, -2.3639, -2.4755, -2.4475, -2.4997, -2.4879, -2.5011,\n",
      "        -2.4378, -2.4995, -2.4231, -2.4605, -2.4917, -2.4590, -2.4747, -2.4089,\n",
      "        -2.4113, -2.4142, -2.4408, -2.4821, -2.5085, -2.5009, -2.4097, -2.4481,\n",
      "        -2.4939, -2.4374], device='mps:0')\n",
      "mean: tensor(-2.4581, device='mps:0')\n",
      "iter_dt 0.99s; iter 10: train loss 1.14473 temperature: 5.499999999999998\n",
      "mean_logits tensor([-2.0215, -2.1147, -2.2355, -2.1032, -2.3011, -2.0996, -2.5298, -2.7075,\n",
      "        -2.2560, -2.4191, -2.5114, -2.3819, -2.0772, -2.4604, -2.5187, -2.4835,\n",
      "        -2.0057, -2.2265, -2.4765, -2.4783, -2.3518, -2.2935, -2.2986, -2.4508,\n",
      "        -2.1455, -1.7923, -2.1464, -2.0614, -2.2616, -2.1356, -2.5788, -2.3085,\n",
      "        -2.2040, -2.4933, -2.2406, -2.1040, -2.1529, -1.8854, -2.4700, -2.5100,\n",
      "        -2.6072, -2.0768, -1.8409, -2.0585, -2.3935, -2.3695, -2.5511, -1.8802,\n",
      "        -1.8478, -2.3541], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4582, -2.4368, -2.4307, -2.4985, -2.4656, -2.5022, -2.4995, -2.4337,\n",
      "        -2.4323, -2.4833, -2.4773, -2.4416, -2.4988, -2.4978, -2.4401, -2.4462,\n",
      "        -2.4938, -2.4484, -2.4625, -2.4991, -2.4954, -2.4852, -2.4619, -2.4555,\n",
      "        -2.4431, -2.4978, -2.3980, -2.4505, -2.4601, -2.4901, -2.5214, -2.4530,\n",
      "        -2.5199, -2.4967, -2.4972, -2.5075, -2.4642, -2.4387, -2.3957, -2.5005,\n",
      "        -2.4621, -2.4925, -2.4255, -2.4909, -2.4994, -2.4841, -2.5011, -2.4664,\n",
      "        -2.4671, -2.4844], device='mps:0')\n",
      "mean: tensor(-2.4710, device='mps:0')\n",
      "iter_dt 0.98s; iter 11: train loss 1.13949 temperature: 5.549999999999998\n",
      "mean_logits tensor([-2.0001, -2.0516, -2.2039, -2.4085, -2.3729, -2.7774, -2.0940, -2.2904,\n",
      "        -2.3774, -2.4947, -2.1543, -1.9033, -2.0570, -2.2083, -2.0122, -2.2144,\n",
      "        -2.4146, -2.3287, -2.0424, -2.0434, -2.5181, -2.5278, -1.9180, -2.3725,\n",
      "        -2.2699, -2.2675, -2.1058, -2.4025, -2.0703, -2.3003, -1.8654, -2.4881,\n",
      "        -1.9240, -2.1534, -2.6509, -2.1930, -2.5886, -2.1533, -2.6536, -2.4325,\n",
      "        -2.2716, -2.5055, -2.5868, -2.2517, -2.1833, -2.6369, -2.0839, -2.4003,\n",
      "        -2.4957, -1.8927], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5016, -2.4953, -2.5000, -2.4474, -2.3948, -2.5019, -2.4440, -2.4629,\n",
      "        -2.4920, -2.4605, -2.4441, -2.4309, -2.4796, -2.4551, -2.4343, -2.4826,\n",
      "        -2.4510, -2.4578, -2.4838, -2.4959, -2.5026, -2.4016, -2.4312, -2.4570,\n",
      "        -2.4493, -2.4767, -2.4774, -2.4526, -2.4820, -2.4433, -2.4968, -2.4924,\n",
      "        -2.4552, -2.3741, -2.3589, -2.5006, -2.5020, -2.4575, -2.4746, -2.4457,\n",
      "        -2.3589, -2.4664, -2.4704, -2.3523, -2.4650, -2.4960, -2.4468, -2.4968,\n",
      "        -2.3467, -2.4400], device='mps:0')\n",
      "mean: tensor(-2.4557, device='mps:0')\n",
      "iter_dt 0.98s; iter 12: train loss 1.45186 temperature: 5.599999999999998\n",
      "mean_logits tensor([-1.9898, -2.5837, -2.3077, -2.3793, -1.7603, -2.4589, -2.8285, -2.7471,\n",
      "        -2.1409, -2.2972, -2.4852, -2.3860, -2.6114, -2.3567, -2.3146, -2.5998,\n",
      "        -2.5564, -2.2821, -2.4433, -2.5018, -2.2634, -2.0155, -2.5217, -2.1434,\n",
      "        -2.3485, -2.3578, -2.3714, -2.7634, -2.2346, -1.9462, -2.3206, -1.9936,\n",
      "        -2.4376, -3.0074, -2.1624, -2.5408, -2.1548, -2.8117, -2.6325, -2.5935,\n",
      "        -2.3370, -2.3679, -2.4325, -1.9550, -2.2497, -2.5331, -3.0507, -2.4696,\n",
      "        -2.7216, -2.2366], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4965, -2.4988, -2.4672, -2.4669, -2.5017, -2.4438, -2.4413, -2.4197,\n",
      "        -2.4476, -2.5224, -2.5035, -2.4984, -2.4993, -2.4863, -2.5015, -2.5008,\n",
      "        -2.4710, -2.4785, -2.4444, -2.4534, -2.4913, -2.4994, -2.5011, -2.4946,\n",
      "        -2.4797, -2.4823, -2.4335, -2.4055, -2.4227, -2.4011, -2.4556, -2.4991,\n",
      "        -2.3787, -2.5009, -2.4742, -2.4852, -2.4941, -2.4719, -2.4523, -2.4969,\n",
      "        -2.5029, -2.4714, -2.4999, -2.4425, -2.4477, -2.4140, -2.4014, -2.4667,\n",
      "        -2.4465, -2.4895], device='mps:0')\n",
      "mean: tensor(-2.4689, device='mps:0')\n",
      "iter_dt 0.99s; iter 13: train loss 1.27900 temperature: 5.649999999999998\n",
      "mean_logits tensor([-2.5108, -2.4701, -2.1535, -2.4705, -2.6250, -2.2393, -2.6878, -2.0166,\n",
      "        -2.3796, -2.2121, -2.3751, -2.0489, -2.3062, -2.1353, -2.3485, -2.4160,\n",
      "        -2.4282, -2.8208, -2.3944, -2.0887, -2.5621, -2.1590, -1.8963, -2.0087,\n",
      "        -2.2671, -2.5786, -2.2513, -2.7298, -2.7886, -2.0566, -2.6533, -2.1747,\n",
      "        -2.2705, -1.8247, -2.4031, -2.1884, -2.6423, -2.6032, -2.0098, -2.7677,\n",
      "        -2.0787, -2.7350, -2.2324, -2.4492, -2.3700, -1.9900, -2.7865, -2.1736,\n",
      "        -2.4889, -2.1118], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4793, -2.4446, -2.4989, -2.4820, -2.4965, -2.4875, -2.4161, -2.4338,\n",
      "        -2.4892, -2.5185, -2.4734, -2.4678, -2.4702, -2.5024, -2.4177, -2.4970,\n",
      "        -2.4511, -2.4063, -2.2577, -2.4696, -2.5129, -2.4932, -2.4600, -2.4941,\n",
      "        -2.4304, -2.4896, -2.4774, -2.4737, -2.4210, -2.4982, -2.3981, -2.4095,\n",
      "        -2.4884, -2.4865, -2.4353, -2.4415, -2.4790, -2.5045, -2.4147, -2.4330,\n",
      "        -2.3933, -2.4783, -2.4690, -2.4889, -2.4616, -2.4784, -2.4460, -2.4935,\n",
      "        -2.4757, -2.5014], device='mps:0')\n",
      "mean: tensor(-2.4617, device='mps:0')\n",
      "iter_dt 0.99s; iter 14: train loss 1.09491 temperature: 5.6999999999999975\n",
      "mean_logits tensor([-2.0419, -2.4694, -2.3492, -2.4125, -2.0883, -2.1014, -2.0883, -2.1207,\n",
      "        -2.6894, -2.1329, -2.8398, -2.3713, -2.4881, -2.4787, -1.9690, -2.1948,\n",
      "        -2.3366, -2.4334, -2.4196, -2.2934, -2.4048, -2.6463, -2.7017, -2.4955,\n",
      "        -2.2542, -2.5276, -2.6263, -2.2826, -2.1319, -2.3625, -2.5060, -2.4187,\n",
      "        -2.1749, -2.2120, -2.2244, -2.4640, -2.2465, -2.0756, -2.5969, -2.6747,\n",
      "        -2.3325, -1.9288, -1.8596, -2.5287, -2.4571, -1.9176, -2.1244, -2.1244,\n",
      "        -2.2055, -2.3205], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4998, -2.4438, -2.4652, -2.5033, -2.4995, -2.4427, -2.4988, -2.4962,\n",
      "        -2.4102, -2.4578, -2.4749, -2.4995, -2.4369, -2.4822, -2.4661, -2.4808,\n",
      "        -2.4570, -2.4617, -2.4792, -2.4906, -2.4255, -2.4686, -2.4746, -2.4898,\n",
      "        -2.4615, -2.4997, -2.4801, -2.4222, -2.4985, -2.5017, -2.4085, -2.5048,\n",
      "        -2.4252, -2.4386, -2.4999, -2.4464, -2.4604, -2.4629, -2.4679, -2.3414,\n",
      "        -2.4899, -2.4960, -2.4996, -2.4297, -2.4287, -2.4866, -2.5001, -2.4486,\n",
      "        -2.4973, -2.4589], device='mps:0')\n",
      "mean: tensor(-2.4672, device='mps:0')\n",
      "iter_dt 0.98s; iter 15: train loss 1.40341 temperature: 5.749999999999997\n",
      "mean_logits tensor([-2.1503, -2.1223, -2.7332, -2.5690, -2.5155, -2.7165, -2.7001, -2.0919,\n",
      "        -2.3853, -2.1283, -2.6021, -2.4616, -2.3091, -2.3120, -2.3417, -2.2084,\n",
      "        -2.6028, -2.5808, -2.5309, -2.4454, -2.2620, -2.4757, -2.4755, -2.2595,\n",
      "        -2.8836, -2.3000, -2.3873, -1.9215, -2.5228, -2.3115, -2.1983, -1.9354,\n",
      "        -2.6555, -2.1687, -2.3723, -2.3338, -2.2046, -2.8683, -2.4279, -2.0921,\n",
      "        -2.5156, -2.4605, -2.8604, -2.3057, -2.1638, -2.0614, -2.2485, -2.7174,\n",
      "        -2.3039, -3.1220], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4877, -2.4443, -2.4237, -2.4574, -2.4978, -2.4638, -2.4096, -2.4912,\n",
      "        -2.4924, -2.4995, -2.4971, -2.3392, -2.4951, -2.4788, -2.4602, -2.4249,\n",
      "        -2.4574, -2.4994, -2.4936, -2.5006, -2.4684, -2.4353, -2.4990, -2.4610,\n",
      "        -2.3369, -2.4312, -2.4977, -2.4162, -2.4975, -2.4021, -2.4991, -2.4670,\n",
      "        -2.4411, -2.4568, -2.4893, -2.4789, -2.4614, -2.4449, -2.4554, -2.4936,\n",
      "        -2.4134, -2.4206, -2.4937, -2.4998, -2.4461, -2.4102, -2.5006, -2.4662,\n",
      "        -2.4378, -2.4663], device='mps:0')\n",
      "mean: tensor(-2.4600, device='mps:0')\n",
      "iter_dt 0.97s; iter 16: train loss 1.42746 temperature: 5.799999999999997\n",
      "mean_logits tensor([-2.1258, -2.6722, -1.6089, -2.1363, -2.3566, -2.1576, -2.0645, -2.3818,\n",
      "        -2.0083, -2.5104, -2.4894, -2.1326, -2.1470, -2.4969, -2.4286, -2.1712,\n",
      "        -3.0781, -2.5898, -2.3716, -2.8394, -2.6887, -2.7057, -1.9679, -1.9660,\n",
      "        -1.9824, -2.0343, -2.6179, -2.5468, -2.2916, -2.1062, -2.2180, -2.2947,\n",
      "        -2.5631, -2.4385, -2.3252, -2.6375, -2.5571, -2.5269, -1.9992, -2.3262,\n",
      "        -2.2734, -2.4614, -2.0918, -2.1967, -2.6690, -2.3822, -2.4845, -2.4939,\n",
      "        -2.2834, -2.5917], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4651, -2.4722, -2.5007, -2.4915, -2.4328, -2.5070, -2.4965, -2.4032,\n",
      "        -2.4867, -2.4583, -2.4792, -2.4994, -2.4901, -2.4473, -2.4526, -2.4249,\n",
      "        -2.4237, -2.4967, -2.4700, -2.4766, -2.5015, -2.4280, -2.4110, -2.4461,\n",
      "        -2.4980, -2.4504, -2.4417, -2.3377, -2.4924, -2.5074, -2.4931, -2.4968,\n",
      "        -2.4928, -2.4803, -2.4656, -2.3508, -2.3890, -2.4991, -2.4288, -2.5038,\n",
      "        -2.4465, -2.4759, -2.4775, -2.4595, -2.4917, -2.5065, -2.4590, -2.4587,\n",
      "        -2.4997, -2.4883], device='mps:0')\n",
      "mean: tensor(-2.4650, device='mps:0')\n",
      "iter_dt 0.97s; iter 17: train loss 1.11062 temperature: 5.849999999999997\n",
      "mean_logits tensor([-2.4514, -2.3243, -2.8155, -2.4192, -2.6053, -2.6577, -2.4804, -2.5571,\n",
      "        -2.7062, -2.5455, -2.7035, -2.3934, -1.9855, -1.7167, -2.5221, -2.9418,\n",
      "        -2.0825, -2.5687, -2.6008, -2.2731, -2.5651, -2.4667, -2.3044, -2.3320,\n",
      "        -2.6342, -2.2042, -2.3010, -2.5634, -2.3279, -2.2458, -2.5017, -2.5110,\n",
      "        -2.4810, -2.5250, -2.4855, -2.1533, -2.2354, -2.8592, -2.1898, -2.5457,\n",
      "        -2.3427, -2.6528, -1.8924, -2.0918, -1.7104, -2.8063, -2.4645, -2.6048,\n",
      "        -2.6408, -2.6413], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4932, -2.4695, -2.4797, -2.5069, -2.4931, -2.4450, -2.3723, -2.4998,\n",
      "        -2.4831, -2.4932, -2.5017, -2.4313, -2.3705, -2.4938, -2.4893, -2.4266,\n",
      "        -2.4924, -2.4882, -2.4948, -2.4328, -2.5007, -2.4888, -2.4995, -2.5036,\n",
      "        -2.3971, -2.4320, -2.4973, -2.3839, -2.4381, -2.4404, -2.4489, -2.5011,\n",
      "        -2.4552, -2.4671, -2.4791, -2.4960, -2.4986, -2.4794, -2.4465, -2.4980,\n",
      "        -2.4934, -2.4336, -2.4922, -2.3939, -2.4833, -2.4975, -2.4336, -2.4990,\n",
      "        -2.4931, -2.4140], device='mps:0')\n",
      "mean: tensor(-2.4668, device='mps:0')\n",
      "iter_dt 0.98s; iter 18: train loss 1.42702 temperature: 5.899999999999997\n",
      "mean_logits tensor([-1.9849, -2.6338, -1.9885, -2.3691, -2.5291, -2.6237, -2.2381, -2.7943,\n",
      "        -2.4649, -2.7607, -2.3073, -2.3508, -2.4778, -2.6534, -2.1461, -2.5439,\n",
      "        -2.0684, -2.0415, -2.3860, -2.4278, -3.0191, -2.2904, -2.0074, -2.6856,\n",
      "        -2.2769, -2.4856, -2.6356, -2.1638, -2.2161, -2.4424, -2.2963, -2.8670,\n",
      "        -2.1198, -2.5842, -2.3738, -2.7270, -2.2445, -2.6964, -2.4163, -2.5286,\n",
      "        -2.2206, -2.3117, -2.0228, -2.1099, -2.3681, -2.7273, -2.6782, -2.1016,\n",
      "        -2.8845, -1.9191], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4819, -2.4454, -2.4118, -2.4632, -2.4340, -2.3574, -2.4240, -2.4206,\n",
      "        -2.4922, -2.4998, -2.4615, -2.4354, -2.4606, -2.4234, -2.4555, -2.4744,\n",
      "        -2.4685, -2.4419, -2.4811, -2.4018, -2.4052, -2.4842, -2.4609, -2.4733,\n",
      "        -2.4985, -2.4481, -2.4509, -2.4439, -2.4991, -2.3994, -2.4036, -2.4626,\n",
      "        -2.4183, -2.4568, -2.4719, -2.3468, -2.4471, -2.4711, -2.4452, -2.4999,\n",
      "        -2.4850, -2.4399, -2.4362, -2.5053, -2.4977, -2.4925, -2.4135, -2.4658,\n",
      "        -2.4706, -2.5029], device='mps:0')\n",
      "mean: tensor(-2.4526, device='mps:0')\n",
      "iter_dt 0.98s; iter 19: train loss 0.67295 temperature: 5.949999999999997\n",
      "mean_logits tensor([-2.2208, -2.1585, -2.3899, -2.6438, -2.3674, -2.4594, -2.1374, -2.5540,\n",
      "        -2.3443, -2.3003, -2.3109, -2.4005, -2.3168, -2.3371, -2.2748, -2.3684,\n",
      "        -2.4970, -2.6449, -2.3805, -2.5700, -2.2917, -2.3572, -2.4560, -2.4427,\n",
      "        -2.4017, -2.3503, -2.4119, -2.7714, -2.7618, -2.4974, -2.4742, -2.1001,\n",
      "        -2.6322, -2.4022, -2.8268, -2.4808, -2.3666, -2.2445, -2.0735, -1.7622,\n",
      "        -2.6208, -2.5812, -2.0521, -2.5517, -2.2531, -2.6986, -2.1901, -2.1234,\n",
      "        -2.4775, -2.5729], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4426, -2.4693, -2.4613, -2.4705, -2.4651, -2.4522, -2.4389, -2.4545,\n",
      "        -2.4997, -2.3893, -2.4979, -2.4603, -2.4930, -2.5170, -2.4634, -2.4950,\n",
      "        -2.4858, -2.4441, -2.4371, -2.5058, -2.4633, -2.4862, -2.4289, -2.5025,\n",
      "        -2.4692, -2.4312, -2.4527, -2.5108, -2.5271, -2.4972, -2.3721, -2.4220,\n",
      "        -2.4729, -2.4881, -2.4727, -2.4950, -2.5021, -2.4451, -2.4837, -2.4428,\n",
      "        -2.5061, -2.4239, -2.4978, -2.4760, -2.4259, -2.4921, -2.3732, -2.4909,\n",
      "        -2.4343, -2.4398], device='mps:0')\n",
      "mean: tensor(-2.4654, device='mps:0')\n",
      "iter_dt 0.99s; iter 20: train loss 0.66316 temperature: 5.9999999999999964\n",
      "mean_logits tensor([-2.3126, -2.7067, -2.1632, -2.3704, -2.4784, -2.2123, -2.6075, -2.5412,\n",
      "        -2.4492, -2.4538, -2.3393, -2.4742, -2.3102, -2.4705, -2.4578, -2.5526,\n",
      "        -2.4171, -2.5901, -1.9998, -2.5636, -2.6932, -2.4310, -2.1801, -2.1441,\n",
      "        -2.4749, -2.6205, -2.0845, -1.9578, -2.1952, -2.2703, -2.5252, -2.4330,\n",
      "        -2.5537, -2.3314, -2.1768, -2.2499, -2.1931, -2.3161, -2.4061, -2.4429,\n",
      "        -2.2530, -2.2690, -2.5609, -2.6568, -2.3079, -2.7941, -2.1939, -2.7450,\n",
      "        -2.2414, -2.3126], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4706, -2.4876, -2.4623, -2.4460, -2.5026, -2.4933, -2.4800, -2.4469,\n",
      "        -2.4956, -2.4608, -2.4967, -2.4489, -2.4361, -2.4360, -2.4421, -2.4613,\n",
      "        -2.4355, -2.4813, -2.4436, -2.4342, -2.4942, -2.4822, -2.4584, -2.3832,\n",
      "        -2.3184, -2.4220, -2.4616, -2.5048, -2.4993, -2.4784, -2.4955, -2.4264,\n",
      "        -2.5017, -2.4773, -2.4414, -2.4803, -2.4980, -2.4623, -2.3996, -2.4833,\n",
      "        -2.4449, -2.4435, -2.4991, -2.4839, -2.4908, -2.4565, -2.4785, -2.4783,\n",
      "        -2.4683, -2.3974], device='mps:0')\n",
      "mean: tensor(-2.4614, device='mps:0')\n",
      "iter_dt 0.99s; iter 21: train loss 1.10236 temperature: 6.049999999999996\n",
      "mean_logits tensor([-2.0912, -2.5020, -2.5352, -2.5502, -2.6000, -2.3029, -2.4161, -2.4581,\n",
      "        -2.4930, -2.2813, -2.4604, -2.9717, -2.4642, -2.1945, -2.5801, -2.3679,\n",
      "        -2.3904, -2.6405, -2.5827, -2.3787, -2.6530, -2.8389, -2.8961, -2.2509,\n",
      "        -2.2478, -2.1647, -2.3488, -2.3423, -2.0958, -2.2049, -2.4621, -2.5897,\n",
      "        -2.7571, -2.7368, -2.4608, -2.5061, -2.7940, -2.6426, -2.7311, -2.5651,\n",
      "        -2.3084, -2.3545, -2.6564, -2.3760, -2.4728, -2.4151, -2.0285, -2.9599,\n",
      "        -2.6504, -2.4541], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4547, -2.4555, -2.4995, -2.4343, -2.4334, -2.4549, -2.4132, -2.4965,\n",
      "        -2.4855, -2.4696, -2.4415, -2.4613, -2.4565, -2.5010, -2.4451, -2.4488,\n",
      "        -2.4372, -2.4916, -2.4450, -2.5005, -2.5019, -2.4924, -2.2700, -2.4990,\n",
      "        -2.4999, -2.4592, -2.5018, -2.4032, -2.4975, -2.4609, -2.4428, -2.4987,\n",
      "        -2.4619, -2.4615, -2.4399, -2.3743, -2.4937, -2.4996, -2.4852, -2.4790,\n",
      "        -2.5006, -2.5080, -2.4913, -2.4593, -2.4988, -2.4841, -2.3263, -2.4762,\n",
      "        -2.5031, -2.4838], device='mps:0')\n",
      "mean: tensor(-2.4636, device='mps:0')\n",
      "iter_dt 0.99s; iter 22: train loss 0.72726 temperature: 6.099999999999996\n",
      "mean_logits tensor([-2.4091, -2.6406, -2.6835, -2.4073, -2.3414, -2.0993, -2.6733, -2.6396,\n",
      "        -2.4011, -2.5737, -2.3947, -2.4235, -2.5350, -2.4700, -2.2274, -2.4530,\n",
      "        -2.6007, -2.3016, -2.1747, -2.2563, -2.2347, -2.3512, -2.7453, -2.4133,\n",
      "        -2.4571, -2.5881, -2.4703, -1.8610, -2.6684, -2.2316, -2.4920, -2.6166,\n",
      "        -2.3479, -2.1888, -2.6017, -2.2394, -2.1768, -2.2075, -2.3545, -2.5781,\n",
      "        -2.2586, -2.1948, -2.4326, -2.1939, -2.7128, -2.7060, -2.7028, -2.3631,\n",
      "        -2.0361, -2.6456], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4011, -2.5009, -2.4089, -2.4284, -2.4752, -2.4363, -2.4879, -2.4977,\n",
      "        -2.4305, -2.4015, -2.4993, -2.4977, -2.5002, -2.4869, -2.4367, -2.4924,\n",
      "        -2.5025, -2.4975, -2.4911, -2.4609, -2.4306, -2.4897, -2.4526, -2.4588,\n",
      "        -2.4090, -2.4584, -2.4498, -2.4587, -2.4114, -2.5094, -2.5111, -2.4859,\n",
      "        -2.4499, -2.4270, -2.4315, -2.4976, -2.4849, -2.5011, -2.4044, -2.4602,\n",
      "        -2.4992, -2.4976, -2.4401, -2.4973, -2.4355, -2.4621, -2.4058, -2.4371,\n",
      "        -2.3601, -2.4617], device='mps:0')\n",
      "mean: tensor(-2.4602, device='mps:0')\n",
      "iter_dt 0.99s; iter 23: train loss 1.30077 temperature: 6.149999999999996\n",
      "mean_logits tensor([-2.4556, -2.4428, -2.8629, -2.3298, -2.2792, -2.6331, -2.5578, -2.1136,\n",
      "        -2.4872, -2.1950, -2.7323, -2.8213, -2.3584, -2.6470, -2.2814, -2.1783,\n",
      "        -2.2605, -2.2986, -2.8644, -2.4129, -2.4207, -1.9527, -2.3703, -2.1809,\n",
      "        -2.1864, -1.7445, -2.1048, -2.4682, -2.1728, -2.3324, -2.2613, -2.0248,\n",
      "        -2.5443, -2.3017, -2.3778, -1.8653, -2.6183, -2.3904, -3.0120, -1.9241,\n",
      "        -2.3647, -2.4189, -2.4328, -2.5804, -2.3345, -2.1076, -2.3751, -2.8650,\n",
      "        -2.2220, -2.5720], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4503, -2.4307, -2.4730, -2.4796, -2.4564, -2.4998, -2.3833, -2.4937,\n",
      "        -2.4818, -2.4572, -2.4041, -2.5252, -2.4719, -2.4175, -2.4384, -2.4985,\n",
      "        -2.4834, -2.4915, -2.4851, -2.4542, -2.4521, -2.4625, -2.4621, -2.4696,\n",
      "        -2.5058, -2.4694, -2.4594, -2.4534, -2.4289, -2.2576, -2.4966, -2.4991,\n",
      "        -2.4738, -2.4707, -2.3077, -2.4911, -2.4579, -2.4955, -2.5068, -2.4312,\n",
      "        -2.4645, -2.5083, -2.4645, -2.4993, -2.4961, -2.4984, -2.4676, -2.4981,\n",
      "        -2.4006, -2.5007], device='mps:0')\n",
      "mean: tensor(-2.4625, device='mps:0')\n",
      "iter_dt 1.00s; iter 24: train loss 0.75176 temperature: 6.199999999999996\n",
      "mean_logits tensor([-2.1876, -2.4337, -2.3042, -2.5193, -2.3952, -2.2662, -2.4146, -2.5628,\n",
      "        -2.5506, -2.3819, -2.6984, -2.2338, -2.3534, -2.2325, -2.6420, -2.3651,\n",
      "        -2.0514, -2.7531, -2.5954, -2.7194, -2.6643, -2.2471, -2.5079, -2.3412,\n",
      "        -2.1730, -2.2538, -2.5119, -2.2773, -2.2797, -2.2157, -1.9674, -2.3755,\n",
      "        -2.6754, -2.6005, -2.8393, -2.3015, -2.1467, -2.4024, -2.6127, -2.5888,\n",
      "        -2.6113, -2.1711, -2.4443, -2.5866, -2.2449, -2.0679, -2.1668, -2.5743,\n",
      "        -2.3975, -2.2663], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4764, -2.4633, -2.4391, -2.4556, -2.3696, -2.4201, -2.4624, -2.4985,\n",
      "        -2.4549, -2.5001, -2.5007, -2.4404, -2.4788, -2.4995, -2.4991, -2.4338,\n",
      "        -2.4154, -2.5094, -2.4531, -2.5019, -2.4517, -2.4582, -2.4484, -2.4945,\n",
      "        -2.4976, -2.5008, -2.4993, -2.5067, -2.4534, -2.4733, -2.4948, -2.4673,\n",
      "        -2.4461, -2.4933, -2.4962, -2.4970, -2.4344, -2.4116, -2.4578, -2.3868,\n",
      "        -2.3375, -2.4878, -2.4434, -2.4616, -2.3925, -2.4890, -2.4934, -2.4660,\n",
      "        -2.4665, -2.4936], device='mps:0')\n",
      "mean: tensor(-2.4635, device='mps:0')\n",
      "iter_dt 0.99s; iter 25: train loss 0.79293 temperature: 6.249999999999996\n",
      "mean_logits tensor([-2.4768, -2.4459, -2.3893, -2.6905, -2.6571, -2.3503, -2.3704, -2.3054,\n",
      "        -2.4526, -2.5463, -2.1276, -2.1077, -2.2606, -2.3670, -2.1064, -2.0417,\n",
      "        -2.2500, -2.3944, -2.5396, -2.1120, -2.0958, -2.0153, -2.7647, -2.4118,\n",
      "        -2.2937, -2.4434, -2.4005, -2.5373, -2.7739, -2.6387, -2.4349, -1.4542,\n",
      "        -2.7759, -2.3836, -2.3767, -2.5304, -2.2469, -2.5128, -2.3769, -2.5885,\n",
      "        -2.7203, -2.5811, -2.3661, -2.4254, -2.3134, -2.3344, -2.4011, -2.3804,\n",
      "        -2.6208, -2.4516], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4940, -2.5007, -2.4643, -2.4629, -2.4305, -2.4334, -2.4871, -2.4649,\n",
      "        -2.4992, -2.4335, -2.4540, -2.5012, -2.3913, -2.4540, -2.4974, -2.5007,\n",
      "        -2.4963, -2.5021, -2.4615, -2.4996, -2.5016, -2.4995, -2.4937, -2.4484,\n",
      "        -2.5088, -2.5085, -2.4082, -2.4444, -2.4355, -2.4171, -2.4617, -2.2971,\n",
      "        -2.4622, -2.4896, -2.4570, -2.4572, -2.5071, -2.4892, -2.4582, -2.4872,\n",
      "        -2.4561, -2.4375, -2.4657, -2.4818, -2.4328, -2.4111, -2.4997, -2.3871,\n",
      "        -2.4988, -2.5012], device='mps:0')\n",
      "mean: tensor(-2.4647, device='mps:0')\n",
      "iter_dt 0.99s; iter 26: train loss 0.69525 temperature: 6.299999999999995\n",
      "mean_logits tensor([-2.2840, -2.3304, -2.3348, -2.2025, -2.5683, -2.0261, -2.4910, -2.1698,\n",
      "        -2.5643, -2.1592, -2.7483, -2.0156, -2.1560, -2.5004, -2.6158, -2.6728,\n",
      "        -2.0868, -2.5069, -2.4092, -2.5396, -2.5830, -1.9812, -2.5083, -2.4201,\n",
      "        -2.3578, -2.3578, -2.2320, -2.2871, -2.2436, -2.7176, -2.1257, -1.9261,\n",
      "        -2.4834, -2.7069, -2.3177, -2.6521, -2.5086, -2.4196, -2.5465, -2.5272,\n",
      "        -2.6618, -2.4712, -2.5007, -2.1991, -2.2840, -2.6532, -2.3307, -2.3936,\n",
      "        -2.5049, -2.4456], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4553, -2.5022, -2.4703, -2.4787, -2.4095, -2.5070, -2.4615, -2.4216,\n",
      "        -2.4852, -2.4322, -2.4407, -2.5002, -2.4255, -2.4633, -2.4243, -2.4834,\n",
      "        -2.4704, -2.3933, -2.4601, -2.4347, -2.5002, -2.4299, -2.4903, -2.4753,\n",
      "        -2.4912, -2.4689, -2.4065, -2.4181, -2.5005, -2.4999, -2.4222, -2.4665,\n",
      "        -2.4367, -2.4537, -2.4477, -2.4989, -2.4326, -2.4833, -2.4435, -2.4996,\n",
      "        -2.4128, -2.4992, -2.4181, -2.4124, -2.4379, -2.5010, -2.4569, -2.5015,\n",
      "        -2.4909, -2.4745], device='mps:0')\n",
      "mean: tensor(-2.4598, device='mps:0')\n",
      "iter_dt 1.00s; iter 27: train loss 0.95305 temperature: 6.349999999999995\n",
      "mean_logits tensor([-2.5622, -2.6429, -2.4652, -2.6311, -2.3528, -2.7526, -2.8360, -2.1413,\n",
      "        -2.0286, -1.7562, -1.9898, -1.9945, -2.3891, -2.2114, -2.3795, -2.4428,\n",
      "        -2.5787, -2.1252, -2.4045, -2.2217, -2.7776, -2.2659, -1.9761, -2.6200,\n",
      "        -2.4057, -2.2897, -2.5772, -2.6750, -2.4296, -2.4099, -2.4408, -2.6575,\n",
      "        -2.2802, -2.3706, -2.5518, -2.3436, -2.1243, -2.5744, -2.3116, -2.3294,\n",
      "        -2.0331, -2.2872, -2.2672, -2.5650, -2.5848, -2.6023, -2.2444, -2.0297,\n",
      "        -2.6891, -2.1369], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4928, -2.4718, -2.4369, -2.4214, -2.4987, -2.5006, -2.4993, -2.4397,\n",
      "        -2.4488, -2.4625, -2.4271, -2.4593, -2.4396, -2.4772, -2.4684, -2.4336,\n",
      "        -2.4932, -2.5007, -2.4925, -2.5009, -2.4635, -2.4709, -2.3791, -2.4962,\n",
      "        -2.4762, -2.4685, -2.4183, -2.4067, -2.4992, -2.4928, -2.4634, -2.5248,\n",
      "        -2.4623, -2.4553, -2.4385, -2.5038, -2.4529, -2.4410, -2.4787, -2.4995,\n",
      "        -2.4973, -2.4433, -2.4066, -2.4393, -2.4590, -2.4281, -2.4930, -2.4684,\n",
      "        -2.4995, -2.4763], device='mps:0')\n",
      "mean: tensor(-2.4653, device='mps:0')\n",
      "iter_dt 0.99s; iter 28: train loss 0.95250 temperature: 6.399999999999995\n",
      "mean_logits tensor([-2.3347, -2.5062, -2.5653, -2.2477, -2.3264, -2.8266, -2.2738, -1.9600,\n",
      "        -2.3043, -2.5185, -2.5136, -2.4259, -2.2637, -2.5224, -2.6407, -2.5609,\n",
      "        -2.7159, -2.2985, -1.9356, -1.9891, -2.6168, -2.5159, -1.7672, -2.5371,\n",
      "        -2.4291, -2.7363, -2.5648, -2.3715, -2.5012, -2.7997, -2.4088, -2.3981,\n",
      "        -2.1574, -2.1577, -2.1540, -2.8654, -1.8708, -2.4640, -2.1843, -2.5108,\n",
      "        -2.6626, -2.3498, -2.3338, -2.3590, -2.6316, -2.5112, -2.1702, -2.3331,\n",
      "        -2.5689, -2.5396], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4816, -2.3882, -2.4619, -2.4624, -2.4689, -2.5066, -2.4623, -2.4590,\n",
      "        -2.4566, -2.5023, -2.4597, -2.5018, -2.4571, -2.3670, -2.4694, -2.4051,\n",
      "        -2.4919, -2.4128, -2.4558, -2.4147, -2.4414, -2.4587, -2.4565, -2.4496,\n",
      "        -2.4602, -2.4544, -2.4504, -2.4343, -2.3641, -2.4376, -2.4958, -2.4766,\n",
      "        -2.4095, -2.4952, -2.5000, -2.4513, -2.4961, -2.4988, -2.4683, -2.4879,\n",
      "        -2.5009, -2.4901, -2.5016, -2.5011, -2.5021, -2.5000, -2.4785, -2.4495,\n",
      "        -2.4558, -2.4667], device='mps:0')\n",
      "mean: tensor(-2.4624, device='mps:0')\n",
      "iter_dt 1.01s; iter 29: train loss 0.80290 temperature: 6.449999999999995\n",
      "mean_logits tensor([-2.4835, -2.0656, -2.7359, -2.3227, -2.3969, -2.1305, -2.3602, -2.5862,\n",
      "        -2.2014, -2.7683, -1.9146, -2.6900, -2.7015, -2.0508, -2.4539, -2.5944,\n",
      "        -2.3368, -2.5672, -2.4102, -2.4811, -2.3887, -2.4764, -2.0502, -2.4864,\n",
      "        -2.2947, -2.5816, -2.1996, -2.3392, -2.2808, -2.6379, -2.4909, -2.5584,\n",
      "        -2.3040, -2.6430, -2.5034, -2.2229, -2.4395, -2.0431, -2.1702, -2.2457,\n",
      "        -2.6589, -2.2573, -2.2271, -2.4009, -1.9841, -2.3347, -2.5547, -2.2744,\n",
      "        -2.0733, -2.3655], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5004, -2.4661, -2.4584, -2.4243, -2.4972, -2.4517, -2.4804, -2.4745,\n",
      "        -2.4770, -2.4065, -2.4989, -2.5076, -2.4371, -2.4472, -2.4684, -2.4467,\n",
      "        -2.4081, -2.4580, -2.4448, -2.4813, -2.4761, -2.4422, -2.4967, -2.3958,\n",
      "        -2.4345, -2.4539, -2.4690, -2.4677, -2.4231, -2.4701, -2.4895, -2.4644,\n",
      "        -2.4071, -2.4470, -2.4609, -2.5014, -2.4874, -2.4849, -2.4332, -2.4772,\n",
      "        -2.4789, -2.5017, -2.4367, -2.4548, -2.4258, -2.4997, -2.5208, -2.4802,\n",
      "        -2.4702, -2.5002], device='mps:0')\n",
      "mean: tensor(-2.4637, device='mps:0')\n",
      "iter_dt 1.00s; iter 30: train loss 0.79811 temperature: 6.499999999999995\n",
      "mean_logits tensor([-2.1812, -2.1842, -2.7423, -2.4985, -2.2846, -2.2380, -2.3639, -2.0442,\n",
      "        -2.3729, -2.0416, -2.6711, -2.3267, -2.5310, -2.5690, -2.6605, -2.3796,\n",
      "        -2.4700, -2.2616, -2.5937, -2.5000, -2.4424, -2.3082, -2.3073, -2.3418,\n",
      "        -2.3924, -2.5668, -2.3121, -2.6469, -2.5569, -2.5417, -2.3485, -2.2008,\n",
      "        -2.2624, -2.3493, -2.3008, -2.4178, -2.2712, -2.4396, -2.4318, -1.9975,\n",
      "        -2.3132, -2.2813, -2.3048, -2.5198, -2.1992, -2.5364, -2.8822, -2.0854,\n",
      "        -2.5320, -2.7025], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4388, -2.4734, -2.5074, -2.4333, -2.4321, -2.3790, -2.4963, -2.4918,\n",
      "        -2.4189, -2.5175, -2.4630, -2.4267, -2.3829, -2.4161, -2.4508, -2.4788,\n",
      "        -2.4458, -2.4209, -2.4287, -2.5024, -2.4607, -2.4945, -2.4753, -2.4903,\n",
      "        -2.4677, -2.4860, -2.4014, -2.4893, -2.4451, -2.5010, -2.5044, -2.4339,\n",
      "        -2.4315, -2.4471, -2.4983, -2.4588, -2.4714, -2.4368, -2.4929, -2.4674,\n",
      "        -2.4543, -2.4650, -2.4979, -2.4594, -2.4683, -2.4555, -2.1593, -2.4315,\n",
      "        -2.5153, -2.4406], device='mps:0')\n",
      "mean: tensor(-2.4541, device='mps:0')\n",
      "iter_dt 0.98s; iter 31: train loss 0.81632 temperature: 6.5499999999999945\n",
      "mean_logits tensor([-1.9849, -2.6584, -2.1752, -2.3819, -2.5205, -2.3907, -2.2442, -2.5204,\n",
      "        -2.2529, -2.8977, -2.3397, -2.2800, -2.4539, -2.4606, -2.4858, -2.6229,\n",
      "        -1.9834, -2.3252, -2.0569, -2.6256, -2.6909, -2.3024, -2.6562, -2.1361,\n",
      "        -2.6764, -2.5840, -2.4917, -2.2102, -2.5544, -2.5374, -2.5079, -2.4417,\n",
      "        -2.6917, -2.3098, -2.1888, -2.1404, -2.4567, -2.3435, -2.1298, -2.5718,\n",
      "        -2.4954, -2.0910, -2.3637, -2.2153, -2.4697, -2.5584, -2.3454, -2.2476,\n",
      "        -2.4735, -2.1138], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4951, -2.4330, -2.4728, -2.4603, -2.4963, -2.4998, -2.5051, -2.5014,\n",
      "        -2.4845, -2.4796, -2.4182, -2.4996, -2.4368, -2.4822, -2.5002, -2.3598,\n",
      "        -2.4959, -2.4774, -2.3678, -2.4539, -2.4106, -2.4191, -2.3994, -2.4978,\n",
      "        -2.4561, -2.4101, -2.4958, -2.4554, -2.4609, -2.4617, -2.4577, -2.4608,\n",
      "        -2.4207, -2.4314, -2.4994, -2.3753, -2.4435, -2.4590, -2.4397, -2.4378,\n",
      "        -2.4723, -2.4619, -2.4128, -2.4585, -2.4368, -2.4107, -2.4840, -2.4687,\n",
      "        -2.4678, -2.4944], device='mps:0')\n",
      "mean: tensor(-2.4556, device='mps:0')\n",
      "iter_dt 0.99s; iter 32: train loss 0.81308 temperature: 6.599999999999994\n",
      "mean_logits tensor([-2.2086, -2.3899, -2.4728, -1.9508, -2.4945, -2.2044, -2.4157, -2.4382,\n",
      "        -2.6108, -2.3245, -2.7964, -2.3620, -2.4020, -2.4180, -2.3194, -2.1592,\n",
      "        -2.2935, -2.7103, -2.5057, -2.7609, -2.2183, -2.2712, -2.4125, -2.0655,\n",
      "        -2.4187, -2.6831, -2.4427, -2.3702, -2.5225, -2.0043, -2.4969, -2.7791,\n",
      "        -1.9387, -2.4174, -2.6458, -2.3240, -1.9016, -2.4780, -2.4170, -2.3242,\n",
      "        -2.1055, -2.2849, -2.5902, -2.4947, -2.5398, -2.5748, -2.3041, -2.6236,\n",
      "        -2.1077, -2.3505], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4790, -2.4203, -2.4323, -2.4467, -2.4681, -2.4271, -2.4495, -2.4281,\n",
      "        -2.4658, -2.5095, -2.4024, -2.5006, -2.4994, -2.5090, -2.4397, -2.4175,\n",
      "        -2.5005, -2.4935, -2.4884, -2.4220, -2.5003, -2.3753, -2.4663, -2.4880,\n",
      "        -2.4850, -2.4454, -2.5015, -2.5007, -2.4603, -2.5008, -2.4669, -2.5010,\n",
      "        -2.4917, -2.5011, -2.4480, -2.5012, -2.4321, -2.4997, -2.4053, -2.5095,\n",
      "        -2.4595, -2.4987, -2.4599, -2.4962, -2.4939, -2.4628, -2.4530, -2.5017,\n",
      "        -2.4431, -2.4341], device='mps:0')\n",
      "mean: tensor(-2.4677, device='mps:0')\n",
      "iter_dt 1.01s; iter 33: train loss 0.67291 temperature: 6.649999999999994\n",
      "mean_logits tensor([-2.2549, -2.3986, -2.3758, -2.4157, -2.4104, -2.6491, -2.6593, -2.4350,\n",
      "        -2.8716, -2.5751, -2.4070, -2.5287, -2.7455, -2.4447, -2.4616, -2.4326,\n",
      "        -2.3014, -2.6046, -2.1531, -2.0155, -2.6740, -2.3888, -2.4958, -2.2551,\n",
      "        -2.5468, -2.4323, -2.2679, -2.3653, -2.6426, -2.3762, -2.1420, -2.5289,\n",
      "        -2.6236, -2.2418, -2.2726, -2.8220, -2.0694, -2.4533, -2.0444, -2.0319,\n",
      "        -2.5387, -2.2768, -2.6134, -2.4287, -2.2440, -2.3793, -2.6092, -2.3227,\n",
      "        -2.0775, -2.3588], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4644, -2.4670, -2.5010, -2.4572, -2.4381, -2.4430, -2.4438, -2.4411,\n",
      "        -2.4922, -2.4649, -2.4615, -2.4995, -2.5029, -2.4573, -2.4700, -2.4668,\n",
      "        -2.4976, -2.4706, -2.4374, -2.4516, -2.4708, -2.4978, -2.4804, -2.3748,\n",
      "        -2.4645, -2.4673, -2.3736, -2.4714, -2.4187, -2.3814, -2.4753, -2.4632,\n",
      "        -2.4828, -2.4042, -2.4667, -2.4266, -2.4203, -2.4946, -2.4991, -2.4136,\n",
      "        -2.4799, -2.4340, -2.4919, -2.4831, -2.4389, -2.4255, -2.4323, -2.5014,\n",
      "        -2.4171, -2.4451], device='mps:0')\n",
      "mean: tensor(-2.4565, device='mps:0')\n",
      "iter_dt 0.97s; iter 34: train loss 0.84787 temperature: 6.699999999999994\n",
      "mean_logits tensor([-2.4048, -2.3673, -2.4434, -2.1819, -2.4150, -2.0868, -2.2719, -2.6379,\n",
      "        -2.4477, -2.3160, -1.9827, -2.2123, -2.6897, -2.2547, -2.5214, -2.3517,\n",
      "        -2.3265, -2.6495, -2.6517, -2.4852, -2.2684, -2.6899, -2.2993, -2.4827,\n",
      "        -2.4801, -2.3816, -2.5521, -2.0359, -2.2062, -2.3635, -2.0552, -2.4472,\n",
      "        -2.2896, -2.3254, -2.2744, -2.3201, -2.0325, -2.2308, -2.1509, -2.5380,\n",
      "        -1.9449, -2.4692, -2.3608, -2.0238, -2.2604, -2.6772, -2.0457, -2.8122,\n",
      "        -2.6802, -2.2578], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3434, -2.4948, -2.4874, -2.4892, -2.4363, -2.5014, -2.4988, -2.5038,\n",
      "        -2.4831, -2.4648, -2.4954, -2.4290, -2.4985, -2.4726, -2.4363, -2.4771,\n",
      "        -2.4988, -2.4987, -2.4961, -2.4825, -2.4375, -2.4590, -2.4284, -2.4854,\n",
      "        -2.4366, -2.4078, -2.4904, -2.3975, -2.4859, -2.4639, -2.4359, -2.4948,\n",
      "        -2.4600, -2.4938, -2.4973, -2.5105, -2.5061, -2.4626, -2.4299, -2.5009,\n",
      "        -2.4273, -2.4761, -2.2995, -2.4815, -2.5004, -2.4880, -2.4660, -2.3827,\n",
      "        -2.4943, -2.4841], device='mps:0')\n",
      "mean: tensor(-2.4654, device='mps:0')\n",
      "iter_dt 0.99s; iter 35: train loss 0.69946 temperature: 6.749999999999994\n",
      "mean_logits tensor([-2.5086, -2.2022, -2.3447, -2.4867, -2.4344, -2.3777, -2.1450, -2.7241,\n",
      "        -2.6398, -2.7101, -2.4066, -2.1369, -2.5067, -2.5505, -2.3427, -2.5525,\n",
      "        -1.8949, -1.9697, -2.3000, -2.5254, -2.3657, -2.2051, -2.5506, -2.5083,\n",
      "        -2.2127, -2.2613, -2.6530, -2.4104, -2.2846, -2.4211, -2.3191, -2.6864,\n",
      "        -2.4862, -2.5024, -2.5291, -2.2815, -2.1051, -2.0218, -2.2614, -2.3644,\n",
      "        -2.0854, -2.3508, -2.5161, -2.3866, -2.4730, -2.3840, -2.2333, -2.3750,\n",
      "        -2.5551, -1.9943], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4678, -2.4643, -2.4948, -2.4563, -2.4374, -2.4760, -2.4542, -2.4783,\n",
      "        -2.4861, -2.4645, -2.4442, -2.4654, -2.4082, -2.4987, -2.5002, -2.4919,\n",
      "        -2.4952, -2.4977, -2.4884, -2.4686, -2.5004, -2.4741, -2.4917, -2.5072,\n",
      "        -2.5007, -2.4533, -2.4638, -2.5000, -2.5081, -2.5000, -2.3890, -2.3658,\n",
      "        -2.3785, -2.4453, -2.5003, -2.4983, -2.4381, -2.4305, -2.4593, -2.4678,\n",
      "        -2.5008, -2.4969, -2.5081, -2.4375, -2.5629, -2.4468, -2.4602, -2.4431,\n",
      "        -2.5007, -2.3955], device='mps:0')\n",
      "mean: tensor(-2.4693, device='mps:0')\n",
      "iter_dt 0.99s; iter 36: train loss 0.73687 temperature: 6.799999999999994\n",
      "mean_logits tensor([-2.3506, -2.6550, -2.6279, -2.3460, -2.6336, -2.4106, -2.1454, -2.4496,\n",
      "        -2.3410, -2.2830, -2.1216, -2.2460, -2.5498, -2.5256, -2.1852, -2.4845,\n",
      "        -2.4455, -2.3507, -2.4968, -2.6722, -2.0699, -2.3247, -2.3573, -2.2770,\n",
      "        -2.1575, -2.1998, -2.2712, -2.1771, -2.2199, -2.5720, -2.4627, -1.9659,\n",
      "        -2.4024, -1.9932, -2.5706, -2.1404, -2.5582, -2.6553, -2.3836, -2.4419,\n",
      "        -2.2538, -2.6237, -2.4473, -2.0688, -2.3772, -1.8201, -2.1284, -2.5711,\n",
      "        -2.4197, -2.4938], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4243, -2.5026, -2.4978, -2.4632, -2.4299, -2.4282, -2.4937, -2.4173,\n",
      "        -2.4097, -2.5012, -2.4574, -2.4503, -2.4010, -2.4266, -2.5018, -2.4694,\n",
      "        -2.4639, -2.4600, -2.5025, -2.4711, -2.4616, -2.3894, -2.4546, -2.4522,\n",
      "        -2.3724, -2.4521, -2.5014, -2.4867, -2.4523, -2.3802, -2.4854, -2.4963,\n",
      "        -2.4895, -2.4930, -2.4632, -2.4289, -2.4246, -2.4922, -2.4826, -2.4557,\n",
      "        -2.4666, -2.4634, -2.4954, -2.4971, -2.4679, -2.4543, -2.4797, -2.4711,\n",
      "        -2.4128, -2.5021], device='mps:0')\n",
      "mean: tensor(-2.4599, device='mps:0')\n",
      "iter_dt 1.03s; iter 37: train loss 0.70080 temperature: 6.849999999999993\n",
      "mean_logits tensor([-2.5718, -2.2169, -2.5783, -2.2938, -2.3073, -2.5764, -2.2734, -2.3648,\n",
      "        -2.6392, -2.3290, -2.5802, -2.3489, -2.6788, -2.4260, -2.1708, -2.1054,\n",
      "        -2.2640, -2.1849, -2.6502, -2.5657, -2.5211, -2.4934, -2.3365, -2.4853,\n",
      "        -2.5693, -2.4531, -2.2165, -2.2303, -2.2242, -2.2724, -2.1436, -2.4898,\n",
      "        -2.5665, -2.2001, -2.1760, -2.4331, -2.1418, -1.9298, -2.2271, -2.1009,\n",
      "        -2.1780, -2.6107, -2.5469, -2.6809, -2.4328, -2.5005, -2.5455, -2.3212,\n",
      "        -2.4721, -2.0215], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5003, -2.4949, -2.4150, -2.4302, -2.3654, -2.4698, -2.4284, -2.4849,\n",
      "        -2.4332, -2.5083, -2.5030, -2.4598, -2.4653, -2.4593, -2.5422, -2.4891,\n",
      "        -2.4740, -2.4960, -2.4973, -2.5052, -2.4926, -2.4596, -2.4975, -2.4377,\n",
      "        -2.4364, -2.4912, -2.4548, -2.4961, -2.4993, -2.5006, -2.5092, -2.4636,\n",
      "        -2.4622, -2.4617, -2.4992, -2.4962, -2.4462, -2.4276, -2.4927, -2.4998,\n",
      "        -2.4306, -2.4588, -2.4697, -2.4177, -2.4938, -2.4905, -2.4649, -2.4343,\n",
      "        -2.4623, -2.4464], device='mps:0')\n",
      "mean: tensor(-2.4703, device='mps:0')\n",
      "iter_dt 1.04s; iter 38: train loss 0.52377 temperature: 6.899999999999993\n",
      "mean_logits tensor([-2.2524, -2.3910, -2.3529, -2.2741, -2.3535, -2.5402, -2.5892, -2.4570,\n",
      "        -2.5407, -2.5423, -2.0971, -2.3810, -2.2773, -2.5643, -2.2464, -2.4233,\n",
      "        -2.0117, -2.5515, -2.5058, -2.3201, -2.0046, -2.5857, -2.3938, -2.3991,\n",
      "        -2.4277, -2.2959, -2.4196, -2.3950, -2.5141, -2.2831, -2.6220, -2.4389,\n",
      "        -2.4035, -2.3645, -2.5083, -2.5827, -2.4671, -2.6375, -2.5186, -1.9091,\n",
      "        -2.4502, -2.3429, -2.3331, -1.8613, -2.2129, -2.5613, -2.5782, -2.4136,\n",
      "        -2.0927, -2.3933], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4619, -2.4634, -2.4765, -2.4577, -2.4439, -2.4911, -2.4727, -2.5076,\n",
      "        -2.5046, -2.4955, -2.3968, -2.4412, -2.4973, -2.4451, -2.5014, -2.4662,\n",
      "        -2.4329, -2.4904, -2.4748, -2.4786, -2.4980, -2.5045, -2.5055, -2.4743,\n",
      "        -2.4704, -2.4815, -2.4803, -2.4802, -2.4973, -2.4985, -2.5002, -2.4737,\n",
      "        -2.4810, -2.5020, -2.4847, -2.4225, -2.4556, -2.4441, -2.4765, -2.4360,\n",
      "        -2.4946, -2.5002, -2.4286, -2.4625, -2.4828, -2.4959, -2.5000, -2.4135,\n",
      "        -2.4949, -2.4664], device='mps:0')\n",
      "mean: tensor(-2.4741, device='mps:0')\n",
      "iter_dt 0.95s; iter 39: train loss 0.83460 temperature: 6.949999999999993\n",
      "mean_logits tensor([-2.0733, -2.1694, -2.8974, -2.4356, -2.4307, -2.4806, -2.4207, -2.3099,\n",
      "        -2.6065, -2.3157, -2.2763, -2.3235, -2.3590, -2.3411, -2.3266, -2.4435,\n",
      "        -2.5410, -1.8790, -2.7243, -2.1277, -2.4504, -2.8206, -2.3909, -2.8320,\n",
      "        -2.2681, -2.5768, -2.2510, -2.3445, -2.6787, -2.4441, -2.2862, -2.3744,\n",
      "        -2.7157, -2.2918, -2.3960, -2.3264, -1.9527, -2.5350, -2.2061, -2.2298,\n",
      "        -2.4439, -2.3805, -2.6566, -2.3698, -1.9674, -2.4393, -2.4623, -2.3603,\n",
      "        -2.3603, -2.4916], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4409, -2.4746, -2.4710, -2.4918, -2.4436, -2.4985, -2.3977, -2.3996,\n",
      "        -2.4937, -2.4700, -2.5086, -2.4468, -2.4890, -2.4802, -2.4603, -2.4524,\n",
      "        -2.5136, -2.4471, -2.3678, -2.5073, -2.4602, -2.4993, -2.4331, -2.4510,\n",
      "        -2.4939, -2.4697, -2.4718, -2.4872, -2.4753, -2.5074, -2.4248, -2.4338,\n",
      "        -2.4915, -2.3817, -2.4521, -2.4964, -2.3996, -2.5007, -2.4936, -2.5004,\n",
      "        -2.4489, -2.4800, -2.4371, -2.4989, -2.5016, -2.4615, -2.4647, -2.5010,\n",
      "        -2.4136, -2.4886], device='mps:0')\n",
      "mean: tensor(-2.4655, device='mps:0')\n",
      "iter_dt 1.02s; iter 40: train loss 0.91358 temperature: 6.999999999999993\n",
      "mean_logits tensor([-2.4461, -2.3202, -2.4585, -2.9039, -2.2623, -1.9287, -2.5931, -2.5353,\n",
      "        -2.2957, -2.4786, -2.1167, -2.0226, -2.6580, -2.2309, -2.4077, -2.2589,\n",
      "        -2.6787, -2.2852, -2.7452, -2.6198, -2.4800, -2.5883, -2.5663, -2.2593,\n",
      "        -2.7295, -2.5022, -2.7055, -2.4263, -2.3519, -1.7641, -2.0285, -2.3620,\n",
      "        -2.5083, -2.4580, -2.4965, -2.1929, -2.2485, -2.2070, -2.6836, -2.1024,\n",
      "        -2.6116, -2.2612, -2.3578, -2.5172, -2.2431, -2.4629, -2.4925, -2.2014,\n",
      "        -2.0861, -2.5346], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4886, -2.4627, -2.4970, -2.5004, -2.4772, -2.5010, -2.4445, -2.4941,\n",
      "        -2.5007, -2.4906, -2.4963, -2.4048, -2.3897, -2.4613, -2.4108, -2.4847,\n",
      "        -2.4946, -2.4610, -2.4489, -2.4843, -2.5048, -2.4997, -2.4773, -2.5016,\n",
      "        -2.4791, -2.4717, -2.4356, -2.4914, -2.4245, -2.4305, -2.4632, -2.4905,\n",
      "        -2.5007, -2.4920, -2.4485, -2.4927, -2.4557, -2.4944, -2.4950, -2.4803,\n",
      "        -2.4144, -2.4574, -2.4664, -2.5013, -2.4961, -2.4702, -2.4681, -2.4987,\n",
      "        -2.4714, -2.3547], device='mps:0')\n",
      "mean: tensor(-2.4704, device='mps:0')\n",
      "iter_dt 1.00s; iter 41: train loss 0.84525 temperature: 7.049999999999993\n",
      "mean_logits tensor([-2.6317, -2.3033, -2.6528, -2.7635, -2.6915, -2.0781, -2.4691, -2.3671,\n",
      "        -2.6624, -2.5037, -2.4670, -2.4012, -1.8752, -2.7686, -2.1926, -2.2878,\n",
      "        -2.8379, -2.3912, -2.4916, -2.4279, -2.6339, -2.6148, -2.2377, -2.6788,\n",
      "        -1.8820, -2.3870, -2.5272, -2.4452, -2.3783, -2.3477, -2.3509, -2.2705,\n",
      "        -2.4794, -2.7017, -2.3757, -2.6669, -2.5092, -2.4216, -2.6360, -2.0582,\n",
      "        -2.4454, -1.7602, -2.4620, -2.3824, -2.5596, -2.6173, -2.6286, -2.5116,\n",
      "        -2.5025, -2.7042], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4650, -2.4192, -2.4588, -2.4889, -2.4812, -2.4556, -2.4997, -2.4855,\n",
      "        -2.4865, -2.4171, -2.4987, -2.4454, -2.4981, -2.4759, -2.4913, -2.4722,\n",
      "        -2.4956, -2.5031, -2.4353, -2.5088, -2.5012, -2.3978, -2.4397, -2.5009,\n",
      "        -2.5024, -2.4983, -2.5006, -2.4281, -2.4989, -2.4088, -2.5030, -2.4294,\n",
      "        -2.4999, -2.4872, -2.4663, -2.4961, -2.4411, -2.5019, -2.5031, -2.4925,\n",
      "        -2.4846, -2.4620, -2.4925, -2.4668, -2.4455, -2.4808, -2.3578, -2.4381,\n",
      "        -2.4487, -2.4177], device='mps:0')\n",
      "mean: tensor(-2.4695, device='mps:0')\n",
      "iter_dt 0.99s; iter 42: train loss 0.60602 temperature: 7.0999999999999925\n",
      "mean_logits tensor([-2.5582, -2.1808, -2.5796, -2.5678, -2.4869, -2.5779, -2.3045, -2.7696,\n",
      "        -2.6380, -2.3359, -2.0373, -2.4933, -2.3197, -2.2516, -2.4377, -2.5263,\n",
      "        -2.2956, -2.5017, -2.1889, -2.3939, -2.2341, -2.4224, -2.4697, -2.4118,\n",
      "        -2.5783, -2.6138, -2.0785, -2.4623, -2.4340, -2.5337, -2.4466, -2.5015,\n",
      "        -2.2774, -2.3720, -2.2764, -2.5126, -2.7548, -1.9373, -2.4387, -2.5186,\n",
      "        -2.3293, -2.4260, -2.7206, -2.6282, -2.2774, -2.6617, -2.5488, -2.4657,\n",
      "        -2.1153, -2.2241], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4885, -2.4931, -2.4784, -2.4463, -2.4923, -2.4677, -2.4957, -2.4617,\n",
      "        -2.4789, -2.4679, -2.4703, -2.4793, -2.4041, -2.4983, -2.4446, -2.3686,\n",
      "        -2.4609, -2.4158, -2.4658, -2.3571, -2.4413, -2.5013, -2.3999, -2.5004,\n",
      "        -2.4780, -2.5021, -2.5026, -2.4737, -2.5008, -2.4289, -2.4855, -2.4873,\n",
      "        -2.4927, -2.5002, -2.4995, -2.5021, -2.5078, -2.5002, -2.4825, -2.4460,\n",
      "        -2.4813, -2.4928, -2.4865, -2.5019, -2.4768, -2.4613, -2.4456, -2.4343,\n",
      "        -2.4960, -2.4921], device='mps:0')\n",
      "mean: tensor(-2.4707, device='mps:0')\n",
      "iter_dt 0.99s; iter 43: train loss 0.90092 temperature: 7.149999999999992\n",
      "mean_logits tensor([-2.1679, -2.2173, -2.3084, -2.3732, -2.6637, -2.1628, -2.4800, -2.2798,\n",
      "        -2.4944, -2.1068, -2.2159, -2.2035, -2.0374, -2.4334, -2.8001, -2.5906,\n",
      "        -2.4571, -2.6402, -2.4779, -2.2967, -2.1591, -2.1218, -2.5002, -2.6695,\n",
      "        -2.2623, -2.4678, -2.4609, -2.2383, -2.3354, -2.4149, -2.3809, -2.3363,\n",
      "        -2.2549, -2.4595, -2.4463, -2.5498, -2.3902, -2.7341, -2.4752, -1.8431,\n",
      "        -2.3145, -1.8182, -2.1865, -2.2099, -2.5806, -1.9040, -2.8367, -2.5456,\n",
      "        -2.3849, -2.4802], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4967, -2.4962, -2.4921, -2.4285, -2.4966, -2.4524, -2.4522, -2.4717,\n",
      "        -2.4640, -2.5060, -2.5017, -2.4917, -2.4901, -2.4714, -2.4999, -2.4947,\n",
      "        -2.4551, -2.4421, -2.5009, -2.3405, -2.4681, -2.4615, -2.4207, -2.4920,\n",
      "        -2.4987, -2.4824, -2.4979, -2.4982, -2.4454, -2.5043, -2.4943, -2.4689,\n",
      "        -2.3952, -2.5023, -2.4615, -2.4930, -2.4884, -2.4612, -2.4623, -2.4999,\n",
      "        -2.4682, -2.4984, -2.4459, -2.5028, -2.5016, -2.4779, -2.5057, -2.4311,\n",
      "        -2.4510, -2.4984], device='mps:0')\n",
      "mean: tensor(-2.4744, device='mps:0')\n",
      "iter_dt 0.99s; iter 44: train loss 0.72055 temperature: 7.199999999999992\n",
      "mean_logits tensor([-2.5114, -2.4477, -2.3728, -2.3622, -2.6993, -2.4160, -2.4461, -2.7759,\n",
      "        -2.0912, -2.5189, -2.2765, -2.3424, -2.7869, -2.4852, -2.4165, -2.4616,\n",
      "        -2.6156, -2.3431, -1.9929, -2.2026, -2.4864, -2.4148, -2.2417, -2.5809,\n",
      "        -2.0030, -2.5822, -2.0095, -2.1979, -2.2918, -2.1587, -2.2682, -2.4654,\n",
      "        -2.4009, -2.4443, -2.5237, -2.4898, -2.3825, -2.3549, -2.3087, -2.2739,\n",
      "        -2.3322, -2.1112, -2.4952, -2.7065, -2.5902, -2.2229, -2.6055, -2.5771,\n",
      "        -2.2507, -2.2306], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4688, -2.4554, -2.4869, -2.4902, -2.4650, -2.4490, -2.4612, -2.4374,\n",
      "        -2.4635, -2.2405, -2.4770, -2.5307, -2.4736, -2.5021, -2.4771, -2.5016,\n",
      "        -2.5014, -2.4567, -2.5017, -2.4546, -2.4737, -2.5082, -2.4921, -2.5080,\n",
      "        -2.4922, -2.4908, -2.4810, -2.4391, -2.4510, -2.4989, -2.4521, -2.4551,\n",
      "        -2.4767, -2.4786, -2.4333, -2.4547, -2.4995, -2.4536, -2.4599, -2.4020,\n",
      "        -2.5138, -2.4760, -2.5025, -2.4845, -2.4324, -2.4972, -2.4660, -2.4551,\n",
      "        -2.4737, -2.5002], device='mps:0')\n",
      "mean: tensor(-2.4699, device='mps:0')\n",
      "iter_dt 1.00s; iter 45: train loss 0.72495 temperature: 7.249999999999992\n",
      "mean_logits tensor([-2.5116, -2.2730, -2.3523, -2.4285, -2.3506, -2.2278, -2.2843, -2.1257,\n",
      "        -2.2695, -2.0314, -2.1917, -1.9531, -2.1809, -2.5661, -2.3628, -2.2753,\n",
      "        -2.5441, -2.3238, -2.3702, -2.2309, -2.6610, -2.4143, -2.6231, -2.1050,\n",
      "        -2.7286, -2.6201, -2.6714, -2.2572, -2.5942, -2.3585, -2.5212, -2.4263,\n",
      "        -2.3217, -2.3140, -2.2697, -2.4898, -2.4090, -2.3629, -2.6386, -2.2863,\n",
      "        -2.3667, -2.7322, -2.4219, -2.1050, -2.2659, -2.4690, -2.3180, -2.4466,\n",
      "        -2.0822, -2.3716], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4301, -2.5100, -2.4601, -2.5008, -2.4610, -2.4223, -2.4644, -2.4799,\n",
      "        -2.4938, -2.4929, -2.5085, -2.4855, -2.4473, -2.4538, -2.5021, -2.4437,\n",
      "        -2.4996, -2.4651, -2.4590, -2.4916, -2.4683, -2.4665, -2.4922, -2.4967,\n",
      "        -2.3933, -2.4170, -2.4978, -2.5007, -2.4271, -2.4591, -2.4381, -2.4946,\n",
      "        -2.5009, -2.4879, -2.4822, -2.4341, -2.4983, -2.4471, -2.4359, -2.4975,\n",
      "        -2.5029, -2.5003, -2.4676, -2.4760, -2.5004, -2.4659, -2.4909, -2.4992,\n",
      "        -2.4475, -2.4856], device='mps:0')\n",
      "mean: tensor(-2.4729, device='mps:0')\n",
      "iter_dt 1.00s; iter 46: train loss 0.52341 temperature: 7.299999999999992\n",
      "mean_logits tensor([-2.2531, -2.3604, -2.6291, -2.2354, -2.2484, -2.1149, -2.3613, -2.5336,\n",
      "        -1.9909, -2.3344, -2.5212, -2.1996, -2.4591, -2.5278, -2.0602, -2.3433,\n",
      "        -2.5767, -2.3154, -2.5500, -2.6017, -2.4583, -2.2887, -2.4993, -2.2870,\n",
      "        -2.2067, -2.1824, -2.5722, -2.6134, -2.6717, -2.3194, -2.2610, -2.0816,\n",
      "        -2.4092, -2.3606, -2.3780, -2.3775, -2.2768, -2.2718, -2.4070, -2.4646,\n",
      "        -2.3521, -2.3566, -2.2856, -2.5442, -2.3979, -2.2720, -2.2089, -2.4151,\n",
      "        -2.4753, -2.5822], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4894, -2.4401, -2.4693, -2.5050, -2.5040, -2.4326, -2.4835, -2.5010,\n",
      "        -2.4698, -2.4588, -2.4963, -2.4670, -2.5037, -2.4593, -2.4065, -2.5074,\n",
      "        -2.5025, -2.4888, -2.5006, -2.4394, -2.5002, -2.4490, -2.5036, -2.4385,\n",
      "        -2.4959, -2.4956, -2.4941, -2.4993, -2.4759, -2.4636, -2.4914, -2.4907,\n",
      "        -2.4965, -2.4742, -2.4991, -2.5065, -2.4966, -2.2619, -2.4460, -2.4627,\n",
      "        -2.4745, -2.5033, -2.4973, -2.5015, -2.4204, -2.4525, -2.4700, -2.4668,\n",
      "        -2.5086, -2.3913], device='mps:0')\n",
      "mean: tensor(-2.4731, device='mps:0')\n",
      "iter_dt 0.97s; iter 47: train loss 0.53438 temperature: 7.349999999999992\n",
      "mean_logits tensor([-1.9972, -2.4156, -2.5148, -2.3069, -2.4013, -2.6448, -2.4893, -2.2856,\n",
      "        -2.2286, -2.4925, -2.3356, -2.6432, -2.2663, -2.4616, -2.5303, -2.3633,\n",
      "        -2.4059, -2.1939, -2.4027, -2.2458, -2.3798, -2.2375, -2.2321, -2.1294,\n",
      "        -2.7430, -2.1367, -2.0993, -2.4786, -1.9737, -2.5287, -2.5061, -2.4663,\n",
      "        -2.5702, -2.3502, -2.6505, -2.3015, -2.4441, -2.5352, -2.3602, -2.4988,\n",
      "        -2.1989, -2.4418, -2.6779, -2.6981, -2.4974, -2.6117, -2.4212, -2.4387,\n",
      "        -2.4324, -2.3086], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5005, -2.4629, -2.4454, -2.4434, -2.3750, -2.4317, -2.4475, -2.4600,\n",
      "        -2.4972, -2.4835, -2.4334, -2.4981, -2.4416, -2.5006, -2.4889, -2.4916,\n",
      "        -2.5009, -2.4772, -2.4976, -2.4954, -2.4924, -2.4740, -2.4044, -2.4845,\n",
      "        -2.4992, -2.4971, -2.4539, -2.4917, -2.4291, -2.4954, -2.4983, -2.4599,\n",
      "        -2.4570, -2.4995, -2.4812, -2.4226, -2.4773, -2.4935, -2.4995, -2.4857,\n",
      "        -2.5001, -2.4952, -2.4926, -2.5031, -2.4923, -2.4774, -2.5031, -2.4118,\n",
      "        -2.4823, -2.4579], device='mps:0')\n",
      "mean: tensor(-2.4737, device='mps:0')\n",
      "iter_dt 1.03s; iter 48: train loss 0.93009 temperature: 7.3999999999999915\n",
      "mean_logits tensor([-2.3274, -2.2490, -2.2763, -2.1062, -2.4055, -2.3755, -2.4330, -2.5923,\n",
      "        -2.1879, -2.3206, -2.1964, -2.0455, -2.4975, -2.3102, -2.2678, -2.4626,\n",
      "        -2.1144, -2.1982, -2.4239, -2.4684, -2.2495, -2.1653, -2.4104, -2.2462,\n",
      "        -2.5429, -2.6945, -2.3235, -2.2389, -2.3374, -2.2570, -2.6424, -2.5235,\n",
      "        -2.5800, -2.2314, -2.3435, -3.1142, -2.4214, -2.2419, -2.4498, -2.5284,\n",
      "        -2.3402, -2.5859, -2.4224, -2.2194, -2.5878, -2.7582, -2.7006, -1.8922,\n",
      "        -2.2941, -2.1825], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4736, -2.4477, -2.4458, -2.4466, -2.4977, -2.4965, -2.4930, -2.4452,\n",
      "        -2.3148, -2.4943, -2.4672, -2.4641, -2.5102, -2.4293, -2.4501, -2.5007,\n",
      "        -2.4480, -2.4225, -2.4922, -2.4629, -2.4927, -2.4994, -2.4993, -2.5249,\n",
      "        -2.4951, -2.4470, -2.4732, -2.5021, -2.4712, -2.4320, -2.4400, -2.5081,\n",
      "        -2.4994, -2.4426, -2.4791, -2.4922, -2.4653, -2.5013, -2.4701, -2.4997,\n",
      "        -2.4960, -2.5026, -2.4455, -2.4946, -2.4564, -2.5085, -2.4931, -2.4867,\n",
      "        -2.4768, -2.4577], device='mps:0')\n",
      "mean: tensor(-2.4731, device='mps:0')\n",
      "iter_dt 1.03s; iter 49: train loss 0.77956 temperature: 7.449999999999991\n",
      "mean_logits tensor([-2.6968, -2.4573, -1.9082, -2.0656, -2.3172, -2.2064, -2.4002, -2.2536,\n",
      "        -2.4731, -2.2016, -2.4828, -2.2960, -2.4874, -2.3717, -2.4430, -2.3235,\n",
      "        -2.4530, -2.7867, -2.4755, -2.5473, -2.6244, -2.5039, -2.3553, -2.5559,\n",
      "        -1.9558, -2.4203, -2.1273, -2.3977, -2.7808, -2.2677, -2.3668, -2.2745,\n",
      "        -2.2451, -2.7010, -2.3669, -2.3613, -2.2985, -2.3996, -1.9178, -2.6558,\n",
      "        -2.6691, -2.6206, -2.2323, -2.3473, -2.2076, -2.5476, -2.4838, -2.6406,\n",
      "        -2.3550, -2.3491], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4678, -2.4967, -2.5006, -2.4508, -2.4902, -2.4909, -2.5007, -2.4696,\n",
      "        -2.4730, -2.4470, -2.5008, -2.4910, -2.5008, -2.4946, -2.5075, -2.4985,\n",
      "        -2.4416, -2.5006, -2.5084, -2.4160, -2.4667, -2.4503, -2.4548, -2.4921,\n",
      "        -2.4868, -2.4982, -2.4928, -2.4323, -2.4544, -2.4757, -2.4919, -2.4537,\n",
      "        -2.4483, -2.4945, -2.4581, -2.4571, -2.5013, -2.4300, -2.4980, -2.4395,\n",
      "        -2.3917, -2.4182, -2.4539, -2.4865, -2.4615, -2.4307, -2.3745, -2.4509,\n",
      "        -2.4823, -2.4944], device='mps:0')\n",
      "mean: tensor(-2.4694, device='mps:0')\n",
      "iter_dt 0.98s; iter 50: train loss 0.46405 temperature: 7.499999999999991\n",
      "mean_logits tensor([-2.6446, -2.3944, -2.6793, -2.3310, -2.4479, -2.4858, -2.6664, -2.4460,\n",
      "        -2.4188, -2.4308, -2.5024, -2.2457, -2.2128, -2.3964, -2.5796, -2.5630,\n",
      "        -2.1786, -2.4488, -2.1920, -2.4760, -2.4536, -2.5958, -2.4216, -2.7252,\n",
      "        -2.5803, -2.4020, -2.5164, -2.3138, -2.3287, -2.4813, -2.5357, -2.2734,\n",
      "        -2.4317, -2.1961, -2.5416, -2.6461, -2.3152, -2.3391, -2.7111, -2.4192,\n",
      "        -2.4342, -2.4884, -2.4152, -2.6849, -2.2641, -2.2679, -2.5727, -2.1440,\n",
      "        -2.2004, -2.5604], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4980, -2.4773, -2.4199, -2.4937, -2.4943, -2.5006, -2.4423, -2.4459,\n",
      "        -2.4866, -2.5006, -2.4594, -2.4775, -2.4530, -2.4480, -2.4731, -2.4210,\n",
      "        -2.5022, -2.4656, -2.5081, -2.4947, -2.4999, -2.4957, -2.4335, -2.3856,\n",
      "        -2.5021, -2.4336, -2.4788, -2.3285, -2.4811, -2.5000, -2.5027, -2.4603,\n",
      "        -2.4890, -2.4570, -2.5086, -2.4648, -2.4695, -2.4987, -2.4767, -2.4973,\n",
      "        -2.4918, -2.5024, -2.3139, -2.4967, -2.4859, -2.4324, -2.4064, -2.4577,\n",
      "        -2.5020, -2.4455], device='mps:0')\n",
      "mean: tensor(-2.4672, device='mps:0')\n",
      "iter_dt 1.00s; iter 51: train loss 0.48406 temperature: 7.549999999999991\n",
      "mean_logits tensor([-2.5820, -2.6733, -2.3787, -2.2587, -2.4764, -2.5977, -2.6002, -2.5491,\n",
      "        -2.3824, -2.4790, -2.3284, -2.6408, -2.4515, -2.2656, -2.3591, -2.3543,\n",
      "        -2.2847, -2.3392, -2.3549, -2.4698, -2.6260, -2.5592, -2.5332, -2.3744,\n",
      "        -2.5206, -2.1844, -2.2900, -2.0474, -2.3687, -2.3876, -2.6224, -2.5171,\n",
      "        -2.4696, -2.1694, -2.1823, -2.5177, -2.1668, -2.1280, -1.9685, -2.3296,\n",
      "        -2.6164, -2.5549, -2.5103, -2.5027, -2.6222, -2.4288, -2.4386, -2.2101,\n",
      "        -2.3880, -2.4805], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5001, -2.5122, -2.4599, -2.4793, -2.5005, -2.4614, -2.4939, -2.5009,\n",
      "        -2.4635, -2.4234, -2.5124, -2.4974, -2.4992, -2.4668, -2.4819, -2.5025,\n",
      "        -2.4597, -2.4667, -2.5628, -2.4136, -2.4434, -2.4990, -2.4795, -2.5008,\n",
      "        -2.4461, -2.4981, -2.4581, -2.4208, -2.4976, -2.5008, -2.4611, -2.4996,\n",
      "        -2.4813, -2.4970, -2.4985, -2.4597, -2.4074, -2.4666, -2.4936, -2.4528,\n",
      "        -2.4915, -2.4165, -2.4951, -2.4269, -2.4879, -2.3940, -2.4905, -2.5005,\n",
      "        -2.4278, -2.3659], device='mps:0')\n",
      "mean: tensor(-2.4723, device='mps:0')\n",
      "iter_dt 1.00s; iter 52: train loss 0.71130 temperature: 7.599999999999991\n",
      "mean_logits tensor([-2.7788, -2.3534, -2.5383, -2.7228, -2.0401, -2.6448, -2.2763, -2.4238,\n",
      "        -2.3814, -2.1462, -2.5122, -2.2360, -2.3838, -2.4427, -2.5673, -2.6059,\n",
      "        -2.6361, -2.0434, -2.6546, -2.0523, -2.3324, -2.6252, -2.4313, -2.5576,\n",
      "        -2.3857, -2.8007, -2.7215, -2.1073, -2.6803, -2.2732, -2.4167, -2.3309,\n",
      "        -2.3639, -2.4408, -2.4099, -2.7048, -2.5421, -2.5372, -2.6683, -2.1761,\n",
      "        -2.4666, -2.1828, -2.2091, -2.3786, -2.3511, -2.3743, -2.2205, -2.6415,\n",
      "        -2.1185, -2.4941], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5020, -2.3855, -2.5015, -2.4653, -2.4954, -2.4966, -2.4975, -2.4647,\n",
      "        -2.4542, -2.4494, -2.4697, -2.5004, -2.4667, -2.4597, -2.4962, -2.5041,\n",
      "        -2.4199, -2.4657, -2.4584, -2.4215, -2.5012, -2.5161, -2.4945, -2.4809,\n",
      "        -2.4767, -2.5076, -2.4990, -2.4931, -2.5007, -2.5247, -2.4834, -2.4471,\n",
      "        -2.4985, -2.4605, -2.4547, -2.4309, -2.4641, -2.5076, -2.5016, -2.4349,\n",
      "        -2.4273, -2.5122, -2.4328, -2.4694, -2.4983, -2.5001, -2.4621, -2.4937,\n",
      "        -2.4999, -2.4999], device='mps:0')\n",
      "mean: tensor(-2.4770, device='mps:0')\n",
      "iter_dt 1.00s; iter 53: train loss 0.50545 temperature: 7.649999999999991\n",
      "mean_logits tensor([-2.5624, -2.5790, -2.2972, -2.5271, -2.1205, -2.4311, -2.3322, -2.5574,\n",
      "        -2.6379, -2.4108, -2.3614, -2.4413, -2.2741, -2.2950, -2.5025, -2.5310,\n",
      "        -2.4532, -2.5799, -2.4538, -2.2092, -2.3473, -2.2893, -2.9019, -2.3220,\n",
      "        -2.5647, -2.1758, -2.5270, -2.5967, -2.2879, -2.7723, -2.2114, -2.4232,\n",
      "        -2.2394, -2.4221, -2.2773, -2.2818, -2.0654, -2.4907, -2.1085, -2.5878,\n",
      "        -2.3217, -2.5359, -2.3555, -2.4582, -2.3483, -2.4906, -2.2147, -2.5153,\n",
      "        -2.5290, -2.2664], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4985, -2.4943, -2.5160, -2.4963, -2.4069, -2.4162, -2.4998, -2.4747,\n",
      "        -2.4993, -2.4306, -2.4938, -2.4745, -2.4387, -2.4511, -2.4452, -2.4604,\n",
      "        -2.4861, -2.4600, -2.4907, -2.4713, -2.4769, -2.4290, -2.5007, -2.4895,\n",
      "        -2.5019, -2.4773, -2.4942, -2.5006, -2.4916, -2.5003, -2.4921, -2.4768,\n",
      "        -2.4584, -2.4671, -2.4981, -2.3855, -2.4471, -2.5044, -2.4431, -2.4860,\n",
      "        -2.4711, -2.4954, -2.5013, -2.4393, -2.4575, -2.4561, -2.4808, -2.5012,\n",
      "        -2.4978, -2.4880], device='mps:0')\n",
      "mean: tensor(-2.4743, device='mps:0')\n",
      "iter_dt 1.01s; iter 54: train loss 0.59472 temperature: 7.69999999999999\n",
      "mean_logits tensor([-2.6259, -2.6281, -2.4427, -2.3268, -2.7527, -2.2138, -2.5178, -2.3487,\n",
      "        -2.3389, -2.6123, -2.4519, -1.8177, -2.3965, -2.3788, -2.3214, -2.2841,\n",
      "        -2.2156, -2.3743, -2.4598, -2.5501, -2.0984, -2.5834, -2.0018, -2.6303,\n",
      "        -2.3302, -2.6455, -2.7187, -2.5237, -2.5943, -2.3322, -2.5755, -2.6347,\n",
      "        -2.3669, -2.5958, -2.2848, -2.4496, -2.4964, -2.1513, -2.5138, -2.4197,\n",
      "        -2.4573, -2.4890, -2.5950, -2.0792, -2.4651, -2.4208, -2.4657, -2.3666,\n",
      "        -2.7274, -2.5113], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5001, -2.4651, -2.4626, -2.5024, -2.4852, -2.4560, -2.5006, -2.4899,\n",
      "        -2.4498, -2.5006, -2.4981, -2.5008, -2.4789, -2.4980, -2.4932, -2.5014,\n",
      "        -2.5019, -2.4953, -2.4849, -2.4869, -2.4848, -2.4988, -2.4909, -2.5003,\n",
      "        -2.3522, -2.4993, -2.4657, -2.5083, -2.4900, -2.4978, -2.4610, -2.4997,\n",
      "        -2.4878, -2.4399, -2.4893, -2.4989, -2.4987, -2.4997, -2.4897, -2.4660,\n",
      "        -2.4631, -2.4028, -2.5074, -2.5026, -2.4528, -2.4774, -2.4282, -2.4752,\n",
      "        -2.4996, -2.5089], device='mps:0')\n",
      "mean: tensor(-2.4818, device='mps:0')\n",
      "iter_dt 1.00s; iter 55: train loss 0.73726 temperature: 7.74999999999999\n",
      "mean_logits tensor([-2.3792, -2.4209, -2.5148, -2.5037, -2.3603, -2.3714, -2.2028, -2.5420,\n",
      "        -2.7358, -2.2668, -2.4915, -2.7422, -2.5058, -2.4724, -2.5951, -2.4143,\n",
      "        -2.4466, -2.4726, -2.1736, -2.0167, -2.4435, -2.0734, -2.4653, -2.3099,\n",
      "        -2.3703, -2.3847, -2.2652, -2.1687, -2.6067, -2.1312, -2.1918, -2.0233,\n",
      "        -2.6692, -2.4375, -2.3861, -2.5235, -2.3280, -2.5032, -2.6970, -2.9496,\n",
      "        -2.5159, -2.5801, -2.6999, -2.6799, -2.4320, -2.1814, -2.3994, -2.4835,\n",
      "        -2.2667, -2.4156], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4536, -2.5025, -2.4161, -2.4649, -2.5065, -2.4355, -2.5028, -2.4935,\n",
      "        -2.4652, -2.4507, -2.4978, -2.4694, -2.4929, -2.4593, -2.4688, -2.4606,\n",
      "        -2.4616, -2.4520, -2.4770, -2.4903, -2.4677, -2.4523, -2.4803, -2.4663,\n",
      "        -2.4992, -2.5010, -2.5001, -2.5025, -2.4464, -2.4408, -2.4787, -2.4281,\n",
      "        -2.4345, -2.5017, -2.4379, -2.4421, -2.4836, -2.5003, -2.5003, -2.4973,\n",
      "        -2.4487, -2.4483, -2.3964, -2.4527, -2.4377, -2.5010, -2.4970, -2.4274,\n",
      "        -2.5011, -2.4350], device='mps:0')\n",
      "mean: tensor(-2.4685, device='mps:0')\n",
      "iter_dt 1.00s; iter 56: train loss 0.50016 temperature: 7.79999999999999\n",
      "mean_logits tensor([-2.6652, -2.5540, -2.5245, -2.3220, -2.5998, -2.3375, -2.4441, -2.3715,\n",
      "        -2.0568, -2.6373, -2.4421, -2.4554, -2.6618, -2.7033, -2.4785, -2.4107,\n",
      "        -2.3478, -2.4077, -2.4662, -2.6415, -2.6818, -2.7139, -2.2819, -2.5694,\n",
      "        -2.2964, -2.4380, -2.5963, -2.5862, -2.5397, -2.7176, -2.4088, -2.7322,\n",
      "        -2.5925, -2.3180, -1.9885, -2.1578, -2.5612, -2.1760, -2.2946, -2.1746,\n",
      "        -2.2640, -2.3911, -2.7500, -2.4021, -2.5343, -2.5098, -2.2890, -2.3828,\n",
      "        -2.3969, -2.2875], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4991, -2.4535, -2.4868, -2.4880, -2.4938, -2.5001, -2.4286, -2.5043,\n",
      "        -2.4470, -2.4983, -2.4973, -2.4648, -2.4685, -2.5091, -2.4972, -2.4932,\n",
      "        -2.4905, -2.4461, -2.4328, -2.4793, -2.5007, -2.5029, -2.4804, -2.3420,\n",
      "        -2.5090, -2.4778, -2.4613, -2.5074, -2.5038, -2.4922, -2.4963, -2.5000,\n",
      "        -2.4541, -2.4119, -2.4177, -2.4067, -2.4933, -2.4873, -2.4194, -2.4405,\n",
      "        -2.5019, -2.4886, -2.5009, -2.3850, -2.5013, -2.4772, -2.4387, -2.4685,\n",
      "        -2.5008, -2.4056], device='mps:0')\n",
      "mean: tensor(-2.4710, device='mps:0')\n",
      "iter_dt 1.00s; iter 57: train loss 0.46855 temperature: 7.84999999999999\n",
      "mean_logits tensor([-2.5895, -2.4613, -2.3766, -2.3071, -2.5542, -2.1675, -2.1868, -2.5166,\n",
      "        -2.5118, -2.1952, -2.1476, -2.4599, -2.4377, -2.3317, -2.5900, -2.4464,\n",
      "        -2.3920, -2.3569, -2.3431, -2.4023, -2.6789, -2.5532, -2.5372, -2.2383,\n",
      "        -2.4778, -2.5454, -2.5975, -2.2787, -2.2320, -2.4435, -2.4742, -2.5008,\n",
      "        -2.0541, -2.2532, -2.4081, -2.3675, -2.0952, -2.2841, -2.6949, -2.5169,\n",
      "        -2.5880, -2.6030, -2.4365, -2.4250, -2.3786, -2.4202, -2.5425, -2.0824,\n",
      "        -2.6771, -2.4806], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3839, -2.4918, -2.5010, -2.4131, -2.5014, -2.4848, -2.4942, -2.5028,\n",
      "        -2.4612, -2.4609, -2.5009, -2.4373, -2.5151, -2.4496, -2.5028, -2.4856,\n",
      "        -2.4997, -2.4462, -2.4473, -2.4987, -2.4690, -2.4417, -2.4659, -2.4418,\n",
      "        -2.4481, -2.4542, -2.5018, -2.4097, -2.4243, -2.4900, -2.4290, -2.4998,\n",
      "        -2.4682, -2.5012, -2.4648, -2.5017, -2.4989, -2.4968, -2.5005, -2.3557,\n",
      "        -2.4652, -2.4974, -2.4420, -2.5183, -2.4627, -2.4527, -2.4578, -2.4985,\n",
      "        -2.5011, -2.4953], device='mps:0')\n",
      "mean: tensor(-2.4706, device='mps:0')\n",
      "iter_dt 1.02s; iter 58: train loss 0.54288 temperature: 7.89999999999999\n",
      "mean_logits tensor([-2.3452, -2.5369, -2.7047, -2.5837, -2.7066, -2.5538, -2.4714, -2.5270,\n",
      "        -2.2635, -2.4894, -2.5560, -2.5746, -2.1967, -2.7624, -2.6290, -2.4424,\n",
      "        -2.3288, -2.3981, -2.5970, -2.3449, -2.0796, -2.4436, -2.4757, -2.4039,\n",
      "        -2.5907, -2.3747, -2.4851, -2.2574, -2.2621, -2.3472, -2.4895, -2.6616,\n",
      "        -2.5542, -2.5896, -2.5614, -2.5896, -2.7032, -2.4682, -2.7947, -2.4834,\n",
      "        -2.6236, -2.1328, -2.1926, -2.7070, -2.5477, -2.1428, -2.5959, -2.4375,\n",
      "        -2.4128, -2.6513], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4314, -2.5016, -2.4776, -2.4234, -2.4989, -2.4823, -2.4952, -2.5090,\n",
      "        -2.4834, -2.4469, -2.4971, -2.4466, -2.4908, -2.4668, -2.4767, -2.4411,\n",
      "        -2.4950, -2.4615, -2.4927, -2.4036, -2.4957, -2.4978, -2.4941, -2.4527,\n",
      "        -2.4701, -2.5006, -2.4989, -2.5003, -2.5001, -2.4939, -2.4684, -2.4706,\n",
      "        -2.5008, -2.4210, -2.4183, -2.4729, -2.5050, -2.4953, -2.4954, -2.4988,\n",
      "        -2.4774, -2.4972, -2.4713, -2.4598, -2.5013, -2.4607, -2.5026, -2.4587,\n",
      "        -2.4745, -2.4961], device='mps:0')\n",
      "mean: tensor(-2.4774, device='mps:0')\n",
      "iter_dt 1.06s; iter 59: train loss 0.60176 temperature: 7.9499999999999895\n",
      "mean_logits tensor([-2.4728, -2.4442, -2.3771, -2.3544, -2.4982, -2.2684, -2.6840, -2.3938,\n",
      "        -2.3973, -2.4856, -2.4302, -2.7989, -2.5132, -2.1848, -2.0975, -2.2500,\n",
      "        -2.4260, -2.9085, -2.4169, -2.7584, -2.4211, -2.5366, -2.3884, -2.4850,\n",
      "        -2.4946, -2.5835, -2.4178, -2.2959, -2.1571, -2.2576, -2.5269, -2.3621,\n",
      "        -2.5071, -2.4062, -2.5922, -2.1736, -2.4890, -2.7563, -2.5421, -2.4533,\n",
      "        -2.3800, -2.4485, -2.5313, -2.6093, -2.4776, -2.3446, -2.3846, -2.7501,\n",
      "        -2.5854, -2.4815], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4936, -2.4102, -2.4446, -2.4537, -2.4307, -2.4987, -2.4449, -2.4859,\n",
      "        -2.4983, -2.4929, -2.4804, -2.4394, -2.3836, -2.4647, -2.4288, -2.5012,\n",
      "        -2.4626, -2.4479, -2.4538, -2.4572, -2.4444, -2.4928, -2.4345, -2.4431,\n",
      "        -2.4912, -2.4460, -2.3861, -2.4693, -2.4680, -2.4973, -2.4113, -2.4985,\n",
      "        -2.4945, -2.4795, -2.4632, -2.4982, -2.4371, -2.4864, -2.4992, -2.5016,\n",
      "        -2.2625, -2.4884, -2.4625, -2.5002, -2.4962, -2.4939, -2.4322, -2.4249,\n",
      "        -2.5085, -2.5073], device='mps:0')\n",
      "mean: tensor(-2.4618, device='mps:0')\n",
      "iter_dt 1.05s; iter 60: train loss 0.44624 temperature: 7.999999999999989\n",
      "mean_logits tensor([-2.2581, -2.6461, -2.3669, -2.3619, -2.2568, -2.4430, -2.2285, -2.4802,\n",
      "        -2.5241, -2.6425, -2.3156, -2.4845, -2.3425, -2.3392, -2.5572, -2.5452,\n",
      "        -2.3596, -2.3659, -2.3334, -2.7884, -2.2362, -2.4621, -2.7675, -2.3108,\n",
      "        -2.1800, -2.2436, -2.5876, -2.6712, -2.4458, -2.5289, -2.2365, -2.3475,\n",
      "        -2.2648, -2.1151, -2.2502, -2.2984, -2.1928, -2.4881, -2.4045, -2.4146,\n",
      "        -2.4844, -2.5761, -2.4478, -2.2479, -2.6805, -2.6078, -2.5175, -2.3403,\n",
      "        -2.5572, -2.4729], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4781, -2.4497, -2.4665, -2.4837, -2.4045, -2.4869, -2.5009, -2.5015,\n",
      "        -2.4925, -2.4653, -2.4276, -2.4441, -2.4987, -2.4701, -2.4676, -2.5003,\n",
      "        -2.4446, -2.4260, -2.4922, -2.5048, -2.4934, -2.4840, -2.5091, -2.4954,\n",
      "        -2.4362, -2.4331, -2.4983, -2.4892, -2.5027, -2.4482, -2.4438, -2.4945,\n",
      "        -2.4972, -2.4631, -2.4972, -2.5105, -2.3538, -2.4602, -2.4473, -2.4826,\n",
      "        -2.5002, -2.4970, -2.5021, -2.4884, -2.5016, -2.5005, -2.5107, -2.4617,\n",
      "        -2.4853, -2.4099], device='mps:0')\n",
      "mean: tensor(-2.4741, device='mps:0')\n",
      "iter_dt 1.01s; iter 61: train loss 0.54439 temperature: 8.04999999999999\n",
      "mean_logits tensor([-2.3922, -2.5759, -2.5587, -2.0896, -2.7202, -2.2620, -2.4803, -2.1743,\n",
      "        -2.4785, -2.5182, -2.4650, -2.6779, -2.4240, -2.2051, -2.3203, -2.5624,\n",
      "        -2.4122, -2.7526, -2.5343, -2.6588, -2.4903, -2.4839, -2.5540, -2.3088,\n",
      "        -2.5723, -2.8352, -2.2931, -2.3061, -2.1269, -2.4197, -2.3404, -2.6176,\n",
      "        -2.4089, -2.2841, -2.3608, -2.2736, -2.4317, -2.2732, -2.3550, -2.3584,\n",
      "        -2.7425, -2.6303, -2.4167, -2.4009, -2.5507, -2.5150, -2.6501, -2.3710,\n",
      "        -2.5792, -2.5958], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4838, -2.4990, -2.4659, -2.4659, -2.4406, -2.4933, -2.4940, -2.4009,\n",
      "        -2.4955, -2.4330, -2.5008, -2.4872, -2.5132, -2.4969, -2.3606, -2.3996,\n",
      "        -2.4525, -2.4989, -2.4614, -2.5004, -2.4971, -2.4538, -2.4994, -2.4999,\n",
      "        -2.4424, -2.4903, -2.4587, -2.4763, -2.4624, -2.4883, -2.4990, -2.4246,\n",
      "        -2.4582, -2.4992, -2.4866, -2.4490, -2.4862, -2.4939, -2.5034, -2.4843,\n",
      "        -2.4466, -2.4358, -2.3514, -2.4956, -2.4397, -2.4968, -2.4631, -2.4654,\n",
      "        -2.4363, -2.4933], device='mps:0')\n",
      "mean: tensor(-2.4684, device='mps:0')\n",
      "iter_dt 0.98s; iter 62: train loss 0.76120 temperature: 8.09999999999999\n",
      "mean_logits tensor([-2.4281, -2.3338, -2.3885, -2.7613, -2.1889, -2.6073, -2.1486, -2.5947,\n",
      "        -2.3526, -2.3666, -2.6596, -2.2883, -3.0484, -2.3650, -2.5961, -2.5965,\n",
      "        -2.3948, -2.4484, -2.5585, -2.7558, -2.4478, -2.3342, -2.5397, -2.7386,\n",
      "        -2.4297, -2.6336, -2.2480, -2.5638, -2.4427, -2.4558, -2.2919, -2.2028,\n",
      "        -2.6728, -2.5848, -2.7292, -2.4540, -2.5042, -2.2844, -2.4118, -2.2552,\n",
      "        -2.2571, -2.3664, -2.1873, -2.5216, -2.4087, -2.5178, -2.1478, -2.5591,\n",
      "        -2.2900, -2.3373], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5022, -2.4994, -2.4974, -2.4821, -2.4378, -2.5017, -2.4621, -2.5032,\n",
      "        -2.4989, -2.5000, -2.4853, -2.3914, -2.4291, -2.4983, -2.4379, -2.4483,\n",
      "        -2.4457, -2.4577, -2.5060, -2.4602, -2.5005, -2.4957, -2.4975, -2.5007,\n",
      "        -2.5053, -2.5011, -2.4589, -2.4914, -2.5003, -2.4941, -2.4891, -2.4522,\n",
      "        -2.4852, -2.4636, -2.4523, -2.4615, -2.4844, -2.4760, -2.4909, -2.4624,\n",
      "        -2.4994, -2.5024, -2.4920, -2.4956, -2.5015, -2.4853, -2.4753, -2.4641,\n",
      "        -2.4659, -2.4982], device='mps:0')\n",
      "mean: tensor(-2.4798, device='mps:0')\n",
      "iter_dt 0.99s; iter 63: train loss 0.58625 temperature: 8.149999999999991\n",
      "mean_logits tensor([-2.1869, -2.3870, -2.6703, -2.5435, -2.7546, -2.4460, -2.1444, -2.4064,\n",
      "        -2.4362, -2.5521, -2.1194, -1.9653, -2.7003, -2.6076, -2.5760, -2.4139,\n",
      "        -2.1622, -2.5653, -2.4978, -2.7557, -2.7172, -2.6210, -2.4030, -2.2437,\n",
      "        -2.4522, -2.5329, -2.5775, -2.3321, -2.1798, -2.5162, -2.4902, -2.3898,\n",
      "        -2.3117, -2.2861, -2.3064, -2.4643, -2.5121, -2.4130, -2.4690, -2.3542,\n",
      "        -2.7150, -2.2888, -2.0855, -2.4255, -2.3863, -2.4482, -2.3184, -2.5011,\n",
      "        -2.4161, -1.9572], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5124, -2.4903, -2.4592, -2.5032, -2.5013, -2.4785, -2.4920, -2.4458,\n",
      "        -2.4832, -2.4999, -2.5030, -2.4860, -2.5041, -2.4638, -2.3791, -2.4272,\n",
      "        -2.4432, -2.4674, -2.5084, -2.5020, -2.4945, -2.5027, -2.4695, -2.4538,\n",
      "        -2.4434, -2.5006, -2.4871, -2.5008, -2.4745, -2.4605, -2.5002, -2.4788,\n",
      "        -2.4124, -2.4647, -2.4980, -2.4426, -2.4252, -2.4988, -2.4944, -2.4363,\n",
      "        -2.5076, -2.4659, -2.4014, -2.5073, -2.4509, -2.5401, -2.4716, -2.4593,\n",
      "        -2.5168, -2.4480], device='mps:0')\n",
      "mean: tensor(-2.4752, device='mps:0')\n",
      "iter_dt 0.99s; iter 64: train loss 0.48695 temperature: 8.199999999999992\n",
      "mean_logits tensor([-2.4069, -2.3191, -2.4646, -2.5237, -2.4775, -2.5765, -2.6474, -2.0813,\n",
      "        -2.7147, -2.4245, -2.3584, -2.0200, -2.4370, -2.7330, -2.2728, -2.6037,\n",
      "        -2.5189, -2.5529, -2.3097, -2.3539, -2.5372, -2.6227, -2.3381, -2.3439,\n",
      "        -2.3920, -2.3157, -2.4725, -2.5747, -2.2224, -2.2795, -2.5065, -2.4215,\n",
      "        -2.4540, -2.0542, -2.3812, -2.4775, -2.5461, -2.3724, -2.4399, -2.4802,\n",
      "        -2.3748, -2.3243, -2.4407, -2.7119, -2.3089, -1.9912, -2.4407, -2.5948,\n",
      "        -2.4036, -2.3663], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4878, -2.5000, -2.4342, -2.4531, -2.4752, -2.5088, -2.4284, -2.4715,\n",
      "        -2.5009, -2.5030, -2.4635, -2.4534, -2.5197, -2.4248, -2.4984, -2.4080,\n",
      "        -2.4904, -2.4945, -2.4667, -2.4868, -2.4740, -2.4839, -2.4546, -2.4743,\n",
      "        -2.4594, -2.4661, -2.4399, -2.4931, -2.4981, -2.5034, -2.5546, -2.4985,\n",
      "        -2.5083, -2.3545, -2.5016, -2.4469, -2.4493, -2.4158, -2.4994, -2.4376,\n",
      "        -2.5044, -2.4874, -2.4549, -2.4321, -2.4692, -2.4733, -2.4693, -2.4760,\n",
      "        -2.4863, -2.5015], device='mps:0')\n",
      "mean: tensor(-2.4727, device='mps:0')\n",
      "iter_dt 1.00s; iter 65: train loss 0.59624 temperature: 8.249999999999993\n",
      "mean_logits tensor([-2.2618, -2.5155, -2.2972, -2.1400, -2.4252, -2.5102, -2.3050, -2.1174,\n",
      "        -2.3135, -2.4822, -2.2894, -2.2604, -2.3261, -2.5165, -2.6691, -2.5972,\n",
      "        -2.0587, -2.6212, -2.3652, -2.2672, -2.1728, -2.7133, -2.2099, -2.5856,\n",
      "        -2.2202, -2.4061, -2.1874, -2.0898, -2.5957, -2.5400, -2.4376, -2.5416,\n",
      "        -2.2221, -2.4385, -2.6585, -2.1373, -2.7469, -2.2032, -2.5268, -2.5849,\n",
      "        -2.3205, -2.5410, -2.3448, -2.3016, -2.5165, -2.4092, -2.5266, -2.4638,\n",
      "        -2.2721, -2.3370], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4365, -2.4593, -2.5069, -2.4898, -2.4785, -2.4938, -2.4265, -2.4905,\n",
      "        -2.3945, -2.5009, -2.5091, -2.4871, -2.4939, -2.4987, -2.4927, -2.4895,\n",
      "        -2.5023, -2.4602, -2.4903, -2.4410, -2.4835, -2.4325, -2.4398, -2.4360,\n",
      "        -2.5041, -2.4706, -2.4294, -2.4544, -2.5010, -2.4932, -2.4859, -2.4998,\n",
      "        -2.4651, -2.4450, -2.4984, -2.4787, -2.5082, -2.4986, -2.4966, -2.4707,\n",
      "        -2.4737, -2.4931, -2.4818, -2.4812, -2.3838, -2.4899, -2.4891, -2.4485,\n",
      "        -2.5010, -2.4580], device='mps:0')\n",
      "mean: tensor(-2.4747, device='mps:0')\n",
      "iter_dt 1.41s; iter 66: train loss 0.46947 temperature: 8.299999999999994\n",
      "mean_logits tensor([-2.4162, -2.6278, -2.5730, -2.1053, -2.4239, -2.3363, -2.4998, -2.6941,\n",
      "        -2.4592, -2.6645, -2.6371, -2.2609, -2.5716, -2.4320, -2.6028, -2.2570,\n",
      "        -2.3502, -2.4037, -2.6548, -2.7441, -2.4098, -2.4872, -2.6578, -2.7803,\n",
      "        -2.5882, -2.3807, -2.6989, -2.6407, -2.5091, -2.4191, -2.3281, -2.2319,\n",
      "        -2.3929, -2.4753, -2.5305, -2.3671, -2.4670, -2.3739, -2.2466, -2.5113,\n",
      "        -2.2429, -2.2532, -2.5186, -2.3386, -2.0797, -2.7070, -2.4262, -2.5212,\n",
      "        -2.7099, -2.5042], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4587, -2.4914, -2.5005, -2.5013, -2.4465, -2.4570, -2.4969, -2.4564,\n",
      "        -2.4888, -2.4942, -2.4308, -2.4546, -2.4784, -2.4355, -2.4864, -2.4981,\n",
      "        -2.3559, -2.4617, -2.4992, -2.5011, -2.4780, -2.5015, -2.5000, -2.5374,\n",
      "        -2.4970, -2.3866, -2.5009, -2.4953, -2.4866, -2.4988, -2.5030, -2.4658,\n",
      "        -2.4848, -2.4181, -2.5018, -2.4642, -2.4974, -2.4688, -2.4932, -2.4903,\n",
      "        -2.5007, -2.5017, -2.5001, -2.4581, -2.4630, -2.5002, -2.5040, -2.4786,\n",
      "        -2.4989, -2.4515], device='mps:0')\n",
      "mean: tensor(-2.4784, device='mps:0')\n",
      "iter_dt 1.42s; iter 67: train loss 0.57234 temperature: 8.349999999999994\n",
      "mean_logits tensor([-2.4522, -2.5081, -2.7062, -2.2689, -2.3101, -2.2534, -2.6125, -2.4961,\n",
      "        -2.4129, -2.4904, -2.6043, -2.5998, -2.6625, -2.5489, -2.5746, -2.5790,\n",
      "        -2.3881, -2.3586, -2.4418, -2.3326, -1.9376, -2.1027, -2.2675, -2.1200,\n",
      "        -2.4228, -2.7657, -2.4677, -2.4426, -2.4434, -2.4181, -2.3248, -2.1111,\n",
      "        -2.2605, -2.3227, -2.3007, -2.3666, -2.1540, -2.5829, -2.4392, -2.3736,\n",
      "        -2.7119, -2.5295, -2.5964, -2.2518, -2.6189, -2.4555, -2.5359, -2.3799,\n",
      "        -2.3919, -2.3409], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4489, -2.4642, -2.3420, -2.4500, -2.5029, -2.5085, -2.5015, -2.4362,\n",
      "        -2.4869, -2.4971, -2.4085, -2.4966, -2.4595, -2.4991, -2.4510, -2.4836,\n",
      "        -2.5170, -2.4538, -2.4742, -2.4384, -2.4886, -2.5004, -2.4575, -2.4497,\n",
      "        -2.4679, -2.4984, -2.4785, -2.4939, -2.4959, -2.4646, -2.4819, -2.4990,\n",
      "        -2.4867, -2.4369, -2.5006, -2.4960, -2.4950, -2.4944, -2.4309, -2.4993,\n",
      "        -2.4649, -2.5032, -2.4407, -2.4054, -2.4419, -2.4955, -2.4973, -2.4630,\n",
      "        -2.4802, -2.4896], device='mps:0')\n",
      "mean: tensor(-2.4724, device='mps:0')\n",
      "iter_dt 1.41s; iter 68: train loss 0.51921 temperature: 8.399999999999995\n",
      "mean_logits tensor([-2.2241, -2.5070, -2.4961, -2.3437, -2.4180, -2.2930, -2.4053, -2.7389,\n",
      "        -2.2746, -2.4129, -2.3562, -2.5858, -2.6156, -2.1158, -2.3275, -2.5043,\n",
      "        -2.4025, -2.4113, -2.2594, -2.4511, -2.4561, -2.4811, -2.2778, -2.6436,\n",
      "        -2.3747, -2.1905, -2.3716, -2.2324, -2.8029, -2.4184, -2.5027, -2.4986,\n",
      "        -2.3814, -2.3705, -2.6146, -2.5317, -2.4485, -2.3955, -2.2294, -2.5011,\n",
      "        -2.4317, -2.6661, -2.6572, -2.2351, -2.4450, -2.4093, -2.6224, -2.2279,\n",
      "        -1.9911, -2.0987], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4904, -2.5043, -2.4705, -2.4779, -2.4801, -2.3943, -2.5004, -2.4620,\n",
      "        -2.4997, -2.4773, -2.4596, -2.4950, -2.4638, -2.5158, -2.3918, -2.4668,\n",
      "        -2.5002, -2.5066, -2.4679, -2.4935, -2.4752, -2.4469, -2.5008, -2.4419,\n",
      "        -2.4565, -2.4321, -2.5061, -2.4721, -2.4971, -2.4972, -2.4741, -2.4979,\n",
      "        -2.4664, -2.5030, -2.4729, -2.4660, -2.4958, -2.5061, -2.4837, -2.4869,\n",
      "        -2.5001, -2.4931, -2.4815, -2.5026, -2.4293, -2.4951, -2.4996, -2.4349,\n",
      "        -2.4590, -2.4938], device='mps:0')\n",
      "mean: tensor(-2.4777, device='mps:0')\n",
      "iter_dt 1.37s; iter 69: train loss 0.68471 temperature: 8.449999999999996\n",
      "mean_logits tensor([-2.4935, -2.6521, -2.4243, -2.4350, -2.1320, -2.3439, -2.4036, -2.3198,\n",
      "        -2.1824, -2.1897, -2.4736, -2.6013, -2.2540, -2.1157, -2.6412, -2.2862,\n",
      "        -2.4578, -2.4920, -2.3524, -2.5780, -2.4399, -2.3749, -2.0702, -2.3161,\n",
      "        -2.4970, -2.4492, -2.5643, -2.1604, -2.2560, -2.5506, -2.5232, -2.1235,\n",
      "        -2.2474, -2.4764, -2.1020, -2.7361, -2.5995, -2.4489, -2.0569, -2.7679,\n",
      "        -2.2070, -2.6558, -2.3012, -2.2300, -2.2546, -2.3352, -2.0555, -2.4434,\n",
      "        -2.2933, -2.2847], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4961, -2.5189, -2.4588, -2.4959, -2.5123, -2.4439, -2.4438, -2.5026,\n",
      "        -2.4502, -2.4520, -2.4906, -2.4865, -2.4885, -2.5003, -2.5022, -2.4708,\n",
      "        -2.4701, -2.4993, -2.4914, -2.4395, -2.4674, -2.4896, -2.4858, -2.4628,\n",
      "        -2.4492, -2.4663, -2.4917, -2.4946, -2.4972, -2.5004, -2.4981, -2.5035,\n",
      "        -2.3886, -2.4925, -2.4411, -2.4441, -2.5094, -2.5212, -2.4690, -2.5011,\n",
      "        -2.4807, -2.4221, -2.4832, -2.4666, -2.4992, -2.4469, -2.5040, -2.4759,\n",
      "        -2.3708, -2.4903], device='mps:0')\n",
      "mean: tensor(-2.4765, device='mps:0')\n",
      "iter_dt 1.42s; iter 70: train loss 0.42751 temperature: 8.499999999999996\n",
      "mean_logits tensor([-2.4538, -2.4038, -2.3435, -2.1924, -2.3112, -2.5041, -2.4916, -2.5101,\n",
      "        -2.4356, -2.4013, -2.2883, -2.4186, -2.2390, -2.5403, -2.3889, -2.6587,\n",
      "        -2.3320, -2.8729, -2.5009, -2.5488, -2.4446, -2.3117, -2.4568, -2.1471,\n",
      "        -2.5973, -2.7021, -2.4202, -2.3943, -2.2419, -2.3872, -2.5632, -2.4941,\n",
      "        -2.6018, -2.4446, -2.7059, -2.5899, -2.1917, -2.3326, -2.3615, -2.2861,\n",
      "        -2.3653, -2.3659, -2.4961, -2.4869, -2.4697, -2.4164, -2.5528, -2.2499,\n",
      "        -2.3781, -2.6195], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4905, -2.4902, -2.5000, -2.4801, -2.4998, -2.4510, -2.4993, -2.4788,\n",
      "        -2.4882, -2.4796, -2.4910, -2.4878, -2.4983, -2.4537, -2.4162, -2.4435,\n",
      "        -2.5007, -2.4798, -2.4760, -2.4516, -2.5011, -2.4860, -2.4910, -2.4265,\n",
      "        -2.5003, -2.4543, -2.4877, -2.4818, -2.4297, -2.5010, -2.4192, -2.4986,\n",
      "        -2.4593, -2.4332, -2.5019, -2.4950, -2.4719, -2.4657, -2.4365, -2.4977,\n",
      "        -2.4102, -2.4817, -2.4051, -2.4772, -2.4577, -2.4279, -2.5031, -2.5016,\n",
      "        -2.4966, -2.4994], device='mps:0')\n",
      "mean: tensor(-2.4731, device='mps:0')\n",
      "iter_dt 1.28s; iter 71: train loss 0.43010 temperature: 8.549999999999997\n",
      "mean_logits tensor([-2.2436, -2.6549, -2.3693, -2.5429, -2.6355, -2.4893, -2.3390, -2.6190,\n",
      "        -2.5823, -2.3982, -2.4618, -2.5740, -2.1566, -2.4591, -2.5873, -2.6667,\n",
      "        -2.3602, -2.4262, -2.5908, -2.5455, -2.6577, -2.3963, -2.5436, -2.6618,\n",
      "        -2.4463, -2.5522, -2.2592, -2.3349, -2.0028, -2.5631, -2.3770, -2.1724,\n",
      "        -2.0791, -2.4571, -2.5180, -2.0604, -2.3419, -2.2675, -2.3818, -2.5260,\n",
      "        -2.7187, -2.3981, -2.7489, -2.4190, -2.3669, -2.2672, -2.3084, -2.3019,\n",
      "        -2.4339, -2.6469], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4959, -2.4926, -2.4359, -2.4610, -2.4982, -2.5110, -2.4741, -2.5055,\n",
      "        -2.4790, -2.4657, -2.4466, -2.4975, -2.4199, -2.4987, -2.4639, -2.5010,\n",
      "        -2.4931, -2.4977, -2.4565, -2.5014, -2.4443, -2.5000, -2.4710, -2.4684,\n",
      "        -2.4973, -2.4995, -2.4667, -2.4516, -2.3983, -2.4917, -2.4987, -2.4485,\n",
      "        -2.4041, -2.4179, -2.4639, -2.4939, -2.4413, -2.4116, -2.4390, -2.4936,\n",
      "        -2.5148, -2.4854, -2.4911, -2.5004, -2.3879, -2.4386, -2.4945, -2.4145,\n",
      "        -2.4291, -2.4955], device='mps:0')\n",
      "mean: tensor(-2.4690, device='mps:0')\n",
      "iter_dt 1.21s; iter 72: train loss 0.35508 temperature: 8.599999999999998\n",
      "mean_logits tensor([-2.5651, -2.5316, -2.4148, -2.7666, -2.3281, -2.4050, -2.6545, -2.6052,\n",
      "        -2.3261, -2.3681, -2.6254, -2.3394, -2.5957, -2.4107, -2.1058, -2.2514,\n",
      "        -2.2794, -2.2598, -2.4323, -2.4431, -2.7453, -2.3095, -2.6261, -2.4484,\n",
      "        -2.3056, -2.5227, -2.3200, -2.4647, -2.3925, -2.4638, -2.4618, -2.4337,\n",
      "        -2.3149, -2.5120, -2.3404, -2.4759, -2.3936, -2.4872, -2.5413, -2.2713,\n",
      "        -2.3937, -2.4105, -2.4524, -2.6499, -2.4533, -2.3379, -2.5684, -2.4247,\n",
      "        -2.2190, -2.4022], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4992, -2.4551, -2.5030, -2.4648, -2.4639, -2.4360, -2.4884, -2.4975,\n",
      "        -2.4495, -2.4392, -2.4776, -2.5005, -2.3973, -2.4455, -2.4662, -2.4330,\n",
      "        -2.4415, -2.4906, -2.4993, -2.4766, -2.4657, -2.5035, -2.4895, -2.4360,\n",
      "        -2.4794, -2.5030, -2.4641, -2.5158, -2.4596, -2.4673, -2.5017, -2.4475,\n",
      "        -2.4956, -2.5008, -2.4646, -2.4916, -2.4360, -2.5038, -2.4850, -2.5008,\n",
      "        -2.4339, -2.4551, -2.4909, -2.4411, -2.4433, -2.5011, -2.4937, -2.4530,\n",
      "        -2.4563, -2.4343], device='mps:0')\n",
      "mean: tensor(-2.4708, device='mps:0')\n",
      "iter_dt 1.26s; iter 73: train loss 0.53159 temperature: 8.649999999999999\n",
      "mean_logits tensor([-2.3747, -2.4030, -2.7491, -2.6996, -2.4397, -2.5791, -2.5087, -2.3377,\n",
      "        -2.5956, -2.7073, -2.6390, -2.4429, -2.6289, -2.5242, -2.7274, -2.3922,\n",
      "        -2.3029, -2.6949, -2.4625, -2.5109, -2.4183, -2.0755, -2.5036, -2.3099,\n",
      "        -2.3226, -2.4248, -2.2634, -2.2924, -2.4508, -2.4203, -2.3907, -2.3700,\n",
      "        -2.5898, -2.6252, -2.2694, -2.2895, -2.5450, -2.3046, -2.4661, -2.7059,\n",
      "        -2.6052, -2.2877, -2.3204, -2.2274, -2.5547, -2.2868, -2.6364, -2.2525,\n",
      "        -2.7825, -2.3455], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4945, -2.4978, -2.4915, -2.4966, -2.4939, -2.5017, -2.4379, -2.4189,\n",
      "        -2.4455, -2.4759, -2.4665, -2.4010, -2.4530, -2.4914, -2.5031, -2.4436,\n",
      "        -2.4553, -2.4722, -2.5051, -2.5038, -2.4859, -2.4985, -2.4695, -2.4959,\n",
      "        -2.4943, -2.4958, -2.4761, -2.4897, -2.4792, -2.4829, -2.4375, -2.4334,\n",
      "        -2.4569, -2.4917, -2.4888, -2.4895, -2.4798, -2.4836, -2.5008, -2.4213,\n",
      "        -2.4480, -2.4684, -2.4744, -2.4646, -2.4570, -2.4567, -2.4795, -2.4989,\n",
      "        -2.4863, -2.4972], device='mps:0')\n",
      "mean: tensor(-2.4746, device='mps:0')\n",
      "iter_dt 1.22s; iter 74: train loss 0.46936 temperature: 8.7\n",
      "mean_logits tensor([-2.4829, -2.4482, -2.3516, -2.2228, -2.6872, -2.3256, -2.2257, -2.2816,\n",
      "        -2.2916, -2.4947, -2.4253, -2.4553, -2.5492, -2.5627, -2.5808, -2.2956,\n",
      "        -2.1182, -2.2315, -2.6596, -2.0347, -2.3186, -2.6159, -2.2542, -2.1352,\n",
      "        -2.2595, -2.3393, -2.6533, -2.3036, -2.5332, -2.6869, -2.6603, -2.5872,\n",
      "        -2.4845, -2.5716, -2.5165, -2.4801, -2.5943, -2.5063, -2.2214, -2.4709,\n",
      "        -2.6540, -2.5467, -2.3418, -2.5502, -2.6115, -2.5579, -2.3447, -2.3479,\n",
      "        -2.3209, -2.4065], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4992, -2.3964, -2.4049, -2.4788, -2.4642, -2.4704, -2.4971, -2.4004,\n",
      "        -2.5013, -2.4985, -2.4976, -2.4984, -2.5006, -2.5144, -2.4980, -2.4400,\n",
      "        -2.5060, -2.4895, -2.4514, -2.4357, -2.4853, -2.4986, -2.4997, -2.4985,\n",
      "        -2.4121, -2.4380, -2.4984, -2.4883, -2.5184, -2.4591, -2.4327, -2.5031,\n",
      "        -2.4852, -2.4970, -2.5026, -2.4589, -2.4954, -2.4824, -2.4885, -2.4413,\n",
      "        -2.5035, -2.4990, -2.4691, -2.4067, -2.4318, -2.4306, -2.4758, -2.4821,\n",
      "        -2.3986, -2.4067], device='mps:0')\n",
      "mean: tensor(-2.4706, device='mps:0')\n",
      "iter_dt 1.27s; iter 75: train loss 0.38837 temperature: 8.75\n",
      "mean_logits tensor([-2.3224, -2.3513, -2.5807, -2.5000, -2.3008, -2.6505, -2.2225, -2.0780,\n",
      "        -2.3923, -2.5812, -2.5148, -2.1187, -2.4529, -2.4135, -2.7301, -2.3027,\n",
      "        -2.4269, -2.4620, -2.6530, -2.2635, -2.3480, -2.6454, -2.5355, -2.6187,\n",
      "        -2.4742, -2.4545, -2.5367, -2.5996, -2.4944, -2.5425, -2.3422, -2.3608,\n",
      "        -2.2280, -2.3873, -2.4417, -2.2420, -2.2906, -2.2132, -2.4701, -2.5549,\n",
      "        -2.3898, -2.3511, -2.3740, -2.3491, -2.5911, -2.3031, -2.4545, -2.5645,\n",
      "        -2.4535, -2.3563], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5003, -2.4743, -2.4984, -2.4587, -2.4868, -2.5009, -2.4742, -2.4760,\n",
      "        -2.3980, -2.4955, -2.5003, -2.4350, -2.5015, -2.4984, -2.4150, -2.5010,\n",
      "        -2.5041, -2.4931, -2.4952, -2.4723, -2.4910, -2.4948, -2.4641, -2.4993,\n",
      "        -2.4889, -2.4810, -2.4976, -2.5264, -2.4587, -2.4828, -2.4812, -2.4115,\n",
      "        -2.4782, -2.4128, -2.5002, -2.4946, -2.5015, -2.4947, -2.4704, -2.5078,\n",
      "        -2.4250, -2.4963, -2.4632, -2.4818, -2.4537, -2.4943, -2.4981, -2.4139,\n",
      "        -2.4679, -2.4446], device='mps:0')\n",
      "mean: tensor(-2.4771, device='mps:0')\n",
      "iter_dt 1.18s; iter 76: train loss 0.47294 temperature: 8.8\n",
      "mean_logits tensor([-2.4005, -2.6535, -2.0227, -2.6153, -2.1842, -2.4350, -2.1180, -2.5356,\n",
      "        -2.2912, -2.6658, -2.2204, -2.5698, -2.4857, -2.6022, -2.4884, -2.4539,\n",
      "        -2.5526, -2.7370, -2.6674, -2.3561, -2.5698, -2.2856, -2.2071, -2.5154,\n",
      "        -2.6284, -2.4501, -2.5234, -2.2765, -2.5792, -2.7201, -2.5449, -2.4961,\n",
      "        -2.3753, -2.7064, -2.4397, -2.6118, -2.4250, -2.5081, -2.5262, -2.3844,\n",
      "        -2.3184, -2.6170, -2.4425, -2.4484, -2.0887, -2.3123, -2.5137, -2.2692,\n",
      "        -2.4658, -2.3338], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4750, -2.4622, -2.4737, -2.4017, -2.5074, -2.5006, -2.4311, -2.4345,\n",
      "        -2.5001, -2.4895, -2.5025, -2.4942, -2.4954, -2.4966, -2.4510, -2.4959,\n",
      "        -2.4387, -2.4966, -2.4951, -2.4761, -2.5006, -2.4610, -2.4654, -2.4728,\n",
      "        -2.4831, -2.4736, -2.4986, -2.4530, -2.4965, -2.4811, -2.5007, -2.4603,\n",
      "        -2.4435, -2.4928, -2.4666, -2.4978, -2.4012, -2.4990, -2.5004, -2.4685,\n",
      "        -2.5001, -2.4833, -2.4172, -2.5167, -2.4474, -2.5006, -2.4706, -2.4904,\n",
      "        -2.4945, -2.4938], device='mps:0')\n",
      "mean: tensor(-2.4770, device='mps:0')\n",
      "iter_dt 1.20s; iter 77: train loss 0.48044 temperature: 8.850000000000001\n",
      "mean_logits tensor([-2.7316, -2.6635, -2.4203, -2.7698, -2.3657, -2.3332, -2.6759, -2.5127,\n",
      "        -2.3103, -2.2175, -2.5201, -2.3995, -2.2620, -2.6038, -2.3189, -2.4991,\n",
      "        -2.2449, -2.4819, -2.2231, -2.2397, -2.3762, -2.2993, -2.4264, -2.4014,\n",
      "        -2.2429, -2.7124, -2.4446, -2.5285, -2.1726, -2.3360, -2.2031, -2.2241,\n",
      "        -2.3352, -2.1383, -2.7892, -2.4140, -2.5505, -2.3837, -2.5087, -2.4345,\n",
      "        -2.3953, -2.4161, -2.3395, -2.3661, -2.5753, -2.5891, -2.4271, -2.4033,\n",
      "        -2.6259, -2.4204], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4794, -2.5008, -2.5113, -2.4652, -2.4184, -2.5014, -2.4608, -2.4441,\n",
      "        -2.4444, -2.4692, -2.4949, -2.4880, -2.5001, -2.4942, -2.3952, -2.4944,\n",
      "        -2.4386, -2.5020, -2.3949, -2.4503, -2.4461, -2.4706, -2.4971, -2.5074,\n",
      "        -2.4596, -2.4623, -2.4929, -2.4727, -2.4513, -2.5008, -2.4858, -2.4383,\n",
      "        -2.4064, -2.5037, -2.5010, -2.4360, -2.4998, -2.4381, -2.4925, -2.4610,\n",
      "        -2.4858, -2.5008, -2.5150, -2.4949, -2.4748, -2.4835, -2.4928, -2.4993,\n",
      "        -2.4575, -2.4469], device='mps:0')\n",
      "mean: tensor(-2.4724, device='mps:0')\n",
      "iter_dt 1.12s; iter 78: train loss 0.50910 temperature: 8.900000000000002\n",
      "mean_logits tensor([-2.4926, -2.6771, -2.4721, -2.1980, -2.2356, -2.2307, -2.0090, -2.2555,\n",
      "        -2.5576, -2.4674, -2.4642, -2.4935, -2.6582, -2.4664, -2.2409, -2.5575,\n",
      "        -2.5072, -2.2128, -2.5054, -2.2011, -2.0267, -2.1489, -2.4612, -2.5902,\n",
      "        -2.7299, -2.4225, -2.6492, -2.6344, -2.5506, -2.3155, -2.6226, -2.1928,\n",
      "        -2.5711, -2.3622, -2.6870, -2.4895, -2.3172, -2.4302, -2.1370, -2.5214,\n",
      "        -2.4464, -2.5343, -2.4748, -2.5475, -2.2731, -2.4595, -2.4979, -2.2346,\n",
      "        -2.1504, -2.3423], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4796, -2.4867, -2.5031, -2.4924, -2.4948, -2.5061, -2.4491, -2.4057,\n",
      "        -2.4859, -2.4321, -2.4978, -2.4946, -2.4974, -2.4176, -2.4742, -2.5030,\n",
      "        -2.4927, -2.4113, -2.4456, -2.4904, -2.4487, -2.4685, -2.4605, -2.4949,\n",
      "        -2.4923, -2.4995, -2.4893, -2.4894, -2.4357, -2.4939, -2.5018, -2.4362,\n",
      "        -2.4960, -2.4549, -2.4795, -2.4846, -2.4428, -2.4387, -2.4336, -2.4754,\n",
      "        -2.4462, -2.4598, -2.4941, -2.5024, -2.4976, -2.5022, -2.5090, -2.4634,\n",
      "        -2.4884, -2.5016], device='mps:0')\n",
      "mean: tensor(-2.4748, device='mps:0')\n",
      "iter_dt 1.14s; iter 79: train loss 0.41942 temperature: 8.950000000000003\n",
      "mean_logits tensor([-2.4416, -2.0693, -2.3590, -2.4591, -2.4398, -2.4107, -2.3698, -2.3943,\n",
      "        -2.7429, -2.3197, -2.5600, -2.4236, -2.8045, -2.5516, -2.4261, -2.1335,\n",
      "        -2.5478, -2.3806, -2.3780, -2.4289, -2.6949, -2.4566, -2.2116, -2.3938,\n",
      "        -2.3679, -2.3313, -2.3893, -2.3117, -2.5211, -2.3220, -2.4368, -2.3020,\n",
      "        -2.4665, -2.3843, -2.2229, -2.2790, -2.3912, -2.7070, -2.5944, -2.4272,\n",
      "        -2.4841, -2.7312, -2.2558, -2.5328, -2.5120, -2.4412, -2.5188, -2.5421,\n",
      "        -2.3811, -2.2431], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4962, -2.4942, -2.5131, -2.4829, -2.5011, -2.4729, -2.4564, -2.4655,\n",
      "        -2.4995, -2.4982, -2.4985, -2.4682, -2.4895, -2.3940, -2.5032, -2.4975,\n",
      "        -2.5016, -2.4942, -2.4993, -2.4978, -2.4991, -2.4799, -2.4266, -2.4972,\n",
      "        -2.4358, -2.4918, -2.4988, -2.4542, -2.4371, -2.4601, -2.4797, -2.5017,\n",
      "        -2.4788, -2.4524, -2.4966, -2.4375, -2.4460, -2.5007, -2.4840, -2.4984,\n",
      "        -2.4523, -2.5038, -2.4373, -2.4848, -2.4894, -2.4892, -2.5015, -2.4536,\n",
      "        -2.4143, -2.4519], device='mps:0')\n",
      "mean: tensor(-2.4772, device='mps:0')\n",
      "iter_dt 1.28s; iter 80: train loss 0.47328 temperature: 9.000000000000004\n",
      "mean_logits tensor([-2.3246, -2.5933, -2.3419, -2.5830, -2.3775, -2.3891, -1.9382, -2.2245,\n",
      "        -2.6485, -2.4198, -2.5255, -2.4988, -2.6261, -2.6251, -2.5198, -2.6370,\n",
      "        -2.3950, -2.5599, -2.5023, -2.5426, -2.4443, -2.3253, -2.4499, -2.4017,\n",
      "        -2.1967, -2.4037, -2.2773, -2.5078, -2.6019, -2.5529, -2.6102, -2.3895,\n",
      "        -2.2582, -2.3021, -2.3394, -2.1638, -2.5714, -2.2141, -2.6495, -2.1563,\n",
      "        -2.2057, -2.5405, -2.3058, -2.5636, -2.4500, -2.2764, -2.5236, -2.4112,\n",
      "        -2.3005, -2.5619], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4969, -2.4430, -2.5194, -2.4760, -2.5032, -2.4722, -2.4309, -2.4962,\n",
      "        -2.4995, -2.4612, -2.5030, -2.4943, -2.5056, -2.4943, -2.4574, -2.4471,\n",
      "        -2.4983, -2.4078, -2.4948, -2.4790, -2.4667, -2.5006, -2.5005, -2.4760,\n",
      "        -2.4986, -2.4609, -2.4705, -2.4589, -2.4431, -2.4444, -2.4748, -2.4926,\n",
      "        -2.5000, -2.4690, -2.5005, -2.4775, -2.4641, -2.4753, -2.4961, -2.4817,\n",
      "        -2.5002, -2.4496, -2.4991, -2.4066, -2.4991, -2.5056, -2.4955, -2.3791,\n",
      "        -2.4953, -2.4828], device='mps:0')\n",
      "mean: tensor(-2.4769, device='mps:0')\n",
      "iter_dt 1.34s; iter 81: train loss 0.41755 temperature: 9.050000000000004\n",
      "mean_logits tensor([-2.3221, -2.4902, -2.4740, -2.4789, -2.4786, -2.4068, -2.2849, -2.3134,\n",
      "        -2.2055, -2.2340, -2.3926, -2.3826, -2.3404, -2.2649, -2.5589, -2.1372,\n",
      "        -2.5076, -2.5764, -2.4126, -2.4440, -2.7555, -2.3557, -2.6043, -2.1686,\n",
      "        -2.3633, -2.4865, -2.2844, -2.3332, -2.4599, -2.7592, -2.4005, -2.1907,\n",
      "        -2.2280, -2.4487, -2.2941, -2.2624, -2.4589, -2.4174, -2.4576, -2.1586,\n",
      "        -2.4359, -2.4630, -2.4550, -2.5508, -2.2507, -2.4540, -2.3608, -2.4857,\n",
      "        -2.4414, -2.5362], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4949, -2.4708, -2.5243, -2.4938, -2.4465, -2.5014, -2.4920, -2.5013,\n",
      "        -2.4994, -2.4949, -2.4590, -2.4622, -2.4171, -2.4895, -2.4986, -2.4360,\n",
      "        -2.4980, -2.5030, -2.4821, -2.4517, -2.4472, -2.4975, -2.4998, -2.5168,\n",
      "        -2.4287, -2.5012, -2.4583, -2.4996, -2.4971, -2.5032, -2.4662, -2.4953,\n",
      "        -2.4817, -2.4955, -2.4899, -2.5031, -2.4715, -2.4999, -2.4541, -2.4261,\n",
      "        -2.4988, -2.4950, -2.4589, -2.5027, -2.5001, -2.4759, -2.4631, -2.4853,\n",
      "        -2.4636, -2.4917], device='mps:0')\n",
      "mean: tensor(-2.4817, device='mps:0')\n",
      "iter_dt 1.65s; iter 82: train loss 0.40300 temperature: 9.100000000000005\n",
      "mean_logits tensor([-2.1883, -2.2878, -2.4582, -2.5071, -2.4600, -2.3927, -2.0402, -2.2919,\n",
      "        -2.6763, -2.7221, -2.1529, -2.5758, -2.5823, -2.3724, -2.4332, -2.6595,\n",
      "        -2.5935, -2.4268, -2.3337, -2.5091, -2.2494, -2.6681, -2.4025, -2.2458,\n",
      "        -2.5950, -2.2700, -2.6479, -2.2567, -2.4018, -2.3879, -2.2943, -2.5617,\n",
      "        -2.3338, -2.1500, -2.3857, -2.5833, -2.5595, -2.4791, -2.4294, -2.2665,\n",
      "        -2.6172, -2.4900, -2.2840, -2.2381, -2.4277, -2.5455, -2.3151, -2.4431,\n",
      "        -2.5277, -2.6290], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4610, -2.4454, -2.5023, -2.5191, -2.4743, -2.4955, -2.4028, -2.3875,\n",
      "        -2.5039, -2.4576, -2.4459, -2.4640, -2.4558, -2.4959, -2.4956, -2.5012,\n",
      "        -2.4909, -2.4607, -2.5107, -2.4949, -2.4320, -2.4667, -2.4556, -2.4819,\n",
      "        -2.4964, -2.4132, -2.5006, -2.4937, -2.4981, -2.4733, -2.5008, -2.4399,\n",
      "        -2.4851, -2.4227, -2.4350, -2.4770, -2.5008, -2.4151, -2.4325, -2.4193,\n",
      "        -2.4609, -2.4686, -2.4698, -2.5037, -2.4718, -2.5015, -2.4908, -2.4418,\n",
      "        -2.4474, -2.5061], device='mps:0')\n",
      "mean: tensor(-2.4693, device='mps:0')\n",
      "iter_dt 1.78s; iter 83: train loss 0.26208 temperature: 9.150000000000006\n",
      "mean_logits tensor([-2.3588, -2.6962, -2.6220, -2.2846, -2.3631, -2.3837, -2.5829, -2.5481,\n",
      "        -2.3398, -2.3791, -2.7251, -2.6089, -2.5388, -2.4883, -2.5716, -2.4064,\n",
      "        -2.3319, -2.2159, -2.4150, -2.2731, -2.5127, -2.5457, -2.3913, -2.6120,\n",
      "        -2.5750, -2.6252, -2.3320, -2.5014, -2.3229, -2.5218, -2.3476, -2.5050,\n",
      "        -2.4915, -2.5084, -2.4520, -2.4491, -2.4287, -2.5617, -2.4876, -2.3429,\n",
      "        -2.5715, -2.5141, -2.5535, -2.2729, -2.3347, -2.2549, -2.5612, -2.3793,\n",
      "        -2.3019, -2.5239], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4952, -2.4920, -2.4970, -2.4797, -2.4801, -2.5026, -2.4379, -2.4683,\n",
      "        -2.5036, -2.5008, -2.4960, -2.4831, -2.4656, -2.4826, -2.5100, -2.5002,\n",
      "        -2.4986, -2.3702, -2.4905, -2.4666, -2.4921, -2.4370, -2.4592, -2.5005,\n",
      "        -2.4986, -2.4920, -2.4477, -2.4994, -2.4962, -2.4920, -2.5004, -2.3618,\n",
      "        -2.4461, -2.5001, -2.4996, -2.4680, -2.4907, -2.5031, -2.4711, -2.4285,\n",
      "        -2.5006, -2.5070, -2.4981, -2.3865, -2.4931, -2.4907, -2.5021, -2.4727,\n",
      "        -2.5002, -2.5003], device='mps:0')\n",
      "mean: tensor(-2.4791, device='mps:0')\n",
      "iter_dt 1.76s; iter 84: train loss 0.38953 temperature: 9.200000000000006\n",
      "mean_logits tensor([-2.4654, -2.5548, -2.5597, -2.7444, -2.3736, -2.4598, -2.2246, -2.2319,\n",
      "        -2.4805, -2.1347, -2.4044, -2.4223, -2.3404, -2.4409, -2.5983, -2.4850,\n",
      "        -2.1621, -2.5292, -2.4457, -2.1971, -2.4487, -2.1493, -2.3996, -2.4841,\n",
      "        -2.6160, -2.6309, -2.5476, -2.4683, -2.4459, -2.2715, -2.4937, -2.2637,\n",
      "        -2.2941, -2.4119, -2.3615, -2.6405, -2.4746, -2.3830, -2.3079, -2.1797,\n",
      "        -2.5181, -2.6932, -2.4334, -2.4561, -2.3740, -2.3497, -2.5612, -2.4776,\n",
      "        -2.4688, -2.5442], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4936, -2.4766, -2.5137, -2.4563, -2.4996, -2.4903, -2.4794, -2.4639,\n",
      "        -2.4508, -2.4428, -2.5006, -2.4989, -2.5011, -2.4962, -2.4938, -2.4992,\n",
      "        -2.4829, -2.4994, -2.5014, -2.5008, -2.5030, -2.4152, -2.5001, -2.4623,\n",
      "        -2.4916, -2.3983, -2.5013, -2.4986, -2.5035, -2.4944, -2.4376, -2.4803,\n",
      "        -2.4952, -2.4794, -2.5024, -2.4537, -2.4982, -2.4523, -2.4522, -2.4659,\n",
      "        -2.3895, -2.4988, -2.4979, -2.4940, -2.4990, -2.4169, -2.4410, -2.4972,\n",
      "        -2.4922, -2.4579], device='mps:0')\n",
      "mean: tensor(-2.4782, device='mps:0')\n",
      "iter_dt 1.61s; iter 85: train loss 0.43408 temperature: 9.250000000000007\n",
      "mean_logits tensor([-2.3197, -2.4457, -2.1951, -2.1934, -2.3013, -2.3575, -2.2717, -2.5684,\n",
      "        -2.2940, -2.4139, -2.3684, -2.3333, -2.5097, -2.3778, -2.3646, -2.7884,\n",
      "        -2.3122, -2.5296, -2.4395, -2.5427, -2.5727, -2.6776, -2.4857, -2.4751,\n",
      "        -2.6495, -2.3731, -2.5547, -2.2192, -2.5830, -2.3587, -2.1532, -2.6498,\n",
      "        -2.5471, -2.2417, -2.3402, -2.3573, -2.4243, -2.4683, -2.4388, -2.5514,\n",
      "        -2.2833, -2.3543, -2.3516, -2.2881, -2.6615, -2.4913, -2.4993, -2.4926,\n",
      "        -2.6188, -2.6898], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.3983, -2.4748, -2.4900, -2.5054, -2.4798, -2.4378, -2.4262, -2.4958,\n",
      "        -2.5007, -2.5006, -2.4340, -2.5019, -2.4951, -2.5001, -2.4681, -2.4581,\n",
      "        -2.4275, -2.4682, -2.4357, -2.4099, -2.4718, -2.4998, -2.4976, -2.4952,\n",
      "        -2.5100, -2.5006, -2.4353, -2.5019, -2.4627, -2.4631, -2.5102, -2.4755,\n",
      "        -2.4284, -2.5017, -2.4951, -2.4971, -2.5085, -2.4901, -2.4991, -2.4708,\n",
      "        -2.4943, -2.4620, -2.4875, -2.4943, -2.5008, -2.4966, -2.4957, -2.4642,\n",
      "        -2.5019, -2.4957], device='mps:0')\n",
      "mean: tensor(-2.4783, device='mps:0')\n",
      "iter_dt 1.70s; iter 86: train loss 0.26660 temperature: 9.300000000000008\n",
      "mean_logits tensor([-2.4624, -2.6511, -2.5924, -2.2901, -2.5764, -2.2864, -2.5096, -2.6089,\n",
      "        -2.4278, -2.5177, -2.3318, -2.4693, -2.3490, -2.5772, -2.2547, -2.3223,\n",
      "        -2.3593, -2.4651, -2.4042, -2.4311, -2.5735, -2.5401, -2.5171, -2.4517,\n",
      "        -2.4353, -2.6095, -2.4529, -2.4831, -2.5465, -2.4301, -2.3970, -2.5461,\n",
      "        -2.6276, -2.4155, -2.1749, -2.4817, -2.4167, -2.5502, -2.4384, -2.6897,\n",
      "        -2.4987, -2.3881, -2.3999, -2.4213, -2.7255, -2.4612, -2.5106, -2.4609,\n",
      "        -2.3083, -2.3332], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4863, -2.4967, -2.4667, -2.4845, -2.5019, -2.4498, -2.4929, -2.5003,\n",
      "        -2.4823, -2.4795, -2.5528, -2.4939, -2.4823, -2.5009, -2.4973, -2.4954,\n",
      "        -2.4869, -2.5063, -2.4950, -2.4851, -2.4508, -2.5011, -2.4614, -2.4776,\n",
      "        -2.4993, -2.4822, -2.5005, -2.4667, -2.4933, -2.4475, -2.5012, -2.4820,\n",
      "        -2.4898, -2.3363, -2.5280, -2.5012, -2.4934, -2.4816, -2.4102, -2.4479,\n",
      "        -2.4983, -2.4583, -2.4123, -2.4603, -2.4866, -2.4767, -2.4924, -2.4921,\n",
      "        -2.4914, -2.4702], device='mps:0')\n",
      "mean: tensor(-2.4806, device='mps:0')\n",
      "iter_dt 1.80s; iter 87: train loss 0.53070 temperature: 9.350000000000009\n",
      "mean_logits tensor([-2.4713, -2.5234, -2.3258, -2.3382, -2.7100, -2.2703, -2.1760, -2.5312,\n",
      "        -2.1356, -2.2203, -2.0171, -2.4708, -2.1756, -2.7529, -2.7370, -2.2778,\n",
      "        -2.4088, -2.5224, -2.6367, -2.5731, -2.6160, -2.1053, -2.2793, -2.3204,\n",
      "        -2.4212, -2.6556, -2.2370, -2.4041, -2.5961, -2.4503, -2.3892, -2.5080,\n",
      "        -2.6241, -2.4087, -2.5938, -2.6595, -2.4125, -2.4453, -2.5976, -2.2838,\n",
      "        -2.4456, -2.4853, -2.3463, -2.4164, -2.4755, -2.4228, -2.2433, -2.3967,\n",
      "        -2.2922, -2.6158], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4392, -2.4786, -2.4292, -2.4463, -2.4938, -2.4846, -2.4966, -2.5019,\n",
      "        -2.4797, -2.4660, -2.5072, -2.4574, -2.4661, -2.4792, -2.5024, -2.4967,\n",
      "        -2.4981, -2.5000, -2.4789, -2.4987, -2.4778, -2.4910, -2.5113, -2.4526,\n",
      "        -2.4520, -2.4900, -2.4750, -2.4682, -2.3796, -2.4959, -2.3990, -2.4189,\n",
      "        -2.4926, -2.4490, -2.4340, -2.4988, -2.4953, -2.4344, -2.4449, -2.4361,\n",
      "        -2.4983, -2.4667, -2.4961, -2.4987, -2.4444, -2.4593, -2.4452, -2.4460,\n",
      "        -2.4906, -2.5026], device='mps:0')\n",
      "mean: tensor(-2.4709, device='mps:0')\n",
      "iter_dt 1.75s; iter 88: train loss 0.27306 temperature: 9.40000000000001\n",
      "mean_logits tensor([-2.5118, -2.6456, -2.5957, -2.4993, -2.4778, -2.5254, -2.4653, -2.5405,\n",
      "        -2.4135, -2.4301, -2.3327, -2.5571, -2.3074, -2.4748, -2.1293, -2.3862,\n",
      "        -2.5523, -2.5976, -2.2208, -2.4764, -2.4650, -2.5088, -2.4245, -2.3035,\n",
      "        -2.4039, -2.3741, -2.3155, -2.6384, -2.6073, -2.4337, -2.5693, -2.4168,\n",
      "        -2.4704, -2.4421, -2.4222, -2.6817, -2.3782, -2.7236, -2.5728, -2.6157,\n",
      "        -2.3413, -2.4843, -2.2231, -2.5749, -2.4994, -2.3869, -2.2197, -2.3639,\n",
      "        -2.3941, -2.5041], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4928, -2.5026, -2.4932, -2.4991, -2.4321, -2.4480, -2.4756, -2.4925,\n",
      "        -2.4820, -2.4877, -2.4962, -2.4606, -2.4902, -2.4255, -2.5030, -2.4649,\n",
      "        -2.4493, -2.5023, -2.4349, -2.4962, -2.5010, -2.4885, -2.4851, -2.4247,\n",
      "        -2.5014, -2.4489, -2.4798, -2.4802, -2.4918, -2.4296, -2.4859, -2.4846,\n",
      "        -2.4598, -2.4741, -2.5020, -2.5222, -2.4973, -2.4970, -2.4607, -2.4806,\n",
      "        -2.4837, -2.4718, -2.4822, -2.4767, -2.4749, -2.4666, -2.4596, -2.4997,\n",
      "        -2.5019, -2.4639], device='mps:0')\n",
      "mean: tensor(-2.4781, device='mps:0')\n",
      "iter_dt 1.88s; iter 89: train loss 0.44353 temperature: 9.45000000000001\n",
      "mean_logits tensor([-2.5029, -2.4390, -2.3732, -2.7374, -2.4548, -2.6297, -2.5547, -2.4615,\n",
      "        -2.5392, -2.5771, -2.3566, -2.4285, -2.4998, -2.4829, -2.5878, -2.2839,\n",
      "        -2.4828, -2.3824, -2.5324, -2.6126, -2.4482, -2.4681, -2.2763, -2.4557,\n",
      "        -2.4382, -2.4175, -2.3598, -2.6370, -2.3615, -2.4959, -2.3242, -2.5207,\n",
      "        -2.4684, -2.5307, -2.6029, -2.0969, -2.2778, -2.5013, -2.2885, -2.4388,\n",
      "        -2.5323, -2.8293, -2.1446, -2.5227, -1.9722, -2.5434, -2.6670, -2.3261,\n",
      "        -2.6908, -2.4977], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5008, -2.4978, -2.4951, -2.4765, -2.4967, -2.5015, -2.4526, -2.4982,\n",
      "        -2.5097, -2.4957, -2.4291, -2.5000, -2.4987, -2.5237, -2.4106, -2.4958,\n",
      "        -2.4976, -2.4985, -2.4784, -2.4503, -2.5543, -2.4848, -2.3298, -2.4338,\n",
      "        -2.4917, -2.4898, -2.5179, -2.4711, -2.4969, -2.4947, -2.4989, -2.4898,\n",
      "        -2.4983, -2.4717, -2.4258, -2.4378, -2.4940, -2.4850, -2.4343, -2.5016,\n",
      "        -2.4900, -2.4444, -2.4960, -2.4368, -2.4634, -2.5005, -2.4449, -2.4679,\n",
      "        -2.4908, -2.4587], device='mps:0')\n",
      "mean: tensor(-2.4781, device='mps:0')\n",
      "iter_dt 1.85s; iter 90: train loss 0.42354 temperature: 9.50000000000001\n",
      "mean_logits tensor([-2.6721, -2.6564, -2.4074, -2.3748, -2.0628, -2.6101, -2.3500, -2.5264,\n",
      "        -2.6833, -2.4673, -2.4380, -2.1240, -2.3993, -2.6130, -2.3827, -2.3269,\n",
      "        -2.2782, -2.6181, -2.4766, -2.3906, -2.4513, -2.7775, -2.5995, -2.3376,\n",
      "        -2.6145, -2.5879, -2.5406, -2.4067, -2.5168, -2.6454, -2.5624, -2.3758,\n",
      "        -2.4003, -2.5157, -2.4355, -2.2858, -2.5127, -2.5052, -2.5983, -2.1495,\n",
      "        -2.1796, -2.3679, -2.4343, -2.2987, -2.4639, -2.5164, -2.3727, -2.5025,\n",
      "        -2.4357, -2.2986], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4609, -2.5009, -2.4660, -2.4991, -2.5021, -2.4891, -2.4618, -2.4203,\n",
      "        -2.5008, -2.5007, -2.4938, -2.4578, -2.4694, -2.4630, -2.4788, -2.3740,\n",
      "        -2.4967, -2.4478, -2.5046, -2.4819, -2.5000, -2.4535, -2.4676, -2.4580,\n",
      "        -2.4690, -2.4740, -2.5009, -2.4607, -2.4937, -2.4973, -2.4978, -2.4985,\n",
      "        -2.4515, -2.4583, -2.4811, -2.4978, -2.5002, -2.4342, -2.4702, -2.4892,\n",
      "        -2.5001, -2.4568, -2.4573, -2.5012, -2.4903, -2.4140, -2.4901, -2.4697,\n",
      "        -2.4614, -2.4644], device='mps:0')\n",
      "mean: tensor(-2.4746, device='mps:0')\n",
      "iter_dt 1.98s; iter 91: train loss 0.38679 temperature: 9.550000000000011\n",
      "mean_logits tensor([-2.3414, -2.2926, -2.5644, -2.5695, -2.3733, -2.5541, -2.8011, -2.5943,\n",
      "        -2.0724, -2.2563, -2.4051, -2.5580, -2.2842, -2.4115, -2.3394, -2.3094,\n",
      "        -2.2911, -2.4373, -2.4135, -2.3731, -2.4945, -2.5825, -2.2813, -2.6169,\n",
      "        -2.4111, -2.5675, -2.4971, -2.6314, -2.5710, -2.3106, -2.4568, -2.6159,\n",
      "        -2.4249, -2.3264, -2.3849, -2.3203, -2.4028, -2.4501, -2.3844, -2.3271,\n",
      "        -2.4389, -2.2860, -2.7014, -2.5531, -2.7233, -2.2441, -2.4991, -2.5403,\n",
      "        -2.4212, -2.5318], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5060, -2.5015, -2.4483, -2.5013, -2.4926, -2.4996, -2.4848, -2.4749,\n",
      "        -2.4315, -2.4681, -2.5013, -2.5004, -2.4972, -2.4177, -2.3822, -2.5066,\n",
      "        -2.4992, -2.4963, -2.4736, -2.5011, -2.3702, -2.4412, -2.4513, -2.4620,\n",
      "        -2.4364, -2.5001, -2.4935, -2.4988, -2.5206, -2.4981, -2.4294, -2.4598,\n",
      "        -2.5639, -2.4749, -2.4918, -2.4986, -2.3947, -2.4991, -2.4845, -2.4602,\n",
      "        -2.5023, -2.5033, -2.5002, -2.4820, -2.5022, -2.4469, -2.4969, -2.4950,\n",
      "        -2.5190, -2.4911], device='mps:0')\n",
      "mean: tensor(-2.4790, device='mps:0')\n",
      "iter_dt 1.97s; iter 92: train loss 0.41532 temperature: 9.600000000000012\n",
      "mean_logits tensor([-2.2228, -2.3377, -2.5959, -2.3652, -2.1741, -2.4944, -2.6185, -2.2751,\n",
      "        -2.5263, -2.4333, -2.5817, -2.4368, -2.5407, -2.6630, -2.5874, -2.3691,\n",
      "        -2.6430, -2.5976, -2.5736, -2.2787, -2.6018, -2.6799, -2.3606, -2.2617,\n",
      "        -2.3663, -2.4495, -2.4274, -2.5198, -2.1030, -2.1674, -2.3332, -2.5318,\n",
      "        -2.4037, -2.7711, -2.5828, -2.1742, -2.4251, -2.5165, -2.6541, -2.2430,\n",
      "        -2.4142, -2.3275, -2.4400, -2.5380, -2.5689, -2.4944, -2.4314, -2.1792,\n",
      "        -2.3285, -2.6026], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4594, -2.4974, -2.5008, -2.5001, -2.4356, -2.4897, -2.4966, -2.4072,\n",
      "        -2.5014, -2.4542, -2.4412, -2.5071, -2.4998, -2.5030, -2.4880, -2.4843,\n",
      "        -2.4811, -2.4997, -2.4839, -2.4802, -2.4908, -2.5000, -2.4320, -2.5065,\n",
      "        -2.4957, -2.4507, -2.4983, -2.4810, -2.4999, -2.5007, -2.3438, -2.4659,\n",
      "        -2.4666, -2.4968, -2.4584, -2.4667, -2.5068, -2.4266, -2.4896, -2.5013,\n",
      "        -2.4266, -2.4610, -2.4848, -2.4867, -2.4980, -2.4965, -2.5633, -2.4134,\n",
      "        -2.4941, -2.4911], device='mps:0')\n",
      "mean: tensor(-2.4781, device='mps:0')\n",
      "iter_dt 2.09s; iter 93: train loss 0.57324 temperature: 9.650000000000013\n",
      "mean_logits tensor([-2.5228, -2.6015, -2.5622, -2.5537, -2.2593, -2.0830, -2.6687, -2.3295,\n",
      "        -2.4500, -2.1530, -2.4262, -2.6251, -2.5005, -2.3270, -2.2182, -2.6576,\n",
      "        -2.4176, -2.5485, -2.2076, -2.4238, -2.1707, -2.4852, -2.3395, -2.6437,\n",
      "        -2.8123, -2.5073, -2.5655, -2.3020, -2.5762, -2.1120, -2.3962, -2.5926,\n",
      "        -2.5338, -2.5701, -2.4527, -2.4051, -2.2368, -2.5600, -2.0194, -2.1364,\n",
      "        -2.6541, -2.4832, -2.4524, -2.5473, -2.5393, -2.3936, -2.4725, -2.4863,\n",
      "        -2.7063, -2.1683], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5635, -2.4901, -2.4740, -2.5044, -2.4754, -2.4201, -2.4939, -2.4263,\n",
      "        -2.4813, -2.4953, -2.4948, -2.4573, -2.5000, -2.4622, -2.4954, -2.4603,\n",
      "        -2.5173, -2.4874, -2.5065, -2.4531, -2.5028, -2.4788, -2.5019, -2.4598,\n",
      "        -2.5027, -2.4760, -2.4892, -2.4955, -2.4894, -2.4961, -2.5019, -2.5085,\n",
      "        -2.4614, -2.4999, -2.4947, -2.4996, -2.5037, -2.5190, -2.4969, -2.4931,\n",
      "        -2.4709, -2.5135, -2.5006, -2.5035, -2.4999, -2.4993, -2.5008, -2.4950,\n",
      "        -2.4997, -2.4984], device='mps:0')\n",
      "mean: tensor(-2.4902, device='mps:0')\n",
      "iter_dt 2.06s; iter 94: train loss 0.55505 temperature: 9.700000000000014\n",
      "mean_logits tensor([-2.2564, -2.7797, -2.3867, -2.5130, -2.4612, -2.1875, -2.3514, -2.6078,\n",
      "        -2.4418, -2.3661, -2.3606, -2.0340, -2.3903, -2.8168, -2.3587, -2.3121,\n",
      "        -2.4572, -2.3625, -2.2907, -2.5020, -2.4912, -2.5874, -2.4237, -2.3762,\n",
      "        -2.4937, -2.4687, -2.5672, -2.3968, -2.8133, -2.5589, -2.3592, -2.6198,\n",
      "        -2.3783, -2.2150, -2.2647, -2.2368, -2.6523, -2.5860, -2.1031, -2.5442,\n",
      "        -2.4401, -2.4774, -2.7131, -2.3039, -2.3899, -2.6049, -2.2774, -2.5626,\n",
      "        -2.3685, -2.4157], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4445, -2.4990, -2.4216, -2.4525, -2.4359, -2.4961, -2.4957, -2.4899,\n",
      "        -2.4941, -2.4843, -2.4989, -2.4885, -2.4981, -2.4785, -2.4916, -2.4652,\n",
      "        -2.4744, -2.5008, -2.4949, -2.4804, -2.5021, -2.4458, -2.4994, -2.4988,\n",
      "        -2.5008, -2.4965, -2.5084, -2.4419, -2.4864, -2.4604, -2.4803, -2.4612,\n",
      "        -2.5205, -2.4973, -2.4920, -2.5029, -2.4864, -2.4929, -2.4489, -2.4460,\n",
      "        -2.3995, -2.5026, -2.4958, -2.4901, -2.4507, -2.4290, -2.4815, -2.4744,\n",
      "        -2.5009, -2.5010], device='mps:0')\n",
      "mean: tensor(-2.4796, device='mps:0')\n",
      "iter_dt 1.49s; iter 95: train loss 0.34036 temperature: 9.750000000000014\n",
      "mean_logits tensor([-2.2744, -2.5709, -2.3361, -2.5554, -2.3086, -2.5303, -2.6511, -2.5051,\n",
      "        -2.4049, -2.5902, -2.2716, -2.5657, -2.3252, -2.4881, -2.4464, -2.5576,\n",
      "        -2.4245, -2.5378, -2.2866, -2.4210, -2.6202, -2.4506, -2.5719, -2.6196,\n",
      "        -2.3556, -2.1316, -2.5889, -2.6409, -2.3677, -2.3440, -2.5816, -2.3289,\n",
      "        -2.4725, -2.6408, -2.5719, -2.2655, -2.5047, -2.7955, -2.3949, -2.1651,\n",
      "        -2.5073, -2.5455, -2.5684, -2.5903, -2.5601, -2.4276, -2.3852, -2.3540,\n",
      "        -2.3478, -2.6316], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4999, -2.4872, -2.3966, -2.4568, -2.4908, -2.5008, -2.4588, -2.5004,\n",
      "        -2.5006, -2.5062, -2.4590, -2.4804, -2.4640, -2.4318, -2.4983, -2.5006,\n",
      "        -2.4957, -2.4180, -2.4661, -2.4998, -2.4829, -2.4639, -2.5865, -2.5013,\n",
      "        -2.4924, -2.4883, -2.4997, -2.4983, -2.4837, -2.5005, -2.4286, -2.4732,\n",
      "        -2.4894, -2.4607, -2.4556, -2.5003, -2.4880, -2.4981, -2.4971, -2.4224,\n",
      "        -2.4993, -2.4743, -2.5026, -2.4468, -2.5018, -2.4599, -2.4877, -2.4470,\n",
      "        -2.4391, -2.5014], device='mps:0')\n",
      "mean: tensor(-2.4797, device='mps:0')\n",
      "iter_dt 1.03s; iter 96: train loss 0.32487 temperature: 9.800000000000015\n",
      "mean_logits tensor([-2.2996, -2.4623, -2.5604, -2.7393, -2.4715, -2.5705, -2.4298, -2.2701,\n",
      "        -2.5959, -2.3983, -2.5133, -2.4275, -2.3506, -2.4850, -2.4474, -2.4115,\n",
      "        -2.3608, -2.2518, -2.4051, -2.4846, -2.4108, -2.3743, -2.4637, -2.4741,\n",
      "        -2.6444, -2.3735, -2.4491, -2.4826, -2.3312, -2.6870, -2.6320, -2.2377,\n",
      "        -2.3909, -2.2888, -2.5322, -2.3899, -2.5783, -2.2391, -2.2344, -2.6330,\n",
      "        -2.1059, -2.3112, -2.4132, -2.4376, -2.4354, -2.5815, -2.4898, -2.4681,\n",
      "        -2.3235, -2.5774], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4991, -2.4560, -2.4973, -2.4688, -2.4947, -2.4854, -2.4998, -2.5012,\n",
      "        -2.4950, -2.4948, -2.4709, -2.4626, -2.4527, -2.4624, -2.4342, -2.4943,\n",
      "        -2.5030, -2.4981, -2.4912, -2.4919, -2.4998, -2.4646, -2.4610, -2.4567,\n",
      "        -2.4339, -2.3652, -2.4718, -2.5000, -2.4944, -2.4999, -2.4701, -2.4551,\n",
      "        -2.4076, -2.5008, -2.5032, -2.4942, -2.4991, -2.4887, -2.4902, -2.4614,\n",
      "        -2.4446, -2.4611, -2.4966, -2.4542, -2.4687, -2.4978, -2.4507, -2.4946,\n",
      "        -2.4917, -2.4977], device='mps:0')\n",
      "mean: tensor(-2.4766, device='mps:0')\n",
      "iter_dt 1.13s; iter 97: train loss 0.47452 temperature: 9.850000000000016\n",
      "mean_logits tensor([-2.6119, -2.1682, -2.4485, -2.3837, -2.3411, -2.5744, -1.9764, -2.3353,\n",
      "        -2.3597, -2.2386, -2.4984, -2.1856, -2.5895, -2.4713, -2.5534, -2.5275,\n",
      "        -2.6659, -2.5670, -2.4357, -2.2824, -2.4199, -2.1384, -2.5948, -2.4465,\n",
      "        -2.4742, -2.3328, -2.0127, -2.4120, -2.3900, -2.3066, -2.7096, -2.4437,\n",
      "        -2.5265, -2.2868, -2.3295, -2.4024, -2.3221, -2.4823, -2.7153, -2.4529,\n",
      "        -2.7627, -2.5785, -2.4489, -2.6168, -2.4939, -2.3110, -2.5677, -2.2275,\n",
      "        -2.6690, -2.6089], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4859, -2.4421, -2.5005, -2.4979, -2.4793, -2.4899, -2.4949, -2.4739,\n",
      "        -2.4989, -2.4561, -2.4790, -2.4139, -2.4990, -2.4993, -2.4722, -2.5200,\n",
      "        -2.4702, -2.4324, -2.4952, -2.5034, -2.4930, -2.4947, -2.4938, -2.4429,\n",
      "        -2.4951, -2.4993, -2.3596, -2.4303, -2.3725, -2.4760, -2.4849, -2.4913,\n",
      "        -2.4732, -2.4556, -2.4972, -2.4969, -2.5013, -2.4644, -2.4935, -2.4664,\n",
      "        -2.4884, -2.4735, -2.4151, -2.5004, -2.4810, -2.4980, -2.5049, -2.4604,\n",
      "        -2.4748, -2.4742], device='mps:0')\n",
      "mean: tensor(-2.4751, device='mps:0')\n",
      "iter_dt 1.21s; iter 98: train loss 0.42326 temperature: 9.900000000000016\n",
      "mean_logits tensor([-2.5254, -2.4156, -2.6040, -2.5470, -2.1407, -2.6201, -2.2961, -2.2322,\n",
      "        -2.1463, -2.5853, -2.5060, -2.4446, -2.4706, -2.3945, -2.3012, -2.4720,\n",
      "        -2.5175, -2.4059, -2.4281, -2.7035, -2.2272, -2.6793, -2.1088, -2.3000,\n",
      "        -2.4856, -2.4086, -2.4359, -2.3408, -2.5425, -2.1944, -2.4145, -2.1867,\n",
      "        -2.4689, -2.4398, -2.6000, -2.1038, -2.2908, -2.3247, -2.4281, -2.4169,\n",
      "        -2.4822, -2.2747, -2.4399, -2.4384, -2.6861, -2.6572, -2.3280, -2.3362,\n",
      "        -2.4229, -2.4805], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5006, -2.4428, -2.4851, -2.4987, -2.4613, -2.4659, -2.4923, -2.4981,\n",
      "        -2.4592, -2.4701, -2.4505, -2.4958, -2.4733, -2.4978, -2.4561, -2.4490,\n",
      "        -2.4480, -2.4994, -2.4586, -2.4875, -2.4998, -2.4921, -2.4750, -2.4817,\n",
      "        -2.5030, -2.5005, -2.4980, -2.3949, -2.4906, -2.5028, -2.4345, -2.4447,\n",
      "        -2.4256, -2.4923, -2.5028, -2.4537, -2.4971, -2.4957, -2.3857, -2.4987,\n",
      "        -2.5000, -2.4474, -2.5012, -2.4736, -2.4670, -2.4996, -2.4995, -2.4743,\n",
      "        -2.4944, -2.4966], device='mps:0')\n",
      "mean: tensor(-2.4763, device='mps:0')\n",
      "iter_dt 1.14s; iter 99: train loss 0.47140 temperature: 9.950000000000017\n",
      "mean_logits tensor([-2.5693, -2.4693, -2.4359, -2.5682, -2.6488, -2.8151, -2.3761, -2.2784,\n",
      "        -2.4769, -2.3243, -2.5407, -2.6261, -2.5568, -2.4952, -2.4109, -2.6117,\n",
      "        -2.4148, -2.7488, -2.1994, -2.3275, -2.5195, -2.6730, -2.5113, -2.6003,\n",
      "        -2.5398, -2.6113, -2.4842, -2.2805, -2.2993, -2.2082, -2.3170, -2.4545,\n",
      "        -2.4138, -2.2728, -2.6095, -2.5977, -2.2661, -2.5011, -2.2620, -2.3337,\n",
      "        -2.4835, -2.3903, -2.2277, -2.7381, -2.5420, -2.2764, -2.4932, -2.1733,\n",
      "        -2.2820, -2.0978], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4410, -2.4667, -2.4713, -2.4032, -2.4540, -2.4992, -2.5021, -2.5005,\n",
      "        -2.4847, -2.4347, -2.4665, -2.4863, -2.4994, -2.5629, -2.4446, -2.5193,\n",
      "        -2.5009, -2.4999, -2.4414, -2.4820, -2.5008, -2.5397, -2.4673, -2.4962,\n",
      "        -2.4982, -2.4940, -2.3899, -2.4498, -2.4897, -2.4999, -2.4330, -2.4830,\n",
      "        -2.4195, -2.5027, -2.5574, -2.5018, -2.4881, -2.5544, -2.5225, -2.4445,\n",
      "        -2.4997, -2.4880, -2.4115, -2.4437, -2.4767, -2.4522, -2.4691, -2.4629,\n",
      "        -2.4101, -2.4930], device='mps:0')\n",
      "mean: tensor(-2.4780, device='mps:0')\n",
      "current_prefixes: [7278 4037 5557 4534 4632 6985  380 4805 4101 4404 4883  611  346 1045\n",
      " 2273 6235 5773 2879  256  465 6084 8286  375 5500  264  814   67 8921\n",
      "   67 4136]\n",
      "layer: 7 starts running\n",
      "number of parameters: 91.99M\n",
      "running on device mps\n",
      "iter_dt 0.00s; iter 0: train loss 4.45604 temperature: 5\n",
      "mean_logits tensor([-1.5508, -1.8832, -2.0418, -1.7482, -1.6835, -2.0275, -2.2457, -2.2887,\n",
      "        -1.8465, -2.1299, -1.8139, -1.8867, -2.2190, -2.3778, -2.2031, -1.9758,\n",
      "        -1.9117, -1.7010, -2.0260, -1.6599, -1.7869, -2.3573, -2.3918, -1.6576,\n",
      "        -2.1675, -1.8612, -2.0133, -1.6075, -2.0491, -2.0338, -2.0673, -1.9822,\n",
      "        -1.8431, -1.5389, -1.9822, -2.0870, -1.5507, -2.3282, -2.0879, -2.5396,\n",
      "        -2.2554, -1.9543, -1.7667, -2.0972, -2.3367, -2.3057, -1.7020, -2.2082,\n",
      "        -2.0358, -1.5751], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5767, -2.5865, -2.5714, -2.5420, -2.5085, -2.5837, -2.5050, -2.5840,\n",
      "        -2.5525, -2.5994, -2.5420, -2.5868, -2.5862, -2.5825, -2.5351, -2.5423,\n",
      "        -2.5683, -2.5806, -2.5848, -2.5646, -2.5684, -2.5182, -2.4968, -2.5869,\n",
      "        -2.5858, -2.5594, -2.5375, -2.5349, -2.5765, -2.5561, -2.5297, -2.5472,\n",
      "        -2.5107, -2.5847, -2.5705, -2.5048, -2.5953, -2.5086, -2.5410, -2.5399,\n",
      "        -2.5651, -2.5818, -2.5830, -2.5838, -2.5759, -2.5779, -2.5847, -2.5600,\n",
      "        -2.5184, -2.5199], device='mps:0')\n",
      "mean: tensor(-2.5577, device='mps:0')\n",
      "iter_dt 1695864412.22s; iter 1: train loss 3.86876 temperature: 5.05\n",
      "mean_logits tensor([-1.8105, -1.9170, -2.0050, -2.3878, -1.7624, -2.1866, -1.8276, -2.0100,\n",
      "        -2.0732, -2.3829, -1.6724, -2.1747, -2.2689, -1.8807, -2.5914, -1.8891,\n",
      "        -2.0575, -2.3021, -2.1244, -1.9391, -2.0151, -2.0642, -1.7796, -1.9505,\n",
      "        -2.0685, -1.8873, -1.7338, -2.1219, -2.3552, -2.0158, -2.0225, -2.0510,\n",
      "        -2.0362, -2.1202, -2.4977, -1.9690, -1.5920, -1.6615, -1.8538, -2.0880,\n",
      "        -1.9876, -2.2343, -2.2659, -1.9533, -2.2665, -1.8050, -1.8492, -2.0645,\n",
      "        -1.6049, -1.9457], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5079, -2.4430, -2.5791, -2.5385, -2.5436, -2.5699, -2.4988, -2.5026,\n",
      "        -2.5610, -2.5812, -2.5473, -2.5857, -2.4922, -2.5669, -2.5399, -2.5369,\n",
      "        -2.5867, -2.5154, -2.5460, -2.5958, -2.5289, -2.5202, -2.5828, -2.4796,\n",
      "        -2.5862, -2.5166, -2.5819, -2.5924, -2.5863, -2.5855, -2.5221, -2.5843,\n",
      "        -2.5771, -2.5858, -2.5436, -2.5227, -2.5925, -2.5323, -2.4755, -2.5812,\n",
      "        -2.5300, -2.5719, -2.5927, -2.5750, -2.6028, -2.5392, -2.5328, -2.5305,\n",
      "        -2.4649, -2.5768], device='mps:0')\n",
      "mean: tensor(-2.5487, device='mps:0')\n",
      "iter_dt 1.07s; iter 2: train loss 4.05764 temperature: 5.1\n",
      "mean_logits tensor([-2.1917, -1.9793, -2.2355, -2.2197, -2.0466, -1.8261, -1.6666, -1.9909,\n",
      "        -2.3023, -2.1085, -2.0800, -1.5284, -1.5255, -2.0736, -2.1138, -2.0711,\n",
      "        -2.0648, -1.7794, -2.5568, -2.0532, -2.1395, -2.2156, -1.9109, -1.6908,\n",
      "        -1.8521, -2.1153, -2.0808, -1.8497, -1.8521, -2.3348, -1.9177, -2.0457,\n",
      "        -2.1366, -1.8459, -2.2037, -1.9568, -2.0569, -1.7055, -2.0843, -1.8312,\n",
      "        -1.6766, -2.0628, -2.9446, -2.0260, -2.0309, -2.4303, -1.6448, -2.2276,\n",
      "        -2.4282, -1.9828], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5382, -2.5488, -2.5203, -2.5806, -2.5830, -2.5788, -2.5396, -2.5695,\n",
      "        -2.5782, -2.5745, -2.5056, -2.5795, -2.5737, -2.5848, -2.5461, -2.5795,\n",
      "        -2.5726, -2.5119, -2.5829, -2.5288, -2.5366, -2.5814, -2.5931, -2.5862,\n",
      "        -2.5721, -2.5319, -2.5440, -2.4959, -2.5797, -2.5768, -2.5858, -2.5718,\n",
      "        -2.5829, -2.5795, -2.5823, -2.5860, -2.5402, -2.5447, -2.4800, -2.4847,\n",
      "        -2.4518, -2.5714, -2.5750, -2.4929, -2.5524, -2.5562, -2.5741, -2.5629,\n",
      "        -2.5182, -2.5870], device='mps:0')\n",
      "mean: tensor(-2.5551, device='mps:0')\n",
      "iter_dt 1.08s; iter 3: train loss 2.99945 temperature: 5.1499999999999995\n",
      "mean_logits tensor([-2.7309, -1.8898, -1.5642, -2.2805, -1.9501, -1.9715, -2.0417, -1.8736,\n",
      "        -2.0173, -1.9714, -2.0717, -2.1870, -2.8287, -1.7320, -2.0570, -2.1308,\n",
      "        -2.0749, -2.4897, -2.1126, -2.2207, -2.1481, -2.1936, -2.3888, -2.2228,\n",
      "        -2.2943, -1.9729, -2.4905, -1.7420, -2.2753, -1.8710, -2.3191, -2.0000,\n",
      "        -2.3071, -1.8538, -2.7578, -2.1361, -2.5265, -2.0700, -2.0943, -2.3134,\n",
      "        -2.2509, -2.0564, -1.8897, -1.8861, -2.0549, -2.4565, -2.1276, -2.5049,\n",
      "        -2.3730, -2.2406], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5830, -2.5152, -2.5921, -2.5792, -2.5911, -2.5805, -2.5228, -2.5817,\n",
      "        -2.5709, -2.5764, -2.5427, -2.5280, -2.5431, -2.5467, -2.5850, -2.4899,\n",
      "        -2.5079, -2.5077, -2.5850, -2.5752, -2.5882, -2.5799, -2.5413, -2.5808,\n",
      "        -2.5857, -2.5104, -2.5774, -2.5335, -2.5154, -2.5856, -2.5760, -2.4933,\n",
      "        -2.5019, -2.5669, -2.5855, -2.5768, -2.5828, -2.5782, -2.5562, -2.5861,\n",
      "        -2.5419, -2.5864, -2.5662, -2.5840, -2.5833, -2.5865, -2.5688, -2.5403,\n",
      "        -2.5826, -2.5966], device='mps:0')\n",
      "mean: tensor(-2.5609, device='mps:0')\n",
      "iter_dt 1.08s; iter 4: train loss 3.46750 temperature: 5.199999999999999\n",
      "mean_logits tensor([-2.1820, -2.4805, -2.1370, -1.8714, -2.2597, -1.8840, -1.9140, -2.1493,\n",
      "        -1.9675, -1.6762, -1.4617, -1.9899, -1.9219, -1.9271, -2.3630, -2.1245,\n",
      "        -2.3968, -2.3304, -2.5436, -2.2180, -2.2967, -1.7495, -1.7644, -2.1195,\n",
      "        -2.7901, -2.2225, -2.1705, -2.0695, -2.0515, -2.2846, -2.2330, -2.1655,\n",
      "        -2.6553, -1.9399, -1.7728, -2.1870, -1.8768, -2.0022, -2.5944, -1.8286,\n",
      "        -1.5935, -2.2468, -2.3055, -2.0328, -2.0890, -2.2693, -1.7495, -2.3171,\n",
      "        -2.1645, -1.9435], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5331, -2.5543, -2.5830, -2.5691, -2.5172, -2.5850, -2.5851, -2.5038,\n",
      "        -2.5588, -2.5616, -2.4597, -2.5406, -2.5600, -2.5465, -2.5914, -2.5748,\n",
      "        -2.5819, -2.5788, -2.5856, -2.5527, -2.5712, -2.4675, -2.5928, -2.5841,\n",
      "        -2.5735, -2.5849, -2.5638, -2.5864, -2.5859, -2.5675, -2.5689, -2.5282,\n",
      "        -2.5836, -2.5968, -2.5857, -2.5893, -2.5913, -2.5857, -2.5603, -2.5389,\n",
      "        -2.5600, -2.5356, -2.5335, -2.5851, -2.5861, -2.5836, -2.5890, -2.5835,\n",
      "        -2.5936, -2.5865], device='mps:0')\n",
      "mean: tensor(-2.5653, device='mps:0')\n",
      "iter_dt 1.07s; iter 5: train loss 2.11775 temperature: 5.249999999999999\n",
      "mean_logits tensor([-2.5084, -2.8714, -2.2651, -2.1946, -2.5580, -2.3828, -1.9425, -1.8698,\n",
      "        -2.1048, -2.2946, -2.2946, -2.5079, -1.9777, -2.0314, -2.2137, -2.5532,\n",
      "        -2.5877, -2.3824, -2.3135, -2.1800, -2.0865, -2.1961, -2.2396, -2.5213,\n",
      "        -1.8293, -2.1747, -1.8996, -2.3100, -2.1122, -2.0094, -2.3394, -1.7405,\n",
      "        -2.1754, -2.3826, -1.9376, -2.1609, -2.3322, -2.1489, -2.3784, -2.5424,\n",
      "        -2.2299, -2.4843, -1.8417, -2.3511, -2.1926, -2.4644, -2.1231, -2.2474,\n",
      "        -2.0788, -2.1344], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5348, -2.5805, -2.4495, -2.5213, -2.5834, -2.5260, -2.5859, -2.5282,\n",
      "        -2.4164, -2.5844, -2.5868, -2.5792, -2.5858, -2.5832, -2.5855, -2.5159,\n",
      "        -2.5801, -2.5034, -2.5802, -2.5856, -2.5081, -2.5864, -2.5455, -2.5796,\n",
      "        -2.5233, -2.5834, -2.5779, -2.5477, -2.5288, -2.5317, -2.5834, -2.5635,\n",
      "        -2.5868, -2.5792, -2.4921, -2.5474, -2.5052, -2.5839, -2.5399, -2.5788,\n",
      "        -2.5848, -2.5726, -2.5869, -2.5450, -2.5194, -2.5832, -2.5836, -2.5541,\n",
      "        -2.4718, -2.5882], device='mps:0')\n",
      "mean: tensor(-2.5532, device='mps:0')\n",
      "iter_dt 1.05s; iter 6: train loss 2.43650 temperature: 5.299999999999999\n",
      "mean_logits tensor([-2.2809, -1.8718, -2.3751, -2.0890, -2.2875, -2.4748, -2.5702, -1.5408,\n",
      "        -1.9017, -1.8900, -2.1075, -1.9243, -2.5835, -2.0057, -2.0628, -2.2570,\n",
      "        -2.0996, -2.2861, -2.1724, -2.0249, -2.0270, -2.5918, -2.1041, -2.4884,\n",
      "        -2.4520, -2.4079, -2.4924, -1.6613, -2.2426, -1.7161, -2.4648, -2.6785,\n",
      "        -2.6578, -1.7753, -1.9922, -2.2260, -2.3618, -2.6157, -2.0162, -1.9822,\n",
      "        -2.5566, -2.1860, -2.5686, -1.9242, -2.7211, -2.2372, -2.7323, -2.4413,\n",
      "        -1.9864, -2.1114], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5235, -2.5921, -2.5828, -2.5676, -2.5833, -2.5360, -2.5935, -2.5882,\n",
      "        -2.5479, -2.5542, -2.5114, -2.5573, -2.5855, -2.5695, -2.5091, -2.5654,\n",
      "        -2.5859, -2.5242, -2.5819, -2.5288, -2.5837, -2.5770, -2.5670, -2.5880,\n",
      "        -2.5328, -2.5837, -2.5353, -2.4806, -2.4752, -2.5800, -2.5857, -2.5830,\n",
      "        -2.5653, -2.5420, -2.5711, -2.5848, -2.5667, -2.5794, -2.5665, -2.5255,\n",
      "        -2.5427, -2.5768, -2.5643, -2.5952, -2.5858, -2.5718, -2.5742, -2.5915,\n",
      "        -2.4960, -2.4527], device='mps:0')\n",
      "mean: tensor(-2.5582, device='mps:0')\n",
      "iter_dt 1.05s; iter 7: train loss 2.04078 temperature: 5.349999999999999\n",
      "mean_logits tensor([-2.8360, -2.5978, -2.7373, -2.1832, -2.6781, -2.5663, -2.4888, -1.7116,\n",
      "        -1.7909, -2.3226, -2.3770, -1.6541, -2.4816, -2.0071, -2.5517, -2.5471,\n",
      "        -2.4572, -2.1955, -1.9158, -2.3752, -2.2045, -2.3731, -1.9166, -2.6861,\n",
      "        -2.0636, -2.5466, -2.0941, -1.9066, -2.2748, -2.2741, -2.1781, -2.2952,\n",
      "        -2.4809, -1.9708, -2.2622, -2.2861, -2.4557, -2.4126, -2.4042, -2.0192,\n",
      "        -2.1363, -2.2271, -2.6121, -2.1065, -2.9239, -2.2814, -2.4124, -2.1665,\n",
      "        -2.0548, -2.4205], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5839, -2.5769, -2.5136, -2.5827, -2.5857, -2.5501, -2.5863, -2.5677,\n",
      "        -2.4968, -2.5627, -2.5334, -2.5682, -2.5440, -2.5277, -2.5267, -2.5839,\n",
      "        -2.5527, -2.5861, -2.5132, -2.5118, -2.5836, -2.5858, -2.5439, -2.5015,\n",
      "        -2.5494, -2.5873, -2.5673, -2.5560, -2.4896, -2.5651, -2.5819, -2.5706,\n",
      "        -2.5441, -2.5788, -2.5629, -2.5840, -2.5649, -2.5729, -2.5626, -2.5988,\n",
      "        -2.5863, -2.5751, -2.5858, -2.5214, -2.4695, -2.5863, -2.5150, -2.5311,\n",
      "        -2.5775, -2.5187], device='mps:0')\n",
      "mean: tensor(-2.5554, device='mps:0')\n",
      "iter_dt 1.07s; iter 8: train loss 2.42445 temperature: 5.399999999999999\n",
      "mean_logits tensor([-2.2878, -1.8793, -2.3303, -2.1764, -1.9560, -2.5697, -2.3717, -2.1024,\n",
      "        -2.6771, -2.7261, -2.0467, -2.1378, -2.2465, -2.4883, -2.3123, -1.7823,\n",
      "        -2.6842, -1.7017, -2.3684, -2.1853, -2.2444, -1.8959, -2.2938, -2.1790,\n",
      "        -2.5170, -2.4250, -1.9650, -2.5215, -2.3347, -2.4549, -2.1309, -2.7942,\n",
      "        -2.1658, -2.6215, -1.8334, -2.6279, -2.4400, -2.8354, -2.4688, -1.7474,\n",
      "        -2.3756, -2.2226, -2.6588, -2.4222, -2.8582, -2.7008, -2.2979, -3.2569,\n",
      "        -1.7716, -2.3539], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5822, -2.5644, -2.5618, -2.5000, -2.5761, -2.5415, -2.5022, -2.5887,\n",
      "        -2.5845, -2.5388, -2.5313, -2.5819, -2.5826, -2.5826, -2.4928, -2.5607,\n",
      "        -2.5480, -2.5099, -2.5880, -2.5932, -2.5717, -2.5861, -2.5803, -2.5457,\n",
      "        -2.5266, -2.5843, -2.5169, -2.5638, -2.5886, -2.5828, -2.5788, -2.5358,\n",
      "        -2.5339, -2.5794, -2.4962, -2.5790, -2.5852, -2.5852, -2.5365, -2.5664,\n",
      "        -2.5444, -2.5253, -2.5847, -2.5963, -2.5856, -2.5837, -2.5834, -2.5803,\n",
      "        -2.5854, -2.5596], device='mps:0')\n",
      "mean: tensor(-2.5613, device='mps:0')\n",
      "iter_dt 1.05s; iter 9: train loss 1.66337 temperature: 5.449999999999998\n",
      "mean_logits tensor([-2.3249, -2.1011, -2.6832, -2.1185, -2.2324, -2.6737, -2.5430, -1.7091,\n",
      "        -2.2877, -1.8599, -2.1002, -2.2519, -2.1430, -2.1272, -2.3278, -2.6762,\n",
      "        -2.6154, -2.4751, -2.3701, -2.0521, -2.5153, -2.4521, -2.4154, -2.4133,\n",
      "        -2.5588, -2.1138, -2.4770, -2.4938, -2.3127, -2.5453, -2.2934, -2.3768,\n",
      "        -1.8036, -2.2176, -2.1353, -2.1698, -2.7319, -2.3128, -2.6910, -2.3548,\n",
      "        -2.1426, -2.7238, -1.9925, -2.6651, -2.9642, -2.3219, -2.2939, -2.4854,\n",
      "        -2.7703, -2.5658], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5418, -2.5664, -2.5537, -2.5414, -2.5862, -2.5834, -2.5681, -2.5771,\n",
      "        -2.5380, -2.5418, -2.5669, -2.5757, -2.5717, -2.5859, -2.5864, -2.5870,\n",
      "        -2.5417, -2.5811, -2.5258, -2.5820, -2.5856, -2.5774, -2.5816, -2.5113,\n",
      "        -2.5911, -2.4867, -2.5483, -2.5832, -2.5384, -2.5834, -2.5856, -2.5863,\n",
      "        -2.5953, -2.5780, -2.5840, -2.5266, -2.5557, -2.5822, -2.4895, -2.5751,\n",
      "        -2.5394, -2.5887, -2.5832, -2.4961, -2.5820, -2.5551, -2.5862, -2.5824,\n",
      "        -2.5839, -2.5860], device='mps:0')\n",
      "mean: tensor(-2.5646, device='mps:0')\n",
      "iter_dt 1.07s; iter 10: train loss 1.97138 temperature: 5.499999999999998\n",
      "mean_logits tensor([-2.7785, -2.7460, -2.9215, -2.3101, -2.3104, -2.2730, -2.8028, -2.3351,\n",
      "        -2.6212, -2.2307, -2.6300, -1.9290, -2.6128, -2.5836, -2.7599, -2.7393,\n",
      "        -2.3510, -2.4489, -1.7392, -2.2538, -2.3861, -2.3879, -2.7173, -2.8179,\n",
      "        -2.9127, -3.1520, -2.4162, -2.4248, -2.2995, -1.9733, -2.4604, -2.6856,\n",
      "        -2.3128, -3.0260, -3.0319, -2.6420, -2.3493, -2.2072, -2.4751, -2.4524,\n",
      "        -2.5923, -2.4477, -2.5443, -2.3789, -2.3718, -2.3690, -2.0899, -2.8363,\n",
      "        -2.5522, -2.9964], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5855, -2.5380, -2.5907, -2.5670, -2.4992, -2.5679, -2.5879, -2.5393,\n",
      "        -2.5727, -2.5796, -2.5823, -2.5383, -2.5857, -2.5758, -2.5411, -2.3946,\n",
      "        -2.5859, -2.5826, -2.5595, -2.4947, -2.5846, -2.5783, -2.5851, -2.4786,\n",
      "        -2.5008, -2.5887, -2.5927, -2.5856, -2.5359, -2.5857, -2.5680, -2.5610,\n",
      "        -2.5800, -2.5804, -2.5617, -2.5702, -2.5778, -2.5833, -2.5760, -2.5866,\n",
      "        -2.5742, -2.5859, -2.5689, -2.5079, -2.5862, -2.5835, -2.5316, -2.5861,\n",
      "        -2.5322, -2.5442], device='mps:0')\n",
      "mean: tensor(-2.5606, device='mps:0')\n",
      "iter_dt 1.08s; iter 11: train loss 1.61359 temperature: 5.549999999999998\n",
      "mean_logits tensor([-2.5781, -2.3836, -2.1685, -2.2000, -2.4267, -2.3510, -2.6035, -2.3829,\n",
      "        -2.3272, -2.5933, -2.8435, -2.4606, -2.5721, -2.4723, -2.8696, -2.4280,\n",
      "        -2.6966, -2.5672, -2.5251, -2.4794, -2.6424, -2.2315, -2.5468, -2.4911,\n",
      "        -2.0869, -2.5098, -2.2403, -2.4639, -1.9310, -2.9595, -2.7668, -2.3379,\n",
      "        -2.7679, -2.2009, -2.6363, -2.2654, -2.7416, -2.6165, -2.4792, -2.8204,\n",
      "        -2.4504, -3.3202, -2.8270, -2.3993, -2.8402, -2.3586, -2.2544, -2.2410,\n",
      "        -2.4845, -2.4789], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5846, -2.5860, -2.5448, -2.5864, -2.5528, -2.5375, -2.5761, -2.5256,\n",
      "        -2.4776, -2.5306, -2.5835, -2.5856, -2.5352, -2.5379, -2.5400, -2.5751,\n",
      "        -2.5797, -2.5758, -2.5864, -2.5736, -2.5347, -2.5319, -2.5841, -2.5432,\n",
      "        -2.5870, -2.5867, -2.5845, -2.5188, -2.5860, -2.5839, -2.5974, -2.5777,\n",
      "        -2.5486, -2.5861, -2.5737, -2.5812, -2.5858, -2.5864, -2.5349, -2.4608,\n",
      "        -2.5686, -2.5855, -2.5905, -2.5484, -2.5947, -2.5441, -2.5363, -2.5778,\n",
      "        -2.5836, -2.5823], device='mps:0')\n",
      "mean: tensor(-2.5632, device='mps:0')\n",
      "iter_dt 1.04s; iter 12: train loss 1.55672 temperature: 5.599999999999998\n",
      "mean_logits tensor([-2.6052, -2.6017, -2.6851, -2.7352, -2.9417, -3.0279, -2.1645, -2.3494,\n",
      "        -2.3823, -2.1217, -2.2914, -2.3561, -3.0953, -2.9177, -2.4394, -2.5810,\n",
      "        -2.8184, -2.7039, -2.8531, -2.2839, -2.5259, -2.1788, -2.6199, -2.2964,\n",
      "        -2.5291, -2.8480, -2.7248, -2.2715, -2.5143, -2.8872, -2.5681, -2.7871,\n",
      "        -2.9014, -1.9923, -2.3677, -2.5230, -2.2030, -2.2942, -2.2985, -2.6216,\n",
      "        -2.6144, -2.8034, -2.1214, -2.6634, -2.6045, -2.5108, -2.5395, -2.5104,\n",
      "        -2.3202, -2.8340], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5423, -2.5851, -2.5833, -2.5823, -2.5863, -2.5319, -2.5859, -2.5832,\n",
      "        -2.5023, -2.5777, -2.5860, -2.5116, -2.5283, -2.5409, -2.5693, -2.5803,\n",
      "        -2.5907, -2.5308, -2.5048, -2.5774, -2.5524, -2.4828, -2.5840, -2.4831,\n",
      "        -2.5867, -2.5859, -2.5398, -2.5211, -2.5599, -2.5739, -2.5276, -2.5856,\n",
      "        -2.5652, -2.5850, -2.5556, -2.4707, -2.5281, -2.5275, -2.4582, -2.5868,\n",
      "        -2.5819, -2.5871, -2.5037, -2.5332, -2.5659, -2.5340, -2.5829, -2.5764,\n",
      "        -2.5723, -2.5834], device='mps:0')\n",
      "mean: tensor(-2.5532, device='mps:0')\n",
      "iter_dt 1.04s; iter 13: train loss 2.52596 temperature: 5.649999999999998\n",
      "mean_logits tensor([-2.9933, -2.6224, -2.5265, -2.4342, -2.0440, -2.4266, -2.4344, -2.4944,\n",
      "        -2.2695, -2.9262, -2.0011, -2.2601, -2.3324, -2.9822, -2.3224, -1.9657,\n",
      "        -2.5006, -2.6124, -2.4091, -2.7878, -2.4510, -2.9746, -2.3450, -1.9318,\n",
      "        -2.3952, -2.4597, -2.6233, -2.6398, -3.1573, -2.8348, -2.4306, -2.3022,\n",
      "        -2.6176, -2.4065, -2.8788, -2.7191, -1.9143, -2.6713, -2.7571, -2.4092,\n",
      "        -2.9880, -2.7144, -2.6799, -2.7536, -2.7119, -2.6110, -3.0599, -2.1129,\n",
      "        -2.8969, -3.1970], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5733, -2.5363, -2.5862, -2.5382, -2.5865, -2.5859, -2.5854, -2.5831,\n",
      "        -2.5759, -2.5902, -2.5853, -2.5859, -2.5492, -2.4680, -2.5852, -2.5853,\n",
      "        -2.5896, -2.5821, -2.5829, -2.5840, -2.5427, -2.5828, -2.5864, -2.5764,\n",
      "        -2.5834, -2.5831, -2.5346, -2.5421, -2.5672, -2.5328, -2.5713, -2.5659,\n",
      "        -2.5854, -2.4542, -2.5695, -2.5424, -2.5472, -2.5865, -2.5842, -2.5435,\n",
      "        -2.5445, -2.5839, -2.5810, -2.5760, -2.5725, -2.5793, -2.5837, -2.5765,\n",
      "        -2.5797, -2.5745], device='mps:0')\n",
      "mean: tensor(-2.5674, device='mps:0')\n",
      "iter_dt 1.06s; iter 14: train loss 1.09316 temperature: 5.6999999999999975\n",
      "mean_logits tensor([-2.8832, -2.8271, -2.7462, -2.4817, -2.3845, -2.1762, -2.7568, -1.9406,\n",
      "        -2.6555, -2.0409, -2.4200, -2.1401, -2.6081, -2.3317, -2.7077, -2.4645,\n",
      "        -2.3038, -2.3831, -2.1600, -2.2689, -2.3522, -2.7013, -2.4756, -2.2722,\n",
      "        -2.2703, -2.4849, -2.5276, -2.4935, -2.5351, -2.1955, -2.4569, -2.7763,\n",
      "        -2.7710, -2.5349, -2.3139, -2.2566, -2.3970, -2.4120, -2.6832, -2.0590,\n",
      "        -2.4310, -2.3476, -2.5423, -2.3859, -2.4036, -2.4306, -2.3043, -2.5212,\n",
      "        -2.7773, -2.0357], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5111, -2.5902, -2.5710, -2.5826, -2.5807, -2.4911, -2.5872, -2.5281,\n",
      "        -2.5334, -2.5366, -2.5665, -2.5480, -2.5739, -2.5656, -2.5853, -2.5693,\n",
      "        -2.5464, -2.5771, -2.5232, -2.5838, -2.5837, -2.5813, -2.5833, -2.5822,\n",
      "        -2.5171, -2.4809, -2.5572, -2.5223, -2.5832, -2.5435, -2.5824, -2.5863,\n",
      "        -2.5824, -2.5630, -2.5942, -2.5839, -2.5327, -2.5748, -2.5861, -2.5862,\n",
      "        -2.5784, -2.5849, -2.5810, -2.5701, -2.5783, -2.5351, -2.5802, -2.5624,\n",
      "        -2.5860, -2.5834], device='mps:0')\n",
      "mean: tensor(-2.5640, device='mps:0')\n",
      "iter_dt 1.05s; iter 15: train loss 1.81577 temperature: 5.749999999999997\n",
      "mean_logits tensor([-2.5542, -2.2372, -2.3614, -2.6503, -2.2398, -2.0794, -2.2752, -2.3344,\n",
      "        -2.7107, -2.7329, -1.9329, -2.5699, -2.1638, -2.9669, -2.9692, -2.0818,\n",
      "        -2.7821, -2.3228, -2.4909, -2.1888, -2.7716, -3.1279, -2.6911, -1.9535,\n",
      "        -2.2468, -2.6039, -2.4363, -2.2599, -2.3269, -2.4518, -2.5437, -2.4943,\n",
      "        -2.3778, -2.3872, -2.8714, -2.4065, -2.1610, -2.6881, -2.7391, -2.6208,\n",
      "        -3.0553, -2.2616, -2.3091, -2.5812, -2.4270, -2.2015, -2.2980, -2.5292,\n",
      "        -2.5544, -2.4186], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5760, -2.5861, -2.5794, -2.5837, -2.5705, -2.5871, -2.5848, -2.5856,\n",
      "        -2.5901, -2.5957, -2.5820, -2.5317, -2.5912, -2.5781, -2.5709, -2.5857,\n",
      "        -2.5845, -2.5856, -2.5896, -2.5707, -2.5359, -2.5837, -2.4745, -2.5874,\n",
      "        -2.5864, -2.5049, -2.5747, -2.5158, -2.5692, -2.4901, -2.5694, -2.5849,\n",
      "        -2.5238, -2.5862, -2.5617, -2.5856, -2.5381, -2.5402, -2.5924, -2.5332,\n",
      "        -2.5637, -2.5705, -2.5923, -2.5827, -2.5862, -2.5867, -2.5346, -2.5866,\n",
      "        -2.5774, -2.5860], device='mps:0')\n",
      "mean: tensor(-2.5683, device='mps:0')\n",
      "iter_dt 1.07s; iter 16: train loss 1.40913 temperature: 5.799999999999997\n",
      "mean_logits tensor([-2.5102, -2.6005, -2.1313, -2.3344, -2.7946, -2.2468, -2.3326, -2.1898,\n",
      "        -2.3705, -2.3809, -2.5061, -2.5451, -2.6009, -2.2633, -1.9063, -1.7634,\n",
      "        -2.5787, -2.5807, -2.2941, -2.3662, -2.5659, -2.1034, -2.2814, -2.3304,\n",
      "        -2.5878, -2.8111, -2.1430, -2.7085, -3.0099, -2.3295, -2.0895, -2.0297,\n",
      "        -2.4063, -2.4799, -2.2783, -2.1491, -2.4672, -2.8273, -2.6517, -2.8659,\n",
      "        -2.5392, -2.7574, -2.2498, -2.8398, -2.4223, -2.3100, -2.7066, -2.4434,\n",
      "        -2.4307, -2.3773], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5731, -2.5469, -2.5329, -2.5080, -2.5403, -2.4819, -2.5847, -2.5512,\n",
      "        -2.5711, -2.5839, -2.5397, -2.5942, -2.5885, -2.5348, -2.5967, -2.5856,\n",
      "        -2.5821, -2.5889, -2.5827, -2.5377, -2.5832, -2.5811, -2.5865, -2.5933,\n",
      "        -2.5855, -2.5541, -2.4696, -2.5697, -2.5866, -2.5824, -2.5861, -2.5807,\n",
      "        -2.5855, -2.5840, -2.5427, -2.5853, -2.5653, -2.5837, -2.5689, -2.5911,\n",
      "        -2.5813, -2.5822, -2.4653, -2.5865, -2.5866, -2.5793, -2.5883, -2.5677,\n",
      "        -2.5865, -2.5873], device='mps:0')\n",
      "mean: tensor(-2.5676, device='mps:0')\n",
      "iter_dt 1.05s; iter 17: train loss 1.39503 temperature: 5.849999999999997\n",
      "mean_logits tensor([-2.5304, -2.5070, -2.6036, -2.6375, -2.1433, -2.7676, -2.2962, -2.8022,\n",
      "        -2.2119, -2.4655, -2.5199, -2.2615, -2.6317, -2.6396, -2.7102, -2.3299,\n",
      "        -2.7020, -2.6745, -2.5651, -2.8005, -2.8825, -2.5518, -2.4854, -2.3242,\n",
      "        -2.5182, -2.8618, -2.5110, -1.9775, -2.3841, -2.3867, -2.5378, -2.6355,\n",
      "        -2.1576, -2.6799, -2.0727, -2.1973, -2.3629, -2.1639, -2.2912, -3.0231,\n",
      "        -2.5087, -2.1330, -2.1048, -2.8147, -2.5818, -2.3580, -1.8544, -1.9395,\n",
      "        -2.6078, -2.0522], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5479, -2.5807, -2.4928, -2.5941, -2.5910, -2.5768, -2.5157, -2.5934,\n",
      "        -2.5303, -2.5836, -2.5781, -2.5434, -2.5187, -2.5330, -2.5754, -2.5915,\n",
      "        -2.5905, -2.4554, -2.5956, -2.4803, -2.5936, -2.5664, -2.4679, -2.5853,\n",
      "        -2.5956, -2.5886, -2.5712, -2.5102, -2.5503, -2.5409, -2.5830, -2.5489,\n",
      "        -2.5865, -2.5885, -2.5041, -2.5467, -2.5838, -2.5883, -2.5928, -2.5439,\n",
      "        -2.5789, -2.5571, -2.5109, -2.5928, -2.5837, -2.5402, -2.5018, -2.5606,\n",
      "        -2.5866, -2.5850], device='mps:0')\n",
      "mean: tensor(-2.5580, device='mps:0')\n",
      "iter_dt 1.06s; iter 18: train loss 0.95555 temperature: 5.899999999999997\n",
      "mean_logits tensor([-2.5205, -2.3054, -2.1803, -2.2317, -2.5782, -2.3562, -2.2201, -2.6897,\n",
      "        -2.5590, -2.3602, -2.7182, -2.3802, -2.0577, -2.7591, -2.2366, -2.6585,\n",
      "        -2.5125, -2.1816, -2.2553, -2.5616, -2.5373, -2.4581, -2.3590, -2.3066,\n",
      "        -2.5086, -2.4837, -2.5993, -2.6075, -2.5631, -2.0474, -2.4687, -2.4765,\n",
      "        -2.7215, -2.4657, -2.3553, -2.3419, -2.4733, -1.7951, -2.5070, -2.5249,\n",
      "        -2.4560, -2.0893, -2.0702, -2.4580, -2.3964, -2.5592, -2.5327, -2.3431,\n",
      "        -2.4283, -2.3168], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5264, -2.5314, -2.5216, -2.5879, -2.5886, -2.5917, -2.4627, -2.5722,\n",
      "        -2.5512, -2.5864, -2.5758, -2.5768, -2.5855, -2.5830, -2.5777, -2.5842,\n",
      "        -2.5871, -2.5764, -2.5608, -2.5858, -2.5411, -2.5868, -2.5344, -2.5178,\n",
      "        -2.5841, -2.5820, -2.5746, -2.5444, -2.4734, -2.5836, -2.5564, -2.5316,\n",
      "        -2.5929, -2.5426, -2.5862, -2.5700, -2.5731, -2.5679, -2.5893, -2.5209,\n",
      "        -2.5285, -2.5862, -2.5841, -2.5826, -2.5282, -2.5932, -2.5791, -2.5953,\n",
      "        -2.5868, -2.5587], device='mps:0')\n",
      "mean: tensor(-2.5638, device='mps:0')\n",
      "iter_dt 1.05s; iter 19: train loss 1.35519 temperature: 5.949999999999997\n",
      "mean_logits tensor([-2.5764, -2.1609, -2.3238, -2.8153, -2.5243, -2.5222, -2.0746, -2.1873,\n",
      "        -2.3650, -2.2583, -2.4046, -2.1611, -2.7387, -2.8802, -2.5308, -2.0897,\n",
      "        -2.2408, -2.3306, -2.3488, -2.5331, -2.2993, -2.1342, -2.4839, -2.4858,\n",
      "        -2.4247, -2.5967, -2.0601, -2.5607, -2.1957, -2.1547, -2.8291, -2.2649,\n",
      "        -2.6975, -2.5549, -2.2424, -2.5061, -2.3496, -1.9800, -2.4190, -2.2689,\n",
      "        -2.7954, -2.6937, -2.5315, -2.4391, -2.7973, -2.3103, -2.3711, -2.1884,\n",
      "        -2.3115, -1.8054], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5527, -2.5786, -2.4935, -2.5917, -2.5860, -2.5852, -2.5754, -2.5840,\n",
      "        -2.5714, -2.5815, -2.5861, -2.5269, -2.5448, -2.5898, -2.5862, -2.5312,\n",
      "        -2.5702, -2.5789, -2.5754, -2.5372, -2.4619, -2.5797, -2.5348, -2.5530,\n",
      "        -2.5445, -2.5669, -2.5910, -2.5456, -2.5152, -2.5827, -2.5821, -2.5861,\n",
      "        -2.5745, -2.5887, -2.5762, -2.5295, -2.5838, -2.5794, -2.5383, -2.5326,\n",
      "        -2.5754, -2.5743, -2.5739, -2.5937, -2.5853, -2.5693, -2.5957, -2.5836,\n",
      "        -2.5859, -2.5250], device='mps:0')\n",
      "mean: tensor(-2.5647, device='mps:0')\n",
      "iter_dt 1.05s; iter 20: train loss 1.16868 temperature: 5.9999999999999964\n",
      "mean_logits tensor([-2.7284, -2.2440, -2.3639, -2.5030, -2.0336, -2.1358, -2.5754, -2.8040,\n",
      "        -2.5023, -2.3284, -2.1669, -2.1521, -2.7207, -2.6112, -2.2588, -2.0916,\n",
      "        -2.3085, -2.2612, -2.3647, -2.4378, -2.7538, -2.2251, -2.3490, -2.5335,\n",
      "        -2.4380, -1.6531, -2.6377, -2.5227, -2.4757, -2.4918, -2.2294, -2.4231,\n",
      "        -2.3909, -2.2829, -2.6253, -2.6448, -2.4531, -2.1026, -2.8217, -2.4096,\n",
      "        -2.5299, -2.5520, -2.5570, -2.8887, -2.3269, -2.4836, -2.3267, -2.4622,\n",
      "        -2.3044, -2.1712], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5801, -2.5864, -2.5769, -2.5688, -2.5440, -2.5343, -2.5399, -2.5828,\n",
      "        -2.5326, -2.5400, -2.5842, -2.5923, -2.5856, -2.5383, -2.5852, -2.5416,\n",
      "        -2.5360, -2.5961, -2.5814, -2.5751, -2.5867, -2.5832, -2.5722, -2.5646,\n",
      "        -2.5755, -2.5165, -2.5938, -2.5446, -2.5856, -2.5715, -2.5795, -2.5734,\n",
      "        -2.5879, -2.5843, -2.5912, -2.5533, -2.5821, -2.5857, -2.5640, -2.5484,\n",
      "        -2.5850, -2.5078, -2.5859, -2.5807, -2.5508, -2.5852, -2.5832, -2.5732,\n",
      "        -2.5466, -2.5066], device='mps:0')\n",
      "mean: tensor(-2.5670, device='mps:0')\n",
      "iter_dt 1.08s; iter 21: train loss 1.51809 temperature: 6.049999999999996\n",
      "mean_logits tensor([-2.4003, -2.4147, -2.5287, -2.5096, -2.3332, -2.2593, -2.5439, -2.3374,\n",
      "        -2.3379, -2.1191, -2.1375, -2.8347, -2.5413, -2.5111, -2.0655, -2.2883,\n",
      "        -2.7878, -2.6950, -3.0613, -2.5659, -2.2927, -2.5748, -2.9704, -2.4006,\n",
      "        -2.5887, -2.8947, -2.0291, -2.7160, -2.4901, -2.4079, -2.1593, -2.2097,\n",
      "        -2.2442, -2.5173, -2.5983, -2.2186, -2.8846, -2.0829, -2.1986, -2.5162,\n",
      "        -2.7260, -2.2722, -2.4390, -1.8908, -2.4954, -2.2990, -2.0921, -2.5700,\n",
      "        -2.1741, -2.6786], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5750, -2.5172, -2.5831, -2.5214, -2.5589, -2.5837, -2.5383, -2.5833,\n",
      "        -2.5618, -2.5366, -2.5656, -2.5820, -2.5414, -2.5360, -2.5839, -2.5696,\n",
      "        -2.5856, -2.5885, -2.5755, -2.5496, -2.5752, -2.5778, -2.5920, -2.5832,\n",
      "        -2.5404, -2.5824, -2.5716, -2.5927, -2.5381, -2.5769, -2.5390, -2.5802,\n",
      "        -2.5318, -2.5713, -2.5839, -2.5422, -2.5825, -2.5120, -2.5768, -2.5854,\n",
      "        -2.5126, -2.5396, -2.5338, -2.5754, -2.5255, -2.5493, -2.5794, -2.5801,\n",
      "        -2.5941, -2.5466], device='mps:0')\n",
      "mean: tensor(-2.5622, device='mps:0')\n",
      "iter_dt 1.05s; iter 22: train loss 1.16711 temperature: 6.099999999999996\n",
      "mean_logits tensor([-2.4019, -2.8402, -2.4479, -2.5413, -2.2876, -2.5511, -2.6703, -2.1851,\n",
      "        -2.7480, -3.0054, -2.5641, -2.5304, -2.2890, -2.3674, -2.3971, -2.4342,\n",
      "        -2.3918, -2.2519, -2.4276, -2.2230, -2.4024, -2.2314, -2.9567, -2.3567,\n",
      "        -2.5008, -2.4034, -2.3461, -2.4004, -2.3330, -2.3643, -2.3984, -2.5275,\n",
      "        -2.6549, -2.4326, -2.7044, -2.6234, -2.5349, -2.4616, -2.3660, -2.4201,\n",
      "        -2.4873, -2.0079, -1.4782, -2.7185, -2.6701, -2.3365, -2.3257, -2.2055,\n",
      "        -2.2877, -2.3961], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5717, -2.5708, -2.5817, -2.5865, -2.5663, -2.5285, -2.5266, -2.5870,\n",
      "        -2.5463, -2.5774, -2.5373, -2.5795, -2.5867, -2.5872, -2.5836, -2.5430,\n",
      "        -2.5322, -2.5312, -2.5790, -2.5194, -2.5608, -2.5792, -2.5738, -2.5883,\n",
      "        -2.5411, -2.5868, -2.5628, -2.4610, -2.4838, -2.5734, -2.5053, -2.5652,\n",
      "        -2.5867, -2.5339, -2.5960, -2.5831, -2.5868, -2.5091, -2.5332, -2.5567,\n",
      "        -2.5939, -2.5860, -2.5851, -2.5644, -2.5826, -2.5863, -2.5830, -2.5839,\n",
      "        -2.5424, -2.5329], device='mps:0')\n",
      "mean: tensor(-2.5606, device='mps:0')\n",
      "iter_dt 1.05s; iter 23: train loss 1.53942 temperature: 6.149999999999996\n",
      "mean_logits tensor([-2.1116, -2.6107, -2.4646, -2.2557, -2.3692, -2.6183, -2.2284, -2.3907,\n",
      "        -2.2207, -2.2692, -2.6287, -2.3950, -2.5516, -2.1288, -2.2793, -1.7529,\n",
      "        -2.6009, -2.4259, -2.0889, -2.3279, -2.6117, -2.6178, -2.4039, -2.3024,\n",
      "        -2.3705, -2.6584, -2.7073, -2.9431, -2.5196, -2.6758, -2.4595, -2.6609,\n",
      "        -2.0975, -2.6125, -2.3461, -3.1439, -2.3111, -2.2482, -2.1302, -2.7020,\n",
      "        -1.8217, -2.0565, -2.3263, -2.1995, -2.4262, -2.2730, -2.3585, -2.4454,\n",
      "        -2.2511, -2.2852], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5801, -2.5755, -2.5866, -2.5797, -2.5863, -2.5889, -2.5873, -2.5954,\n",
      "        -2.5651, -2.5806, -2.5883, -2.5541, -2.5309, -2.5699, -2.5770, -2.5395,\n",
      "        -2.5856, -2.5609, -2.5282, -2.5643, -2.5445, -2.5758, -2.5725, -2.5262,\n",
      "        -2.5229, -2.5316, -2.5333, -2.5850, -2.5307, -2.5958, -2.5916, -2.5864,\n",
      "        -2.5526, -2.5309, -2.5855, -2.5884, -2.5861, -2.5443, -2.5742, -2.5813,\n",
      "        -2.5415, -2.5014, -2.5281, -2.5416, -2.5791, -2.5836, -2.4975, -2.5763,\n",
      "        -2.5314, -2.5775], device='mps:0')\n",
      "mean: tensor(-2.5624, device='mps:0')\n",
      "iter_dt 1.06s; iter 24: train loss 1.21265 temperature: 6.199999999999996\n",
      "mean_logits tensor([-2.4466, -2.5329, -1.9274, -2.3945, -2.0395, -2.2286, -2.6764, -2.2767,\n",
      "        -2.5902, -2.4362, -2.2948, -2.4921, -2.5615, -2.2860, -2.4165, -2.3852,\n",
      "        -2.3112, -2.3813, -2.4371, -2.6484, -2.6237, -2.4562, -2.3837, -2.6421,\n",
      "        -2.7053, -2.2935, -2.2428, -2.8387, -2.3162, -2.3628, -2.5698, -2.1638,\n",
      "        -2.2049, -2.7441, -2.0909, -2.2422, -2.4472, -2.2920, -2.5880, -2.4488,\n",
      "        -2.2230, -2.5694, -2.3230, -2.3019, -2.5053, -2.1811, -2.8918, -2.5651,\n",
      "        -1.9440, -2.1687], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5878, -2.5808, -2.5718, -2.5855, -2.5397, -2.5856, -2.5863, -2.5957,\n",
      "        -2.5671, -2.5554, -2.5793, -2.4943, -2.5818, -2.5562, -2.5355, -2.5526,\n",
      "        -2.4942, -2.5751, -2.5928, -2.5837, -2.5832, -2.5852, -2.5816, -2.5814,\n",
      "        -2.5808, -2.5836, -2.5702, -2.5296, -2.5907, -2.5656, -2.5841, -2.5285,\n",
      "        -2.5798, -2.5167, -2.5806, -2.5788, -2.5758, -2.5951, -2.5849, -2.5858,\n",
      "        -2.5836, -2.5860, -2.5087, -2.5724, -2.5757, -2.5838, -2.5847, -2.5927,\n",
      "        -2.5643, -2.5866], device='mps:0')\n",
      "mean: tensor(-2.5700, device='mps:0')\n",
      "iter_dt 1.04s; iter 25: train loss 1.09087 temperature: 6.249999999999996\n",
      "mean_logits tensor([-2.5198, -2.1707, -2.4210, -2.5430, -2.6378, -2.0657, -2.3793, -2.6804,\n",
      "        -2.3700, -2.4297, -2.1220, -2.0857, -2.5767, -2.3494, -2.3836, -2.4333,\n",
      "        -2.1559, -2.2575, -2.8798, -2.3819, -2.6228, -2.6257, -2.2036, -2.6147,\n",
      "        -2.3449, -2.7372, -2.4075, -2.5289, -2.7651, -2.2731, -2.3143, -2.5894,\n",
      "        -2.2883, -2.2827, -2.5891, -2.4325, -2.5085, -2.2529, -2.3739, -2.2084,\n",
      "        -2.4902, -2.3495, -2.8112, -2.0811, -1.7975, -2.6051, -2.3590, -2.3569,\n",
      "        -2.3727, -2.5171], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5853, -2.5554, -2.5577, -2.5826, -2.5835, -2.5774, -2.5887, -2.5885,\n",
      "        -2.5884, -2.5330, -2.5333, -2.5421, -2.5864, -2.5929, -2.5345, -2.5438,\n",
      "        -2.5784, -2.5275, -2.5929, -2.5450, -2.5946, -2.5886, -2.5865, -2.4750,\n",
      "        -2.5726, -2.5757, -2.5837, -2.5900, -2.5862, -2.5825, -2.5828, -2.5859,\n",
      "        -2.5381, -2.5853, -2.5825, -2.5415, -2.5832, -2.5285, -2.6046, -2.5543,\n",
      "        -2.5937, -2.5460, -2.5773, -2.5418, -2.5872, -2.5292, -2.5736, -2.4988,\n",
      "        -2.5838, -2.5794], device='mps:0')\n",
      "mean: tensor(-2.5670, device='mps:0')\n",
      "iter_dt 1.06s; iter 26: train loss 1.30059 temperature: 6.299999999999995\n",
      "mean_logits tensor([-2.3715, -2.7716, -2.6631, -2.4610, -2.3333, -2.4171, -2.6494, -2.3683,\n",
      "        -2.3883, -2.1769, -2.1955, -2.8332, -2.2984, -2.6669, -1.8676, -2.0913,\n",
      "        -2.5884, -2.9388, -2.4976, -2.3848, -2.2599, -2.4548, -2.7601, -2.0875,\n",
      "        -2.4081, -2.6069, -2.3713, -2.3360, -2.2810, -2.3977, -2.1978, -2.5067,\n",
      "        -2.5361, -2.5255, -2.3163, -2.3169, -2.6182, -2.4007, -2.7797, -2.4871,\n",
      "        -2.0837, -2.2603, -2.3583, -2.1250, -2.2960, -2.2431, -2.1035, -2.5128,\n",
      "        -2.4825, -2.0280], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5744, -2.5416, -2.5613, -2.5370, -2.5927, -2.5830, -2.5497, -2.5859,\n",
      "        -2.5848, -2.5859, -2.5862, -2.5433, -2.5327, -2.5699, -2.5754, -2.5135,\n",
      "        -2.5850, -2.5817, -2.5868, -2.5789, -2.5734, -2.5465, -2.5868, -2.5953,\n",
      "        -2.6077, -2.5890, -2.5108, -2.5838, -2.5713, -2.5837, -2.5845, -2.5835,\n",
      "        -2.5835, -2.5865, -2.5811, -2.5291, -2.5860, -2.5270, -2.5802, -2.5749,\n",
      "        -2.5755, -2.5796, -2.5281, -2.5828, -2.5839, -2.5499, -2.5385, -2.5702,\n",
      "        -2.5902, -2.5473], device='mps:0')\n",
      "mean: tensor(-2.5692, device='mps:0')\n",
      "iter_dt 1.05s; iter 27: train loss 1.19665 temperature: 6.349999999999995\n",
      "mean_logits tensor([-1.9751, -2.5992, -2.5030, -2.6648, -2.3309, -2.1931, -2.3139, -2.2144,\n",
      "        -2.3377, -2.5069, -2.2829, -2.4158, -2.4841, -2.3491, -2.3364, -2.2544,\n",
      "        -2.0917, -2.5311, -2.3800, -2.3503, -2.5696, -2.3466, -2.4661, -2.4414,\n",
      "        -2.1562, -2.3448, -2.5001, -2.6676, -2.5605, -2.0999, -2.4064, -2.2190,\n",
      "        -2.4213, -2.7978, -2.6695, -2.4296, -2.2226, -2.5231, -2.0771, -2.6878,\n",
      "        -2.1964, -2.6877, -2.3196, -2.2355, -2.2644, -2.1806, -2.3612, -2.8447,\n",
      "        -2.3324, -2.0028], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5385, -2.5538, -2.5858, -2.5852, -2.5836, -2.5938, -2.5828, -2.5857,\n",
      "        -2.5798, -2.5859, -2.5759, -2.5850, -2.5390, -2.5100, -2.5538, -2.5336,\n",
      "        -2.5722, -2.5861, -2.5775, -2.5820, -2.5916, -2.5748, -2.5415, -2.5676,\n",
      "        -2.5503, -2.5632, -2.5849, -2.5472, -2.5849, -2.5811, -2.5898, -2.5696,\n",
      "        -2.5290, -2.5866, -2.5818, -2.5836, -2.5865, -2.5837, -2.5866, -2.5792,\n",
      "        -2.5445, -2.5436, -2.5792, -2.5547, -2.5817, -2.5242, -2.5354, -2.5430,\n",
      "        -2.5703, -2.5375], device='mps:0')\n",
      "mean: tensor(-2.5674, device='mps:0')\n",
      "iter_dt 1.06s; iter 28: train loss 1.08623 temperature: 6.399999999999995\n",
      "mean_logits tensor([-2.2167, -2.4539, -2.0565, -2.2737, -2.6340, -2.4562, -2.6988, -2.5553,\n",
      "        -2.1723, -2.3968, -2.6765, -2.3221, -2.3125, -2.0869, -2.6445, -2.0351,\n",
      "        -2.3439, -2.3231, -2.2912, -2.3077, -2.2268, -2.5909, -2.5678, -2.4923,\n",
      "        -2.4867, -2.4634, -2.4104, -2.3863, -1.9484, -2.8191, -2.1382, -2.4523,\n",
      "        -2.3580, -2.6656, -2.7202, -2.5792, -2.4327, -2.6770, -2.6917, -2.0647,\n",
      "        -2.5111, -2.3326, -2.0309, -2.5808, -2.6602, -2.7247, -2.6671, -2.1488,\n",
      "        -2.4208, -2.1903], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5753, -2.5805, -2.5739, -2.5659, -2.5966, -2.5757, -2.5669, -2.5433,\n",
      "        -2.5568, -2.5438, -2.5874, -2.5296, -2.5784, -2.4891, -2.5877, -2.5730,\n",
      "        -2.5516, -2.5869, -2.5867, -2.5350, -2.5753, -2.5831, -2.5751, -2.5740,\n",
      "        -2.5445, -2.5668, -2.5865, -2.5769, -2.5873, -2.5959, -2.5375, -2.5849,\n",
      "        -2.5829, -2.5851, -2.5829, -2.5919, -2.5266, -2.5912, -2.5770, -2.5439,\n",
      "        -2.5730, -2.6069, -2.5780, -2.5453, -2.5839, -2.5779, -2.5805, -2.5431,\n",
      "        -2.5724, -2.5293], device='mps:0')\n",
      "mean: tensor(-2.5689, device='mps:0')\n",
      "iter_dt 1.05s; iter 29: train loss 0.96232 temperature: 6.449999999999995\n",
      "mean_logits tensor([-2.5872, -2.3246, -2.5670, -2.4040, -2.2688, -2.2753, -2.4011, -2.7603,\n",
      "        -2.3379, -2.8245, -2.3413, -2.4850, -2.4872, -2.3043, -2.2369, -2.7221,\n",
      "        -2.3595, -2.2524, -2.0509, -2.2571, -2.7305, -2.6622, -2.4574, -2.7558,\n",
      "        -2.1661, -2.3950, -2.8184, -2.2485, -2.5690, -2.3821, -2.4488, -2.1501,\n",
      "        -2.2514, -2.4662, -2.9307, -2.5458, -2.7077, -2.5048, -2.3309, -2.7019,\n",
      "        -2.1844, -2.5259, -2.5821, -2.6478, -2.2010, -2.7208, -2.3036, -2.4089,\n",
      "        -2.5244, -2.5629], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5832, -2.5755, -2.5875, -2.5307, -2.5754, -2.5809, -2.5593, -2.5830,\n",
      "        -2.5846, -2.5828, -2.5437, -2.5886, -2.5340, -2.5831, -2.5748, -2.5933,\n",
      "        -2.5850, -2.5443, -2.5622, -2.5603, -2.5393, -2.5653, -2.4813, -2.5797,\n",
      "        -2.5353, -2.5863, -2.5938, -2.5805, -2.5700, -2.5205, -2.4812, -2.5869,\n",
      "        -2.5680, -2.5795, -2.5844, -2.5107, -2.5826, -2.5843, -2.5777, -2.5183,\n",
      "        -2.5583, -2.5637, -2.5786, -2.5853, -2.5441, -2.5348, -2.5197, -2.5849,\n",
      "        -2.5414, -2.5860], device='mps:0')\n",
      "mean: tensor(-2.5627, device='mps:0')\n",
      "iter_dt 1.04s; iter 30: train loss 1.21441 temperature: 6.499999999999995\n",
      "mean_logits tensor([-2.1510, -2.6479, -2.2933, -1.9877, -2.3768, -2.0942, -2.5382, -2.5283,\n",
      "        -2.6106, -2.1012, -2.0707, -2.4465, -2.0893, -2.4600, -2.4692, -2.3302,\n",
      "        -2.6228, -2.5738, -2.5505, -2.7491, -2.1833, -2.2633, -2.4533, -2.6528,\n",
      "        -2.4509, -2.2159, -2.6143, -2.6283, -2.4560, -2.4398, -2.2620, -2.3494,\n",
      "        -2.3121, -2.6574, -2.4507, -2.0729, -2.5077, -2.2656, -2.2662, -2.4629,\n",
      "        -2.3594, -2.8074, -2.4589, -3.0452, -2.1925, -2.2614, -2.5621, -2.3010,\n",
      "        -2.0621, -2.5746], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5697, -2.4891, -2.5643, -2.5864, -2.5433, -2.5649, -2.5861, -2.5716,\n",
      "        -2.5735, -2.5224, -2.4687, -2.5856, -2.5861, -2.5864, -2.5832, -2.5667,\n",
      "        -2.5794, -2.5763, -2.5822, -2.5814, -2.5310, -2.5867, -2.5763, -2.5931,\n",
      "        -2.5230, -2.5341, -2.5835, -2.5884, -2.5842, -2.5740, -2.5260, -2.6049,\n",
      "        -2.5482, -2.5810, -2.5842, -2.5332, -2.5863, -2.5540, -2.5831, -2.5861,\n",
      "        -2.5297, -2.5794, -2.5301, -2.5909, -2.5795, -2.5814, -2.5443, -2.5936,\n",
      "        -2.5608, -2.5887], device='mps:0')\n",
      "mean: tensor(-2.5661, device='mps:0')\n",
      "iter_dt 1.04s; iter 31: train loss 0.97310 temperature: 6.5499999999999945\n",
      "mean_logits tensor([-2.5000, -2.1375, -2.4827, -2.5889, -2.3124, -2.4651, -2.6823, -2.3982,\n",
      "        -2.2182, -2.5449, -2.3319, -2.6070, -2.4039, -2.2979, -2.7101, -2.0490,\n",
      "        -2.3502, -2.4297, -2.2611, -2.4239, -1.9610, -2.5241, -2.3789, -2.6860,\n",
      "        -2.5227, -1.9678, -2.4908, -2.1367, -2.6241, -2.3450, -2.8097, -2.5360,\n",
      "        -2.7707, -2.5031, -2.6545, -2.3812, -2.9001, -1.9581, -2.6220, -2.4609,\n",
      "        -2.5722, -2.5791, -2.5399, -2.0966, -2.4880, -2.4608, -2.6713, -2.2592,\n",
      "        -2.5444, -2.5575], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5585, -2.5540, -2.5750, -2.5465, -2.5873, -2.5343, -2.4848, -2.5299,\n",
      "        -2.5679, -2.4998, -2.5743, -2.5831, -2.5580, -2.5500, -2.5793, -2.5747,\n",
      "        -2.5011, -2.5345, -2.5689, -2.5419, -2.5876, -2.5724, -2.5546, -2.5930,\n",
      "        -2.5936, -2.5862, -2.5490, -2.5281, -2.5617, -2.5870, -2.5854, -2.5863,\n",
      "        -2.5859, -2.5319, -2.5856, -2.5863, -2.5867, -2.5165, -2.5827, -2.5771,\n",
      "        -2.5856, -2.5833, -2.5913, -2.5882, -2.5610, -2.5218, -2.5882, -2.5811,\n",
      "        -2.5221, -2.5937], device='mps:0')\n",
      "mean: tensor(-2.5631, device='mps:0')\n",
      "iter_dt 1.07s; iter 32: train loss 0.96068 temperature: 6.599999999999994\n",
      "mean_logits tensor([-2.7247, -2.7184, -2.1416, -2.5253, -2.7980, -2.7240, -2.3464, -2.5179,\n",
      "        -2.1572, -2.5068, -2.5214, -2.4331, -2.6337, -2.6369, -2.6014, -2.2331,\n",
      "        -2.9504, -2.5724, -2.6927, -2.2732, -2.3290, -2.5783, -1.9271, -2.8072,\n",
      "        -2.4369, -2.2557, -2.2770, -2.5617, -2.9276, -2.4680, -2.5776, -2.7656,\n",
      "        -2.4062, -2.9298, -2.5843, -2.3725, -2.4942, -2.5777, -2.5677, -2.5854,\n",
      "        -2.3511, -2.3608, -2.4498, -2.5292, -2.4414, -2.4710, -2.4137, -2.3793,\n",
      "        -2.4291, -2.1438], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5760, -2.5723, -2.5170, -2.5831, -2.5930, -2.5684, -2.5760, -2.5455,\n",
      "        -2.5855, -2.5857, -2.5831, -2.5458, -2.5388, -2.5701, -2.5814, -2.5818,\n",
      "        -2.5878, -2.5856, -2.5549, -2.5621, -2.4104, -2.5248, -2.5977, -2.5802,\n",
      "        -2.5203, -2.5899, -2.5329, -2.4969, -2.5562, -2.5859, -2.5797, -2.5866,\n",
      "        -2.5862, -2.5736, -2.5860, -2.5929, -2.5805, -2.5518, -2.5911, -2.5712,\n",
      "        -2.5167, -2.5876, -2.5346, -2.5937, -2.5498, -2.5821, -2.5840, -2.5822,\n",
      "        -2.5852, -2.5785], device='mps:0')\n",
      "mean: tensor(-2.5657, device='mps:0')\n",
      "iter_dt 1.08s; iter 33: train loss 0.81131 temperature: 6.649999999999994\n",
      "mean_logits tensor([-2.5836, -2.4552, -2.3274, -2.8361, -2.3418, -2.5544, -2.6147, -2.4870,\n",
      "        -2.7624, -2.7788, -2.5638, -2.4124, -2.7761, -2.4379, -2.4950, -2.3470,\n",
      "        -2.5666, -2.3607, -2.2526, -2.7426, -2.2275, -2.6845, -2.4901, -2.6733,\n",
      "        -2.5383, -2.0199, -2.3557, -2.7045, -2.3492, -2.3071, -2.6356, -2.4559,\n",
      "        -2.2685, -2.5960, -2.2273, -2.4362, -2.5907, -2.5380, -2.7215, -2.5399,\n",
      "        -2.8568, -2.8394, -2.1760, -2.2939, -2.3174, -2.5161, -2.3682, -2.4512,\n",
      "        -2.4275, -2.7924], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5575, -2.5585, -2.5633, -2.5822, -2.5898, -2.5405, -2.5764, -2.6067,\n",
      "        -2.5797, -2.5799, -2.5860, -2.5937, -2.5806, -2.5297, -2.5857, -2.5840,\n",
      "        -2.5865, -2.5375, -2.5770, -2.5869, -2.5819, -2.5836, -2.4862, -2.5735,\n",
      "        -2.5750, -2.5245, -2.5309, -2.5239, -2.5936, -2.5856, -2.5437, -2.4959,\n",
      "        -2.5382, -2.5532, -2.5844, -2.5903, -2.5938, -2.5852, -2.5886, -2.5791,\n",
      "        -2.5855, -2.5507, -2.5919, -2.5861, -2.5290, -2.5852, -2.5900, -2.5220,\n",
      "        -2.5934, -2.5825], device='mps:0')\n",
      "mean: tensor(-2.5682, device='mps:0')\n",
      "iter_dt 1.11s; iter 34: train loss 0.98183 temperature: 6.699999999999994\n",
      "mean_logits tensor([-2.2414, -2.6260, -2.7084, -2.4180, -2.4661, -2.6992, -2.5732, -2.5735,\n",
      "        -2.3968, -2.5031, -2.6957, -2.6666, -2.6713, -2.5439, -3.1631, -2.6838,\n",
      "        -2.6709, -2.3023, -2.3202, -2.7540, -2.3613, -2.4353, -2.2250, -2.3096,\n",
      "        -2.5531, -2.3328, -2.4847, -2.6373, -2.2547, -2.8074, -2.4724, -2.5062,\n",
      "        -2.4457, -2.2741, -2.3408, -2.6631, -2.9293, -2.3992, -2.2816, -2.6761,\n",
      "        -2.5197, -2.7401, -2.5649, -2.4116, -2.7039, -2.1877, -2.2771, -2.3291,\n",
      "        -2.4126, -2.5815], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5802, -2.5712, -2.5864, -2.5913, -2.5810, -2.5886, -2.5860, -2.5937,\n",
      "        -2.5811, -2.5826, -2.5384, -2.5523, -2.5775, -2.5860, -2.5863, -2.5826,\n",
      "        -2.5299, -2.5867, -2.5352, -2.5928, -2.4608, -2.5726, -2.5336, -2.5767,\n",
      "        -2.5738, -2.5346, -2.5601, -2.5822, -2.5757, -2.5767, -2.5867, -2.5840,\n",
      "        -2.4945, -2.5249, -2.5699, -2.5892, -2.5714, -2.5939, -2.5837, -2.5781,\n",
      "        -2.5270, -2.5103, -2.5385, -2.5838, -2.5924, -2.5765, -2.5821, -2.5656,\n",
      "        -2.5820, -2.5677], device='mps:0')\n",
      "mean: tensor(-2.5672, device='mps:0')\n",
      "iter_dt 1.07s; iter 35: train loss 0.88388 temperature: 6.749999999999994\n",
      "mean_logits tensor([-2.3959, -2.9880, -2.2774, -2.4352, -2.3679, -2.4948, -2.4205, -2.5098,\n",
      "        -2.7237, -2.5139, -2.6700, -2.4027, -2.3269, -2.4055, -2.4745, -2.8194,\n",
      "        -2.4399, -2.4417, -2.6879, -2.6255, -2.3113, -2.5918, -2.5766, -2.7924,\n",
      "        -2.3543, -2.3783, -2.5546, -2.5561, -2.4184, -2.2474, -2.4741, -2.6420,\n",
      "        -2.3170, -2.1240, -2.8283, -2.4221, -2.8994, -2.7402, -2.7815, -2.3341,\n",
      "        -2.6067, -2.3604, -2.6844, -2.3179, -2.5561, -2.3157, -2.5938, -1.9618,\n",
      "        -2.4601, -2.2909], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5728, -2.5859, -2.5580, -2.5855, -2.5427, -2.5411, -2.5484, -2.5859,\n",
      "        -2.5756, -2.5272, -2.5668, -2.5853, -2.5715, -2.5698, -2.5914, -2.5684,\n",
      "        -2.5382, -2.5966, -2.5857, -2.5443, -2.5817, -2.5830, -2.5262, -2.5883,\n",
      "        -2.5423, -2.5862, -2.5888, -2.5060, -2.5607, -2.5336, -2.5857, -2.5740,\n",
      "        -2.5868, -2.5232, -2.5860, -2.5927, -2.5350, -2.5785, -2.5761, -2.5127,\n",
      "        -2.5847, -2.5886, -2.5864, -2.5443, -2.5960, -2.5361, -2.5395, -2.5819,\n",
      "        -2.5866, -2.5308], device='mps:0')\n",
      "mean: tensor(-2.5653, device='mps:0')\n",
      "iter_dt 1.05s; iter 36: train loss 0.68284 temperature: 6.799999999999994\n",
      "mean_logits tensor([-2.4558, -2.5823, -2.2305, -2.6570, -2.7476, -2.4418, -2.4396, -2.2486,\n",
      "        -2.6082, -2.6693, -2.4172, -2.4233, -1.8511, -2.2729, -2.6362, -2.4209,\n",
      "        -2.5802, -2.3442, -2.7558, -2.6986, -2.5528, -2.4192, -2.6718, -2.2199,\n",
      "        -2.8195, -2.4545, -2.4569, -2.4074, -2.3010, -2.4875, -2.1579, -2.4677,\n",
      "        -2.4269, -2.6548, -2.4971, -2.4076, -2.5448, -2.4763, -2.4196, -2.6734,\n",
      "        -2.4913, -2.4530, -2.1859, -2.5631, -2.6255, -2.3717, -2.1955, -2.5948,\n",
      "        -2.7964, -2.6059], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5855, -2.5861, -2.5306, -2.5962, -2.5856, -2.5446, -2.5668, -2.4918,\n",
      "        -2.5801, -2.5833, -2.5295, -2.5869, -2.5909, -2.5229, -2.5862, -2.5938,\n",
      "        -2.5861, -2.5850, -2.5936, -2.5749, -2.5830, -2.5775, -2.5402, -2.5622,\n",
      "        -2.5928, -2.5325, -2.5712, -2.5838, -2.5385, -2.5746, -2.5387, -2.5822,\n",
      "        -2.5797, -2.5280, -2.5849, -2.5867, -2.5726, -2.5855, -2.5204, -2.5848,\n",
      "        -2.5461, -2.5754, -2.5933, -2.5832, -2.5850, -2.5864, -2.5235, -2.5864,\n",
      "        -2.5727, -2.5664], device='mps:0')\n",
      "mean: tensor(-2.5688, device='mps:0')\n",
      "iter_dt 1.05s; iter 37: train loss 1.00832 temperature: 6.849999999999993\n",
      "mean_logits tensor([-2.7598, -2.5790, -2.7580, -2.6367, -2.2441, -2.5247, -2.4687, -2.4580,\n",
      "        -2.3122, -2.8122, -2.1680, -2.5760, -2.7862, -2.6953, -2.6028, -2.7113,\n",
      "        -2.4388, -2.0016, -2.4275, -2.4841, -2.4783, -2.3176, -2.2753, -2.4892,\n",
      "        -2.7938, -2.6166, -2.6731, -2.5625, -2.2480, -2.7142, -2.8830, -2.7211,\n",
      "        -2.6114, -2.7907, -2.1638, -2.4350, -2.4674, -2.3407, -2.1346, -2.8562,\n",
      "        -2.1201, -2.3804, -2.3879, -2.3699, -2.0790, -2.5157, -2.3070, -2.1470,\n",
      "        -2.4933, -2.3018], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5833, -2.5758, -2.5857, -2.5963, -2.5847, -2.5351, -2.5753, -2.4904,\n",
      "        -2.5827, -2.5861, -2.5262, -2.5744, -2.5856, -2.5409, -2.5820, -2.5761,\n",
      "        -2.5927, -2.5770, -2.5269, -2.5863, -2.5395, -2.5924, -2.5175, -2.5433,\n",
      "        -2.5402, -2.5956, -2.5865, -2.5866, -2.5725, -2.5762, -2.5934, -2.5906,\n",
      "        -2.5826, -2.5712, -2.5771, -2.5801, -2.5930, -2.5853, -2.5868, -2.5941,\n",
      "        -2.5572, -2.5690, -2.5420, -2.5114, -2.5724, -2.5852, -2.4831, -2.5863,\n",
      "        -2.5830, -2.5376], device='mps:0')\n",
      "mean: tensor(-2.5679, device='mps:0')\n",
      "iter_dt 1.05s; iter 38: train loss 0.71634 temperature: 6.899999999999993\n",
      "mean_logits tensor([-2.2053, -2.6445, -2.5562, -2.7495, -2.7469, -2.2559, -2.2382, -2.1637,\n",
      "        -2.5438, -2.5312, -2.8562, -2.5498, -2.9143, -2.2806, -2.6439, -2.6774,\n",
      "        -2.5084, -2.4609, -2.5654, -2.7816, -2.3427, -2.4815, -2.5775, -2.7255,\n",
      "        -2.3959, -2.6673, -2.3957, -2.6851, -2.5331, -2.5885, -2.2389, -2.6865,\n",
      "        -2.6040, -2.5381, -2.4740, -2.3381, -2.6493, -2.3349, -2.6026, -2.5152,\n",
      "        -2.5010, -2.4075, -2.8793, -2.3870, -2.3145, -2.3878, -2.7298, -2.7778,\n",
      "        -2.2603, -2.4430], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5738, -2.5401, -2.5866, -2.5775, -2.5852, -2.5841, -2.5318, -2.4710,\n",
      "        -2.5752, -2.5820, -2.5864, -2.5929, -2.5865, -2.5863, -2.5864, -2.5861,\n",
      "        -2.5831, -2.5359, -2.5781, -2.5910, -2.5831, -2.5814, -2.5843, -2.5333,\n",
      "        -2.5865, -2.5865, -2.5820, -2.5431, -2.5212, -2.5960, -2.5185, -2.5887,\n",
      "        -2.5861, -2.5274, -2.5712, -2.5323, -2.5856, -2.5858, -2.5124, -2.5583,\n",
      "        -2.5745, -2.5335, -2.5334, -2.5215, -2.5340, -2.5831, -2.5827, -2.5744,\n",
      "        -2.5822, -2.5265], device='mps:0')\n",
      "mean: tensor(-2.5646, device='mps:0')\n",
      "iter_dt 1.06s; iter 39: train loss 0.77949 temperature: 6.949999999999993\n",
      "mean_logits tensor([-2.3880, -2.4889, -2.4701, -2.6182, -2.2265, -2.3972, -2.8344, -2.7867,\n",
      "        -2.8000, -2.8716, -2.6911, -2.6156, -2.8509, -2.3857, -2.5230, -2.5994,\n",
      "        -2.5497, -2.3552, -2.4236, -2.5281, -2.6844, -2.2284, -2.4822, -2.7685,\n",
      "        -2.5497, -2.3526, -2.5408, -2.0186, -2.7692, -2.2986, -2.3995, -2.5589,\n",
      "        -2.4436, -2.6069, -2.2417, -2.3777, -2.6945, -2.5649, -2.4279, -2.2483,\n",
      "        -2.8379, -2.1900, -2.5669, -2.3351, -2.3688, -2.4812, -2.6822, -2.6769,\n",
      "        -2.6034, -2.5992], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5823, -2.5422, -2.5722, -2.5868, -2.5841, -2.5750, -2.5771, -2.5795,\n",
      "        -2.5886, -2.5757, -2.5678, -2.5733, -2.5344, -2.5937, -2.5742, -2.5961,\n",
      "        -2.5863, -2.5341, -2.5863, -2.5859, -2.5842, -2.5215, -2.5373, -2.5803,\n",
      "        -2.5850, -2.5734, -2.5930, -2.5428, -2.5857, -2.5714, -2.5957, -2.5746,\n",
      "        -2.5863, -2.4931, -2.5960, -2.5812, -2.5831, -2.5770, -2.4930, -2.5213,\n",
      "        -2.5865, -2.5861, -2.5852, -2.5292, -2.5332, -2.5816, -2.5543, -2.5833,\n",
      "        -2.5711, -2.5761], device='mps:0')\n",
      "mean: tensor(-2.5692, device='mps:0')\n",
      "iter_dt 1.04s; iter 40: train loss 0.85826 temperature: 6.999999999999993\n",
      "mean_logits tensor([-2.6851, -2.8519, -2.8904, -2.8220, -2.4398, -2.4860, -2.5648, -2.6797,\n",
      "        -2.1668, -2.7275, -2.2447, -2.2522, -2.4348, -2.6850, -2.8805, -2.4936,\n",
      "        -2.2041, -2.8210, -2.6594, -2.9097, -2.6286, -2.6413, -2.6014, -2.7248,\n",
      "        -2.5476, -2.4307, -2.7577, -2.5630, -2.6843, -2.6033, -2.8849, -2.4162,\n",
      "        -2.4908, -2.3954, -2.4038, -2.4769, -2.8172, -2.5301, -2.7286, -2.5006,\n",
      "        -2.3902, -2.8520, -2.3925, -2.5373, -2.5334, -2.7539, -2.3866, -2.3396,\n",
      "        -2.2631, -2.6625], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5771, -2.5275, -2.5476, -2.5711, -2.5030, -2.5057, -2.5549, -2.5405,\n",
      "        -2.4947, -2.5857, -2.4897, -2.5214, -2.5700, -2.5856, -2.5451, -2.5360,\n",
      "        -2.5766, -2.5574, -2.5874, -2.5934, -2.5351, -2.5439, -2.5829, -2.5861,\n",
      "        -2.5857, -2.5855, -2.5822, -2.5755, -2.5804, -2.5828, -2.5827, -2.5928,\n",
      "        -2.5926, -2.5275, -2.5229, -2.5220, -2.5555, -2.5470, -2.5852, -2.5708,\n",
      "        -2.5841, -2.5616, -2.5329, -2.5861, -2.5910, -2.5796, -2.5441, -2.5481,\n",
      "        -2.5446, -2.5856], device='mps:0')\n",
      "mean: tensor(-2.5593, device='mps:0')\n",
      "iter_dt 1.06s; iter 41: train loss 1.03250 temperature: 7.049999999999993\n",
      "mean_logits tensor([-2.4253, -2.4484, -2.3418, -2.5453, -2.4163, -2.5691, -2.5135, -2.2873,\n",
      "        -2.8398, -2.6115, -2.5984, -2.5125, -2.5178, -2.8000, -2.3179, -2.8160,\n",
      "        -2.5040, -2.9251, -2.4453, -2.8221, -2.3665, -2.4163, -2.5703, -2.5018,\n",
      "        -2.6643, -2.4598, -2.7115, -2.4549, -2.2954, -2.1689, -2.5280, -2.4735,\n",
      "        -2.6726, -2.7775, -2.5902, -2.5766, -2.4632, -2.3872, -2.5587, -2.8939,\n",
      "        -2.7702, -2.4221, -3.0680, -2.5568, -2.5749, -2.1515, -2.9623, -2.3228,\n",
      "        -2.5855, -1.9688], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5391, -2.5860, -2.5492, -2.5576, -2.5863, -2.5257, -2.5389, -2.5307,\n",
      "        -2.5854, -2.5400, -2.5837, -2.5732, -2.5822, -2.5824, -2.5743, -2.5933,\n",
      "        -2.5843, -2.5865, -2.5868, -2.5925, -2.5488, -2.5932, -2.5745, -2.5756,\n",
      "        -2.5831, -2.5443, -2.5934, -2.5947, -2.5463, -2.5833, -2.5386, -2.5820,\n",
      "        -2.5466, -2.5710, -2.5715, -2.5805, -2.5801, -2.5394, -2.5754, -2.5846,\n",
      "        -2.5865, -2.5837, -2.5854, -2.5396, -2.5831, -2.5788, -2.5699, -2.5858,\n",
      "        -2.5844, -2.5320], device='mps:0')\n",
      "mean: tensor(-2.5703, device='mps:0')\n",
      "iter_dt 1.06s; iter 42: train loss 0.84255 temperature: 7.0999999999999925\n",
      "mean_logits tensor([-2.3443, -2.4507, -2.5353, -2.7311, -2.8426, -2.3536, -2.7344, -2.0717,\n",
      "        -2.5797, -2.9242, -2.2566, -2.8047, -2.4256, -2.6196, -2.3946, -2.5784,\n",
      "        -2.7901, -2.5390, -2.6248, -2.4953, -2.7043, -2.7811, -2.1845, -2.4981,\n",
      "        -2.5524, -2.5072, -2.5762, -2.2085, -2.3138, -2.5474, -2.5057, -2.4567,\n",
      "        -2.3706, -2.3183, -2.6467, -2.6510, -2.3037, -2.5491, -2.5305, -2.5705,\n",
      "        -2.6512, -2.4024, -2.4003, -2.4762, -2.5571, -2.9508, -2.5643, -2.3002,\n",
      "        -2.1590, -2.6259], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5949, -2.5801, -2.5863, -2.5879, -2.5861, -2.5435, -2.5933, -2.5496,\n",
      "        -2.5912, -2.5767, -2.4962, -2.5821, -2.5828, -2.4938, -2.5782, -2.5852,\n",
      "        -2.5078, -2.5645, -2.5860, -2.5437, -2.5932, -2.5790, -2.5801, -2.5856,\n",
      "        -2.5677, -2.4769, -2.5377, -2.6065, -2.5883, -2.5484, -2.5940, -2.5863,\n",
      "        -2.5816, -2.5862, -2.5684, -2.5853, -2.5662, -2.5770, -2.5831, -2.5859,\n",
      "        -2.5746, -2.5941, -2.4877, -2.5711, -2.5359, -2.5364, -2.5753, -2.5313,\n",
      "        -2.5831, -2.5825], device='mps:0')\n",
      "mean: tensor(-2.5672, device='mps:0')\n",
      "iter_dt 1.04s; iter 43: train loss 0.92307 temperature: 7.149999999999992\n",
      "mean_logits tensor([-2.6949, -2.8911, -2.3093, -2.2793, -2.5563, -2.1296, -2.6311, -2.5694,\n",
      "        -2.6152, -2.7575, -2.8007, -2.6158, -2.6221, -2.4765, -2.5821, -2.7885,\n",
      "        -2.6974, -2.6686, -2.5866, -2.4199, -2.4088, -2.8782, -2.4204, -2.8448,\n",
      "        -2.7139, -2.3964, -2.8032, -2.7463, -2.5455, -2.3781, -2.6070, -2.3901,\n",
      "        -2.3282, -2.5623, -2.6974, -2.9395, -2.5861, -2.4286, -2.2547, -2.5315,\n",
      "        -2.5854, -2.9278, -2.4707, -2.8499, -2.2603, -2.6701, -2.5316, -2.2369,\n",
      "        -2.4941, -2.4220], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5738, -2.5228, -2.5673, -2.5888, -2.5837, -2.5313, -2.5889, -2.5859,\n",
      "        -2.5840, -2.5586, -2.5938, -2.5838, -2.5969, -2.5886, -2.5864, -2.5857,\n",
      "        -2.5583, -2.5375, -2.5878, -2.5814, -2.5773, -2.5773, -2.5855, -2.5847,\n",
      "        -2.4825, -2.5463, -2.5766, -2.5382, -2.5424, -2.4900, -2.5860, -2.5520,\n",
      "        -2.5857, -2.5658, -2.5620, -2.5289, -2.5721, -2.5824, -2.5656, -2.5350,\n",
      "        -2.5701, -2.5832, -2.5807, -2.5798, -2.5292, -2.5903, -2.5609, -2.5851,\n",
      "        -2.5835, -2.5292], device='mps:0')\n",
      "mean: tensor(-2.5663, device='mps:0')\n",
      "iter_dt 1.05s; iter 44: train loss 0.82653 temperature: 7.199999999999992\n",
      "mean_logits tensor([-2.2526, -2.5176, -2.7201, -2.3165, -2.7299, -2.6609, -2.1712, -2.4675,\n",
      "        -2.8524, -2.1523, -2.6468, -2.2765, -2.3519, -2.3730, -2.5060, -2.5265,\n",
      "        -2.6368, -2.5650, -2.4497, -2.6626, -2.6031, -2.1700, -2.5372, -2.5193,\n",
      "        -2.5061, -2.6297, -2.5510, -2.7148, -2.6164, -2.6314, -2.4695, -2.8930,\n",
      "        -2.0650, -2.5276, -2.7073, -2.4534, -2.2848, -2.5028, -2.3169, -2.4896,\n",
      "        -2.6663, -2.2312, -2.3938, -2.4810, -2.6891, -2.6459, -2.6397, -3.0214,\n",
      "        -2.6491, -2.5072], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5870, -2.5863, -2.5355, -2.5849, -2.5740, -2.4949, -2.5714, -2.5232,\n",
      "        -2.5829, -2.5254, -2.5942, -2.5639, -2.5858, -2.5865, -2.5447, -2.5358,\n",
      "        -2.5463, -2.5367, -2.5638, -2.5899, -2.5178, -2.5707, -2.4904, -2.5857,\n",
      "        -2.5858, -2.5824, -2.5868, -2.5448, -2.5877, -2.5877, -2.5356, -2.5865,\n",
      "        -2.4709, -2.5796, -2.5865, -2.5896, -2.5400, -2.5839, -2.5471, -2.5860,\n",
      "        -2.5956, -2.5857, -2.5956, -2.5480, -2.5854, -2.5447, -2.5349, -2.5470,\n",
      "        -2.5583, -2.5876], device='mps:0')\n",
      "mean: tensor(-2.5628, device='mps:0')\n",
      "iter_dt 1.06s; iter 45: train loss 1.02835 temperature: 7.249999999999992\n",
      "mean_logits tensor([-2.4443, -3.0281, -2.6471, -2.7472, -2.6693, -2.9488, -2.3580, -1.9619,\n",
      "        -2.9705, -2.5458, -2.6115, -2.5974, -2.4878, -2.2953, -2.6831, -2.4862,\n",
      "        -2.5275, -2.4604, -2.5798, -2.1463, -2.4989, -2.3694, -2.5564, -2.4536,\n",
      "        -2.6335, -2.8379, -2.8684, -2.5712, -2.5319, -2.4387, -2.5502, -2.5605,\n",
      "        -2.3345, -2.6411, -2.6090, -2.6022, -2.3169, -2.3881, -2.6146, -1.9103,\n",
      "        -2.6074, -2.8776, -2.3331, -2.4231, -2.5282, -2.6968, -2.4399, -2.4891,\n",
      "        -2.5151, -2.4118], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5505, -2.5408, -2.5605, -2.5852, -2.5831, -2.5741, -2.5373, -2.5325,\n",
      "        -2.5958, -2.4837, -2.5367, -2.5330, -2.5794, -2.5863, -2.3779, -2.5616,\n",
      "        -2.5744, -2.5444, -2.5643, -2.5860, -2.5837, -2.5094, -2.5911, -2.5860,\n",
      "        -2.5828, -2.5926, -2.5857, -2.5859, -2.5754, -2.5758, -2.5238, -2.5332,\n",
      "        -2.5395, -2.5853, -2.5921, -2.5841, -2.5439, -2.5827, -2.5214, -2.5783,\n",
      "        -2.5823, -2.5861, -2.5923, -2.5770, -2.5226, -2.5755, -2.5973, -2.5111,\n",
      "        -2.5704, -2.4817], device='mps:0')\n",
      "mean: tensor(-2.5587, device='mps:0')\n",
      "iter_dt 1.06s; iter 46: train loss 0.89664 temperature: 7.299999999999992\n",
      "mean_logits tensor([-2.5132, -2.2990, -2.3552, -2.2518, -2.4323, -2.7369, -2.2093, -2.8207,\n",
      "        -2.7119, -2.2839, -2.5578, -2.6122, -2.7210, -2.5404, -2.4415, -2.4906,\n",
      "        -2.6274, -2.6925, -2.6465, -2.5287, -2.6416, -2.8409, -2.3163, -2.7403,\n",
      "        -2.4957, -2.3990, -2.6639, -2.4658, -2.7614, -2.6863, -2.3425, -2.5021,\n",
      "        -2.8110, -2.8804, -2.1866, -2.3489, -2.7288, -2.2485, -2.8261, -2.6617,\n",
      "        -2.1373, -2.5557, -2.6194, -2.3494, -2.7052, -2.4682, -2.6230, -2.2454,\n",
      "        -2.6181, -2.9915], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5861, -2.5417, -2.5837, -2.5858, -2.5838, -2.5298, -2.5072, -2.5807,\n",
      "        -2.5551, -2.5756, -2.5767, -2.5863, -2.5811, -2.5777, -2.5831, -2.5692,\n",
      "        -2.5676, -2.5823, -2.5853, -2.5938, -2.5831, -2.5856, -2.5857, -2.5441,\n",
      "        -2.5823, -2.5833, -2.5039, -2.5291, -2.5926, -2.5799, -2.5128, -2.5790,\n",
      "        -2.5365, -2.5888, -2.5862, -2.5795, -2.5496, -2.5413, -2.5910, -2.5830,\n",
      "        -2.5643, -2.5850, -2.5855, -2.5385, -2.5870, -2.5831, -2.5858, -2.5667,\n",
      "        -2.5852, -2.5851], device='mps:0')\n",
      "mean: tensor(-2.5703, device='mps:0')\n",
      "iter_dt 1.05s; iter 47: train loss 0.93557 temperature: 7.349999999999992\n",
      "mean_logits tensor([-2.4788, -2.5505, -2.1706, -2.5286, -2.7894, -2.2938, -2.2972, -2.5341,\n",
      "        -2.7505, -2.4671, -2.7235, -2.5805, -2.8044, -2.5956, -2.3394, -2.5707,\n",
      "        -2.2572, -2.2126, -2.6093, -2.7035, -2.3310, -2.4384, -2.5495, -2.2671,\n",
      "        -2.2534, -2.3221, -2.4356, -2.8343, -2.1992, -2.2722, -2.3303, -2.5149,\n",
      "        -2.5481, -2.3544, -2.5958, -2.3742, -2.2013, -2.7901, -2.3690, -2.5983,\n",
      "        -2.1601, -2.4858, -2.2775, -2.5216, -2.6272, -3.0354, -2.5111, -2.4791,\n",
      "        -2.7320, -2.4568], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5876, -2.5818, -2.5868, -2.5338, -2.5377, -2.5330, -2.5911, -2.5862,\n",
      "        -2.5841, -2.5800, -2.5826, -2.5777, -2.5897, -2.5442, -2.5634, -2.5859,\n",
      "        -2.5329, -2.5588, -2.5918, -2.5862, -2.5964, -2.5436, -2.5875, -2.5039,\n",
      "        -2.5661, -2.5866, -2.5821, -2.5526, -2.5777, -2.5864, -2.5872, -2.5954,\n",
      "        -2.5857, -2.5773, -2.5867, -2.5511, -2.5747, -2.5823, -2.4965, -2.5483,\n",
      "        -2.5397, -2.5905, -2.5374, -2.5962, -2.5872, -2.5903, -2.5948, -2.5836,\n",
      "        -2.5385, -2.5339], device='mps:0')\n",
      "mean: tensor(-2.5695, device='mps:0')\n",
      "iter_dt 1.05s; iter 48: train loss 1.03172 temperature: 7.3999999999999915\n",
      "mean_logits tensor([-2.1473, -2.7256, -2.5510, -2.7151, -2.8041, -2.4111, -2.6499, -2.4501,\n",
      "        -2.3826, -2.7807, -2.3440, -2.4893, -2.5151, -2.3525, -2.4958, -2.7618,\n",
      "        -2.9980, -2.5808, -2.5489, -2.6281, -2.9240, -2.1956, -2.5644, -2.4626,\n",
      "        -2.2350, -2.6039, -2.6226, -2.4994, -2.8516, -2.2624, -2.4757, -2.8104,\n",
      "        -2.5716, -2.5768, -2.7652, -2.5333, -2.4279, -2.3259, -2.4836, -2.3880,\n",
      "        -2.4334, -2.6161, -2.7432, -2.8209, -2.9268, -2.7775, -2.7699, -2.5431,\n",
      "        -2.4203, -2.6320], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5768, -2.5756, -2.5827, -2.5008, -2.5964, -2.5891, -2.5861, -2.5853,\n",
      "        -2.5853, -2.5350, -2.5804, -2.5495, -2.5807, -2.5585, -2.5741, -2.5119,\n",
      "        -2.5826, -2.5289, -2.5859, -2.5855, -2.5123, -2.5829, -2.5483, -2.5856,\n",
      "        -2.5307, -2.5903, -2.5196, -2.5799, -2.5646, -2.5700, -2.5276, -2.5008,\n",
      "        -2.5443, -2.5383, -2.5349, -2.5811, -2.5335, -2.5853, -2.5868, -2.5732,\n",
      "        -2.5882, -2.5936, -2.5380, -2.5558, -2.5389, -2.5855, -2.5861, -2.5850,\n",
      "        -2.5800, -2.5985], device='mps:0')\n",
      "mean: tensor(-2.5638, device='mps:0')\n",
      "iter_dt 1.06s; iter 49: train loss 0.43051 temperature: 7.449999999999991\n",
      "mean_logits tensor([-2.6132, -2.4522, -2.5430, -2.4304, -2.3165, -2.4824, -2.8924, -2.3476,\n",
      "        -2.5996, -2.7033, -2.2654, -2.5891, -2.3948, -2.5687, -2.6285, -2.2577,\n",
      "        -2.5668, -2.5413, -2.7325, -2.5275, -2.2717, -2.4891, -2.5301, -2.4970,\n",
      "        -2.6815, -2.6156, -2.3804, -2.5003, -2.7198, -2.7073, -2.5235, -2.6484,\n",
      "        -2.4113, -2.4388, -2.6682, -2.4367, -2.7135, -2.4042, -2.5575, -2.5051,\n",
      "        -2.3649, -2.7818, -2.5447, -2.6161, -2.4605, -2.4543, -2.3258, -2.5104,\n",
      "        -2.3415, -2.5437], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5830, -2.5520, -2.5835, -2.5751, -2.5651, -2.5323, -2.5444, -2.5401,\n",
      "        -2.5200, -2.5541, -2.5325, -2.5799, -2.5935, -2.5716, -2.5861, -2.4900,\n",
      "        -2.5876, -2.5927, -2.5855, -2.5862, -2.4426, -2.5723, -2.5867, -2.5834,\n",
      "        -2.5678, -2.5863, -2.5821, -2.5868, -2.5746, -2.5957, -2.5883, -2.4980,\n",
      "        -2.5785, -2.5593, -2.5834, -2.5857, -2.5666, -2.5819, -2.5357, -2.5825,\n",
      "        -2.5182, -2.5668, -2.5413, -2.6040, -2.5855, -2.5797, -2.5680, -2.5418,\n",
      "        -2.5627, -2.5394], device='mps:0')\n",
      "mean: tensor(-2.5640, device='mps:0')\n",
      "iter_dt 1.06s; iter 50: train loss 0.77119 temperature: 7.499999999999991\n",
      "mean_logits tensor([-2.6225, -2.4938, -2.4670, -2.6344, -2.5154, -2.5677, -2.0741, -2.4257,\n",
      "        -2.5683, -2.5862, -2.7813, -2.4399, -2.5682, -2.5804, -2.4417, -2.1595,\n",
      "        -2.0654, -2.6048, -2.6739, -2.1183, -2.3122, -2.8381, -2.0700, -2.5511,\n",
      "        -2.3926, -2.2959, -2.2932, -2.5995, -2.2448, -2.3465, -2.5600, -2.5708,\n",
      "        -2.5632, -2.5096, -2.3884, -2.3840, -2.5944, -2.3899, -2.4789, -2.4631,\n",
      "        -2.3433, -2.3646, -2.4879, -2.4650, -2.1253, -2.4229, -2.5771, -2.2523,\n",
      "        -2.4007, -2.6110], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5504, -2.5722, -2.5308, -2.5243, -2.5861, -2.5740, -2.5682, -2.5677,\n",
      "        -2.5389, -2.5701, -2.5470, -2.5457, -2.5912, -2.5285, -2.5838, -2.5367,\n",
      "        -2.5311, -2.5814, -2.5890, -2.5689, -2.5931, -2.5952, -2.5945, -2.5864,\n",
      "        -2.5796, -2.5053, -2.5748, -2.5464, -2.5347, -2.5849, -2.5260, -2.5848,\n",
      "        -2.5687, -2.5863, -2.5740, -2.5434, -2.5441, -2.5867, -2.5777, -2.5763,\n",
      "        -2.5326, -2.5675, -2.5403, -2.5829, -2.5976, -2.5447, -2.5483, -2.5809,\n",
      "        -2.5808, -2.5852], device='mps:0')\n",
      "mean: tensor(-2.5642, device='mps:0')\n",
      "iter_dt 1.05s; iter 51: train loss 0.66042 temperature: 7.549999999999991\n",
      "mean_logits tensor([-2.6011, -2.5971, -2.3541, -2.7145, -2.3801, -2.6518, -2.4471, -2.4275,\n",
      "        -2.2349, -2.7330, -2.3908, -2.4162, -2.5013, -2.7974, -2.3378, -2.5917,\n",
      "        -2.7470, -2.3291, -2.4746, -2.4941, -2.5686, -2.5114, -2.3027, -2.3305,\n",
      "        -2.2262, -2.3486, -2.4927, -2.6594, -2.5622, -2.3936, -2.3785, -2.3948,\n",
      "        -2.5614, -2.6432, -2.3613, -2.7716, -2.4036, -2.7058, -2.6232, -2.6149,\n",
      "        -2.3935, -2.7411, -2.1761, -2.4959, -2.5748, -2.3093, -2.7426, -2.3277,\n",
      "        -2.2076, -2.7795], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5729, -2.5749, -2.5604, -2.5849, -2.5916, -2.5848, -2.5761, -2.5858,\n",
      "        -2.5740, -2.5707, -2.5696, -2.5741, -2.5292, -2.5837, -2.4107, -2.5402,\n",
      "        -2.5440, -2.5832, -2.5847, -2.5489, -2.5843, -2.5682, -2.5736, -2.5834,\n",
      "        -2.5233, -2.5744, -2.5390, -2.5861, -2.5639, -2.5767, -2.5851, -2.5822,\n",
      "        -2.5352, -2.5343, -2.5857, -2.5353, -2.5834, -2.5780, -2.5373, -2.5884,\n",
      "        -2.5224, -2.4965, -2.5767, -2.5792, -2.5935, -2.5262, -2.5790, -2.5814,\n",
      "        -2.5774, -2.5804], device='mps:0')\n",
      "mean: tensor(-2.5635, device='mps:0')\n",
      "iter_dt 1.06s; iter 52: train loss 0.86453 temperature: 7.599999999999991\n",
      "mean_logits tensor([-2.5988, -2.8363, -2.4209, -2.2944, -2.8621, -2.4415, -2.3040, -2.5653,\n",
      "        -2.2902, -2.1841, -2.3017, -2.3443, -2.1758, -2.6010, -2.4808, -2.5794,\n",
      "        -2.2608, -2.4088, -2.5215, -2.6446, -2.4028, -2.7027, -2.4439, -2.4137,\n",
      "        -2.3892, -2.6970, -2.2720, -2.3735, -2.9169, -2.2311, -2.4720, -2.8068,\n",
      "        -2.2999, -2.2272, -2.6271, -2.6594, -2.4837, -2.7701, -2.4324, -2.6001,\n",
      "        -2.6283, -2.3862, -2.3240, -2.7331, -2.4844, -2.3712, -2.2988, -2.4015,\n",
      "        -2.2887, -2.4975], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5464, -2.5828, -2.5860, -2.5752, -2.5871, -2.5410, -2.5441, -2.5384,\n",
      "        -2.5916, -2.5817, -2.5859, -2.5446, -2.5319, -2.5781, -2.4982, -2.5430,\n",
      "        -2.5684, -2.5944, -2.5772, -2.5408, -2.5236, -2.5359, -2.5436, -2.5712,\n",
      "        -2.5981, -2.5445, -2.5813, -2.5813, -2.5651, -2.4630, -2.5852, -2.5837,\n",
      "        -2.5826, -2.4908, -2.5760, -2.5831, -2.5707, -2.5397, -2.5860, -2.5646,\n",
      "        -2.6082, -2.5714, -2.5675, -2.5342, -2.5388, -2.5836, -2.5875, -2.5856,\n",
      "        -2.5758, -2.5927], device='mps:0')\n",
      "mean: tensor(-2.5630, device='mps:0')\n",
      "iter_dt 1.05s; iter 53: train loss 0.92553 temperature: 7.649999999999991\n",
      "mean_logits tensor([-2.6685, -2.4918, -2.7328, -2.3029, -2.3645, -2.5556, -2.2506, -2.3581,\n",
      "        -2.3686, -2.6665, -2.3507, -2.3316, -2.3815, -2.6193, -2.3364, -2.3267,\n",
      "        -2.5923, -2.0873, -2.6199, -2.2630, -2.6543, -2.5647, -2.6579, -2.4179,\n",
      "        -2.5741, -2.4693, -2.4473, -2.5364, -2.9330, -2.3794, -2.3879, -2.3687,\n",
      "        -2.3859, -2.5634, -2.6530, -3.0957, -2.7216, -2.6363, -2.2780, -2.3660,\n",
      "        -2.2785, -2.4391, -2.4817, -2.4392, -2.4720, -2.2798, -2.7623, -2.1964,\n",
      "        -2.7182, -2.3734], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5735, -2.5089, -2.5861, -2.5852, -2.5385, -2.5833, -2.5371, -2.5411,\n",
      "        -2.5840, -2.5799, -2.5922, -2.5740, -2.5863, -2.5372, -2.5379, -2.5315,\n",
      "        -2.5924, -2.5867, -2.5307, -2.5739, -2.5420, -2.4915, -2.5911, -2.5623,\n",
      "        -2.5646, -2.5171, -2.4883, -2.5212, -2.5826, -2.5863, -2.5349, -2.5830,\n",
      "        -2.5853, -2.5826, -2.5704, -2.5853, -2.5833, -2.5718, -2.5362, -2.5380,\n",
      "        -2.5931, -2.5444, -2.5836, -2.5553, -2.5930, -2.5857, -2.5959, -2.5866,\n",
      "        -2.5769, -2.5801], device='mps:0')\n",
      "mean: tensor(-2.5635, device='mps:0')\n",
      "iter_dt 1.05s; iter 54: train loss 0.74047 temperature: 7.69999999999999\n",
      "mean_logits tensor([-2.3751, -2.4136, -2.4654, -2.7040, -2.0834, -2.6405, -2.6113, -2.6878,\n",
      "        -2.1239, -2.1543, -2.2860, -2.6426, -2.6870, -2.4390, -2.4857, -2.4458,\n",
      "        -2.6305, -2.2538, -2.3011, -2.3942, -2.6427, -2.3803, -2.6623, -2.6983,\n",
      "        -2.0813, -2.5744, -2.6500, -2.4160, -2.6817, -2.6801, -2.6687, -2.6884,\n",
      "        -2.3449, -2.5815, -2.4724, -2.6435, -2.6337, -2.4980, -2.7054, -2.3041,\n",
      "        -2.4240, -2.3754, -2.4841, -2.4664, -2.7430, -2.2942, -2.4670, -2.2233,\n",
      "        -2.4319, -2.2196], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5668, -2.5874, -2.5762, -2.5828, -2.5570, -2.6062, -2.5204, -2.5296,\n",
      "        -2.5713, -2.5728, -2.5868, -2.5418, -2.5593, -2.5770, -2.5426, -2.5826,\n",
      "        -2.5830, -2.5768, -2.5810, -2.5836, -2.5817, -2.5393, -2.5192, -2.5394,\n",
      "        -2.5620, -2.5338, -2.5835, -2.5836, -2.5797, -2.5872, -2.5015, -2.5613,\n",
      "        -2.5386, -2.5814, -2.5333, -2.5868, -2.6030, -2.5449, -2.5867, -2.5857,\n",
      "        -2.5869, -2.5755, -2.5858, -2.5667, -2.5848, -2.5856, -2.5419, -2.5349,\n",
      "        -2.5827, -2.5757], device='mps:0')\n",
      "mean: tensor(-2.5668, device='mps:0')\n",
      "iter_dt 1.05s; iter 55: train loss 0.59889 temperature: 7.74999999999999\n",
      "mean_logits tensor([-2.3513, -2.4056, -2.5894, -2.4129, -2.7334, -2.7415, -2.5524, -2.6078,\n",
      "        -2.7171, -2.3990, -2.6782, -2.7573, -2.4861, -2.5569, -2.3122, -2.3371,\n",
      "        -2.5310, -2.5151, -2.6006, -2.4794, -2.5613, -2.7631, -2.5535, -2.4879,\n",
      "        -2.8379, -2.6317, -2.3941, -2.6621, -2.7632, -2.7483, -2.5510, -2.5408,\n",
      "        -2.3921, -2.0534, -2.8544, -2.4528, -2.3782, -2.2351, -2.6166, -2.7017,\n",
      "        -2.5086, -2.1384, -2.5661, -2.5193, -2.5162, -2.6586, -2.5979, -2.5989,\n",
      "        -2.4869, -2.2800], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4636, -2.5944, -2.5839, -2.5391, -2.5427, -2.5318, -2.5336, -2.5291,\n",
      "        -2.5677, -2.5942, -2.5947, -2.5793, -2.5745, -2.5216, -2.5852, -2.5290,\n",
      "        -2.5772, -2.5892, -2.5684, -2.5859, -2.6074, -2.5039, -2.5463, -2.5083,\n",
      "        -2.5766, -2.5657, -2.5388, -2.5327, -2.5389, -2.5859, -2.5706, -2.5000,\n",
      "        -2.5127, -2.5823, -2.5422, -2.5671, -2.5388, -2.4866, -2.5690, -2.5857,\n",
      "        -2.5704, -2.5926, -2.5506, -2.5871, -2.5774, -2.5440, -2.5824, -2.5857,\n",
      "        -2.5876, -2.5246], device='mps:0')\n",
      "mean: tensor(-2.5569, device='mps:0')\n",
      "iter_dt 1.04s; iter 56: train loss 0.70117 temperature: 7.79999999999999\n",
      "mean_logits tensor([-2.4342, -2.2963, -2.4287, -2.7166, -2.8486, -2.3004, -2.4222, -2.5556,\n",
      "        -2.4997, -2.4558, -2.6013, -2.7065, -2.4985, -2.2800, -2.4485, -2.4434,\n",
      "        -2.7748, -2.3484, -2.4582, -2.4009, -2.1095, -2.3419, -2.8196, -2.2759,\n",
      "        -2.3650, -2.7857, -2.6007, -2.6598, -2.5418, -2.4847, -2.6203, -2.1486,\n",
      "        -2.5786, -2.7691, -2.6099, -2.4474, -2.7260, -2.6410, -2.6771, -2.4354,\n",
      "        -2.7243, -2.4423, -2.6700, -2.4559, -2.3653, -2.3155, -2.4676, -2.3985,\n",
      "        -2.3970, -2.5930], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5725, -2.5870, -2.5459, -2.5744, -2.5820, -2.5758, -2.5829, -2.5849,\n",
      "        -2.4855, -2.5847, -2.5941, -2.5289, -2.5507, -2.5855, -2.5741, -2.5764,\n",
      "        -2.5483, -2.5393, -2.5830, -2.5371, -2.5851, -2.5869, -2.5469, -2.5757,\n",
      "        -2.5844, -2.5938, -2.5829, -2.5701, -2.5397, -2.5794, -2.5865, -2.5764,\n",
      "        -2.5316, -2.5378, -2.5193, -2.5829, -2.5867, -2.5842, -2.5765, -2.5762,\n",
      "        -2.5370, -2.5866, -2.5373, -2.5547, -2.5435, -2.5455, -2.5857, -2.5575,\n",
      "        -2.5827, -2.5524], device='mps:0')\n",
      "mean: tensor(-2.5656, device='mps:0')\n",
      "iter_dt 1.07s; iter 57: train loss 0.62501 temperature: 7.84999999999999\n",
      "mean_logits tensor([-2.4191, -2.5572, -2.1850, -2.5443, -2.3488, -2.3299, -2.4890, -2.3884,\n",
      "        -2.6372, -2.5698, -2.4679, -2.3512, -2.5348, -2.5282, -2.3066, -2.4098,\n",
      "        -2.2596, -2.6256, -2.8201, -2.4698, -2.5375, -2.5750, -2.6345, -2.6366,\n",
      "        -2.4987, -2.6238, -2.2180, -2.6296, -2.2890, -2.5714, -2.4940, -2.2452,\n",
      "        -2.2968, -2.5391, -2.3219, -2.4838, -2.2472, -2.8296, -2.4658, -2.5355,\n",
      "        -2.3186, -2.2579, -2.2728, -2.5702, -2.6613, -2.6746, -2.5507, -2.5667,\n",
      "        -2.3852, -2.6717], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5297, -2.5839, -2.5260, -2.5843, -2.5160, -2.5865, -2.5829, -2.5864,\n",
      "        -2.5864, -2.5847, -2.5850, -2.5705, -2.5288, -2.5437, -2.5710, -2.5435,\n",
      "        -2.5696, -2.5959, -2.5860, -2.5937, -2.5715, -2.5855, -2.5047, -2.5751,\n",
      "        -2.5700, -2.5781, -2.5848, -2.5446, -2.5840, -2.5407, -2.5751, -2.5847,\n",
      "        -2.5592, -2.5865, -2.5875, -2.5786, -2.5921, -2.5434, -2.5865, -2.5860,\n",
      "        -2.5187, -2.5838, -2.5817, -2.5822, -2.5863, -2.5843, -2.5739, -2.5398,\n",
      "        -2.5860, -2.5642], device='mps:0')\n",
      "mean: tensor(-2.5695, device='mps:0')\n",
      "iter_dt 1.06s; iter 58: train loss 0.77079 temperature: 7.89999999999999\n",
      "mean_logits tensor([-2.2333, -2.6172, -2.4843, -2.5802, -2.4209, -2.6316, -2.4164, -2.3966,\n",
      "        -2.7854, -2.2859, -2.5355, -2.9338, -2.4322, -2.3957, -2.6663, -2.3671,\n",
      "        -2.1127, -2.5044, -2.2398, -2.4456, -2.4979, -2.3449, -2.5275, -2.4190,\n",
      "        -2.3688, -2.5810, -2.7122, -2.3536, -2.4333, -2.4651, -2.6327, -2.3993,\n",
      "        -2.3947, -2.5552, -2.4441, -2.4024, -2.2969, -2.2732, -2.4328, -2.5420,\n",
      "        -2.8069, -2.4523, -2.7627, -2.9586, -2.4161, -2.4262, -1.9517, -2.4626,\n",
      "        -2.4874, -2.4276], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5388, -2.5803, -2.5884, -2.5299, -2.5313, -2.5748, -2.5302, -2.5864,\n",
      "        -2.5859, -2.5304, -2.5629, -2.5865, -2.5847, -2.5039, -2.5697, -2.5864,\n",
      "        -2.5061, -2.5166, -2.4876, -2.5781, -2.5397, -2.5856, -2.5364, -2.5691,\n",
      "        -2.5262, -2.5834, -2.5858, -2.5433, -2.5131, -2.5806, -2.5359, -2.5884,\n",
      "        -2.4870, -2.5928, -2.5266, -2.5852, -2.5709, -2.5868, -2.5837, -2.5632,\n",
      "        -2.5287, -2.5765, -2.5874, -2.5956, -2.5953, -2.5252, -2.5824, -2.5256,\n",
      "        -2.5883, -2.5826], device='mps:0')\n",
      "mean: tensor(-2.5586, device='mps:0')\n",
      "iter_dt 1.05s; iter 59: train loss 0.73803 temperature: 7.9499999999999895\n",
      "mean_logits tensor([-2.5191, -2.3687, -2.3560, -2.5008, -2.3972, -2.5330, -2.3008, -2.3198,\n",
      "        -2.2627, -2.7681, -2.0740, -2.5632, -2.4356, -2.3952, -2.3317, -2.6001,\n",
      "        -2.2576, -2.5113, -2.4971, -2.5056, -2.6630, -2.5343, -2.3895, -2.6024,\n",
      "        -2.3649, -2.4067, -2.6122, -2.8226, -2.2947, -2.2305, -2.6144, -2.4943,\n",
      "        -2.3512, -2.5468, -2.4158, -2.2418, -2.3755, -2.3141, -2.8142, -2.3782,\n",
      "        -2.2745, -2.3564, -2.6751, -2.5814, -2.6152, -2.4401, -2.4849, -2.1030,\n",
      "        -2.3675, -2.5534], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5464, -2.5749, -2.5832, -2.5828, -2.5763, -2.5447, -2.5804, -2.5393,\n",
      "        -2.5856, -2.5859, -2.5365, -2.5819, -2.5865, -2.5849, -2.5834, -2.5776,\n",
      "        -2.5737, -2.5850, -2.5382, -2.5329, -2.6006, -2.5941, -2.5863, -2.5739,\n",
      "        -2.5203, -2.5771, -2.5840, -2.5912, -2.5957, -2.5552, -2.5699, -2.5856,\n",
      "        -2.5630, -2.5859, -2.5340, -2.5836, -2.5380, -2.5852, -2.5859, -2.5671,\n",
      "        -2.5761, -2.5910, -2.5410, -2.5846, -2.5721, -2.5383, -2.5166, -2.5825,\n",
      "        -2.5795, -2.5232], device='mps:0')\n",
      "mean: tensor(-2.5692, device='mps:0')\n",
      "iter_dt 1.05s; iter 60: train loss 0.78451 temperature: 7.999999999999989\n",
      "mean_logits tensor([-2.6933, -2.7604, -2.4443, -2.3737, -2.0820, -2.2601, -2.2608, -2.5877,\n",
      "        -2.3239, -2.6945, -2.8235, -2.8544, -2.4043, -2.5487, -2.4101, -2.7822,\n",
      "        -2.4357, -2.5063, -2.4227, -2.7898, -2.8252, -2.4597, -2.5033, -2.4656,\n",
      "        -2.4927, -2.4732, -2.0869, -2.5088, -2.6257, -2.7805, -2.5479, -2.6390,\n",
      "        -2.5314, -2.1872, -2.6860, -2.5454, -2.4211, -2.4150, -2.7700, -2.6816,\n",
      "        -2.2230, -2.1572, -2.4029, -2.4808, -2.2534, -2.5039, -2.7485, -2.5942,\n",
      "        -2.4972, -2.5552], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5382, -2.5771, -2.5427, -2.5863, -2.5410, -2.5420, -2.5849, -2.5955,\n",
      "        -2.5827, -2.5755, -2.5862, -2.5831, -2.5429, -2.5683, -2.5299, -2.5706,\n",
      "        -2.5921, -2.5308, -2.4910, -2.5318, -2.5233, -2.5361, -2.5383, -2.5750,\n",
      "        -2.5198, -2.5865, -2.5840, -2.5709, -2.5392, -2.5860, -2.5810, -2.5120,\n",
      "        -2.5863, -2.5468, -2.5830, -2.5463, -2.5814, -2.5861, -2.5827, -2.5754,\n",
      "        -2.5298, -2.5864, -2.5860, -2.5923, -2.4810, -2.5384, -2.5837, -2.5425,\n",
      "        -2.5240, -2.5863], device='mps:0')\n",
      "mean: tensor(-2.5597, device='mps:0')\n",
      "iter_dt 1.05s; iter 61: train loss 0.45219 temperature: 8.04999999999999\n",
      "mean_logits tensor([-2.5555, -2.2151, -2.4581, -2.3662, -2.8100, -2.4722, -2.5608, -2.7425,\n",
      "        -2.6531, -2.5075, -2.6773, -2.5820, -2.5124, -2.3540, -2.6973, -2.3899,\n",
      "        -2.5337, -2.4812, -2.6052, -2.6772, -2.5281, -2.2122, -2.5864, -2.4806,\n",
      "        -2.4196, -2.4825, -2.6473, -2.5956, -2.4163, -2.5011, -2.4613, -2.5656,\n",
      "        -2.3791, -2.4022, -2.4019, -2.8684, -2.4069, -2.5367, -2.3205, -2.2911,\n",
      "        -2.6066, -2.7352, -2.6001, -2.5146, -2.4843, -2.5576, -2.5501, -2.5577,\n",
      "        -2.3397, -2.4436], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5387, -2.5829, -2.5188, -2.5852, -2.5841, -2.5801, -2.5298, -2.5762,\n",
      "        -2.5430, -2.5106, -2.5616, -2.5863, -2.5830, -2.5838, -2.5809, -2.5758,\n",
      "        -2.5815, -2.5181, -2.5725, -2.5196, -2.5407, -2.5527, -2.4795, -2.5860,\n",
      "        -2.5839, -2.5787, -2.5833, -2.5862, -2.5858, -2.5842, -2.5820, -2.5860,\n",
      "        -2.5862, -2.5763, -2.5362, -2.5805, -2.5725, -2.5794, -2.5865, -2.5516,\n",
      "        -2.5836, -2.5953, -2.5761, -2.5839, -2.5517, -2.5847, -2.5754, -2.5839,\n",
      "        -2.5356, -2.5186], device='mps:0')\n",
      "mean: tensor(-2.5660, device='mps:0')\n",
      "iter_dt 1.06s; iter 62: train loss 0.48332 temperature: 8.09999999999999\n",
      "mean_logits tensor([-2.4547, -2.3241, -2.6321, -2.7159, -2.6687, -2.7650, -2.4599, -2.7603,\n",
      "        -2.4704, -2.3724, -2.3487, -2.4551, -2.6160, -2.6529, -2.3445, -2.6511,\n",
      "        -2.4868, -2.1074, -2.4288, -2.3657, -2.7389, -2.5235, -2.5590, -2.4496,\n",
      "        -2.5240, -2.5984, -2.3733, -2.4855, -2.2889, -2.4465, -2.5399, -2.3945,\n",
      "        -2.6320, -2.2926, -2.2333, -2.7200, -2.5109, -2.3316, -2.6661, -2.5858,\n",
      "        -2.4229, -2.3940, -2.5737, -2.4241, -2.5007, -2.5675, -2.3834, -2.2804,\n",
      "        -2.5228, -2.5727], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5360, -2.5714, -2.5326, -2.5838, -2.5174, -2.5840, -2.5993, -2.5646,\n",
      "        -2.5430, -2.5752, -2.5247, -2.5520, -2.5728, -2.5427, -2.5906, -2.5858,\n",
      "        -2.5750, -2.5856, -2.5866, -2.5294, -2.5860, -2.5854, -2.5776, -2.5304,\n",
      "        -2.4891, -2.5616, -2.5386, -2.5697, -2.5476, -2.5418, -2.5897, -2.5536,\n",
      "        -2.5804, -2.5260, -2.4901, -2.5738, -2.5794, -2.5953, -2.5852, -2.5871,\n",
      "        -2.5854, -2.5795, -2.5842, -2.5775, -2.5410, -2.5248, -2.5392, -2.5804,\n",
      "        -2.5350, -2.5869], device='mps:0')\n",
      "mean: tensor(-2.5615, device='mps:0')\n",
      "iter_dt 1.05s; iter 63: train loss 0.93826 temperature: 8.149999999999991\n",
      "mean_logits tensor([-2.3614, -2.5659, -3.0015, -2.5335, -2.8447, -2.3277, -2.5450, -2.3735,\n",
      "        -2.4109, -2.8847, -2.6084, -2.3257, -2.5620, -2.5017, -2.4702, -2.5392,\n",
      "        -2.3369, -2.2607, -2.4473, -2.2739, -2.4829, -2.5021, -2.7938, -2.2503,\n",
      "        -2.7246, -2.1263, -2.6527, -2.6508, -2.2671, -2.5413, -2.1205, -2.3194,\n",
      "        -2.6690, -2.4360, -2.1974, -2.6539, -2.1361, -2.4916, -2.5754, -2.5332,\n",
      "        -2.4900, -2.7085, -2.3692, -2.4725, -2.2398, -2.3333, -2.6537, -2.6779,\n",
      "        -2.4362, -2.5057], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5861, -2.5790, -2.5554, -2.5310, -2.5188, -2.5903, -2.5861, -2.5864,\n",
      "        -2.5565, -2.5817, -2.5301, -2.5852, -2.5001, -2.5444, -2.5527, -2.5798,\n",
      "        -2.4926, -2.5851, -2.5938, -2.5293, -2.5849, -2.5852, -2.5863, -2.5862,\n",
      "        -2.5515, -2.5753, -2.5797, -2.5754, -2.5851, -2.5831, -2.5855, -2.5803,\n",
      "        -2.5367, -2.5788, -2.4848, -2.5859, -2.5363, -2.5298, -2.5926, -2.5827,\n",
      "        -2.5867, -2.5293, -2.5753, -2.5421, -2.5810, -2.5893, -2.5685, -2.5830,\n",
      "        -2.5869, -2.5395], device='mps:0')\n",
      "mean: tensor(-2.5646, device='mps:0')\n",
      "iter_dt 1.06s; iter 64: train loss 0.81285 temperature: 8.199999999999992\n",
      "mean_logits tensor([-2.5753, -2.6862, -2.1839, -2.4791, -2.6593, -2.6810, -2.6927, -2.4838,\n",
      "        -2.6950, -2.7755, -2.1823, -2.5911, -2.4485, -2.3011, -2.5809, -2.4405,\n",
      "        -2.5262, -2.8049, -2.5812, -2.4781, -2.0858, -2.2172, -2.5085, -2.4690,\n",
      "        -2.5363, -2.3720, -2.4360, -2.6294, -2.7489, -2.4493, -2.3047, -2.4323,\n",
      "        -2.5567, -2.6482, -2.3731, -3.0383, -2.5964, -2.2216, -2.5812, -2.2010,\n",
      "        -2.5058, -2.8813, -2.3939, -2.3725, -2.6248, -2.5188, -2.4724, -2.3413,\n",
      "        -2.6447, -2.8042], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5844, -2.5764, -2.5400, -2.5633, -2.5857, -2.5869, -2.5643, -2.5181,\n",
      "        -2.5759, -2.5210, -2.5185, -2.5453, -2.5898, -2.5866, -2.5433, -2.5844,\n",
      "        -2.5858, -2.5504, -2.5862, -2.5345, -2.5858, -2.5806, -2.5567, -2.5266,\n",
      "        -2.5783, -2.5836, -2.5946, -2.5853, -2.5769, -2.5404, -2.5372, -2.5852,\n",
      "        -2.5242, -2.5395, -2.5346, -2.5953, -2.5866, -2.5801, -2.5377, -2.5277,\n",
      "        -2.5823, -2.5855, -2.4994, -2.5779, -2.5859, -2.5757, -2.5867, -2.5793,\n",
      "        -2.5340, -2.5865], device='mps:0')\n",
      "mean: tensor(-2.5638, device='mps:0')\n",
      "iter_dt 1.06s; iter 65: train loss 0.64724 temperature: 8.249999999999993\n",
      "mean_logits tensor([-2.4964, -2.6071, -2.4738, -2.1770, -2.4342, -2.5711, -2.8164, -2.8530,\n",
      "        -2.4363, -2.4163, -2.5031, -2.4622, -2.5048, -2.5848, -2.3065, -2.6831,\n",
      "        -2.7997, -2.4980, -2.4143, -2.3928, -2.6467, -2.6288, -2.3052, -2.5206,\n",
      "        -2.7470, -2.6226, -2.4203, -2.3954, -2.2571, -2.6244, -2.4810, -2.5828,\n",
      "        -2.5858, -2.5420, -2.3240, -2.4405, -2.4014, -2.5451, -2.3452, -2.6715,\n",
      "        -2.4342, -2.3308, -2.7028, -2.4374, -2.8220, -2.8822, -2.2893, -2.3388,\n",
      "        -2.6652, -2.4624], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5773, -2.5822, -2.5843, -2.5524, -2.5321, -2.5835, -2.5826, -2.5608,\n",
      "        -2.5512, -2.5863, -2.5321, -2.5828, -2.5721, -2.5746, -2.5817, -2.5722,\n",
      "        -2.5384, -2.5820, -2.5801, -2.5811, -2.5822, -2.5864, -2.5422, -2.5857,\n",
      "        -2.5757, -2.5862, -2.5825, -2.5846, -2.5831, -2.5174, -2.5446, -2.5847,\n",
      "        -2.5240, -2.5889, -2.5891, -2.5793, -2.5927, -2.5818, -2.5794, -2.5831,\n",
      "        -2.5722, -2.5806, -2.5900, -2.5863, -2.5827, -2.5741, -2.5817, -2.5139,\n",
      "        -2.5713, -2.5864], device='mps:0')\n",
      "mean: tensor(-2.5721, device='mps:0')\n",
      "iter_dt 1.05s; iter 66: train loss 0.64800 temperature: 8.299999999999994\n",
      "mean_logits tensor([-2.6018, -2.4497, -2.5471, -2.4744, -2.8252, -2.4293, -2.9246, -2.2940,\n",
      "        -2.7183, -2.5276, -2.7733, -2.6039, -2.6352, -2.6479, -2.5878, -2.8728,\n",
      "        -2.4978, -2.5089, -2.2901, -2.4922, -2.6290, -2.6093, -2.1962, -2.3899,\n",
      "        -2.4663, -2.5807, -2.5772, -2.7247, -2.3832, -2.5196, -2.6510, -2.7511,\n",
      "        -2.5593, -2.6015, -2.7705, -2.6746, -2.5317, -2.7049, -2.5479, -2.5690,\n",
      "        -2.6186, -2.3903, -2.4544, -2.3572, -2.1924, -2.4933, -2.3928, -2.7700,\n",
      "        -2.4396, -2.2986], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5374, -2.4831, -2.5168, -2.5038, -2.5506, -2.5726, -2.5758, -2.5747,\n",
      "        -2.5751, -2.5896, -2.5829, -2.5291, -2.5963, -2.5863, -2.5493, -2.5010,\n",
      "        -2.5296, -2.5431, -2.5828, -2.5856, -2.5678, -2.5868, -2.5780, -2.5895,\n",
      "        -2.4788, -2.5288, -2.5720, -2.5861, -2.5887, -2.5783, -2.5861, -2.5868,\n",
      "        -2.5356, -2.5851, -2.5303, -2.5853, -2.5005, -2.5663, -2.5879, -2.5870,\n",
      "        -2.5861, -2.5865, -2.5696, -2.5869, -2.5705, -2.5865, -2.5739, -2.5681,\n",
      "        -2.5847, -2.5919], device='mps:0')\n",
      "mean: tensor(-2.5635, device='mps:0')\n",
      "iter_dt 1.05s; iter 67: train loss 0.58036 temperature: 8.349999999999994\n",
      "mean_logits tensor([-2.4401, -2.6402, -2.1601, -2.5552, -2.4894, -2.5278, -2.5990, -2.5837,\n",
      "        -2.4847, -2.4290, -2.5446, -2.4096, -2.2553, -2.4698, -2.2416, -2.7983,\n",
      "        -2.6655, -2.6617, -2.6221, -2.6300, -2.4987, -2.5701, -2.4878, -2.4661,\n",
      "        -2.4280, -2.6960, -2.3237, -2.7223, -2.6432, -2.5680, -2.4235, -2.4432,\n",
      "        -2.6481, -2.3222, -2.7300, -2.5368, -2.3849, -2.4392, -2.7677, -2.3888,\n",
      "        -2.5390, -2.3800, -2.6065, -2.4319, -2.5307, -2.3470, -2.1414, -2.9604,\n",
      "        -2.6903, -2.4140], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5741, -2.5592, -2.5957, -2.5800, -2.5866, -2.5302, -2.5700, -2.5750,\n",
      "        -2.5692, -2.5829, -2.5957, -2.5200, -2.5842, -2.5381, -2.5275, -2.5764,\n",
      "        -2.5436, -2.5774, -2.5915, -2.5825, -2.5431, -2.4544, -2.5361, -2.5825,\n",
      "        -2.5661, -2.5954, -2.5864, -2.5293, -2.5871, -2.5594, -2.5947, -2.5867,\n",
      "        -2.5831, -2.5253, -2.5782, -2.5856, -2.5588, -2.5304, -2.5824, -2.5859,\n",
      "        -2.5833, -2.5845, -2.5829, -2.4958, -2.5810, -2.5838, -2.5449, -2.5865,\n",
      "        -2.5381, -2.5439], device='mps:0')\n",
      "mean: tensor(-2.5647, device='mps:0')\n",
      "iter_dt 1.05s; iter 68: train loss 0.64550 temperature: 8.399999999999995\n",
      "mean_logits tensor([-2.4418, -2.6410, -2.5479, -2.7302, -2.7815, -2.7212, -2.4721, -2.4983,\n",
      "        -2.7392, -2.7546, -2.5961, -2.7370, -2.6760, -2.5303, -2.5520, -2.5266,\n",
      "        -2.2707, -2.6998, -2.6886, -2.4206, -2.3519, -2.5071, -2.3522, -2.4991,\n",
      "        -2.7191, -2.6095, -2.4813, -2.6180, -2.7789, -2.7351, -2.7483, -2.7157,\n",
      "        -2.4376, -2.1071, -2.3531, -2.4654, -2.3897, -2.3875, -2.6117, -2.5926,\n",
      "        -2.2178, -2.6787, -2.5829, -2.5279, -2.5222, -2.7181, -2.3802, -2.7511,\n",
      "        -2.7783, -2.8703], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5196, -2.5851, -2.5863, -2.5966, -2.5653, -2.5006, -2.5335, -2.5822,\n",
      "        -2.5705, -2.5953, -2.5424, -2.5321, -2.5732, -2.4874, -2.5646, -2.5863,\n",
      "        -2.5808, -2.5281, -2.5417, -2.5504, -2.5929, -2.5866, -2.5747, -2.5456,\n",
      "        -2.5433, -2.5862, -2.5769, -2.5784, -2.5860, -2.5862, -2.5862, -2.5867,\n",
      "        -2.5861, -2.5860, -2.5852, -2.5919, -2.5350, -2.5869, -2.5859, -2.4919,\n",
      "        -2.5839, -2.4803, -2.5658, -2.5443, -2.5868, -2.5228, -2.5866, -2.5800,\n",
      "        -2.5866, -2.5866], device='mps:0')\n",
      "mean: tensor(-2.5645, device='mps:0')\n",
      "iter_dt 1.06s; iter 69: train loss 0.67092 temperature: 8.449999999999996\n",
      "mean_logits tensor([-2.4480, -2.5143, -2.5635, -2.6548, -2.5017, -2.6851, -2.1728, -2.7266,\n",
      "        -2.8909, -2.5741, -2.7697, -2.5383, -2.5116, -2.5164, -2.6630, -2.6593,\n",
      "        -2.5202, -2.3579, -2.3122, -2.3266, -2.6898, -2.7019, -2.5337, -2.6191,\n",
      "        -2.7180, -2.7142, -2.6070, -2.1089, -2.3416, -2.3350, -2.6387, -2.4592,\n",
      "        -2.6086, -2.6090, -2.6660, -2.5278, -2.5344, -2.7589, -2.5358, -2.5953,\n",
      "        -2.7369, -2.4636, -2.8178, -2.4746, -2.3797, -2.2562, -2.6008, -2.8364,\n",
      "        -2.1192, -2.3405], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5830, -2.5863, -2.5757, -2.5857, -2.5863, -2.5858, -2.5753, -2.5952,\n",
      "        -2.5754, -2.5202, -2.5961, -2.5728, -2.5867, -2.5816, -2.5855, -2.5760,\n",
      "        -2.5696, -2.5000, -2.5162, -2.5774, -2.5842, -2.4867, -2.5594, -2.5574,\n",
      "        -2.5835, -2.5659, -2.5370, -2.5819, -2.5759, -2.5439, -2.5862, -2.5857,\n",
      "        -2.5406, -2.5860, -2.5802, -2.5324, -2.5831, -2.5830, -2.5893, -2.5669,\n",
      "        -2.5795, -2.5968, -2.5860, -2.5826, -2.5927, -2.5871, -2.5383, -2.5282,\n",
      "        -2.5762, -2.5863], device='mps:0')\n",
      "mean: tensor(-2.5699, device='mps:0')\n",
      "iter_dt 1.05s; iter 70: train loss 0.44283 temperature: 8.499999999999996\n",
      "mean_logits tensor([-2.4890, -2.6446, -2.3197, -2.7269, -2.7264, -2.5272, -2.3748, -2.5174,\n",
      "        -2.7120, -2.4978, -2.6224, -2.6106, -2.5067, -2.4485, -2.6737, -2.5009,\n",
      "        -2.6216, -2.5612, -2.4928, -2.3605, -2.3201, -2.3642, -2.6563, -2.3800,\n",
      "        -2.1585, -2.7201, -2.6206, -2.6922, -2.4299, -2.7005, -2.5227, -2.4950,\n",
      "        -2.5739, -2.3301, -2.4610, -2.8912, -2.6691, -2.5639, -2.5532, -2.4201,\n",
      "        -2.2882, -2.4978, -2.1970, -2.6040, -2.6646, -2.6512, -2.4824, -2.4143,\n",
      "        -2.3525, -2.5808], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5309, -2.5857, -2.5448, -2.5710, -2.5760, -2.5732, -2.5859, -2.5771,\n",
      "        -2.5793, -2.5859, -2.5837, -2.5731, -2.5318, -2.5246, -2.5415, -2.5481,\n",
      "        -2.5786, -2.5855, -2.5857, -2.5744, -2.5218, -2.5836, -2.5633, -2.5776,\n",
      "        -2.5677, -2.5956, -2.5690, -2.5716, -2.5238, -2.5756, -2.5402, -2.5437,\n",
      "        -2.5829, -2.5800, -2.5399, -2.5867, -2.5450, -2.5395, -2.5854, -2.5400,\n",
      "        -2.4066, -2.5839, -2.5937, -2.5835, -2.5764, -2.5862, -2.5393, -2.5704,\n",
      "        -2.5706, -2.5920], device='mps:0')\n",
      "mean: tensor(-2.5634, device='mps:0')\n",
      "iter_dt 1.05s; iter 71: train loss 0.68902 temperature: 8.549999999999997\n",
      "mean_logits tensor([-2.5551, -2.5675, -2.2364, -2.3499, -2.5401, -2.2322, -2.5591, -2.6651,\n",
      "        -2.3922, -2.4964, -2.6813, -2.2317, -2.5176, -2.5951, -2.6157, -2.2133,\n",
      "        -2.5282, -2.6280, -3.0087, -2.3276, -2.5760, -2.5925, -2.4847, -2.4323,\n",
      "        -2.6098, -2.6409, -2.7871, -2.4861, -2.3567, -2.6354, -2.6744, -2.5980,\n",
      "        -2.2345, -2.7079, -2.3034, -2.7468, -2.3493, -2.6882, -2.2051, -2.5382,\n",
      "        -2.8768, -2.4370, -2.4306, -2.5305, -2.6033, -2.4424, -2.5374, -2.6714,\n",
      "        -2.6273, -2.4513], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5458, -2.5850, -2.5258, -2.5833, -2.5302, -2.5383, -2.5802, -2.5852,\n",
      "        -2.5974, -2.5863, -2.5272, -2.5764, -2.5810, -2.5563, -2.5757, -2.5265,\n",
      "        -2.5289, -2.5295, -2.5539, -2.5884, -2.5919, -2.5586, -2.5798, -2.5848,\n",
      "        -2.5855, -2.5860, -2.5433, -2.5784, -2.5866, -2.5853, -2.5852, -2.5850,\n",
      "        -2.5859, -2.5842, -2.5406, -2.5865, -2.5069, -2.5822, -2.5983, -2.5857,\n",
      "        -2.5705, -2.5263, -2.5933, -2.5863, -2.5853, -2.5716, -2.5748, -2.5676,\n",
      "        -2.5338, -2.5228], device='mps:0')\n",
      "mean: tensor(-2.5671, device='mps:0')\n",
      "iter_dt 1.04s; iter 72: train loss 0.79260 temperature: 8.599999999999998\n",
      "mean_logits tensor([-2.5912, -2.3651, -2.4949, -2.7413, -2.3475, -2.3933, -2.6970, -2.4684,\n",
      "        -2.5987, -2.5756, -2.8368, -2.6643, -2.6787, -2.3092, -2.2094, -2.5269,\n",
      "        -2.5691, -2.4410, -2.6909, -2.7608, -2.4088, -2.3008, -2.4130, -2.6203,\n",
      "        -2.3978, -2.4712, -2.6749, -2.4674, -2.3954, -2.6581, -2.4434, -2.5742,\n",
      "        -2.5633, -2.3416, -2.3918, -2.5765, -2.3324, -2.1285, -2.4384, -2.6452,\n",
      "        -2.6408, -2.2484, -2.6230, -2.2316, -3.0607, -2.6360, -2.6869, -2.3489,\n",
      "        -2.3976, -2.4324], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4824, -2.5855, -2.5671, -2.5944, -2.5542, -2.5680, -2.5749, -2.5682,\n",
      "        -2.5236, -2.5288, -2.5182, -2.5801, -2.5843, -2.5761, -2.5862, -2.5891,\n",
      "        -2.5410, -2.5648, -2.4108, -2.5847, -2.5755, -2.5230, -2.5421, -2.5329,\n",
      "        -2.5704, -2.5833, -2.5863, -2.5761, -2.5358, -2.5740, -2.5840, -2.5972,\n",
      "        -2.5845, -2.5854, -2.5841, -2.5402, -2.5851, -2.5265, -2.5942, -2.5266,\n",
      "        -2.5963, -2.5473, -2.5738, -2.5843, -2.5688, -2.5637, -2.5829, -2.5392,\n",
      "        -2.5789, -2.5863], device='mps:0')\n",
      "mean: tensor(-2.5622, device='mps:0')\n",
      "iter_dt 1.05s; iter 73: train loss 0.68521 temperature: 8.649999999999999\n",
      "mean_logits tensor([-2.4055, -2.4372, -2.3824, -2.3352, -2.4364, -2.2573, -2.6779, -2.6551,\n",
      "        -2.6557, -2.6569, -2.4750, -2.6055, -2.4400, -2.5487, -2.2858, -2.6009,\n",
      "        -2.7662, -2.7301, -2.4607, -2.5016, -2.6418, -2.6376, -2.5393, -2.5846,\n",
      "        -2.4906, -2.2388, -2.2774, -2.1885, -2.1099, -2.2315, -2.7697, -2.5213,\n",
      "        -2.5402, -2.4740, -2.5541, -2.6979, -2.7165, -2.3249, -2.5109, -2.1507,\n",
      "        -2.6080, -2.6244, -2.6180, -2.4377, -2.4502, -2.2740, -2.7457, -2.6212,\n",
      "        -2.9004, -2.5722], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5864, -2.4877, -2.5840, -2.5269, -2.5594, -2.5239, -2.5705, -2.5953,\n",
      "        -2.5758, -2.5970, -2.5854, -2.5896, -2.5861, -2.5665, -2.5266, -2.5313,\n",
      "        -2.5888, -2.5781, -2.5850, -2.5262, -2.5805, -2.5856, -2.5845, -2.5273,\n",
      "        -2.5885, -2.5258, -2.5864, -2.5823, -2.5836, -2.5781, -2.5867, -2.5732,\n",
      "        -2.5767, -2.4980, -2.5861, -2.5474, -2.5745, -2.5298, -2.5958, -2.5958,\n",
      "        -2.5990, -2.5713, -2.5831, -2.5300, -2.5779, -2.5897, -2.3941, -2.5565,\n",
      "        -2.5831, -2.5240], device='mps:0')\n",
      "mean: tensor(-2.5633, device='mps:0')\n",
      "iter_dt 1.08s; iter 74: train loss 0.52797 temperature: 8.7\n",
      "mean_logits tensor([-2.8094, -2.5148, -2.4344, -2.4632, -2.4682, -2.5049, -2.3598, -2.4273,\n",
      "        -2.6872, -2.6561, -2.4643, -2.7229, -2.5438, -2.7237, -2.6533, -2.4027,\n",
      "        -2.6931, -2.6259, -2.5831, -2.4629, -2.5657, -2.4722, -2.6782, -2.5884,\n",
      "        -2.6060, -2.5936, -2.8020, -2.2066, -2.4363, -2.5254, -2.6015, -2.7456,\n",
      "        -2.4945, -2.4532, -2.6536, -2.2719, -2.4076, -2.5197, -2.6765, -2.7166,\n",
      "        -2.3461, -2.8078, -2.3523, -2.4685, -2.3918, -2.2794, -2.5495, -2.7199,\n",
      "        -2.6945, -2.3668], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5824, -2.5687, -2.5661, -2.5445, -2.5861, -2.5962, -2.5859, -2.5784,\n",
      "        -2.5536, -2.5478, -2.5445, -2.5602, -2.5544, -2.4154, -2.5837, -2.5200,\n",
      "        -2.5718, -2.5705, -2.5383, -2.5698, -2.5859, -2.5972, -2.5764, -2.5852,\n",
      "        -2.5808, -2.5851, -2.5941, -2.5715, -2.5740, -2.5863, -2.5489, -2.5859,\n",
      "        -2.5530, -2.5863, -2.5648, -2.5840, -2.5883, -2.5854, -2.5843, -2.5229,\n",
      "        -2.5738, -2.5277, -2.5688, -2.5705, -2.5964, -2.5071, -2.5464, -2.5768,\n",
      "        -2.5783, -2.5927], device='mps:0')\n",
      "mean: tensor(-2.5663, device='mps:0')\n",
      "iter_dt 1.04s; iter 75: train loss 0.55144 temperature: 8.75\n",
      "mean_logits tensor([-2.3273, -2.3977, -2.5111, -2.4099, -2.3956, -2.5151, -2.3763, -2.5970,\n",
      "        -2.4358, -2.4435, -2.3727, -2.3294, -2.3308, -2.4393, -2.4101, -2.6201,\n",
      "        -2.4478, -2.7010, -2.4210, -2.6726, -2.6163, -2.3010, -2.5204, -2.6473,\n",
      "        -2.4739, -2.3947, -2.6529, -2.7067, -2.6426, -2.4017, -2.3552, -2.9381,\n",
      "        -2.4399, -2.5322, -2.3764, -2.4555, -2.3946, -2.7300, -2.7526, -2.3493,\n",
      "        -2.5814, -2.4942, -2.7753, -2.4282, -2.5115, -2.4491, -2.3599, -2.5358,\n",
      "        -2.6643, -2.4115], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5819, -2.5156, -2.5944, -2.5444, -2.5425, -2.5216, -2.5702, -2.5842,\n",
      "        -2.5926, -2.5319, -2.5837, -2.5864, -2.5734, -2.5529, -2.5801, -2.5870,\n",
      "        -2.5146, -2.4895, -2.5749, -2.5610, -2.5839, -2.4851, -2.5764, -2.5599,\n",
      "        -2.5864, -2.5856, -2.5742, -2.5710, -2.5837, -2.5845, -2.5264, -2.5194,\n",
      "        -2.5841, -2.5462, -2.5845, -2.5472, -2.5768, -2.5864, -2.5390, -2.5837,\n",
      "        -2.5781, -2.5864, -2.5798, -2.5679, -2.5865, -2.5804, -2.5382, -2.5862,\n",
      "        -2.5920, -2.5824], device='mps:0')\n",
      "mean: tensor(-2.5649, device='mps:0')\n",
      "iter_dt 1.06s; iter 76: train loss 0.38771 temperature: 8.8\n",
      "mean_logits tensor([-2.5379, -2.5301, -2.8464, -2.5057, -2.4477, -2.5728, -2.3997, -2.6083,\n",
      "        -2.3838, -2.6449, -2.4712, -2.6908, -2.5448, -2.6882, -2.4328, -2.5834,\n",
      "        -2.5542, -2.4867, -2.5863, -2.5667, -2.5648, -2.5319, -2.4307, -2.6113,\n",
      "        -2.4726, -2.5161, -2.7345, -2.6603, -2.2729, -2.7440, -2.6469, -2.5819,\n",
      "        -2.7630, -2.6227, -2.5707, -2.5732, -2.6065, -2.2071, -2.4339, -2.5054,\n",
      "        -2.4724, -2.8716, -2.4470, -2.4417, -2.7749, -2.5498, -2.6187, -2.4553,\n",
      "        -2.3584, -2.4998], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5480, -2.5866, -2.5850, -2.5397, -2.5766, -2.5308, -2.5046, -2.5692,\n",
      "        -2.5838, -2.5860, -2.5559, -2.5885, -2.5655, -2.5961, -2.5774, -2.5766,\n",
      "        -2.5376, -2.5824, -2.5959, -2.5716, -2.5855, -2.5868, -2.5815, -2.5855,\n",
      "        -2.5888, -2.5459, -2.5838, -2.5142, -2.5627, -2.5403, -2.5779, -2.5864,\n",
      "        -2.5664, -2.5916, -2.5414, -2.5805, -2.5858, -2.5626, -2.5261, -2.5876,\n",
      "        -2.5856, -2.5743, -2.5721, -2.5750, -2.5853, -2.5770, -2.5602, -2.5738,\n",
      "        -2.5846, -2.5540], device='mps:0')\n",
      "mean: tensor(-2.5696, device='mps:0')\n",
      "iter_dt 1.03s; iter 77: train loss 0.54780 temperature: 8.850000000000001\n",
      "mean_logits tensor([-2.5492, -2.5232, -2.5853, -2.9458, -2.4980, -2.6865, -2.4383, -2.5178,\n",
      "        -2.7131, -2.4706, -2.4733, -2.6204, -2.5596, -2.5069, -2.6920, -2.7597,\n",
      "        -2.3959, -2.4158, -2.4426, -2.4444, -2.6073, -2.3551, -2.2103, -2.4753,\n",
      "        -2.3816, -2.6552, -2.4407, -2.3516, -2.4095, -2.4067, -2.5881, -2.4916,\n",
      "        -2.6273, -2.5068, -2.5554, -2.3765, -2.5053, -2.3352, -2.7149, -2.5450,\n",
      "        -2.7703, -2.7666, -2.3487, -2.4209, -2.5359, -2.6093, -2.5654, -2.5332,\n",
      "        -2.4990, -2.8926], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5859, -2.5756, -2.5835, -2.5377, -2.5909, -2.5319, -2.5866, -2.5439,\n",
      "        -2.5534, -2.5494, -2.5775, -2.5362, -2.5334, -2.5859, -2.5410, -2.5845,\n",
      "        -2.5316, -2.5860, -2.5863, -2.5677, -2.5624, -2.5944, -2.5157, -2.5866,\n",
      "        -2.5863, -2.5431, -2.5738, -2.5798, -2.5450, -2.5020, -2.5447, -2.5828,\n",
      "        -2.5864, -2.5640, -2.5315, -2.5952, -2.5738, -2.5300, -2.5514, -2.5704,\n",
      "        -2.5862, -2.5102, -2.5939, -2.5408, -2.5272, -2.5864, -2.5826, -2.5817,\n",
      "        -2.5851, -2.5852], device='mps:0')\n",
      "mean: tensor(-2.5634, device='mps:0')\n",
      "iter_dt 1.06s; iter 78: train loss 0.53367 temperature: 8.900000000000002\n",
      "mean_logits tensor([-2.7623, -2.5704, -2.3514, -2.7372, -2.4103, -2.7203, -2.3901, -2.7859,\n",
      "        -2.5944, -2.6748, -2.5243, -2.5247, -2.5041, -2.7117, -2.5630, -2.3822,\n",
      "        -2.6228, -2.3890, -2.6205, -2.3745, -2.5520, -2.3707, -2.8708, -2.4359,\n",
      "        -2.7713, -2.3988, -2.6368, -2.2875, -2.4027, -2.6700, -2.5180, -2.4893,\n",
      "        -2.3407, -2.4258, -2.5736, -2.7050, -2.6575, -2.4202, -2.6920, -2.4935,\n",
      "        -2.5875, -2.7347, -2.1552, -2.7047, -2.5423, -2.2486, -2.6754, -2.3830,\n",
      "        -2.6916, -2.4329], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5802, -2.5930, -2.5733, -2.5849, -2.4842, -2.5525, -2.5958, -2.5769,\n",
      "        -2.5924, -2.5765, -2.5325, -2.5698, -2.5861, -2.5815, -2.5722, -2.5765,\n",
      "        -2.5863, -2.5812, -2.5276, -2.5862, -2.5852, -2.5963, -2.5808, -2.5791,\n",
      "        -2.5806, -2.5523, -2.5648, -2.5278, -2.5425, -2.5836, -2.5506, -2.5707,\n",
      "        -2.5853, -2.5861, -2.5958, -2.5564, -2.5819, -2.5916, -2.5793, -2.5763,\n",
      "        -2.5859, -2.5461, -2.4873, -2.5288, -2.5861, -2.5433, -2.5800, -2.5861,\n",
      "        -2.5420, -2.5872], device='mps:0')\n",
      "mean: tensor(-2.5690, device='mps:0')\n",
      "iter_dt 1.10s; iter 79: train loss 0.51644 temperature: 8.950000000000003\n",
      "mean_logits tensor([-2.4790, -2.4398, -2.6967, -2.4542, -2.1884, -2.4027, -2.4976, -2.6480,\n",
      "        -2.6008, -2.6868, -2.6713, -2.6411, -2.5449, -2.5135, -2.4500, -2.5055,\n",
      "        -2.6155, -2.2853, -2.6031, -2.3294, -2.4960, -2.4652, -2.5791, -2.6527,\n",
      "        -2.5215, -2.5489, -2.3926, -2.4424, -2.5442, -2.5803, -2.8346, -2.5583,\n",
      "        -2.4518, -2.0827, -2.6375, -2.6368, -2.5195, -2.8447, -2.3720, -2.4573,\n",
      "        -2.6096, -2.3608, -2.5976, -2.5992, -2.7112, -2.5014, -2.6103, -2.9148,\n",
      "        -2.6898, -2.4883], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5859, -2.5686, -2.5752, -2.5292, -2.5508, -2.5534, -2.5974, -2.5866,\n",
      "        -2.5432, -2.5772, -2.5832, -2.5869, -2.5854, -2.5890, -2.5805, -2.5416,\n",
      "        -2.5438, -2.5841, -2.5894, -2.5292, -2.5825, -2.5848, -2.5825, -2.5536,\n",
      "        -2.5961, -2.5437, -2.5847, -2.5758, -2.5851, -2.5856, -2.5858, -2.5782,\n",
      "        -2.5805, -2.5960, -2.5753, -2.5708, -2.5421, -2.5482, -2.5961, -2.5825,\n",
      "        -2.5856, -2.5896, -2.5933, -2.5751, -2.5522, -2.5950, -2.5377, -2.5851,\n",
      "        -2.5847, -2.5470], device='mps:0')\n",
      "mean: tensor(-2.5731, device='mps:0')\n",
      "iter_dt 1.03s; iter 80: train loss 0.56237 temperature: 9.000000000000004\n",
      "mean_logits tensor([-2.6514, -2.6778, -2.5526, -2.3832, -2.4366, -2.3669, -2.2843, -2.5270,\n",
      "        -2.5841, -2.6224, -2.3259, -2.5296, -2.5670, -2.6399, -2.4256, -2.6432,\n",
      "        -2.5302, -2.4137, -2.5014, -2.4350, -2.7214, -2.7194, -2.4091, -2.7418,\n",
      "        -2.1700, -2.7270, -2.3327, -2.6581, -2.5526, -2.3096, -2.5450, -2.6756,\n",
      "        -2.6010, -2.8268, -2.7475, -2.4326, -2.5097, -2.3334, -2.5525, -2.6540,\n",
      "        -2.4249, -2.2478, -2.3737, -2.4906, -2.3976, -2.4528, -2.1695, -2.3027,\n",
      "        -2.5386, -2.7530], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5706, -2.5674, -2.5908, -2.5423, -2.5862, -2.5741, -2.5804, -2.5870,\n",
      "        -2.5945, -2.5943, -2.5654, -2.5395, -2.5502, -2.5953, -2.5947, -2.5116,\n",
      "        -2.5230, -2.4488, -2.5865, -2.5283, -2.5735, -2.5810, -2.5796, -2.5868,\n",
      "        -2.5826, -2.5833, -2.4034, -2.5744, -2.5824, -2.5382, -2.5861, -2.5385,\n",
      "        -2.5837, -2.4895, -2.5866, -2.5742, -2.5828, -2.5961, -2.5824, -2.5864,\n",
      "        -2.5641, -2.5554, -2.5833, -2.5622, -2.5334, -2.5391, -2.5863, -2.5278,\n",
      "        -2.5845, -2.5158], device='mps:0')\n",
      "mean: tensor(-2.5615, device='mps:0')\n",
      "iter_dt 1.04s; iter 81: train loss 0.52013 temperature: 9.050000000000004\n",
      "mean_logits tensor([-2.5041, -2.8105, -2.5139, -2.4413, -2.3121, -2.7315, -2.6575, -2.7321,\n",
      "        -2.3559, -2.3641, -2.7216, -2.6732, -2.6433, -2.6515, -2.7005, -2.5723,\n",
      "        -2.4142, -2.3512, -2.6634, -2.6937, -2.5175, -2.6852, -2.5190, -2.2192,\n",
      "        -2.6121, -2.3776, -2.5565, -2.3415, -2.6000, -2.2026, -2.5767, -2.5388,\n",
      "        -2.5895, -2.6126, -2.4837, -2.4035, -2.5300, -2.7577, -2.7529, -2.6418,\n",
      "        -2.6501, -2.4483, -2.4789, -2.5501, -2.3440, -2.2429, -2.8134, -2.4038,\n",
      "        -2.5372, -2.5382], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5877, -2.5855, -2.5840, -2.5857, -2.5482, -2.5770, -2.5864, -2.5867,\n",
      "        -2.5671, -2.5824, -2.5328, -2.5738, -2.5435, -2.5852, -2.5862, -2.5428,\n",
      "        -2.5709, -2.5793, -2.5859, -2.5450, -2.5859, -2.4141, -2.6016, -2.5380,\n",
      "        -2.5271, -2.5797, -2.5848, -2.5557, -2.5342, -2.5857, -2.5772, -2.5774,\n",
      "        -2.5559, -2.5847, -2.5850, -2.5386, -2.5834, -2.5860, -2.5770, -2.5460,\n",
      "        -2.5864, -2.5835, -2.5627, -2.5739, -2.5103, -2.5390, -2.5710, -2.5940,\n",
      "        -2.4692, -2.5729], device='mps:0')\n",
      "mean: tensor(-2.5643, device='mps:0')\n",
      "iter_dt 1.04s; iter 82: train loss 0.62668 temperature: 9.100000000000005\n",
      "mean_logits tensor([-2.3745, -2.3906, -2.5924, -2.6471, -2.6998, -2.6865, -2.5035, -2.3891,\n",
      "        -2.5706, -2.4776, -2.4676, -2.4903, -2.6807, -2.2690, -2.5859, -2.7717,\n",
      "        -2.2816, -2.6568, -2.3406, -2.2648, -2.6930, -2.7931, -2.6439, -2.6034,\n",
      "        -2.6683, -2.7204, -2.5652, -2.5920, -2.3464, -2.6522, -2.5015, -2.9378,\n",
      "        -2.5665, -2.7130, -2.6319, -2.5239, -2.1408, -2.6969, -2.4501, -2.4318,\n",
      "        -2.3677, -2.6412, -2.4844, -2.4950, -2.3958, -2.6019, -2.3365, -2.7314,\n",
      "        -2.5953, -2.1695], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5825, -2.5868, -2.5856, -2.5313, -2.5398, -2.5853, -2.5913, -2.5841,\n",
      "        -2.5864, -2.5863, -2.5729, -2.5751, -2.5865, -2.5675, -2.5856, -2.5828,\n",
      "        -2.5675, -2.5764, -2.5836, -2.5736, -2.5858, -2.5934, -2.5848, -2.5754,\n",
      "        -2.5383, -2.5808, -2.5872, -2.5737, -2.5765, -2.5869, -2.5328, -2.5543,\n",
      "        -2.5795, -2.5886, -2.5398, -2.5786, -2.5844, -2.5449, -2.5292, -2.5844,\n",
      "        -2.5837, -2.5827, -2.5861, -2.5239, -2.5658, -2.5839, -2.5747, -2.5864,\n",
      "        -2.5874, -2.5928], device='mps:0')\n",
      "mean: tensor(-2.5740, device='mps:0')\n",
      "iter_dt 1.07s; iter 83: train loss 0.53697 temperature: 9.150000000000006\n",
      "mean_logits tensor([-2.5283, -2.8653, -2.9684, -2.4113, -2.5939, -2.3113, -2.6372, -2.4808,\n",
      "        -2.5850, -2.6032, -2.5041, -2.5491, -2.6688, -2.5401, -2.3362, -2.6036,\n",
      "        -2.6108, -2.6569, -2.4684, -2.5828, -2.7592, -2.7132, -2.5610, -2.5229,\n",
      "        -2.4027, -2.5152, -2.5224, -2.6365, -2.5485, -2.6664, -2.6730, -2.5661,\n",
      "        -2.7770, -2.6084, -2.8562, -2.4564, -2.5027, -2.2294, -2.5602, -2.3697,\n",
      "        -2.6055, -2.6557, -2.7627, -2.6323, -2.2311, -2.7226, -2.7215, -2.4797,\n",
      "        -2.4631, -2.5739], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5762, -2.5713, -2.4915, -2.5797, -2.5342, -2.5383, -2.5785, -2.5309,\n",
      "        -2.5766, -2.5740, -2.5825, -2.5866, -2.5958, -2.5892, -2.5491, -2.5827,\n",
      "        -2.5866, -2.5941, -2.5202, -2.5346, -2.5974, -2.5947, -2.5198, -2.5860,\n",
      "        -2.5754, -2.5845, -2.5743, -2.5703, -2.5771, -2.5641, -2.5854, -2.5703,\n",
      "        -2.5774, -2.5853, -2.5815, -2.5857, -2.5432, -2.5839, -2.5653, -2.5856,\n",
      "        -2.5991, -2.5277, -2.5833, -2.5736, -2.5046, -2.5924, -2.5870, -2.5852,\n",
      "        -2.5842, -2.5862], device='mps:0')\n",
      "mean: tensor(-2.5701, device='mps:0')\n",
      "iter_dt 1.06s; iter 84: train loss 0.52359 temperature: 9.200000000000006\n",
      "mean_logits tensor([-2.3304, -2.3263, -2.5920, -2.6853, -2.5374, -2.4674, -2.7700, -2.3860,\n",
      "        -2.5591, -2.8633, -2.4103, -2.5890, -2.2721, -2.4941, -2.5213, -2.5283,\n",
      "        -2.5917, -2.8318, -2.5436, -2.4183, -2.5709, -2.6583, -2.6693, -2.7857,\n",
      "        -2.5128, -2.4066, -2.6625, -2.5022, -2.2851, -2.3338, -2.5775, -2.6457,\n",
      "        -2.5691, -2.7259, -2.3634, -2.6127, -2.4208, -2.3916, -2.5077, -2.5392,\n",
      "        -2.4254, -2.5383, -2.4845, -2.1692, -2.6571, -2.5014, -2.4696, -2.8002,\n",
      "        -2.2870, -2.6625], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5922, -2.5598, -2.5218, -2.5377, -2.5768, -2.5901, -2.5889, -2.5865,\n",
      "        -2.5864, -2.5951, -2.5145, -2.5638, -2.5885, -2.5760, -2.5865, -2.5805,\n",
      "        -2.5848, -2.5768, -2.5772, -2.5296, -2.5439, -2.5853, -2.5761, -2.5831,\n",
      "        -2.5792, -2.5635, -2.5864, -2.5649, -2.5413, -2.5965, -2.5805, -2.5685,\n",
      "        -2.5954, -2.5889, -2.5144, -2.5835, -2.5484, -2.5868, -2.5797, -2.5957,\n",
      "        -2.5439, -2.5867, -2.5317, -2.5907, -2.5435, -2.5710, -2.5698, -2.5606,\n",
      "        -2.5765, -2.5800], device='mps:0')\n",
      "mean: tensor(-2.5706, device='mps:0')\n",
      "iter_dt 1.07s; iter 85: train loss 0.57617 temperature: 9.250000000000007\n",
      "mean_logits tensor([-2.6405, -2.5587, -2.3398, -2.1760, -2.6835, -2.4332, -2.3706, -2.2591,\n",
      "        -2.5814, -2.7685, -2.3119, -2.3403, -2.2507, -2.5090, -2.7392, -2.7042,\n",
      "        -2.5619, -2.5848, -2.5635, -2.4325, -2.7759, -2.8225, -2.4893, -2.6831,\n",
      "        -2.6227, -2.4637, -2.6300, -2.9448, -2.4764, -2.6068, -2.4959, -2.3607,\n",
      "        -2.1517, -2.4558, -2.7305, -2.4988, -2.6318, -2.6053, -2.5983, -2.3046,\n",
      "        -2.5615, -2.5292, -2.4813, -2.6056, -2.3850, -2.6871, -2.4602, -2.4580,\n",
      "        -2.5557, -2.6110], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5855, -2.5863, -2.5770, -2.5639, -2.5863, -2.5852, -2.5383, -2.5767,\n",
      "        -2.5865, -2.5785, -2.5912, -2.5629, -2.4873, -2.5868, -2.5614, -2.5867,\n",
      "        -2.5381, -2.5292, -2.5963, -2.6030, -2.5818, -2.5863, -2.5621, -2.5651,\n",
      "        -2.5855, -2.5861, -2.5708, -2.5809, -2.5373, -2.5841, -2.5678, -2.5863,\n",
      "        -2.5164, -2.5867, -2.5281, -2.5867, -2.5578, -2.5863, -2.5817, -2.5832,\n",
      "        -2.5847, -2.5392, -2.5838, -2.5771, -2.5855, -2.5860, -2.5489, -2.4350,\n",
      "        -2.5872, -2.5848], device='mps:0')\n",
      "mean: tensor(-2.5688, device='mps:0')\n",
      "iter_dt 1.04s; iter 86: train loss 0.37862 temperature: 9.300000000000008\n",
      "mean_logits tensor([-2.3337, -2.5277, -2.4448, -2.5351, -2.5047, -2.5776, -2.6543, -2.5307,\n",
      "        -2.3063, -2.5453, -2.4195, -2.4288, -2.5758, -2.3640, -2.4783, -2.5030,\n",
      "        -2.7083, -2.4987, -2.4214, -2.4209, -2.4163, -2.6176, -2.7072, -2.6333,\n",
      "        -2.7325, -2.4156, -2.3900, -2.6660, -2.7084, -2.3012, -2.4652, -2.4558,\n",
      "        -2.5187, -2.7987, -2.5298, -2.3777, -2.6861, -2.5309, -2.4659, -2.5025,\n",
      "        -2.3632, -2.6253, -2.6492, -2.6730, -2.5790, -2.3890, -2.7783, -2.3932,\n",
      "        -2.4951, -2.4573], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5255, -2.5333, -2.5437, -2.5782, -2.5866, -2.5841, -2.5832, -2.5378,\n",
      "        -2.5620, -2.5795, -2.5867, -2.5701, -2.5940, -2.5357, -2.5648, -2.5759,\n",
      "        -2.5936, -2.5833, -2.6037, -2.5831, -2.5761, -2.5928, -2.5852, -2.5853,\n",
      "        -2.5857, -2.5893, -2.5740, -2.5852, -2.5821, -2.5854, -2.5955, -2.5863,\n",
      "        -2.5834, -2.5880, -2.5852, -2.5875, -2.5977, -2.5807, -2.5456, -2.5938,\n",
      "        -2.5553, -2.4943, -2.5378, -2.5873, -2.5588, -2.5791, -2.5809, -2.5864,\n",
      "        -2.5848, -2.5595], device='mps:0')\n",
      "mean: tensor(-2.5743, device='mps:0')\n",
      "iter_dt 1.21s; iter 87: train loss 0.57717 temperature: 9.350000000000009\n",
      "mean_logits tensor([-2.3868, -2.4455, -2.5796, -2.4279, -2.3384, -2.4977, -2.4877, -2.5243,\n",
      "        -2.3946, -2.4580, -2.6018, -2.1357, -2.8196, -2.6865, -2.5996, -2.3054,\n",
      "        -2.7295, -2.1911, -2.5175, -2.3589, -2.3826, -2.1284, -2.4327, -2.4294,\n",
      "        -2.5345, -2.4935, -2.6865, -2.5592, -2.5391, -2.4237, -2.5942, -2.5480,\n",
      "        -2.5437, -2.7107, -2.4370, -2.4354, -2.4465, -2.3903, -2.2994, -2.4143,\n",
      "        -2.6257, -2.4611, -2.5197, -2.2021, -2.6447, -2.2481, -2.5222, -2.7335,\n",
      "        -2.6307, -2.5191], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5857, -2.5806, -2.5300, -2.5732, -2.5865, -2.5947, -2.5807, -2.5447,\n",
      "        -2.5609, -2.5607, -2.5880, -2.5835, -2.5856, -2.5759, -2.5843, -2.5759,\n",
      "        -2.5859, -2.5246, -2.5782, -2.5752, -2.5396, -2.5860, -2.5400, -2.5856,\n",
      "        -2.5881, -2.5764, -2.5295, -2.5964, -2.5941, -2.5427, -2.5498, -2.5438,\n",
      "        -2.5928, -2.5750, -2.5781, -2.5349, -2.5587, -2.5713, -2.5861, -2.5962,\n",
      "        -2.5783, -2.5804, -2.5578, -2.5821, -2.5846, -2.5645, -2.5695, -2.5820,\n",
      "        -2.5452, -2.5766], device='mps:0')\n",
      "mean: tensor(-2.5708, device='mps:0')\n",
      "iter_dt 1.14s; iter 88: train loss 0.49021 temperature: 9.40000000000001\n",
      "mean_logits tensor([-2.7409, -2.6060, -2.5948, -2.4839, -2.5268, -2.4942, -2.6493, -2.3061,\n",
      "        -2.5570, -2.5033, -2.3022, -2.5978, -2.4652, -2.4631, -2.3508, -2.5170,\n",
      "        -2.8147, -2.3304, -2.5938, -2.2146, -2.3648, -2.6699, -2.5066, -2.4209,\n",
      "        -2.5670, -2.5493, -2.6820, -2.5676, -2.3504, -2.5316, -2.6211, -2.4437,\n",
      "        -2.5490, -2.6493, -2.3968, -2.7080, -2.1861, -2.5342, -2.7412, -2.8300,\n",
      "        -2.4502, -2.6931, -2.3575, -2.6634, -2.6072, -2.7487, -2.3563, -2.5450,\n",
      "        -2.5498, -2.4593], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5805, -2.5347, -2.5695, -2.5249, -2.5862, -2.5905, -2.5850, -2.5849,\n",
      "        -2.5632, -2.5785, -2.5350, -2.4817, -2.5869, -2.5862, -2.5838, -2.5859,\n",
      "        -2.5848, -2.5857, -2.5806, -2.5802, -2.5753, -2.5864, -2.5830, -2.5543,\n",
      "        -2.5509, -2.5864, -2.5362, -2.5600, -2.5875, -2.5871, -2.5860, -2.5690,\n",
      "        -2.5808, -2.5520, -2.5937, -2.5770, -2.5857, -2.5920, -2.5833, -2.5860,\n",
      "        -2.5848, -2.5784, -2.5685, -2.5639, -2.5737, -2.5845, -2.5229, -2.5859,\n",
      "        -2.5767, -2.5858], device='mps:0')\n",
      "mean: tensor(-2.5725, device='mps:0')\n",
      "iter_dt 1.05s; iter 89: train loss 0.41962 temperature: 9.45000000000001\n",
      "mean_logits tensor([-2.8126, -2.4479, -2.2892, -2.5710, -2.5447, -2.4116, -2.8129, -2.5593,\n",
      "        -2.5224, -2.6322, -2.6375, -2.5738, -2.7200, -2.4315, -2.3929, -2.6749,\n",
      "        -2.3916, -2.3187, -2.4095, -2.3025, -2.5165, -2.4514, -2.5722, -2.5018,\n",
      "        -2.6850, -2.7619, -2.6240, -2.3645, -2.3731, -2.3768, -2.7657, -2.5262,\n",
      "        -2.7670, -2.5871, -2.3328, -2.7437, -2.6657, -2.5109, -2.6629, -2.5521,\n",
      "        -2.3886, -2.4719, -2.4437, -2.4716, -2.5039, -2.6257, -2.4054, -2.5549,\n",
      "        -2.4550, -2.4845], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5988, -2.5775, -2.5286, -2.5858, -2.5774, -2.5862, -2.5313, -2.5740,\n",
      "        -2.5384, -2.5423, -2.5826, -2.5769, -2.5975, -2.5784, -2.5861, -2.5683,\n",
      "        -2.5936, -2.5236, -2.5302, -2.5779, -2.5759, -2.5774, -2.5349, -2.5650,\n",
      "        -2.5858, -2.5444, -2.5826, -2.5846, -2.5464, -2.5752, -2.5858, -2.5434,\n",
      "        -2.5851, -2.5577, -2.5219, -2.5915, -2.5875, -2.5282, -2.5819, -2.5183,\n",
      "        -2.5651, -2.5319, -2.5246, -2.5873, -2.5874, -2.5849, -2.5380, -2.5869,\n",
      "        -2.5819, -2.5760], device='mps:0')\n",
      "mean: tensor(-2.5659, device='mps:0')\n",
      "iter_dt 1.06s; iter 90: train loss 0.39227 temperature: 9.50000000000001\n",
      "mean_logits tensor([-2.5236, -2.8553, -2.5031, -2.5740, -2.7066, -2.4813, -2.4882, -2.6179,\n",
      "        -2.3797, -2.5722, -2.6064, -2.4406, -2.5691, -2.1880, -2.5417, -2.2430,\n",
      "        -2.4227, -2.5054, -2.6293, -2.6676, -2.6193, -2.7324, -2.6321, -2.4268,\n",
      "        -2.3156, -2.4418, -2.3387, -2.2828, -2.7310, -2.4702, -2.4420, -2.4896,\n",
      "        -2.6509, -2.5726, -2.5096, -2.6228, -2.5964, -2.6564, -2.4932, -2.5348,\n",
      "        -2.2324, -2.5238, -2.5973, -2.6165, -2.4666, -2.4624, -2.2626, -2.3632,\n",
      "        -2.5819, -2.5382], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5678, -2.5994, -2.5648, -2.5770, -2.5827, -2.5832, -2.5740, -2.5423,\n",
      "        -2.5794, -2.5792, -2.5761, -2.5351, -2.5865, -2.5762, -2.5957, -2.5299,\n",
      "        -2.5785, -2.5862, -2.5868, -2.5295, -2.5759, -2.5763, -2.5832, -2.5254,\n",
      "        -2.5850, -2.5775, -2.5205, -2.5926, -2.5787, -2.4973, -2.5459, -2.5287,\n",
      "        -2.5857, -2.5852, -2.5930, -2.5865, -2.5448, -2.5862, -2.5138, -2.5807,\n",
      "        -2.5386, -2.5806, -2.5451, -2.5893, -2.5357, -2.5839, -2.5234, -2.5866,\n",
      "        -2.5773, -2.5240], device='mps:0')\n",
      "mean: tensor(-2.5655, device='mps:0')\n",
      "iter_dt 1.04s; iter 91: train loss 0.40525 temperature: 9.550000000000011\n",
      "mean_logits tensor([-2.5071, -2.8530, -2.5191, -2.3440, -2.5631, -2.5703, -2.5053, -2.2776,\n",
      "        -2.7435, -2.5955, -2.5025, -2.5728, -2.3818, -2.5122, -2.4443, -2.5982,\n",
      "        -2.4382, -2.4008, -2.4707, -2.3189, -2.3975, -2.5862, -2.5407, -2.5619,\n",
      "        -2.4784, -2.4299, -2.6329, -2.2373, -2.4084, -2.3992, -2.7645, -2.4902,\n",
      "        -2.4734, -2.5283, -2.6346, -2.4125, -2.6230, -2.4786, -2.4585, -2.5379,\n",
      "        -2.5317, -2.6951, -2.5429, -2.4942, -2.5852, -2.4880, -2.6536, -2.5551,\n",
      "        -2.1838, -2.6114], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5860, -2.5796, -2.5807, -2.5868, -2.5807, -2.5669, -2.5416, -2.5350,\n",
      "        -2.5736, -2.5851, -2.5558, -2.5876, -2.5909, -2.5771, -2.5850, -2.5879,\n",
      "        -2.5872, -2.5855, -2.5861, -2.5774, -2.5186, -2.5804, -2.5347, -2.5389,\n",
      "        -2.5719, -2.5763, -2.5860, -2.5821, -2.5853, -2.5701, -2.5865, -2.5661,\n",
      "        -2.5846, -2.5821, -2.5479, -2.5867, -2.5433, -2.5829, -2.5802, -2.5765,\n",
      "        -2.5778, -2.5834, -2.5809, -2.5397, -2.5848, -2.5835, -2.5854, -2.5776,\n",
      "        -2.5852, -2.5279], device='mps:0')\n",
      "mean: tensor(-2.5729, device='mps:0')\n",
      "iter_dt 1.05s; iter 92: train loss 0.58799 temperature: 9.600000000000012\n",
      "mean_logits tensor([-2.8748, -2.7267, -2.6593, -2.3943, -2.3720, -2.6202, -2.6983, -2.4862,\n",
      "        -2.7405, -2.5959, -2.3962, -2.3441, -2.6852, -2.8024, -2.5053, -2.6262,\n",
      "        -2.5976, -2.5196, -2.6076, -2.3627, -2.7974, -2.5066, -2.3854, -2.7332,\n",
      "        -2.3028, -2.8315, -2.6158, -2.1792, -2.7156, -2.4371, -2.4625, -2.6526,\n",
      "        -2.5479, -2.3957, -2.6053, -2.4316, -2.4699, -2.6570, -2.2096, -2.6614,\n",
      "        -2.5527, -2.6354, -2.6789, -2.5332, -2.6085, -2.6142, -2.3067, -2.2772,\n",
      "        -2.4130, -2.5066], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5857, -2.5858, -2.5508, -2.5863, -2.5854, -2.5926, -2.5863, -2.5960,\n",
      "        -2.5437, -2.5862, -2.5189, -2.5842, -2.5777, -2.5980, -2.5743, -2.5571,\n",
      "        -2.5638, -2.5916, -2.5637, -2.5640, -2.5553, -2.5951, -2.5685, -2.5855,\n",
      "        -2.5923, -2.5867, -2.5761, -2.5865, -2.5857, -2.5938, -2.5971, -2.5360,\n",
      "        -2.5838, -2.5297, -2.5765, -2.5357, -2.5726, -2.5890, -2.5859, -2.5772,\n",
      "        -2.5771, -2.5959, -2.5854, -2.5832, -2.5311, -2.5898, -2.5733, -2.5866,\n",
      "        -2.5862, -2.5867], device='mps:0')\n",
      "mean: tensor(-2.5759, device='mps:0')\n",
      "iter_dt 1.07s; iter 93: train loss 0.56730 temperature: 9.650000000000013\n",
      "mean_logits tensor([-2.6436, -2.4925, -2.7054, -2.3654, -2.3995, -2.6645, -2.6747, -2.6200,\n",
      "        -2.5164, -2.3892, -2.4834, -2.3852, -2.7320, -2.5254, -2.6446, -2.3971,\n",
      "        -2.3615, -2.6410, -2.6899, -2.1948, -2.4884, -2.5173, -2.6578, -2.6504,\n",
      "        -2.7606, -2.4325, -2.6251, -2.2021, -2.6089, -2.4843, -2.8135, -2.4808,\n",
      "        -2.6512, -2.8441, -2.4759, -2.5761, -2.6802, -2.5529, -2.5234, -2.4252,\n",
      "        -2.6626, -2.4324, -2.5478, -2.5989, -3.0383, -2.5244, -2.5778, -2.6647,\n",
      "        -2.6106, -2.6402], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5854, -2.5833, -2.5741, -2.5881, -2.5856, -2.5861, -2.5716, -2.5718,\n",
      "        -2.5855, -2.5807, -2.5708, -2.5869, -2.5835, -2.5465, -2.5862, -2.5623,\n",
      "        -2.5387, -2.5850, -2.5768, -2.5844, -2.5772, -2.5923, -2.5851, -2.5861,\n",
      "        -2.5869, -2.5861, -2.5416, -2.5856, -2.5861, -2.5863, -2.5826, -2.5841,\n",
      "        -2.5834, -2.5687, -2.5832, -2.5859, -2.5859, -2.5843, -2.5433, -2.5754,\n",
      "        -2.5748, -2.5986, -2.5644, -2.5453, -2.5855, -2.5625, -2.5811, -2.5497,\n",
      "        -2.5863, -2.5868], device='mps:0')\n",
      "mean: tensor(-2.5772, device='mps:0')\n",
      "iter_dt 1.06s; iter 94: train loss 0.51514 temperature: 9.700000000000014\n",
      "mean_logits tensor([-2.6991, -2.5253, -2.5583, -2.4893, -2.9350, -2.6166, -2.5063, -2.6959,\n",
      "        -2.5321, -2.6172, -2.9523, -2.6496, -2.6580, -2.7269, -2.4860, -2.5357,\n",
      "        -2.5973, -2.4005, -2.5993, -2.6318, -2.4216, -2.4833, -2.3904, -2.5640,\n",
      "        -2.7244, -2.6799, -2.7782, -2.4213, -2.8085, -2.6959, -2.3804, -2.4618,\n",
      "        -2.5974, -2.3939, -2.5322, -2.5552, -2.7823, -2.6176, -2.8199, -2.4381,\n",
      "        -2.5071, -2.5885, -2.6415, -2.4382, -2.3806, -2.6184, -2.5374, -2.5423,\n",
      "        -2.4675, -2.5766], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5944, -2.5717, -2.5346, -2.5673, -2.5789, -2.5714, -2.5879, -2.5622,\n",
      "        -2.5998, -2.5790, -2.5975, -2.5846, -2.5803, -2.5835, -2.5819, -2.5939,\n",
      "        -2.5754, -2.5826, -2.5975, -2.5780, -2.5852, -2.5857, -2.5849, -2.5962,\n",
      "        -2.5079, -2.5861, -2.5768, -2.5831, -2.5494, -2.5611, -2.5676, -2.5834,\n",
      "        -2.5374, -2.5860, -2.5856, -2.5735, -2.5816, -2.5886, -2.5609, -2.5724,\n",
      "        -2.5834, -2.5759, -2.5862, -2.5680, -2.5778, -2.5801, -2.5817, -2.5353,\n",
      "        -2.5171, -2.5752], device='mps:0')\n",
      "mean: tensor(-2.5747, device='mps:0')\n",
      "iter_dt 1.07s; iter 95: train loss 0.61345 temperature: 9.750000000000014\n",
      "mean_logits tensor([-2.3880, -2.4737, -2.8570, -2.4304, -2.5200, -2.4624, -2.4393, -2.5070,\n",
      "        -2.4996, -2.8345, -2.3358, -2.3972, -2.4769, -2.5555, -2.8777, -2.5196,\n",
      "        -2.5246, -2.5782, -2.4463, -2.6295, -2.4705, -2.5705, -2.3898, -2.5190,\n",
      "        -2.7245, -2.6667, -2.3741, -2.3579, -2.6933, -2.7919, -2.5187, -2.8259,\n",
      "        -2.4024, -2.4679, -2.6974, -2.6609, -2.7053, -2.4699, -2.2830, -2.6681,\n",
      "        -2.5587, -2.3976, -2.6050, -2.7163, -2.5855, -2.9923, -2.6382, -2.5713,\n",
      "        -2.6972, -2.5687], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5953, -2.5853, -2.5869, -2.5882, -2.5864, -2.5441, -2.5459, -2.5361,\n",
      "        -2.5392, -2.5754, -2.5840, -2.5869, -2.5769, -2.5323, -2.5759, -2.5541,\n",
      "        -2.5806, -2.5902, -2.5832, -2.5965, -2.4788, -2.5871, -2.5821, -2.5882,\n",
      "        -2.5754, -2.5850, -2.5778, -2.5336, -2.5848, -2.5408, -2.5848, -2.5887,\n",
      "        -2.5737, -2.5259, -2.5855, -2.5864, -2.5867, -2.5772, -2.5881, -2.5346,\n",
      "        -2.5505, -2.5769, -2.5738, -2.5644, -2.4810, -2.5818, -2.5957, -2.5837,\n",
      "        -2.5872, -2.5842], device='mps:0')\n",
      "mean: tensor(-2.5698, device='mps:0')\n",
      "iter_dt 1.06s; iter 96: train loss 0.33068 temperature: 9.800000000000015\n",
      "mean_logits tensor([-2.2146, -2.5652, -2.7065, -2.3746, -2.3839, -2.6124, -2.6971, -2.5233,\n",
      "        -2.6901, -2.4659, -2.2569, -2.6774, -2.6417, -2.4281, -2.6704, -2.6631,\n",
      "        -2.6868, -2.4401, -2.5203, -2.3477, -2.5444, -2.6570, -2.4296, -2.3671,\n",
      "        -2.6328, -2.4985, -2.5607, -2.4825, -2.7061, -2.5986, -2.6821, -2.5707,\n",
      "        -2.6970, -2.5687, -2.6426, -2.5364, -2.4386, -2.5418, -2.6668, -2.3700,\n",
      "        -2.4810, -2.7099, -2.5880, -2.5943, -2.6284, -2.5052, -2.5111, -2.5635,\n",
      "        -2.5857, -2.4317], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5861, -2.5948, -2.5671, -2.5767, -2.5837, -2.5832, -2.5855, -2.5863,\n",
      "        -2.5867, -2.5344, -2.5808, -2.5431, -2.5861, -2.5426, -2.5826, -2.5014,\n",
      "        -2.5774, -2.5854, -2.5860, -2.5862, -2.5732, -2.5468, -2.5826, -2.5565,\n",
      "        -2.5861, -2.5557, -2.5866, -2.5735, -2.5314, -2.5847, -2.5228, -2.5852,\n",
      "        -2.5854, -2.5859, -2.5868, -2.5075, -2.5196, -2.5842, -2.5809, -2.5821,\n",
      "        -2.5251, -2.5834, -2.5860, -2.5759, -2.5863, -2.5813, -2.5218, -2.5253,\n",
      "        -2.5863, -2.5800], device='mps:0')\n",
      "mean: tensor(-2.5685, device='mps:0')\n",
      "iter_dt 1.06s; iter 97: train loss 0.68492 temperature: 9.850000000000016\n",
      "mean_logits tensor([-2.3717, -2.6153, -2.4855, -2.3603, -2.4843, -2.3458, -2.7874, -2.4566,\n",
      "        -2.6415, -2.8479, -2.8390, -2.2441, -2.6327, -2.4668, -2.8149, -2.3457,\n",
      "        -2.5718, -2.4156, -2.5286, -2.5776, -2.3666, -2.5541, -2.6903, -2.5214,\n",
      "        -2.6138, -2.8678, -2.2629, -2.5284, -2.4168, -2.3659, -2.5996, -2.7083,\n",
      "        -2.6890, -2.7879, -2.5136, -2.4480, -2.7701, -2.3119, -2.3370, -2.7566,\n",
      "        -2.5068, -2.8127, -2.7045, -2.2620, -2.5854, -2.6947, -2.4671, -2.2406,\n",
      "        -2.4563, -2.5349], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5811, -2.5751, -2.5254, -2.5852, -2.5285, -2.5761, -2.5834, -2.5759,\n",
      "        -2.5763, -2.5854, -2.5199, -2.5868, -2.5387, -2.5105, -2.5891, -2.5342,\n",
      "        -2.5864, -2.5854, -2.5564, -2.5940, -2.5790, -2.5847, -2.5826, -2.5706,\n",
      "        -2.5796, -2.5859, -2.5861, -2.5782, -2.5845, -2.5736, -2.5439, -2.5829,\n",
      "        -2.5814, -2.5836, -2.5383, -2.5327, -2.5808, -2.5726, -2.5732, -2.5828,\n",
      "        -2.5834, -2.5863, -2.5807, -2.5866, -2.5866, -2.5824, -2.5759, -2.5383,\n",
      "        -2.5622, -2.4888], device='mps:0')\n",
      "mean: tensor(-2.5688, device='mps:0')\n",
      "iter_dt 1.05s; iter 98: train loss 0.39759 temperature: 9.900000000000016\n",
      "mean_logits tensor([-2.5069, -2.7140, -2.6415, -2.5584, -2.4587, -2.5142, -2.5292, -2.5660,\n",
      "        -2.6472, -2.2777, -2.6870, -2.6011, -2.6144, -2.4867, -2.3481, -2.7224,\n",
      "        -2.5137, -2.5844, -2.4383, -2.6722, -2.3168, -2.6125, -2.6172, -2.5877,\n",
      "        -2.4745, -2.7910, -2.7195, -2.3457, -2.2861, -2.4999, -2.7424, -2.6601,\n",
      "        -2.6559, -2.5590, -2.3315, -2.3548, -2.6931, -2.5688, -2.2955, -2.5828,\n",
      "        -2.5085, -2.5813, -2.5445, -2.5761, -2.5220, -2.6724, -2.4692, -2.8830,\n",
      "        -2.4546, -2.6928], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5337, -2.5858, -2.5842, -2.5769, -2.5921, -2.5720, -2.5837, -2.5374,\n",
      "        -2.5800, -2.5283, -2.5390, -2.5964, -2.5338, -2.5947, -2.5857, -2.5825,\n",
      "        -2.5855, -2.5863, -2.5724, -2.5885, -2.5785, -2.5342, -2.5871, -2.5235,\n",
      "        -2.4818, -2.5822, -2.5765, -2.5776, -2.5850, -2.5155, -2.5856, -2.5814,\n",
      "        -2.5813, -2.5854, -2.5735, -2.5390, -2.5753, -2.5861, -2.5475, -2.5889,\n",
      "        -2.5862, -2.5782, -2.5829, -2.5825, -2.5422, -2.5858, -2.5770, -2.5771,\n",
      "        -2.5858, -2.5796], device='mps:0')\n",
      "mean: tensor(-2.5700, device='mps:0')\n",
      "iter_dt 1.07s; iter 99: train loss 0.40048 temperature: 9.950000000000017\n",
      "mean_logits tensor([-2.4856, -2.5536, -2.7207, -2.6955, -2.6292, -2.4606, -2.3508, -2.5103,\n",
      "        -2.7329, -2.7541, -2.8666, -2.4411, -2.4160, -2.6256, -2.5749, -2.5513,\n",
      "        -2.4777, -2.5811, -2.5001, -2.6177, -2.5016, -2.5711, -2.5862, -2.6811,\n",
      "        -2.5033, -2.7135, -2.8438, -2.4367, -2.2881, -2.7284, -2.2481, -2.6522,\n",
      "        -2.6233, -2.3009, -2.4564, -2.6814, -2.6406, -2.6161, -2.6275, -2.5813,\n",
      "        -2.7019, -2.5887, -2.5917, -2.6888, -2.5366, -2.5672, -2.5154, -2.5172,\n",
      "        -2.6406, -2.7298], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5858, -2.5955, -2.5284, -2.5831, -2.5833, -2.5955, -2.5859, -2.5748,\n",
      "        -2.5852, -2.5855, -2.5955, -2.5864, -2.5780, -2.5679, -2.5867, -2.5883,\n",
      "        -2.5235, -2.5402, -2.5734, -2.5852, -2.5862, -2.5763, -2.5380, -2.5773,\n",
      "        -2.5742, -2.5862, -2.5861, -2.5760, -2.5211, -2.5862, -2.5859, -2.5857,\n",
      "        -2.5855, -2.5974, -2.5868, -2.5776, -2.5853, -2.5837, -2.5747, -2.5236,\n",
      "        -2.5652, -2.5811, -2.5856, -2.5850, -2.5821, -2.5867, -2.5857, -2.5725,\n",
      "        -2.5551, -2.5254], device='mps:0')\n",
      "mean: tensor(-2.5749, device='mps:0')\n",
      "current_prefixes: [7278 4037 5557 4534 4632 6985  380 4805 4101 4404 4883  611  346 1045\n",
      " 2273 6235 5773 2879  256  465 6084 8286  375 5500  264  814   67 8921\n",
      "   67 4136 4385 6604  200 1773 2049]\n",
      "layer: 8 starts running\n",
      "number of parameters: 91.99M\n",
      "running on device mps\n",
      "iter_dt 0.00s; iter 0: train loss 4.44137 temperature: 5\n",
      "mean_logits tensor([-1.9321, -2.1966, -2.1787, -1.9937, -2.2404, -2.4160, -2.3520, -2.1020,\n",
      "        -2.0432, -2.1146, -2.1470, -2.1370, -1.8448, -1.9701, -1.5838, -2.0240,\n",
      "        -2.2032, -1.9021, -2.0621, -2.0662, -2.0617, -2.3993, -2.1504, -1.8299,\n",
      "        -2.1241, -2.0266, -1.9091, -2.4548, -1.4745, -1.7442, -1.6747, -1.4370,\n",
      "        -2.2221, -2.1354, -2.1862, -2.0871, -1.7869, -1.7206, -2.3776, -2.0445,\n",
      "        -1.4567, -2.1658, -2.2993, -1.9796, -2.4393, -1.8646, -2.1001, -1.9997,\n",
      "        -1.6878, -1.7418], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5395, -2.6091, -2.5953, -2.6080, -2.5984, -2.6037, -2.6067, -2.5614,\n",
      "        -2.6070, -2.6053, -2.6078, -2.6120, -2.5716, -2.4990, -2.6193, -2.5236,\n",
      "        -2.5913, -2.6063, -2.5903, -2.6036, -2.5382, -2.5310, -2.5735, -2.6074,\n",
      "        -2.5151, -2.5981, -2.5790, -2.5558, -2.6022, -2.5815, -2.6105, -2.5463,\n",
      "        -2.5833, -2.5649, -2.5877, -2.6278, -2.6071, -2.4826, -2.6075, -2.5967,\n",
      "        -2.5440, -2.5874, -2.5180, -2.6248, -2.5684, -2.6075, -2.5739, -2.5964,\n",
      "        -2.5521, -2.5354], device='mps:0')\n",
      "mean: tensor(-2.5793, device='mps:0')\n",
      "iter_dt 1695864520.79s; iter 1: train loss 4.86419 temperature: 5.05\n",
      "mean_logits tensor([-1.6431, -2.0855, -2.1538, -2.0878, -2.2245, -1.8355, -2.0904, -1.4773,\n",
      "        -2.1794, -1.8140, -2.2410, -1.9699, -2.4767, -1.9556, -1.4059, -2.0141,\n",
      "        -2.2905, -1.8279, -1.9701, -2.0310, -1.9376, -1.6712, -2.2123, -1.9712,\n",
      "        -1.7337, -2.1203, -1.8312, -2.0518, -2.0068, -2.3256, -1.6489, -1.9357,\n",
      "        -2.0873, -2.0430, -1.7357, -1.7950, -2.0872, -2.2386, -2.3220, -1.9895,\n",
      "        -1.7017, -2.5027, -1.8103, -1.7255, -2.2621, -2.2117, -2.0481, -1.5180,\n",
      "        -2.0477, -2.4220], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5380, -2.5708, -2.6113, -2.6020, -2.5443, -2.4871, -2.5974, -2.5630,\n",
      "        -2.6077, -2.6072, -2.6079, -2.5601, -2.5448, -2.6043, -2.5461, -2.5881,\n",
      "        -2.5984, -2.6016, -2.6061, -2.6013, -2.5992, -2.5954, -2.6079, -2.5369,\n",
      "        -2.6075, -2.5927, -2.6049, -2.5976, -2.5666, -2.6098, -2.5583, -2.6069,\n",
      "        -2.5893, -2.6065, -2.6078, -2.6083, -2.5338, -2.5987, -2.5651, -2.6085,\n",
      "        -2.6088, -2.6055, -2.6045, -2.6073, -2.5163, -2.5211, -2.5818, -2.6061,\n",
      "        -2.6029, -2.5949], device='mps:0')\n",
      "mean: tensor(-2.5848, device='mps:0')\n",
      "iter_dt 1.08s; iter 2: train loss 4.35503 temperature: 5.1\n",
      "mean_logits tensor([-2.0131, -1.9572, -1.7287, -2.3068, -2.2155, -1.8228, -2.0976, -2.1945,\n",
      "        -1.6901, -1.8670, -1.9521, -1.7302, -2.4362, -1.6730, -1.9970, -2.0776,\n",
      "        -1.8092, -2.5074, -2.0970, -1.6444, -2.0747, -1.8699, -2.1937, -1.9259,\n",
      "        -2.3115, -2.1255, -2.6684, -2.5790, -2.1914, -2.1439, -1.4568, -2.0086,\n",
      "        -2.0344, -2.1666, -1.8382, -2.1088, -2.2837, -2.0889, -2.1923, -1.8780,\n",
      "        -2.0831, -2.1626, -2.1006, -1.8825, -1.8653, -1.9291, -1.9636, -2.6963,\n",
      "        -1.9124, -1.9595], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5675, -2.5177, -2.6029, -2.5899, -2.6076, -2.5915, -2.5680, -2.6076,\n",
      "        -2.6086, -2.6063, -2.5826, -2.6006, -2.5807, -2.6018, -2.5588, -2.6042,\n",
      "        -2.5999, -2.6072, -2.6078, -2.5898, -2.6078, -2.5918, -2.6044, -2.6043,\n",
      "        -2.6103, -2.5514, -2.5895, -2.5447, -2.6000, -2.6021, -2.5117, -2.5463,\n",
      "        -2.5937, -2.6072, -2.5527, -2.5999, -2.5120, -2.5282, -2.5626, -2.6169,\n",
      "        -2.6083, -2.5976, -2.5107, -2.5804, -2.5708, -2.5653, -2.6163, -2.5344,\n",
      "        -2.6009, -2.5907], device='mps:0')\n",
      "mean: tensor(-2.5823, device='mps:0')\n",
      "iter_dt 1.08s; iter 3: train loss 4.65564 temperature: 5.1499999999999995\n",
      "mean_logits tensor([-2.1988, -2.0688, -2.1095, -2.0400, -1.8579, -1.8704, -2.2795, -1.5901,\n",
      "        -2.0609, -2.0570, -2.1043, -2.2246, -2.4877, -2.7691, -2.1664, -1.9939,\n",
      "        -1.6456, -1.9500, -1.6866, -1.8945, -2.0940, -1.9569, -2.0045, -2.2103,\n",
      "        -2.1911, -1.9973, -2.0749, -1.4647, -1.8307, -1.6996, -2.0924, -1.8067,\n",
      "        -2.0944, -2.0962, -2.1899, -1.9352, -2.0174, -2.3244, -2.2238, -1.9409,\n",
      "        -1.6948, -2.1181, -1.7412, -1.6487, -1.6990, -2.1321, -1.9237, -2.3181,\n",
      "        -2.1930, -1.8523], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6078, -2.6040, -2.5585, -2.5679, -2.6072, -2.6018, -2.5718, -2.6056,\n",
      "        -2.5998, -2.6102, -2.5524, -2.4834, -2.5851, -2.6061, -2.6075, -2.6074,\n",
      "        -2.6071, -2.6038, -2.5994, -2.5913, -2.5955, -2.5817, -2.5784, -2.5987,\n",
      "        -2.6077, -2.5401, -2.5618, -2.5616, -2.6083, -2.5353, -2.6127, -2.5979,\n",
      "        -2.6028, -2.5979, -2.5392, -2.4860, -2.5925, -2.5395, -2.6056, -2.5040,\n",
      "        -2.5976, -2.5892, -2.5049, -2.6041, -2.5948, -2.6076, -2.5468, -2.6105,\n",
      "        -2.5960, -2.6025], device='mps:0')\n",
      "mean: tensor(-2.5816, device='mps:0')\n",
      "iter_dt 1.08s; iter 4: train loss 3.83981 temperature: 5.199999999999999\n",
      "mean_logits tensor([-1.9831, -1.7999, -1.8041, -2.0980, -2.0975, -2.2707, -2.1890, -2.3589,\n",
      "        -1.7298, -2.2532, -2.0860, -1.5952, -2.3904, -2.0617, -2.3581, -2.2163,\n",
      "        -1.8559, -2.1844, -2.5066, -1.8886, -1.9376, -1.9005, -2.0534, -2.2260,\n",
      "        -1.9967, -2.0841, -2.4499, -2.2374, -2.3458, -2.1020, -2.2892, -1.9427,\n",
      "        -2.0582, -1.8080, -1.7807, -2.1014, -2.2576, -1.9492, -1.9245, -2.2328,\n",
      "        -1.9758, -1.9217, -2.4489, -2.0168, -1.6052, -1.7751, -2.2202, -2.3097,\n",
      "        -1.9925, -2.3422], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6008, -2.6005, -2.5494, -2.5958, -2.5147, -2.5414, -2.4906, -2.5478,\n",
      "        -2.6079, -2.5841, -2.6220, -2.5164, -2.6082, -2.6052, -2.6021, -2.6080,\n",
      "        -2.6083, -2.6079, -2.5883, -2.5449, -2.6106, -2.6035, -2.5455, -2.5939,\n",
      "        -2.5991, -2.5578, -2.6037, -2.5853, -2.6077, -2.4906, -2.6049, -2.6080,\n",
      "        -2.5864, -2.6022, -2.5765, -2.5669, -2.6070, -2.5542, -2.5680, -2.5860,\n",
      "        -2.6058, -2.6082, -2.5984, -2.6040, -2.4746, -2.6055, -2.6068, -2.5661,\n",
      "        -2.6117, -2.6117], device='mps:0')\n",
      "mean: tensor(-2.5819, device='mps:0')\n",
      "iter_dt 1.07s; iter 5: train loss 3.17060 temperature: 5.249999999999999\n",
      "mean_logits tensor([-2.2214, -2.2113, -2.4864, -2.1353, -2.2804, -2.3280, -2.5845, -2.0319,\n",
      "        -2.2627, -1.8173, -1.8315, -2.0551, -2.0769, -1.8477, -1.9532, -1.8217,\n",
      "        -2.2879, -1.7673, -2.3607, -2.2637, -1.8621, -1.8638, -2.0469, -2.5004,\n",
      "        -2.2361, -1.7774, -2.4507, -2.3573, -2.0804, -2.1699, -2.2313, -2.4216,\n",
      "        -2.3169, -2.5066, -2.1940, -2.3712, -2.1324, -2.0721, -1.5757, -1.8959,\n",
      "        -2.5503, -2.4188, -2.3010, -1.8393, -2.5014, -2.0511, -2.2971, -1.6762,\n",
      "        -1.9310, -2.4870], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5287, -2.6081, -2.6080, -2.5884, -2.5558, -2.4870, -2.6073, -2.5964,\n",
      "        -2.5351, -2.5567, -2.6024, -2.5850, -2.4723, -2.6071, -2.5948, -2.5354,\n",
      "        -2.6052, -2.5972, -2.5939, -2.6070, -2.5424, -2.5902, -2.6089, -2.5901,\n",
      "        -2.5553, -2.5936, -2.6053, -2.5386, -2.5859, -2.5864, -2.6084, -2.6083,\n",
      "        -2.5873, -2.5440, -2.6066, -2.6066, -2.6026, -2.6058, -2.5164, -2.5541,\n",
      "        -2.5376, -2.5834, -2.6077, -2.6126, -2.5815, -2.6058, -2.6081, -2.6036,\n",
      "        -2.5790, -2.6081], device='mps:0')\n",
      "mean: tensor(-2.5807, device='mps:0')\n",
      "iter_dt 1.05s; iter 6: train loss 3.87504 temperature: 5.299999999999999\n",
      "mean_logits tensor([-2.1586, -2.0885, -1.8936, -2.0149, -2.0266, -2.4369, -2.0429, -1.9220,\n",
      "        -2.2931, -2.0033, -2.1970, -2.0886, -2.2849, -2.0867, -2.1535, -1.9097,\n",
      "        -2.0906, -2.1306, -1.7846, -2.0913, -2.5130, -2.3528, -2.2320, -2.2575,\n",
      "        -1.9701, -2.0557, -1.8855, -2.2995, -2.0636, -1.9606, -2.1411, -1.4298,\n",
      "        -2.0414, -1.7488, -1.9433, -1.9426, -2.1626, -2.3848, -1.8349, -1.9408,\n",
      "        -1.9821, -2.1074, -2.0734, -2.1856, -1.8769, -2.4157, -1.9491, -1.9447,\n",
      "        -2.1135, -1.6989], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6080, -2.5988, -2.5987, -2.5471, -2.5631, -2.6122, -2.6081, -2.5196,\n",
      "        -2.5881, -2.6076, -2.5167, -2.5987, -2.6083, -2.5267, -2.4567, -2.6051,\n",
      "        -2.6016, -2.5571, -2.6037, -2.5296, -2.5945, -2.5914, -2.6072, -2.5401,\n",
      "        -2.6020, -2.5851, -2.5936, -2.6023, -2.5576, -2.6029, -2.5303, -2.4563,\n",
      "        -2.5571, -2.6079, -2.5849, -2.6066, -2.5361, -2.6077, -2.5990, -2.5314,\n",
      "        -2.6000, -2.5955, -2.5970, -2.6095, -2.5511, -2.5480, -2.5618, -2.5878,\n",
      "        -2.5420, -2.6076], device='mps:0')\n",
      "mean: tensor(-2.5750, device='mps:0')\n",
      "iter_dt 1.05s; iter 7: train loss 3.05177 temperature: 5.349999999999999\n",
      "mean_logits tensor([-2.5847, -2.1815, -1.7574, -2.1049, -1.9879, -2.2293, -2.2135, -2.2497,\n",
      "        -2.2074, -2.6108, -2.1209, -2.2153, -1.6183, -1.7132, -2.1935, -2.1579,\n",
      "        -2.3592, -1.5553, -1.9579, -2.3219, -2.1466, -2.0150, -2.5543, -2.2671,\n",
      "        -2.3620, -2.2818, -2.3780, -2.0302, -2.3622, -2.2116, -2.1797, -2.0851,\n",
      "        -2.3761, -2.4746, -1.9660, -1.6266, -2.3690, -1.9818, -1.6928, -2.2699,\n",
      "        -2.2617, -2.1777, -2.4152, -2.5123, -1.8025, -2.1928, -1.6669, -2.0901,\n",
      "        -2.1178, -2.3506], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5686, -2.5567, -2.6062, -2.5941, -2.6067, -2.5539, -2.6079, -2.6113,\n",
      "        -2.5773, -2.5523, -2.5368, -2.5437, -2.4616, -2.6154, -2.5853, -2.6077,\n",
      "        -2.5337, -2.5494, -2.6061, -2.6086, -2.5276, -2.5398, -2.5556, -2.5984,\n",
      "        -2.5593, -2.6058, -2.5488, -2.5801, -2.6049, -2.5767, -2.6070, -2.5273,\n",
      "        -2.5849, -2.6017, -2.5714, -2.5626, -2.6081, -2.5632, -2.3281, -2.6077,\n",
      "        -2.5943, -2.5928, -2.5909, -2.6070, -2.6043, -2.6066, -2.5996, -2.5842,\n",
      "        -2.6043, -2.6073], device='mps:0')\n",
      "mean: tensor(-2.5747, device='mps:0')\n",
      "iter_dt 1.07s; iter 8: train loss 2.76786 temperature: 5.399999999999999\n",
      "mean_logits tensor([-1.7319, -2.3221, -2.4164, -2.3109, -2.3049, -2.6419, -2.1565, -2.2400,\n",
      "        -2.0965, -2.2594, -2.3833, -2.4210, -2.6117, -2.2198, -2.2663, -1.7196,\n",
      "        -2.3959, -2.3886, -2.2065, -2.3001, -2.0491, -2.2227, -2.1019, -1.7186,\n",
      "        -2.0334, -2.1529, -2.0674, -2.0260, -1.8486, -2.2408, -2.2503, -2.3688,\n",
      "        -1.9487, -2.2380, -2.1336, -1.7184, -1.9492, -1.8684, -2.2339, -2.1920,\n",
      "        -2.2873, -2.4945, -2.0603, -2.4434, -2.0605, -2.3191, -2.0355, -2.0026,\n",
      "        -1.7434, -2.7950], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4672, -2.6079, -2.5985, -2.6094, -2.6013, -2.6093, -2.5526, -2.6037,\n",
      "        -2.5092, -2.5927, -2.6104, -2.6083, -2.5944, -2.5936, -2.5955, -2.6059,\n",
      "        -2.5948, -2.6074, -2.5367, -2.6087, -2.5861, -2.5965, -2.6080, -2.6070,\n",
      "        -2.5852, -2.5917, -2.6081, -2.5951, -2.5280, -2.5971, -2.5837, -2.5990,\n",
      "        -2.4974, -2.5059, -2.5365, -2.5803, -2.5460, -2.5588, -2.3493, -2.5880,\n",
      "        -2.5532, -2.5870, -2.5373, -2.5991, -2.6089, -2.6032, -2.5358, -2.5850,\n",
      "        -2.4976, -2.6072], device='mps:0')\n",
      "mean: tensor(-2.5734, device='mps:0')\n",
      "iter_dt 1.09s; iter 9: train loss 2.31412 temperature: 5.449999999999998\n",
      "mean_logits tensor([-2.1799, -1.9858, -2.4067, -2.4059, -2.2163, -2.4676, -1.9623, -2.4084,\n",
      "        -2.2120, -1.9551, -2.1090, -2.1434, -2.5207, -2.1278, -1.8661, -2.5156,\n",
      "        -2.1127, -2.3114, -2.6727, -2.2003, -2.6186, -1.7817, -1.8289, -2.2028,\n",
      "        -2.0429, -1.8021, -2.6823, -2.5077, -2.4484, -2.3128, -2.5112, -2.2292,\n",
      "        -2.2860, -2.2779, -2.3022, -1.9824, -1.7595, -2.1279, -2.5806, -2.8776,\n",
      "        -2.4088, -2.4411, -2.4264, -2.0770, -2.4105, -2.3428, -2.3101, -2.5072,\n",
      "        -2.5039, -2.0383], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5589, -2.5605, -2.5518, -2.5786, -2.5764, -2.6075, -2.5518, -2.5843,\n",
      "        -2.5497, -2.6084, -2.5440, -2.6079, -2.5788, -2.5483, -2.5814, -2.5232,\n",
      "        -2.4851, -2.6081, -2.6045, -2.6078, -2.5965, -2.6069, -2.5732, -2.6024,\n",
      "        -2.5981, -2.6056, -2.6063, -2.6116, -2.6077, -2.5953, -2.6074, -2.5976,\n",
      "        -2.6077, -2.5754, -2.5427, -2.6040, -2.5709, -2.6035, -2.5913, -2.5485,\n",
      "        -2.5981, -2.5980, -2.5923, -2.6064, -2.5425, -2.5866, -2.5674, -2.6078,\n",
      "        -2.6105, -2.6079], device='mps:0')\n",
      "mean: tensor(-2.5837, device='mps:0')\n",
      "iter_dt 1.06s; iter 10: train loss 2.36216 temperature: 5.499999999999998\n",
      "mean_logits tensor([-2.5295, -2.4327, -2.2366, -2.0282, -2.7866, -2.1120, -2.4764, -2.2206,\n",
      "        -2.1529, -2.1376, -2.3471, -2.4970, -2.0828, -1.8407, -2.1150, -2.4551,\n",
      "        -2.6357, -1.9127, -2.3639, -2.4377, -2.6950, -2.4989, -2.0665, -2.4672,\n",
      "        -2.1581, -2.9590, -2.3843, -2.2450, -2.8030, -2.6757, -1.9526, -2.7094,\n",
      "        -2.3227, -2.1577, -2.6439, -2.4506, -1.8744, -1.9908, -2.5744, -2.8147,\n",
      "        -1.4179, -1.9556, -2.4666, -2.4004, -1.8507, -1.8804, -2.3471, -2.6183,\n",
      "        -2.4268, -2.0449], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5688, -2.5694, -2.5418, -2.5372, -2.5491, -2.6070, -2.6072, -2.6070,\n",
      "        -2.5854, -2.6064, -2.6121, -2.6074, -2.5424, -2.5938, -2.5500, -2.5975,\n",
      "        -2.5508, -2.5839, -2.6068, -2.5470, -2.5804, -2.5283, -2.5541, -2.4996,\n",
      "        -2.5635, -2.5901, -2.5987, -2.5857, -2.5462, -2.6107, -2.6067, -2.6064,\n",
      "        -2.6019, -2.5911, -2.5716, -2.5486, -2.5973, -2.5916, -2.6076, -2.5983,\n",
      "        -2.6086, -2.5984, -2.6090, -2.6014, -2.5237, -2.6036, -2.5322, -2.5105,\n",
      "        -2.6074, -2.6080], device='mps:0')\n",
      "mean: tensor(-2.5790, device='mps:0')\n",
      "iter_dt 1.08s; iter 11: train loss 2.57947 temperature: 5.549999999999998\n",
      "mean_logits tensor([-2.1026, -2.0987, -2.1021, -2.3703, -2.6058, -2.1871, -2.1290, -2.1396,\n",
      "        -2.2641, -2.4858, -3.0056, -2.2871, -2.7158, -3.0659, -2.2967, -2.4584,\n",
      "        -2.6399, -2.3570, -2.3939, -1.6908, -2.8658, -2.7416, -2.4267, -1.9277,\n",
      "        -2.2765, -2.3117, -2.1393, -2.1356, -2.2311, -2.1199, -2.8502, -2.1248,\n",
      "        -2.4168, -2.4043, -3.1092, -2.5049, -2.0732, -2.1516, -2.9560, -2.2337,\n",
      "        -1.9159, -2.2198, -2.1313, -2.5617, -2.1071, -1.8897, -2.3938, -2.4680,\n",
      "        -2.1636, -2.4925], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5979, -2.6081, -2.5823, -2.6044, -2.5900, -2.5825, -2.5350, -2.5829,\n",
      "        -2.6024, -2.6051, -2.5987, -2.5465, -2.6069, -2.6076, -2.5829, -2.5573,\n",
      "        -2.5913, -2.5258, -2.6034, -2.6033, -2.6065, -2.6069, -2.5942, -2.5818,\n",
      "        -2.6068, -2.5880, -2.5623, -2.5619, -2.5945, -2.5833, -2.6129, -2.5956,\n",
      "        -2.6010, -2.5804, -2.5485, -2.6069, -2.6042, -2.5615, -2.6071, -2.5115,\n",
      "        -2.6057, -2.5553, -2.5450, -2.5435, -2.5349, -2.5876, -2.6066, -2.5940,\n",
      "        -2.5987, -2.6076], device='mps:0')\n",
      "mean: tensor(-2.5842, device='mps:0')\n",
      "iter_dt 1.06s; iter 12: train loss 1.41803 temperature: 5.599999999999998\n",
      "mean_logits tensor([-2.2596, -2.6337, -2.5047, -2.6988, -2.5343, -2.5149, -2.6195, -1.9897,\n",
      "        -2.1177, -2.1519, -2.4062, -2.5885, -2.6700, -2.7737, -2.6229, -2.9145,\n",
      "        -2.5436, -2.6744, -1.8855, -2.5061, -2.2566, -2.3459, -2.1355, -2.0700,\n",
      "        -2.4123, -1.9799, -2.6870, -2.7694, -2.6636, -2.6964, -2.7595, -2.6136,\n",
      "        -2.2768, -2.3426, -2.6187, -2.3473, -2.5273, -2.3165, -2.2010, -2.4284,\n",
      "        -2.5123, -2.4833, -2.5783, -2.0711, -2.8185, -1.9240, -2.6396, -2.1489,\n",
      "        -2.4458, -2.2938], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6023, -2.5996, -2.5532, -2.5551, -2.6071, -2.6078, -2.6058, -2.5484,\n",
      "        -2.6081, -2.6086, -2.5966, -2.6083, -2.5687, -2.5355, -2.5979, -2.5975,\n",
      "        -2.6060, -2.6034, -2.6049, -2.5425, -2.5902, -2.5675, -2.6062, -2.6107,\n",
      "        -2.6050, -2.6066, -2.5995, -2.5849, -2.5614, -2.6050, -2.5515, -2.5880,\n",
      "        -2.5985, -2.5841, -2.6086, -2.6037, -2.5585, -2.5323, -2.5448, -2.5082,\n",
      "        -2.6049, -2.5996, -2.5927, -2.6057, -2.6045, -2.5896, -2.6125, -2.6073,\n",
      "        -2.5716, -2.5975], device='mps:0')\n",
      "mean: tensor(-2.5872, device='mps:0')\n",
      "iter_dt 1.06s; iter 13: train loss 1.47964 temperature: 5.649999999999998\n",
      "mean_logits tensor([-2.7928, -2.2227, -2.6585, -2.6935, -2.6530, -2.5840, -2.6206, -2.2428,\n",
      "        -2.7720, -2.9047, -2.6518, -2.5465, -2.4717, -2.7980, -2.1289, -2.2813,\n",
      "        -2.7954, -2.0294, -2.3818, -2.4104, -2.0113, -2.5242, -2.4998, -2.6646,\n",
      "        -2.9914, -2.2352, -2.8390, -2.9512, -2.5057, -2.3567, -2.2120, -2.1177,\n",
      "        -2.0636, -2.3293, -2.7091, -2.5022, -2.5202, -2.6249, -2.7465, -1.8977,\n",
      "        -2.4955, -2.6060, -2.6653, -2.7530, -2.7943, -3.0477, -2.1375, -2.3976,\n",
      "        -2.5385, -2.8074], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6073, -2.6079, -2.6013, -2.5985, -2.6073, -2.5451, -2.5294, -2.5950,\n",
      "        -2.6080, -2.6038, -2.5957, -2.5954, -2.4986, -2.6074, -2.5985, -2.6058,\n",
      "        -2.6081, -2.6004, -2.5036, -2.5518, -2.5274, -2.6077, -2.5739, -2.5325,\n",
      "        -2.5360, -2.5981, -2.5859, -2.6048, -2.6072, -2.6080, -2.6094, -2.5723,\n",
      "        -2.5587, -2.4880, -2.6089, -2.6047, -2.5881, -2.6042, -2.6079, -2.5416,\n",
      "        -2.6116, -2.6064, -2.5803, -2.5838, -2.6107, -2.6080, -2.4870, -2.5622,\n",
      "        -2.6075, -2.5772], device='mps:0')\n",
      "mean: tensor(-2.5814, device='mps:0')\n",
      "iter_dt 1.06s; iter 14: train loss 2.22759 temperature: 5.6999999999999975\n",
      "mean_logits tensor([-2.7018, -2.1478, -2.2188, -2.9071, -2.5867, -2.2047, -2.9080, -2.5834,\n",
      "        -2.9729, -2.6603, -3.0551, -2.5548, -2.2411, -2.2464, -2.3212, -1.9220,\n",
      "        -2.6259, -2.0392, -2.6806, -2.1424, -2.5489, -2.7710, -2.9128, -2.3474,\n",
      "        -2.4614, -2.7324, -3.1981, -2.3941, -2.6311, -2.6284, -2.3268, -2.5984,\n",
      "        -2.4391, -2.3416, -3.0425, -2.7072, -2.4825, -2.5427, -2.5075, -2.7454,\n",
      "        -2.6639, -2.3440, -2.6329, -2.4213, -2.9622, -2.4883, -2.0850, -1.9799,\n",
      "        -2.1479, -3.0701], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6075, -2.5868, -2.6072, -2.5989, -2.5488, -2.5983, -2.6069, -2.5780,\n",
      "        -2.5843, -2.5249, -2.5560, -2.5848, -2.5927, -2.5544, -2.6069, -2.5974,\n",
      "        -2.6054, -2.5992, -2.5980, -2.5899, -2.5026, -2.6042, -2.5848, -2.6067,\n",
      "        -2.5868, -2.6076, -2.6120, -2.6073, -2.5551, -2.6079, -2.6050, -2.5929,\n",
      "        -2.6038, -2.5264, -2.5893, -2.6079, -2.5985, -2.5939, -2.6071, -2.6079,\n",
      "        -2.6086, -2.6076, -2.5960, -2.5855, -2.5864, -2.6033, -2.6073, -2.5259,\n",
      "        -2.5512, -2.5796], device='mps:0')\n",
      "mean: tensor(-2.5877, device='mps:0')\n",
      "iter_dt 1.06s; iter 15: train loss 1.74836 temperature: 5.749999999999997\n",
      "mean_logits tensor([-2.2144, -2.7594, -2.5848, -2.5680, -2.4357, -2.0101, -2.5801, -2.1617,\n",
      "        -2.7023, -2.1156, -2.8285, -2.9393, -2.2370, -1.8497, -2.2365, -2.2129,\n",
      "        -2.6906, -2.8264, -2.1789, -2.5427, -2.7078, -2.5831, -2.4063, -2.1217,\n",
      "        -2.0136, -2.4962, -1.9562, -2.8834, -2.6904, -2.1916, -2.7628, -2.4748,\n",
      "        -2.3778, -2.4661, -2.4271, -2.4714, -2.0933, -2.6957, -2.6737, -2.1655,\n",
      "        -2.7092, -2.3265, -2.6887, -1.9244, -2.4144, -2.1648, -2.2640, -2.0994,\n",
      "        -2.5723, -2.2908], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5466, -2.5536, -2.6077, -2.5263, -2.5831, -2.6036, -2.6069, -2.5801,\n",
      "        -2.6073, -2.5776, -2.6136, -2.6097, -2.5362, -2.5443, -2.5889, -2.5470,\n",
      "        -2.6076, -2.5973, -2.5662, -2.5894, -2.4759, -2.5925, -2.5862, -2.6044,\n",
      "        -2.5982, -2.5963, -2.5935, -2.5393, -2.5698, -2.6084, -2.6067, -2.6135,\n",
      "        -2.5937, -2.6016, -2.6046, -2.6039, -2.6038, -2.5836, -2.5497, -2.5974,\n",
      "        -2.5380, -2.6073, -2.5832, -2.5959, -2.6067, -2.5911, -2.5462, -2.5852,\n",
      "        -2.5871, -2.5843], device='mps:0')\n",
      "mean: tensor(-2.5828, device='mps:0')\n",
      "iter_dt 1.08s; iter 16: train loss 1.50073 temperature: 5.799999999999997\n",
      "mean_logits tensor([-2.3374, -2.1691, -2.6166, -2.2465, -2.7270, -2.5012, -2.7319, -1.9329,\n",
      "        -2.3386, -2.2420, -2.6081, -2.4140, -2.9254, -2.4427, -2.2270, -2.7545,\n",
      "        -2.7987, -2.4287, -2.6534, -3.0908, -2.3605, -2.4307, -2.3553, -2.5611,\n",
      "        -2.3392, -2.7394, -2.7577, -2.3728, -2.2662, -2.5973, -2.8401, -2.7298,\n",
      "        -2.3979, -2.4631, -2.3304, -2.3817, -2.1452, -2.9026, -2.3848, -2.2507,\n",
      "        -2.5200, -2.0829, -2.2244, -2.4709, -2.4229, -2.3599, -2.5188, -2.1157,\n",
      "        -2.7394, -2.9104], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5713, -2.6052, -2.6085, -2.5431, -2.6079, -2.6071, -2.5707, -2.6067,\n",
      "        -2.5824, -2.4888, -2.6004, -2.5831, -2.5756, -2.6081, -2.5347, -2.6079,\n",
      "        -2.5498, -2.5688, -2.5840, -2.6076, -2.5921, -2.5994, -2.5540, -2.5838,\n",
      "        -2.5853, -2.6080, -2.5411, -2.5993, -2.5683, -2.6024, -2.5992, -2.5395,\n",
      "        -2.6056, -2.5483, -2.6284, -2.5983, -2.6106, -2.5301, -2.5865, -2.5900,\n",
      "        -2.5844, -2.6249, -2.6052, -2.5440, -2.4581, -2.5796, -2.6082, -2.5985,\n",
      "        -2.5507, -2.6101], device='mps:0')\n",
      "mean: tensor(-2.5809, device='mps:0')\n",
      "iter_dt 1.06s; iter 17: train loss 2.15189 temperature: 5.849999999999997\n",
      "mean_logits tensor([-2.9844, -2.7378, -2.0997, -2.7462, -2.6494, -2.9264, -2.6874, -2.5676,\n",
      "        -2.5611, -2.2299, -2.4207, -2.3909, -2.7049, -2.7506, -2.2795, -1.7769,\n",
      "        -2.6226, -2.3550, -3.0659, -2.3961, -2.8674, -2.5929, -2.7079, -2.5916,\n",
      "        -2.4964, -2.5640, -2.9198, -2.1442, -2.0356, -2.2679, -2.2606, -3.0242,\n",
      "        -2.5294, -1.8187, -2.6960, -2.5879, -2.2069, -2.2938, -2.6253, -1.9175,\n",
      "        -1.7092, -2.8200, -2.4566, -2.7542, -2.5408, -2.8389, -2.1617, -2.6311,\n",
      "        -2.0077, -1.9102], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6054, -2.6075, -2.6085, -2.5451, -2.6053, -2.5850, -2.6080, -2.5512,\n",
      "        -2.6080, -2.5408, -2.5287, -2.5903, -2.6027, -2.5362, -2.5898, -2.6007,\n",
      "        -2.6064, -2.5880, -2.5713, -2.5763, -2.5504, -2.6080, -2.6072, -2.5982,\n",
      "        -2.5394, -2.5863, -2.6001, -2.6055, -2.5939, -2.5988, -2.5885, -2.5248,\n",
      "        -2.5852, -2.6064, -2.6123, -2.6014, -2.5907, -2.5255, -2.5983, -2.5264,\n",
      "        -2.6042, -2.6067, -2.6084, -2.5979, -2.5375, -2.6075, -2.5797, -2.6081,\n",
      "        -2.6050, -2.5187], device='mps:0')\n",
      "mean: tensor(-2.5835, device='mps:0')\n",
      "iter_dt 1.06s; iter 18: train loss 1.37880 temperature: 5.899999999999997\n",
      "mean_logits tensor([-2.3561, -2.6878, -2.4998, -2.3707, -2.4151, -2.7625, -2.5686, -2.5418,\n",
      "        -2.3761, -2.2071, -2.7019, -2.5312, -2.4333, -2.6809, -3.1820, -2.4502,\n",
      "        -2.4276, -2.5484, -2.2477, -2.6233, -2.6520, -2.5014, -2.1407, -2.5126,\n",
      "        -3.0415, -2.5721, -2.5998, -2.3384, -2.6169, -2.6316, -2.7442, -2.4669,\n",
      "        -2.4411, -2.2826, -2.9153, -2.0781, -2.6154, -2.5348, -2.3084, -2.3727,\n",
      "        -2.5820, -2.9922, -2.2301, -2.3417, -2.5049, -2.6835, -2.3485, -2.3400,\n",
      "        -2.8087, -2.4074], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5704, -2.6012, -2.5844, -2.5390, -2.6074, -2.5760, -2.5506, -2.6091,\n",
      "        -2.6042, -2.5980, -2.6043, -2.5819, -2.5894, -2.6079, -2.5388, -2.5360,\n",
      "        -2.5786, -2.6173, -2.6078, -2.5983, -2.6059, -2.5137, -2.5841, -2.5864,\n",
      "        -2.5986, -2.5585, -2.5874, -2.5990, -2.5981, -2.5693, -2.5673, -2.5859,\n",
      "        -2.6078, -2.6029, -2.5840, -2.5287, -2.6072, -2.5672, -2.6067, -2.6079,\n",
      "        -2.5951, -2.5862, -2.5943, -2.5375, -2.6018, -2.5979, -2.6081, -2.6115,\n",
      "        -2.5334, -2.6075], device='mps:0')\n",
      "mean: tensor(-2.5848, device='mps:0')\n",
      "iter_dt 1.05s; iter 19: train loss 1.51306 temperature: 5.949999999999997\n",
      "mean_logits tensor([-2.5088, -2.3592, -2.2794, -2.2509, -2.6212, -2.1144, -2.5567, -2.3763,\n",
      "        -2.4225, -2.0318, -2.7097, -2.3815, -2.3462, -2.4832, -2.8615, -1.9498,\n",
      "        -2.6310, -2.5821, -2.5283, -2.2999, -1.9390, -2.5448, -2.4546, -3.0087,\n",
      "        -2.6963, -2.5992, -2.4263, -2.5947, -2.6210, -2.2606, -2.5818, -2.0649,\n",
      "        -2.2313, -2.5480, -2.5949, -2.5298, -2.0771, -2.5149, -2.4278, -2.6841,\n",
      "        -2.6382, -2.2920, -2.9616, -2.7811, -1.9228, -2.3094, -2.2973, -2.4174,\n",
      "        -2.0940, -2.4125], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5346, -2.5987, -2.5911, -2.5854, -2.6078, -2.5446, -2.6001, -2.5987,\n",
      "        -2.6108, -2.5876, -2.5443, -2.5997, -2.5949, -2.6080, -2.5988, -2.6247,\n",
      "        -2.6061, -2.5352, -2.5410, -2.6088, -2.6061, -2.5950, -2.6040, -2.5848,\n",
      "        -2.5596, -2.5586, -2.5846, -2.5732, -2.5673, -2.5885, -2.5828, -2.6129,\n",
      "        -2.5009, -2.5815, -2.5841, -2.5716, -2.5893, -2.6038, -2.5975, -2.6040,\n",
      "        -2.6058, -2.6023, -2.6074, -2.5679, -2.6187, -2.5973, -2.5700, -2.6027,\n",
      "        -2.5995, -2.6043], device='mps:0')\n",
      "mean: tensor(-2.5869, device='mps:0')\n",
      "iter_dt 1.07s; iter 20: train loss 1.18751 temperature: 5.9999999999999964\n",
      "mean_logits tensor([-2.4767, -2.1381, -2.2911, -2.4604, -2.4179, -1.9727, -2.7042, -2.2584,\n",
      "        -2.5469, -2.2076, -2.6365, -2.1939, -2.2376, -2.1922, -2.2153, -2.5632,\n",
      "        -2.2470, -2.5569, -2.4951, -2.7759, -2.1556, -2.3570, -2.6955, -2.1876,\n",
      "        -2.1169, -2.2537, -2.7291, -2.3807, -2.6912, -2.3277, -2.6521, -2.1925,\n",
      "        -2.2939, -2.2898, -2.4926, -2.5815, -2.4391, -2.5323, -2.3250, -2.6123,\n",
      "        -2.3757, -2.3586, -2.2951, -2.3703, -2.4010, -2.7338, -2.1621, -2.5251,\n",
      "        -2.2417, -2.7853], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5683, -2.5942, -2.5888, -2.5853, -2.6077, -2.5469, -2.6082, -2.5471,\n",
      "        -2.5288, -2.5977, -2.5988, -2.5742, -2.4553, -2.6079, -2.5650, -2.5887,\n",
      "        -2.5298, -2.5719, -2.6039, -2.6070, -2.5573, -2.5535, -2.5754, -2.5814,\n",
      "        -2.5915, -2.6116, -2.6052, -2.5914, -2.5919, -2.5493, -2.5700, -2.5808,\n",
      "        -2.6082, -2.6082, -2.5874, -2.5993, -2.5971, -2.5700, -2.5685, -2.6002,\n",
      "        -2.5878, -2.5783, -2.5876, -2.6011, -2.5975, -2.5460, -2.5982, -2.5780,\n",
      "        -2.5861, -2.6068], device='mps:0')\n",
      "mean: tensor(-2.5808, device='mps:0')\n",
      "iter_dt 1.07s; iter 21: train loss 1.50234 temperature: 6.049999999999996\n",
      "mean_logits tensor([-2.3999, -2.4930, -2.1164, -2.6079, -2.5720, -2.1209, -2.2594, -2.2697,\n",
      "        -2.6045, -1.9665, -2.5655, -2.1500, -2.7105, -2.3557, -2.6404, -2.2955,\n",
      "        -2.4414, -2.1210, -2.6455, -2.6920, -2.2124, -2.1874, -2.1468, -1.9311,\n",
      "        -2.3781, -2.4389, -2.2047, -2.5948, -2.4038, -2.3985, -2.5941, -2.2766,\n",
      "        -2.8445, -2.0938, -2.3715, -2.1106, -2.1560, -2.9369, -2.8078, -2.7165,\n",
      "        -2.3512, -2.0474, -2.5927, -2.6645, -2.6657, -2.6144, -2.1944, -2.4208,\n",
      "        -2.1826, -2.4818], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5657, -2.6074, -2.5346, -2.6081, -2.5971, -2.5514, -2.5983, -2.5851,\n",
      "        -2.6009, -2.5985, -2.5993, -2.6021, -2.5848, -2.5982, -2.5963, -2.5053,\n",
      "        -2.5844, -2.6029, -2.5894, -2.5908, -2.5388, -2.5116, -2.5831, -2.5422,\n",
      "        -2.5988, -2.5962, -2.6037, -2.6081, -2.5682, -2.6016, -2.6077, -2.6060,\n",
      "        -2.5890, -2.6038, -2.5707, -2.6068, -2.6068, -2.6040, -2.5747, -2.5906,\n",
      "        -2.5914, -2.6077, -2.6087, -2.5464, -2.6083, -2.5875, -2.6076, -2.6081,\n",
      "        -2.5523, -2.5386], device='mps:0')\n",
      "mean: tensor(-2.5854, device='mps:0')\n",
      "iter_dt 1.12s; iter 22: train loss 1.34253 temperature: 6.099999999999996\n",
      "mean_logits tensor([-2.6323, -2.6640, -2.1791, -2.6019, -2.6102, -2.5518, -2.5654, -2.0940,\n",
      "        -2.6451, -2.5470, -2.1423, -2.5416, -2.5991, -2.4112, -2.2081, -3.1857,\n",
      "        -2.3205, -2.4669, -2.2438, -2.6501, -2.0618, -2.3668, -2.4683, -2.3136,\n",
      "        -2.0178, -2.2722, -2.3334, -2.5660, -2.7069, -2.5539, -2.2363, -2.6574,\n",
      "        -2.2866, -2.3355, -2.5410, -2.3919, -2.6232, -2.6874, -2.4586, -2.2333,\n",
      "        -2.6149, -2.2613, -2.0615, -2.6458, -2.4165, -2.5188, -2.7144, -2.1530,\n",
      "        -2.7147, -2.4129], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5947, -2.5539, -2.5942, -2.5280, -2.6069, -2.6028, -2.5391, -2.5965,\n",
      "        -2.5393, -2.6053, -2.5986, -2.6078, -2.5987, -2.5688, -2.5919, -2.5983,\n",
      "        -2.5840, -2.5978, -2.5343, -2.6072, -2.5762, -2.5072, -2.6073, -2.5632,\n",
      "        -2.6104, -2.5985, -2.5347, -2.5509, -2.5509, -2.5379, -2.5967, -2.5971,\n",
      "        -2.5944, -2.6083, -2.5738, -2.5861, -2.5922, -2.5986, -2.6061, -2.6083,\n",
      "        -2.6007, -2.6057, -2.5954, -2.5485, -2.6119, -2.5729, -2.5580, -2.5404,\n",
      "        -2.6095, -2.6080], device='mps:0')\n",
      "mean: tensor(-2.5820, device='mps:0')\n",
      "iter_dt 1.16s; iter 23: train loss 1.15106 temperature: 6.149999999999996\n",
      "mean_logits tensor([-2.4026, -2.5911, -2.4849, -2.8849, -2.7281, -2.0229, -2.5187, -2.5840,\n",
      "        -2.1656, -2.3883, -2.6555, -2.3774, -2.2479, -1.8383, -2.4071, -2.5635,\n",
      "        -2.3191, -2.5063, -2.1084, -2.2992, -2.5067, -2.6708, -2.3661, -2.4472,\n",
      "        -2.4777, -2.7163, -2.3076, -2.4854, -2.7111, -2.2583, -2.7639, -2.6084,\n",
      "        -2.4922, -2.1877, -2.4143, -2.5189, -2.3034, -2.1693, -2.0746, -2.0713,\n",
      "        -2.5926, -2.7437, -2.4882, -2.0338, -2.2916, -2.4499, -2.4888, -2.2380,\n",
      "        -2.5588, -2.3022], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5157, -2.5837, -2.6075, -2.5982, -2.5976, -2.5874, -2.5390, -2.5902,\n",
      "        -2.6078, -2.5981, -2.6032, -2.5977, -2.6059, -2.4643, -2.6081, -2.5736,\n",
      "        -2.5789, -2.6044, -2.5759, -2.5666, -2.6079, -2.5427, -2.5407, -2.5858,\n",
      "        -2.5600, -2.6081, -2.5539, -2.5671, -2.5969, -2.6091, -2.5715, -2.5507,\n",
      "        -2.6087, -2.5372, -2.5770, -2.6064, -2.6082, -2.5939, -2.5443, -2.5624,\n",
      "        -2.4619, -2.6069, -2.4695, -2.6126, -2.5967, -2.5009, -2.5404, -2.5274,\n",
      "        -2.5418, -2.5740], device='mps:0')\n",
      "mean: tensor(-2.5714, device='mps:0')\n",
      "iter_dt 1.09s; iter 24: train loss 1.21387 temperature: 6.199999999999996\n",
      "mean_logits tensor([-2.3704, -2.5081, -2.2169, -2.3137, -2.8905, -2.0044, -2.3575, -2.6178,\n",
      "        -2.3883, -2.6225, -2.4783, -2.4440, -2.3334, -2.6578, -2.5405, -2.4246,\n",
      "        -2.1433, -2.2205, -2.2684, -2.2182, -2.2075, -2.5231, -2.6040, -2.5042,\n",
      "        -2.4139, -2.5706, -2.3184, -2.4340, -2.3683, -2.7331, -2.3717, -2.4401,\n",
      "        -2.4447, -2.2671, -2.2871, -2.4002, -2.2595, -2.4354, -2.0424, -2.0614,\n",
      "        -2.8676, -2.5642, -2.0250, -2.1868, -2.7348, -2.4085, -2.6879, -2.5827,\n",
      "        -2.3838, -2.6624], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6069, -2.6091, -2.5751, -2.6037, -2.6078, -2.5467, -2.5477, -2.6072,\n",
      "        -2.6047, -2.5892, -2.5880, -2.5841, -2.5209, -2.4769, -2.5752, -2.6086,\n",
      "        -2.5952, -2.5982, -2.5982, -2.6087, -2.5808, -2.5958, -2.6078, -2.5901,\n",
      "        -2.5890, -2.5975, -2.5527, -2.6028, -2.6086, -2.5187, -2.6053, -2.4968,\n",
      "        -2.5791, -2.5128, -2.5987, -2.5891, -2.5931, -2.6070, -2.6076, -2.5626,\n",
      "        -2.6070, -2.5668, -2.5958, -2.5475, -2.5454, -2.6043, -2.5712, -2.6057,\n",
      "        -2.5792, -2.5993], device='mps:0')\n",
      "mean: tensor(-2.5814, device='mps:0')\n",
      "iter_dt 1.06s; iter 25: train loss 1.28416 temperature: 6.249999999999996\n",
      "mean_logits tensor([-2.4973, -2.4282, -2.5463, -2.5063, -2.0997, -2.4696, -2.8743, -2.6484,\n",
      "        -2.7966, -2.5205, -2.6164, -2.0600, -2.3758, -2.2407, -2.7354, -2.4112,\n",
      "        -2.4090, -2.2339, -2.2744, -2.0706, -2.4314, -2.5432, -2.2768, -2.4704,\n",
      "        -2.4592, -2.4692, -2.7274, -2.8174, -2.3098, -2.8458, -2.6541, -2.1685,\n",
      "        -2.0858, -2.3684, -2.2848, -2.4841, -2.6666, -2.3816, -2.6432, -2.6189,\n",
      "        -2.0487, -2.0807, -2.4020, -2.3961, -2.4061, -2.6335, -2.3000, -1.9934,\n",
      "        -2.1930, -2.3054], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5979, -2.6071, -2.5677, -2.5934, -2.5315, -2.5861, -2.5725, -2.5857,\n",
      "        -2.5989, -2.5377, -2.6073, -2.5900, -2.6086, -2.6076, -2.5870, -2.5368,\n",
      "        -2.6075, -2.6106, -2.6061, -2.6078, -2.5603, -2.6114, -2.5956, -2.5979,\n",
      "        -2.5924, -2.6043, -2.5962, -2.6081, -2.5304, -2.6047, -2.6111, -2.5761,\n",
      "        -2.5167, -2.5717, -2.5510, -2.6067, -2.5409, -2.5881, -2.5990, -2.5380,\n",
      "        -2.5848, -2.5932, -2.6027, -2.6065, -2.6085, -2.6085, -2.5822, -2.6078,\n",
      "        -2.5992, -2.5726], device='mps:0')\n",
      "mean: tensor(-2.5863, device='mps:0')\n",
      "iter_dt 1.06s; iter 26: train loss 1.15043 temperature: 6.299999999999995\n",
      "mean_logits tensor([-2.5709, -2.2603, -2.9264, -2.1334, -2.6688, -2.6137, -2.7369, -2.5903,\n",
      "        -2.4809, -2.4997, -2.3766, -2.2876, -2.1108, -2.4463, -2.3875, -2.5131,\n",
      "        -2.4379, -2.3630, -2.2146, -2.6153, -2.6466, -2.3707, -2.4999, -2.7153,\n",
      "        -2.5387, -2.3760, -2.5837, -2.5963, -2.5794, -2.2043, -2.1388, -2.0462,\n",
      "        -2.1632, -2.5813, -2.6199, -2.4982, -2.3483, -2.4975, -2.2720, -2.7644,\n",
      "        -2.1682, -2.0781, -2.7427, -2.1473, -2.2325, -2.1494, -2.0313, -2.4897,\n",
      "        -2.5115, -2.6328], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5851, -2.5361, -2.5981, -2.6098, -2.6084, -2.6079, -2.6053, -2.6010,\n",
      "        -2.6058, -2.5454, -2.5788, -2.6076, -2.5964, -2.6081, -2.5693, -2.5234,\n",
      "        -2.5264, -2.5828, -2.6296, -2.5259, -2.6070, -2.5928, -2.6083, -2.6083,\n",
      "        -2.6083, -2.5914, -2.6038, -2.4917, -2.5435, -2.5408, -2.5324, -2.5699,\n",
      "        -2.5768, -2.4856, -2.5505, -2.5930, -2.5967, -2.5613, -2.5381, -2.5873,\n",
      "        -2.5494, -2.5569, -2.5788, -2.6038, -2.5876, -2.6072, -2.5487, -2.5774,\n",
      "        -2.5893, -2.6077], device='mps:0')\n",
      "mean: tensor(-2.5769, device='mps:0')\n",
      "iter_dt 1.08s; iter 27: train loss 1.16180 temperature: 6.349999999999995\n",
      "mean_logits tensor([-2.7581, -2.4650, -2.8928, -2.5968, -2.5976, -2.4897, -2.3824, -2.3727,\n",
      "        -2.6341, -2.0052, -2.5222, -2.4791, -2.4108, -2.5712, -2.3875, -2.5027,\n",
      "        -2.3963, -2.5337, -2.4204, -2.6832, -2.4209, -2.5321, -2.5204, -2.9418,\n",
      "        -2.5265, -2.7272, -2.6367, -2.3285, -2.3159, -2.3611, -2.0429, -2.5668,\n",
      "        -2.8954, -2.2070, -2.4988, -2.5015, -2.6110, -2.0850, -2.5723, -2.8867,\n",
      "        -2.4935, -2.1310, -2.4348, -2.3057, -2.3282, -2.1156, -2.2385, -2.8252,\n",
      "        -2.4434, -2.0620], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6067, -2.5731, -2.5781, -2.5980, -2.6082, -2.6076, -2.6005, -2.5879,\n",
      "        -2.5876, -2.6065, -2.5555, -2.5883, -2.5881, -2.5977, -2.6015, -2.5540,\n",
      "        -2.5874, -2.5835, -2.5987, -2.5820, -2.5992, -2.6071, -2.4859, -2.6079,\n",
      "        -2.5979, -2.5354, -2.6022, -2.6040, -2.5843, -2.5931, -2.6082, -2.6036,\n",
      "        -2.5877, -2.5271, -2.6023, -2.6078, -2.5539, -2.5074, -2.5951, -2.5266,\n",
      "        -2.5987, -2.5357, -2.5480, -2.5997, -2.5924, -2.6056, -2.5516, -2.6053,\n",
      "        -2.5861, -2.5912], device='mps:0')\n",
      "mean: tensor(-2.5828, device='mps:0')\n",
      "iter_dt 1.07s; iter 28: train loss 1.16265 temperature: 6.399999999999995\n",
      "mean_logits tensor([-2.3490, -2.7051, -2.2921, -2.4491, -2.7512, -2.1678, -2.3272, -2.5741,\n",
      "        -2.4048, -2.5428, -2.1569, -2.8839, -3.0627, -2.5246, -2.2458, -2.1256,\n",
      "        -2.5219, -2.5138, -1.9656, -2.6972, -2.7568, -2.6280, -2.5513, -2.7893,\n",
      "        -2.8611, -2.3684, -2.1509, -2.4533, -2.7211, -2.1787, -2.6422, -2.7751,\n",
      "        -2.5168, -2.5104, -2.3401, -2.6670, -2.5174, -2.6582, -2.0907, -2.5193,\n",
      "        -2.3064, -2.3407, -2.2686, -2.6835, -2.1933, -2.4201, -2.4467, -2.4831,\n",
      "        -2.1219, -2.5970], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5845, -2.5994, -2.6027, -2.6078, -2.5746, -2.5908, -2.5548, -2.5998,\n",
      "        -2.5302, -2.5683, -2.4961, -2.6056, -2.6079, -2.6075, -2.6041, -2.5964,\n",
      "        -2.5708, -2.5456, -2.5475, -2.6021, -2.5714, -2.5860, -2.6085, -2.5632,\n",
      "        -2.6076, -2.5765, -2.5819, -2.5850, -2.6093, -2.5241, -2.5987, -2.5456,\n",
      "        -2.6079, -2.5720, -2.5593, -2.5756, -2.5322, -2.6067, -2.5510, -2.5903,\n",
      "        -2.5582, -2.5849, -2.5325, -2.5829, -2.5582, -2.5918, -2.6009, -2.5803,\n",
      "        -2.5410, -2.5851], device='mps:0')\n",
      "mean: tensor(-2.5773, device='mps:0')\n",
      "iter_dt 1.25s; iter 29: train loss 1.02804 temperature: 6.449999999999995\n",
      "mean_logits tensor([-2.4523, -2.2541, -2.4899, -2.3128, -2.6315, -2.5313, -2.1079, -2.2253,\n",
      "        -2.3996, -2.3188, -2.2030, -2.1464, -2.0037, -2.3377, -2.5786, -2.4459,\n",
      "        -2.5515, -2.4269, -2.6449, -2.4696, -2.3514, -2.2917, -2.5396, -2.4988,\n",
      "        -2.5395, -2.6551, -2.9959, -2.4605, -2.3849, -2.4683, -2.3557, -2.2503,\n",
      "        -2.7682, -2.3709, -2.5321, -2.2744, -2.5142, -2.8621, -2.4813, -2.7438,\n",
      "        -2.9318, -2.7655, -2.4721, -2.5473, -2.5398, -2.6810, -2.5112, -2.3100,\n",
      "        -2.5793, -2.5443], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6034, -2.6022, -2.6042, -2.5889, -2.5579, -2.5796, -2.5837, -2.6136,\n",
      "        -2.5996, -2.6025, -2.6054, -2.6073, -2.5990, -2.5891, -2.5838, -2.6092,\n",
      "        -2.6061, -2.5953, -2.6072, -2.5969, -2.5550, -2.5628, -2.6074, -2.5572,\n",
      "        -2.5748, -2.6077, -2.6058, -2.6078, -2.5382, -2.5965, -2.5589, -2.5807,\n",
      "        -2.6087, -2.5818, -2.5615, -2.5479, -2.5874, -2.6033, -2.5172, -2.5350,\n",
      "        -2.5986, -2.5387, -2.5486, -2.5883, -2.5242, -2.6074, -2.6081, -2.5248,\n",
      "        -2.5993, -2.5605], device='mps:0')\n",
      "mean: tensor(-2.5826, device='mps:0')\n",
      "iter_dt 1.69s; iter 30: train loss 1.56547 temperature: 6.499999999999995\n",
      "mean_logits tensor([-2.0560, -2.4249, -2.4100, -2.5009, -2.6583, -2.7539, -2.2039, -2.2292,\n",
      "        -2.7259, -2.1093, -2.7608, -2.2988, -2.6895, -2.1944, -2.7897, -3.2292,\n",
      "        -2.2733, -2.2983, -2.6632, -2.6327, -2.8050, -2.2970, -2.6587, -2.2995,\n",
      "        -2.5164, -2.2358, -2.6119, -2.1936, -2.6504, -2.6069, -2.5727, -2.4614,\n",
      "        -2.2480, -2.1661, -2.4456, -2.2369, -2.4883, -2.7786, -2.9525, -2.7426,\n",
      "        -2.7766, -2.8429, -2.3127, -2.5721, -2.6789, -2.2075, -2.5775, -2.2157,\n",
      "        -2.7940, -2.1368], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5859, -2.5247, -2.6046, -2.5445, -2.5528, -2.5907, -2.6086, -2.5456,\n",
      "        -2.5706, -2.6126, -2.5978, -2.5781, -2.5998, -2.5084, -2.5886, -2.6042,\n",
      "        -2.4929, -2.6026, -2.5485, -2.5873, -2.6179, -2.6048, -2.6113, -2.5988,\n",
      "        -2.6075, -2.5919, -2.5257, -2.5869, -2.5907, -2.5834, -2.5524, -2.5873,\n",
      "        -2.6043, -2.5868, -2.6008, -2.5971, -2.5366, -2.6075, -2.6076, -2.5860,\n",
      "        -2.5713, -2.6087, -2.5388, -2.6067, -2.5887, -2.5848, -2.6054, -2.5445,\n",
      "        -2.5754, -2.6073], device='mps:0')\n",
      "mean: tensor(-2.5813, device='mps:0')\n",
      "iter_dt 1.14s; iter 31: train loss 1.00159 temperature: 6.5499999999999945\n",
      "mean_logits tensor([-2.7983, -2.5926, -2.4596, -2.9562, -2.5066, -2.5877, -2.3906, -2.3969,\n",
      "        -2.6919, -2.6568, -2.6525, -2.7357, -2.9677, -2.6842, -2.5520, -2.6668,\n",
      "        -2.6094, -2.4705, -2.2380, -2.7006, -2.4680, -2.4252, -2.4227, -2.6008,\n",
      "        -2.3171, -2.4695, -2.3929, -2.4013, -2.3939, -2.8820, -2.8242, -2.8109,\n",
      "        -2.7004, -2.4877, -2.4483, -2.3643, -2.1967, -2.3876, -2.0864, -2.6551,\n",
      "        -2.4764, -2.8558, -2.9792, -2.7578, -2.7696, -2.3622, -2.7859, -2.2998,\n",
      "        -2.3787, -2.4979], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6082, -2.6038, -2.5938, -2.5987, -2.5202, -2.5480, -2.5697, -2.6044,\n",
      "        -2.5903, -2.5901, -2.6068, -2.5854, -2.6086, -2.5888, -2.5902, -2.6013,\n",
      "        -2.5935, -2.5909, -2.5562, -2.6045, -2.5850, -2.5823, -2.6069, -2.6127,\n",
      "        -2.5549, -2.5889, -2.5877, -2.5591, -2.5546, -2.6080, -2.5474, -2.6069,\n",
      "        -2.5852, -2.6072, -2.6073, -2.5959, -2.5998, -2.5963, -2.5007, -2.5264,\n",
      "        -2.5864, -2.5862, -2.5898, -2.5760, -2.5376, -2.5775, -2.6000, -2.6005,\n",
      "        -2.5942, -2.6081], device='mps:0')\n",
      "mean: tensor(-2.5845, device='mps:0')\n",
      "iter_dt 1.13s; iter 32: train loss 0.78185 temperature: 6.599999999999994\n",
      "mean_logits tensor([-2.5469, -2.1072, -2.4281, -2.2409, -2.4600, -2.5623, -2.7427, -2.4028,\n",
      "        -2.8258, -2.6271, -2.6670, -2.2761, -2.6059, -2.3962, -2.6400, -2.2459,\n",
      "        -2.5551, -2.6127, -2.5550, -2.6528, -2.3748, -2.6015, -2.3498, -2.8180,\n",
      "        -2.4898, -2.2749, -2.6982, -2.6211, -2.6377, -2.3445, -2.3266, -2.4833,\n",
      "        -2.4832, -2.7322, -2.5919, -2.2680, -2.6427, -2.1729, -2.2976, -2.5827,\n",
      "        -2.3382, -2.6515, -2.7634, -2.5937, -2.5118, -2.1842, -2.7558, -2.5863,\n",
      "        -2.4786, -2.7927], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6002, -2.6090, -2.5988, -2.6083, -2.5853, -2.5858, -2.6081, -2.6099,\n",
      "        -2.6043, -2.6027, -2.5878, -2.5475, -2.5726, -2.6092, -2.5385, -2.5556,\n",
      "        -2.5908, -2.5870, -2.5696, -2.5974, -2.6074, -2.5887, -2.6070, -2.5534,\n",
      "        -2.5022, -2.5833, -2.5958, -2.5914, -2.6058, -2.6075, -2.6084, -2.6093,\n",
      "        -2.6059, -2.6083, -2.6045, -2.6033, -2.5849, -2.6018, -2.6082, -2.6094,\n",
      "        -2.5900, -2.5847, -2.5828, -2.6079, -2.5636, -2.6080, -2.6059, -2.5979,\n",
      "        -2.5674, -2.5875], device='mps:0')\n",
      "mean: tensor(-2.5910, device='mps:0')\n",
      "iter_dt 1.10s; iter 33: train loss 0.87815 temperature: 6.649999999999994\n",
      "mean_logits tensor([-2.6592, -2.1970, -2.4086, -2.4380, -2.5089, -2.2975, -2.0871, -2.5759,\n",
      "        -2.8357, -2.7804, -2.2741, -2.3644, -2.7420, -1.9583, -2.2388, -2.4511,\n",
      "        -2.4664, -2.2719, -2.7342, -2.6560, -2.5956, -2.7360, -2.4161, -2.3341,\n",
      "        -2.4393, -2.7594, -2.8830, -2.5423, -2.7888, -2.6145, -2.5467, -2.5498,\n",
      "        -2.5165, -2.4653, -2.6583, -2.3993, -2.3868, -2.3590, -2.3223, -2.2908,\n",
      "        -2.4741, -2.4596, -2.4080, -2.4574, -2.6451, -2.3650, -2.3646, -2.4840,\n",
      "        -2.7664, -2.3605], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5480, -2.5692, -2.5747, -2.5907, -2.5817, -2.5463, -2.5899, -2.5818,\n",
      "        -2.6029, -2.5855, -2.5764, -2.6087, -2.5971, -2.5757, -2.5912, -2.5853,\n",
      "        -2.5230, -2.6080, -2.6077, -2.5884, -2.6081, -2.5496, -2.5048, -2.5899,\n",
      "        -2.6085, -2.5552, -2.5908, -2.5214, -2.5523, -2.5290, -2.5980, -2.5926,\n",
      "        -2.6092, -2.6087, -2.5466, -2.6078, -2.5765, -2.6057, -2.5157, -2.6070,\n",
      "        -2.5594, -2.6069, -2.5876, -2.5372, -2.6075, -2.5465, -2.5445, -2.6083,\n",
      "        -2.6119, -2.5351], device='mps:0')\n",
      "mean: tensor(-2.5771, device='mps:0')\n",
      "iter_dt 1.09s; iter 34: train loss 0.88100 temperature: 6.699999999999994\n",
      "mean_logits tensor([-2.6748, -2.0164, -2.2674, -2.3685, -2.4011, -2.5331, -2.7747, -2.6416,\n",
      "        -2.4696, -2.2917, -2.5872, -2.4123, -2.7335, -2.7290, -2.8609, -2.3599,\n",
      "        -2.6483, -2.8245, -2.6579, -2.5748, -2.3107, -2.5619, -2.8024, -2.6129,\n",
      "        -2.6652, -2.7464, -2.5443, -2.6921, -2.2451, -2.2850, -2.3765, -2.7189,\n",
      "        -2.4500, -2.4933, -2.7289, -2.6718, -2.7404, -2.6221, -2.6056, -2.3074,\n",
      "        -2.1668, -2.8294, -2.5044, -2.5948, -2.5223, -2.5298, -2.1180, -2.1708,\n",
      "        -2.5968, -2.5924], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6084, -2.5616, -2.5303, -2.5912, -2.6081, -2.5965, -2.6065, -2.5880,\n",
      "        -2.5481, -2.5668, -2.5983, -2.5850, -2.5905, -2.5834, -2.5888, -2.5889,\n",
      "        -2.6043, -2.5336, -2.5298, -2.6081, -2.5313, -2.6034, -2.4671, -2.6057,\n",
      "        -2.5600, -2.6077, -2.5699, -2.6003, -2.5731, -2.6053, -2.5967, -2.5385,\n",
      "        -2.5241, -2.5240, -2.5187, -2.5878, -2.6000, -2.5837, -2.6086, -2.5850,\n",
      "        -2.6061, -2.5513, -2.6091, -2.5722, -2.6108, -2.5976, -2.6060, -2.5921,\n",
      "        -2.6018, -2.5343], device='mps:0')\n",
      "mean: tensor(-2.5778, device='mps:0')\n",
      "iter_dt 1.09s; iter 35: train loss 1.23145 temperature: 6.749999999999994\n",
      "mean_logits tensor([-2.6410, -3.1549, -2.7572, -2.4788, -2.3969, -2.8549, -2.3029, -2.4823,\n",
      "        -2.8986, -2.6078, -2.6541, -2.4993, -2.6984, -2.7399, -2.4864, -2.3419,\n",
      "        -2.6599, -2.2081, -2.6420, -2.6461, -2.7328, -2.5995, -2.5893, -2.7023,\n",
      "        -2.3625, -2.9157, -2.0959, -2.3877, -2.7045, -2.1398, -2.6975, -2.3284,\n",
      "        -2.3652, -2.5966, -3.0718, -2.5245, -2.4588, -2.4225, -2.5569, -2.4825,\n",
      "        -2.7017, -2.8970, -2.5231, -2.3998, -2.6491, -2.4923, -2.3502, -2.4256,\n",
      "        -2.3780, -2.5775], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6075, -2.5988, -2.5384, -2.6070, -2.5822, -2.6107, -2.6057, -2.6064,\n",
      "        -2.5992, -2.5989, -2.5898, -2.5755, -2.5609, -2.5906, -2.6079, -2.5684,\n",
      "        -2.5798, -2.6127, -2.6067, -2.6082, -2.6035, -2.5752, -2.5886, -2.5475,\n",
      "        -2.5348, -2.5794, -2.5956, -2.5851, -2.6086, -2.5876, -2.5265, -2.5988,\n",
      "        -2.5963, -2.5815, -2.6119, -2.6045, -2.5934, -2.6033, -2.5656, -2.5877,\n",
      "        -2.5869, -2.5894, -2.5754, -2.5759, -2.6032, -2.6023, -2.5192, -2.6080,\n",
      "        -2.5973, -2.6033], device='mps:0')\n",
      "mean: tensor(-2.5878, device='mps:0')\n",
      "iter_dt 1.16s; iter 36: train loss 0.71182 temperature: 6.799999999999994\n",
      "mean_logits tensor([-2.2047, -2.3821, -2.5385, -2.4143, -2.5436, -2.5083, -2.5409, -2.2722,\n",
      "        -2.5445, -2.3762, -2.3955, -1.9626, -2.7066, -2.3222, -2.5321, -2.2240,\n",
      "        -2.5502, -2.5652, -2.5560, -2.5262, -2.4868, -2.6467, -2.4547, -2.6241,\n",
      "        -2.5600, -2.6095, -2.4741, -2.6364, -2.6776, -2.5624, -2.6498, -2.6723,\n",
      "        -2.6719, -2.4399, -2.2033, -2.2510, -2.0948, -2.4568, -2.5356, -2.1362,\n",
      "        -2.5832, -2.4940, -2.7248, -2.6691, -2.7673, -2.5476, -2.8484, -2.2675,\n",
      "        -2.3841, -2.6005], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5617, -2.6010, -2.5871, -2.5594, -2.5910, -2.6087, -2.5981, -2.6079,\n",
      "        -2.5866, -2.5351, -2.5459, -2.5839, -2.5765, -2.5976, -2.6049, -2.5379,\n",
      "        -2.5482, -2.6061, -2.6083, -2.5379, -2.5898, -2.5711, -2.5767, -2.5386,\n",
      "        -2.5899, -2.4694, -2.6074, -2.6068, -2.5882, -2.6092, -2.6124, -2.5782,\n",
      "        -2.6060, -2.5908, -2.5934, -2.5476, -2.6052, -2.5880, -2.6107, -2.5190,\n",
      "        -2.6077, -2.4929, -2.5366, -2.5903, -2.5879, -2.5374, -2.6036, -2.5967,\n",
      "        -2.5897, -2.5963], device='mps:0')\n",
      "mean: tensor(-2.5784, device='mps:0')\n",
      "iter_dt 1.12s; iter 37: train loss 0.99531 temperature: 6.849999999999993\n",
      "mean_logits tensor([-2.6146, -2.4750, -2.2977, -2.0894, -2.6503, -2.2640, -2.2568, -2.4673,\n",
      "        -2.4640, -2.5250, -2.5933, -2.6062, -2.5734, -2.1664, -2.4647, -2.4230,\n",
      "        -2.7008, -2.7034, -2.7200, -2.4964, -2.6842, -2.3411, -2.6996, -1.6859,\n",
      "        -2.9364, -2.5994, -2.7641, -2.4623, -2.3997, -2.4460, -2.4999, -2.4800,\n",
      "        -2.1466, -2.3933, -2.5038, -2.2727, -2.5926, -2.1678, -2.6317, -2.5641,\n",
      "        -2.8495, -2.3992, -2.6060, -2.7812, -2.4111, -2.2226, -2.2978, -2.3308,\n",
      "        -2.4879, -2.5886], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6084, -2.5474, -2.5641, -2.5609, -2.6070, -2.5865, -2.6083, -2.5537,\n",
      "        -2.5498, -2.5134, -2.5787, -2.5888, -2.6047, -2.6095, -2.5838, -2.5999,\n",
      "        -2.5864, -2.5879, -2.5843, -2.6074, -2.6057, -2.5852, -2.5695, -2.5878,\n",
      "        -2.5835, -2.6080, -2.5748, -2.6064, -2.5725, -2.5690, -2.5834, -2.5254,\n",
      "        -2.5897, -2.5196, -2.5981, -2.6062, -2.5904, -2.6100, -2.6031, -2.5918,\n",
      "        -2.5879, -2.6046, -2.6005, -2.6071, -2.6089, -2.5119, -2.6146, -2.6061,\n",
      "        -2.5396, -2.5504], device='mps:0')\n",
      "mean: tensor(-2.5829, device='mps:0')\n",
      "iter_dt 1.07s; iter 38: train loss 1.20893 temperature: 6.899999999999993\n",
      "mean_logits tensor([-2.8420, -2.5785, -2.5733, -2.6452, -2.1999, -2.1669, -2.5207, -3.2008,\n",
      "        -2.5666, -2.3208, -2.4251, -2.4199, -2.4988, -2.7173, -2.2827, -2.6325,\n",
      "        -2.4603, -2.3562, -2.7571, -2.1031, -2.5911, -2.4436, -2.6301, -2.2287,\n",
      "        -2.1208, -2.8699, -2.4648, -2.6974, -2.4893, -2.4607, -2.7365, -2.3254,\n",
      "        -2.5261, -2.3051, -2.6118, -2.1121, -2.2171, -2.3889, -2.6092, -2.4437,\n",
      "        -2.4601, -2.3687, -2.3701, -2.5885, -2.4175, -2.4033, -2.4623, -2.4815,\n",
      "        -2.6023, -2.3103], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5406, -2.5981, -2.6072, -2.6082, -2.5550, -2.6043, -2.5340, -2.5647,\n",
      "        -2.5983, -2.5886, -2.5924, -2.6054, -2.5797, -2.4905, -2.5752, -2.6047,\n",
      "        -2.5595, -2.5601, -2.6017, -2.5836, -2.6068, -2.6043, -2.5673, -2.6059,\n",
      "        -2.5142, -2.5944, -2.6083, -2.6001, -2.5312, -2.5419, -2.5490, -2.5978,\n",
      "        -2.6079, -2.5262, -2.5841, -2.5814, -2.5665, -2.5906, -2.5705, -2.6082,\n",
      "        -2.5869, -2.5852, -2.5369, -2.5247, -2.5875, -2.5264, -2.6089, -2.5995,\n",
      "        -2.5698, -2.6073], device='mps:0')\n",
      "mean: tensor(-2.5768, device='mps:0')\n",
      "iter_dt 1.15s; iter 39: train loss 1.04924 temperature: 6.949999999999993\n",
      "mean_logits tensor([-2.6788, -2.6035, -2.5920, -2.2956, -2.8110, -2.1922, -2.3286, -2.3569,\n",
      "        -2.4236, -2.7050, -2.4155, -2.5564, -2.4175, -2.7987, -2.3532, -2.6371,\n",
      "        -2.8278, -2.1572, -2.4383, -2.5064, -2.3588, -2.0502, -2.3402, -1.9318,\n",
      "        -2.8236, -2.7082, -2.1481, -2.6521, -2.5344, -2.4161, -2.2689, -2.4077,\n",
      "        -2.7868, -2.7277, -2.8414, -2.6011, -2.4936, -2.5693, -2.3332, -2.3491,\n",
      "        -2.6196, -2.3420, -2.3693, -2.7644, -2.3640, -2.5280, -2.3838, -2.8888,\n",
      "        -2.5538, -2.4728], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6084, -2.5978, -2.5621, -2.5927, -2.6082, -2.6059, -2.5903, -2.6065,\n",
      "        -2.5602, -2.6041, -2.6042, -2.5964, -2.5613, -2.5932, -2.6079, -2.6031,\n",
      "        -2.5335, -2.5790, -2.6054, -2.5694, -2.5914, -2.5490, -2.5978, -2.6116,\n",
      "        -2.5737, -2.6076, -2.5277, -2.5888, -2.5910, -2.6029, -2.5877, -2.5270,\n",
      "        -2.5986, -2.6085, -2.6076, -2.5900, -2.5067, -2.3707, -2.5865, -2.5467,\n",
      "        -2.5894, -2.6031, -2.5964, -2.6042, -2.6019, -2.5854, -2.5905, -2.5559,\n",
      "        -2.5384, -2.5887], device='mps:0')\n",
      "mean: tensor(-2.5803, device='mps:0')\n",
      "iter_dt 1.11s; iter 40: train loss 0.91831 temperature: 6.999999999999993\n",
      "mean_logits tensor([-2.3984, -2.4423, -2.6847, -2.6293, -2.8431, -2.6265, -2.2026, -2.0612,\n",
      "        -2.4522, -2.5969, -2.4206, -2.3415, -2.4053, -2.6399, -2.8437, -2.4564,\n",
      "        -2.5732, -2.5019, -2.8676, -2.6911, -2.8509, -2.4397, -2.5865, -2.5788,\n",
      "        -2.4635, -2.8442, -2.8829, -2.5816, -2.3849, -2.3276, -2.2318, -2.9148,\n",
      "        -2.6635, -2.6207, -2.7792, -2.6458, -2.6194, -2.6925, -2.0833, -2.5559,\n",
      "        -2.7564, -2.4503, -2.4989, -2.4763, -2.4605, -2.4721, -2.8936, -2.8609,\n",
      "        -2.4880, -2.6697], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5554, -2.6053, -2.5933, -2.5834, -2.5905, -2.5620, -2.6078, -2.5979,\n",
      "        -2.5341, -2.5855, -2.5605, -2.5854, -2.5907, -2.6060, -2.6058, -2.5732,\n",
      "        -2.6036, -2.5640, -2.5680, -2.6031, -2.5582, -2.5066, -2.6085, -2.6071,\n",
      "        -2.5309, -2.6058, -2.6006, -2.6045, -2.5721, -2.5998, -2.5389, -2.6125,\n",
      "        -2.5304, -2.6066, -2.5564, -2.6041, -2.4542, -2.5988, -2.5474, -2.5876,\n",
      "        -2.5504, -2.6047, -2.6081, -2.5842, -2.5731, -2.5889, -2.6067, -2.5749,\n",
      "        -2.5532, -2.6048], device='mps:0')\n",
      "mean: tensor(-2.5791, device='mps:0')\n",
      "iter_dt 1.18s; iter 41: train loss 0.97739 temperature: 7.049999999999993\n",
      "mean_logits tensor([-2.6557, -2.4988, -2.6327, -2.7561, -2.6757, -2.3368, -2.7070, -2.5103,\n",
      "        -2.6941, -2.0107, -2.6407, -2.7606, -2.4405, -2.6221, -3.1035, -2.3431,\n",
      "        -2.5735, -2.4625, -2.7855, -2.3968, -2.7061, -2.5635, -2.5013, -2.3209,\n",
      "        -2.2178, -2.5685, -2.6012, -2.1260, -2.4622, -2.3577, -2.3646, -2.7168,\n",
      "        -2.7594, -2.4631, -2.4921, -2.7286, -2.5010, -2.7109, -2.4092, -2.1931,\n",
      "        -2.7159, -2.8619, -2.3372, -2.5491, -2.7833, -2.1451, -2.5760, -2.3944,\n",
      "        -2.3828, -2.3438], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6072, -2.4960, -2.5978, -2.5886, -2.6080, -2.5510, -2.5792, -2.5837,\n",
      "        -2.5035, -2.5299, -2.6049, -2.5304, -2.5859, -2.5970, -2.6127, -2.6106,\n",
      "        -2.6052, -2.6034, -2.5978, -2.5622, -2.6028, -2.5811, -2.5268, -2.5925,\n",
      "        -2.5917, -2.5761, -2.5979, -2.5392, -2.5800, -2.6017, -2.5865, -2.5976,\n",
      "        -2.5956, -2.5170, -2.5981, -2.5426, -2.5172, -2.6093, -2.6107, -2.5987,\n",
      "        -2.5805, -2.5542, -2.6085, -2.5857, -2.5889, -2.6084, -2.5801, -2.6084,\n",
      "        -2.5574, -2.5344], device='mps:0')\n",
      "mean: tensor(-2.5785, device='mps:0')\n",
      "iter_dt 1.22s; iter 42: train loss 0.78958 temperature: 7.0999999999999925\n",
      "mean_logits tensor([-2.7175, -2.8098, -2.4870, -2.6241, -2.4762, -2.2339, -2.6898, -2.4400,\n",
      "        -2.6602, -2.8179, -2.5956, -2.7014, -2.5707, -2.7759, -2.5260, -2.6613,\n",
      "        -2.6075, -2.4751, -2.2545, -2.3282, -2.7558, -2.5151, -2.7057, -2.3079,\n",
      "        -2.4858, -2.1503, -2.4722, -2.2223, -2.4116, -2.4911, -2.5921, -2.4847,\n",
      "        -2.4572, -2.5507, -2.7095, -2.5497, -2.6097, -2.8864, -2.6454, -2.9036,\n",
      "        -2.9792, -2.5284, -2.7471, -2.3643, -2.2999, -2.7977, -2.6958, -2.5227,\n",
      "        -2.5877, -2.6294], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6060, -2.5256, -2.6023, -2.5948, -2.5994, -2.5850, -2.5798, -2.6082,\n",
      "        -2.5895, -2.5852, -2.5908, -2.5817, -2.5546, -2.5897, -2.5674, -2.5989,\n",
      "        -2.5897, -2.6093, -2.6096, -2.6004, -2.5946, -2.4906, -2.5839, -2.5851,\n",
      "        -2.6060, -2.5746, -2.5996, -2.5587, -2.5196, -2.5852, -2.5514, -2.5916,\n",
      "        -2.5892, -2.5913, -2.6074, -2.5989, -2.5987, -2.6011, -2.6085, -2.6124,\n",
      "        -2.5713, -2.6085, -2.6137, -2.6051, -2.5488, -2.5476, -2.5907, -2.6047,\n",
      "        -2.5880, -2.6121], device='mps:0')\n",
      "mean: tensor(-2.5861, device='mps:0')\n",
      "iter_dt 1.27s; iter 43: train loss 0.78818 temperature: 7.149999999999992\n",
      "mean_logits tensor([-2.5683, -2.5247, -2.8490, -2.2553, -2.6094, -2.7418, -2.6802, -2.7691,\n",
      "        -1.9764, -2.4763, -2.8893, -2.4421, -2.6512, -2.5886, -2.6318, -2.2768,\n",
      "        -2.2584, -2.3960, -2.5060, -2.4890, -2.5725, -2.3112, -2.6008, -1.8796,\n",
      "        -2.3399, -2.7188, -2.3542, -2.5508, -2.5862, -2.3838, -2.3729, -2.3103,\n",
      "        -2.7597, -2.7132, -2.4426, -2.4941, -2.8325, -2.4593, -2.3406, -2.4083,\n",
      "        -2.6224, -2.7305, -2.4659, -2.6560, -2.4582, -2.4241, -2.4075, -2.5090,\n",
      "        -2.2691, -2.5700], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5310, -2.5878, -2.5969, -2.6035, -2.5439, -2.6056, -2.6062, -2.5604,\n",
      "        -2.5457, -2.5290, -2.6013, -2.5979, -2.5440, -2.5955, -2.5630, -2.6089,\n",
      "        -2.6092, -2.5307, -2.5818, -2.6070, -2.5786, -2.5423, -2.6070, -2.4724,\n",
      "        -2.5831, -2.6071, -2.5539, -2.5958, -2.5616, -2.6055, -2.5717, -2.5907,\n",
      "        -2.5948, -2.6062, -2.5395, -2.5898, -2.6070, -2.6074, -2.5894, -2.5854,\n",
      "        -2.5271, -2.5898, -2.6031, -2.6117, -2.6063, -2.6063, -2.5952, -2.5826,\n",
      "        -2.5753, -2.6003], device='mps:0')\n",
      "mean: tensor(-2.5807, device='mps:0')\n",
      "iter_dt 1.20s; iter 44: train loss 0.59438 temperature: 7.199999999999992\n",
      "mean_logits tensor([-2.5139, -2.5807, -2.5492, -2.7208, -2.4415, -2.6503, -2.4461, -2.4997,\n",
      "        -2.5273, -2.2508, -2.6828, -2.7131, -2.2650, -2.5226, -2.3630, -2.5537,\n",
      "        -2.5335, -2.4167, -2.5976, -2.5019, -2.2106, -2.2307, -2.4777, -2.7043,\n",
      "        -2.5336, -2.3073, -2.4506, -2.7616, -2.5050, -2.5301, -2.4385, -2.5034,\n",
      "        -2.5616, -2.6559, -2.7457, -2.5933, -2.4030, -2.7219, -2.2056, -2.4939,\n",
      "        -2.7923, -2.3161, -2.6652, -2.3715, -2.4375, -2.8656, -2.2997, -2.8039,\n",
      "        -2.4581, -2.5540], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5899, -2.5495, -2.5882, -2.5985, -2.5527, -2.5854, -2.5502, -2.5871,\n",
      "        -2.6134, -2.5888, -2.5307, -2.6052, -2.4829, -2.6036, -2.6077, -2.5351,\n",
      "        -2.5467, -2.5291, -2.6026, -2.5478, -2.6111, -2.6109, -2.6045, -2.6062,\n",
      "        -2.5455, -2.5982, -2.5917, -2.6041, -2.5559, -2.5853, -2.5930, -2.6083,\n",
      "        -2.5716, -2.6081, -2.6082, -2.5478, -2.6010, -2.5924, -2.5466, -2.5905,\n",
      "        -2.5460, -2.5591, -2.6068, -2.5793, -2.5693, -2.6077, -2.6088, -2.6094,\n",
      "        -2.6086, -2.5492], device='mps:0')\n",
      "mean: tensor(-2.5804, device='mps:0')\n",
      "iter_dt 1.16s; iter 45: train loss 0.57453 temperature: 7.249999999999992\n",
      "mean_logits tensor([-2.2575, -2.4846, -2.4509, -2.5418, -2.6276, -2.5420, -2.4279, -2.7063,\n",
      "        -2.4336, -2.5199, -2.8492, -2.5692, -2.5230, -2.7231, -2.3761, -2.4838,\n",
      "        -2.5091, -2.7291, -2.6889, -2.7236, -2.5576, -2.1582, -2.6254, -2.4811,\n",
      "        -2.6712, -2.5983, -2.6923, -2.8737, -2.4695, -2.5041, -2.4700, -2.6746,\n",
      "        -2.6769, -2.9237, -2.6240, -2.4508, -2.4982, -2.4493, -2.3167, -2.5201,\n",
      "        -2.4798, -2.6528, -2.4733, -2.4189, -2.4932, -2.6062, -2.7964, -2.4753,\n",
      "        -2.3223, -2.6801], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5850, -2.5581, -2.5896, -2.5444, -2.5228, -2.6043, -2.5643, -2.5867,\n",
      "        -2.5878, -2.6049, -2.6079, -2.5982, -2.6028, -2.5611, -2.4808, -2.5779,\n",
      "        -2.5906, -2.5979, -2.5387, -2.5582, -2.5883, -2.6123, -2.5856, -2.5864,\n",
      "        -2.4843, -2.6110, -2.6075, -2.6044, -2.6065, -2.6081, -2.5960, -2.5945,\n",
      "        -2.5346, -2.6115, -2.5648, -2.5958, -2.5985, -2.6017, -2.6086, -2.6077,\n",
      "        -2.5994, -2.6073, -2.5854, -2.6049, -2.5351, -2.5815, -2.6020, -2.5881,\n",
      "        -2.6081, -2.6094], device='mps:0')\n",
      "mean: tensor(-2.5838, device='mps:0')\n",
      "iter_dt 1.15s; iter 46: train loss 0.71118 temperature: 7.299999999999992\n",
      "mean_logits tensor([-2.9550, -2.6104, -2.4288, -2.4846, -2.3069, -2.5446, -2.3372, -2.4935,\n",
      "        -2.5758, -2.6674, -2.6090, -2.4759, -2.5145, -2.4775, -2.5301, -2.4800,\n",
      "        -2.7305, -2.2552, -2.7088, -2.5157, -2.6314, -2.5927, -2.5474, -2.6160,\n",
      "        -2.2519, -2.4244, -2.5378, -2.5022, -2.4154, -2.7291, -2.7871, -2.6134,\n",
      "        -2.4139, -2.4655, -2.2808, -2.6148, -2.2549, -2.4225, -2.9370, -1.9290,\n",
      "        -2.4772, -2.6667, -2.5901, -2.4759, -2.2752, -2.4491, -2.7533, -2.5838,\n",
      "        -2.5060, -2.5519], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5996, -2.6072, -2.5162, -2.5873, -2.5132, -2.5793, -2.5905, -2.5927,\n",
      "        -2.5843, -2.5718, -2.5690, -2.6092, -2.5949, -2.5794, -2.5887, -2.5607,\n",
      "        -2.6068, -2.5722, -2.5578, -2.5785, -2.5714, -2.5467, -2.5667, -2.5780,\n",
      "        -2.6097, -2.6033, -2.5878, -2.5278, -2.6029, -2.6069, -2.5706, -2.6067,\n",
      "        -2.5532, -2.5903, -2.5899, -2.6081, -2.5421, -2.6093, -2.5893, -2.5921,\n",
      "        -2.5764, -2.5760, -2.5645, -2.5989, -2.6044, -2.5995, -2.5504, -2.5521,\n",
      "        -2.5837, -2.5829], device='mps:0')\n",
      "mean: tensor(-2.5800, device='mps:0')\n",
      "iter_dt 1.15s; iter 47: train loss 0.67175 temperature: 7.349999999999992\n",
      "mean_logits tensor([-2.5216, -2.3382, -2.3778, -2.5526, -2.8357, -2.3654, -2.6926, -2.6698,\n",
      "        -2.3583, -2.9248, -2.4657, -2.6031, -2.4609, -2.7624, -2.7551, -2.5007,\n",
      "        -2.2205, -2.4317, -2.5517, -2.8761, -2.6030, -2.4631, -2.5664, -2.4033,\n",
      "        -2.5736, -2.5485, -2.4169, -2.3488, -2.5053, -2.8446, -2.4021, -2.4634,\n",
      "        -2.5188, -2.5500, -2.7072, -2.6106, -2.4898, -2.7164, -2.7276, -2.4664,\n",
      "        -2.3590, -2.7448, -2.2561, -2.5607, -2.4762, -2.4401, -2.2582, -2.6885,\n",
      "        -2.4163, -2.0805], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5884, -2.5901, -2.5483, -2.5893, -2.5281, -2.5573, -2.5355, -2.6123,\n",
      "        -2.5275, -2.5791, -2.5164, -2.5914, -2.5137, -2.5299, -2.5913, -2.5318,\n",
      "        -2.5990, -2.5455, -2.6080, -2.5991, -2.5873, -2.6098, -2.6083, -2.5332,\n",
      "        -2.6074, -2.5861, -2.5896, -2.5538, -2.5308, -2.6083, -2.5987, -2.6033,\n",
      "        -2.5702, -2.5543, -2.6041, -2.5795, -2.5813, -2.5830, -2.6095, -2.5946,\n",
      "        -2.5952, -2.6082, -2.6052, -2.6105, -2.5852, -2.5449, -2.5169, -2.5865,\n",
      "        -2.5311, -2.5100], device='mps:0')\n",
      "mean: tensor(-2.5734, device='mps:0')\n",
      "iter_dt 1.11s; iter 48: train loss 0.79385 temperature: 7.3999999999999915\n",
      "mean_logits tensor([-2.3405, -2.4661, -2.7507, -2.5003, -2.5991, -2.7186, -2.5742, -2.5912,\n",
      "        -2.9571, -2.5431, -2.6454, -2.2971, -2.5562, -2.4932, -2.5242, -2.6121,\n",
      "        -2.7876, -2.7330, -2.7789, -2.8733, -2.6542, -2.5692, -2.3870, -2.7026,\n",
      "        -2.4112, -2.6933, -2.7565, -2.4783, -2.5733, -2.8360, -2.7176, -2.7240,\n",
      "        -2.5446, -2.4293, -2.1612, -2.6422, -2.5635, -2.7262, -2.5705, -2.4211,\n",
      "        -2.1558, -2.3740, -2.7199, -2.7234, -2.4552, -2.5180, -2.5147, -2.6307,\n",
      "        -2.6955, -2.0216], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6050, -2.6074, -2.5817, -2.5244, -2.5819, -2.5682, -2.5953, -2.6096,\n",
      "        -2.6062, -2.6093, -2.5645, -2.5988, -2.5444, -2.5705, -2.5793, -2.6035,\n",
      "        -2.6084, -2.6077, -2.6026, -2.5366, -2.4882, -2.5918, -2.5967, -2.5028,\n",
      "        -2.5589, -2.6022, -2.5990, -2.5539, -2.5740, -2.5340, -2.5774, -2.5908,\n",
      "        -2.6108, -2.6083, -2.6118, -2.5921, -2.5906, -2.6040, -2.5876, -2.6083,\n",
      "        -2.6060, -2.5993, -2.6038, -2.6061, -2.6003, -2.5981, -2.5931, -2.5215,\n",
      "        -2.5286, -2.5867], device='mps:0')\n",
      "mean: tensor(-2.5826, device='mps:0')\n",
      "iter_dt 1.07s; iter 49: train loss 1.01118 temperature: 7.449999999999991\n",
      "mean_logits tensor([-2.5743, -2.7980, -2.7245, -2.2388, -2.5229, -2.2226, -2.6309, -2.7627,\n",
      "        -2.5442, -2.8029, -2.3114, -2.1708, -2.6451, -2.6196, -2.2866, -2.5763,\n",
      "        -2.6484, -2.1610, -2.5257, -2.4378, -2.3417, -2.5279, -2.7304, -2.2740,\n",
      "        -2.6758, -2.3391, -2.2769, -2.4169, -2.3861, -2.5241, -2.5477, -2.8476,\n",
      "        -2.8642, -2.7681, -2.3177, -2.5536, -2.7256, -2.4273, -2.3632, -2.6020,\n",
      "        -2.3810, -2.6736, -2.9003, -2.6788, -1.8626, -2.4829, -2.7520, -2.8159,\n",
      "        -2.6356, -2.3355], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5993, -2.5416, -2.6048, -2.5978, -2.5343, -2.5473, -2.5896, -2.5670,\n",
      "        -2.6023, -2.5311, -2.5874, -2.5862, -2.6082, -2.6043, -2.5984, -2.6051,\n",
      "        -2.5473, -2.4861, -2.6049, -2.5962, -2.6257, -2.5760, -2.6051, -2.6079,\n",
      "        -2.6082, -2.6080, -2.6015, -2.6046, -2.5875, -2.6097, -2.5902, -2.5881,\n",
      "        -2.5956, -2.6038, -2.6010, -2.6083, -2.6113, -2.6082, -2.5843, -2.5658,\n",
      "        -2.5620, -2.5918, -2.6093, -2.5903, -2.6200, -2.6072, -2.5948, -2.6104,\n",
      "        -2.6066, -2.5954], device='mps:0')\n",
      "mean: tensor(-2.5904, device='mps:0')\n",
      "iter_dt 1.09s; iter 50: train loss 0.75115 temperature: 7.499999999999991\n",
      "mean_logits tensor([-2.3410, -2.2961, -2.3623, -2.6137, -2.5682, -2.5715, -2.1619, -2.7426,\n",
      "        -2.6876, -2.3451, -2.3100, -2.5269, -2.8432, -2.8464, -2.5085, -2.5197,\n",
      "        -2.5575, -2.5458, -2.3725, -2.5489, -2.5621, -2.3912, -2.0525, -2.5026,\n",
      "        -2.7474, -2.5098, -2.7603, -2.6948, -2.6961, -2.4833, -2.5789, -2.3848,\n",
      "        -2.6079, -2.5997, -2.6276, -2.4970, -2.6618, -2.5207, -2.3886, -2.6177,\n",
      "        -2.3314, -2.6930, -2.3736, -2.0939, -2.4000, -2.7084, -2.0738, -2.6202,\n",
      "        -2.6409, -2.3855], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5895, -2.6110, -2.5976, -2.5936, -2.5812, -2.6081, -2.5484, -2.6081,\n",
      "        -2.5998, -2.6050, -2.6046, -2.6101, -2.6080, -2.5406, -2.5489, -2.5824,\n",
      "        -2.5284, -2.5897, -2.5581, -2.5970, -2.5054, -2.5336, -2.6066, -2.5580,\n",
      "        -2.5989, -2.5589, -2.6067, -2.5483, -2.5244, -2.5321, -2.5396, -2.4748,\n",
      "        -2.6082, -2.5059, -2.6002, -2.6107, -2.6094, -2.5446, -2.6070, -2.6070,\n",
      "        -2.5805, -2.5356, -2.6082, -2.5845, -2.6052, -2.6095, -2.6055, -2.6056,\n",
      "        -2.5872, -2.5700], device='mps:0')\n",
      "mean: tensor(-2.5776, device='mps:0')\n",
      "iter_dt 1.14s; iter 51: train loss 0.54888 temperature: 7.549999999999991\n",
      "mean_logits tensor([-2.6951, -2.5340, -2.4255, -2.5692, -2.7051, -2.6851, -2.3843, -2.6909,\n",
      "        -2.6469, -2.6565, -2.5205, -2.4625, -2.4507, -2.6452, -2.5893, -2.5273,\n",
      "        -2.5424, -2.5495, -2.5828, -2.6584, -2.4938, -2.6664, -2.4634, -2.6255,\n",
      "        -2.3905, -2.4618, -2.7415, -2.2869, -2.4619, -2.6250, -2.7855, -2.4290,\n",
      "        -2.6480, -2.7215, -2.9189, -2.3901, -2.4660, -2.2204, -2.7460, -2.5349,\n",
      "        -2.2815, -2.4087, -2.5672, -2.3166, -2.2007, -2.3848, -2.5378, -2.3900,\n",
      "        -2.3950, -2.5159], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6085, -2.5954, -2.6074, -2.5930, -2.6032, -2.4986, -2.6068, -2.5386,\n",
      "        -2.5487, -2.5998, -2.5960, -2.5908, -2.6039, -2.5283, -2.5718, -2.5822,\n",
      "        -2.5440, -2.5899, -2.6074, -2.5952, -2.5669, -2.6083, -2.5871, -2.5395,\n",
      "        -2.5909, -2.5905, -2.6078, -2.5463, -2.6093, -2.5836, -2.6069, -2.5400,\n",
      "        -2.5856, -2.5854, -2.6080, -2.6095, -2.5862, -2.6086, -2.5478, -2.6069,\n",
      "        -2.5156, -2.5897, -2.5904, -2.5976, -2.5954, -2.5996, -2.6078, -2.5843,\n",
      "        -2.5235, -2.5465], device='mps:0')\n",
      "mean: tensor(-2.5815, device='mps:0')\n",
      "iter_dt 1.10s; iter 52: train loss 0.77510 temperature: 7.599999999999991\n",
      "mean_logits tensor([-2.8492, -2.3272, -2.3724, -2.3459, -2.6618, -2.4982, -2.3316, -2.6597,\n",
      "        -2.4699, -2.6209, -2.6760, -2.3369, -1.9979, -2.6432, -2.2031, -2.7718,\n",
      "        -2.4778, -2.4397, -2.6746, -2.6975, -2.4845, -2.5840, -2.2845, -2.4204,\n",
      "        -2.4605, -2.6923, -2.8895, -2.8429, -2.8988, -2.4884, -2.5251, -2.3435,\n",
      "        -2.5161, -2.5539, -2.5211, -2.3547, -2.4883, -2.4656, -2.5036, -2.3368,\n",
      "        -2.5711, -2.5869, -2.5792, -2.6179, -2.4489, -2.3946, -2.6837, -2.6600,\n",
      "        -2.6983, -2.3693], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6087, -2.5523, -2.6078, -2.5949, -2.6022, -2.5962, -2.5469, -2.5918,\n",
      "        -2.6061, -2.6068, -2.6134, -2.5765, -2.6022, -2.5802, -2.6080, -2.5721,\n",
      "        -2.5888, -2.6080, -2.5892, -2.5856, -2.6083, -2.5836, -2.5897, -2.5949,\n",
      "        -2.5573, -2.5856, -2.5601, -2.5395, -2.6090, -2.6044, -2.5267, -2.6076,\n",
      "        -2.5879, -2.6051, -2.5905, -2.6083, -2.6036, -2.5665, -2.5999, -2.5921,\n",
      "        -2.6086, -2.5532, -2.5304, -2.5847, -2.6036, -2.5352, -2.4865, -2.5925,\n",
      "        -2.5981, -2.5832], device='mps:0')\n",
      "mean: tensor(-2.5847, device='mps:0')\n",
      "iter_dt 1.16s; iter 53: train loss 0.77499 temperature: 7.649999999999991\n",
      "mean_logits tensor([-2.6178, -2.5699, -2.8671, -2.3833, -2.4063, -2.6550, -2.5852, -2.6582,\n",
      "        -2.4959, -2.3272, -2.8191, -2.7331, -2.6344, -2.6943, -2.7277, -2.8795,\n",
      "        -2.6806, -2.7315, -2.5852, -2.4507, -2.5537, -2.5851, -2.3753, -2.7432,\n",
      "        -2.4245, -2.5513, -2.5816, -2.7769, -2.3252, -2.1938, -2.5893, -2.2349,\n",
      "        -2.6786, -2.6046, -2.8247, -2.3819, -2.4665, -2.3492, -2.5307, -2.6080,\n",
      "        -2.7503, -2.4232, -2.7112, -2.4525, -2.5483, -2.0333, -2.7440, -2.3885,\n",
      "        -2.7885, -2.1653], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5850, -2.5401, -2.5946, -2.5948, -2.5246, -2.5990, -2.5908, -2.5589,\n",
      "        -2.5789, -2.6060, -2.6047, -2.5803, -2.6093, -2.5813, -2.5377, -2.6038,\n",
      "        -2.5360, -2.6063, -2.5854, -2.5404, -2.6002, -2.5730, -2.6068, -2.3615,\n",
      "        -2.5315, -2.5853, -2.6052, -2.5935, -2.5284, -2.5893, -2.5964, -2.4791,\n",
      "        -2.6081, -2.6087, -2.6017, -2.5775, -2.5887, -2.5978, -2.6076, -2.5823,\n",
      "        -2.5888, -2.6084, -2.5699, -2.6128, -2.5849, -2.6007, -2.5947, -2.5820,\n",
      "        -2.5507, -2.5469], device='mps:0')\n",
      "mean: tensor(-2.5764, device='mps:0')\n",
      "iter_dt 1.14s; iter 54: train loss 0.85435 temperature: 7.69999999999999\n",
      "mean_logits tensor([-2.6567, -2.8115, -2.4197, -2.5275, -2.3312, -2.3680, -2.5724, -2.4686,\n",
      "        -2.7829, -2.4217, -2.6728, -2.7318, -2.5511, -2.5025, -2.3951, -2.6818,\n",
      "        -2.7777, -2.5851, -2.3027, -2.2530, -2.2404, -2.4288, -2.7088, -2.3691,\n",
      "        -2.1428, -2.4276, -1.9954, -2.5494, -2.7039, -2.6753, -2.7212, -2.6113,\n",
      "        -2.2921, -2.5073, -2.7278, -2.2763, -2.4753, -2.4846, -2.4923, -2.3366,\n",
      "        -3.0169, -2.3978, -2.5314, -2.7336, -2.1999, -2.7056, -2.7332, -2.3789,\n",
      "        -2.5551, -2.5850], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5535, -2.5884, -2.5480, -2.5910, -2.6048, -2.6082, -2.5521, -2.6089,\n",
      "        -2.6073, -2.5918, -2.5989, -2.5990, -2.6065, -2.5508, -2.6088, -2.6019,\n",
      "        -2.5640, -2.5720, -2.5786, -2.5900, -2.5974, -2.5580, -2.5397, -2.5898,\n",
      "        -2.5495, -2.6068, -2.5336, -2.5179, -2.6013, -2.5872, -2.5708, -2.5994,\n",
      "        -2.6034, -2.6074, -2.5879, -2.5353, -2.6092, -2.5989, -2.5891, -2.5919,\n",
      "        -2.6086, -2.5297, -2.6035, -2.5499, -2.5728, -2.5933, -2.5901, -2.5571,\n",
      "        -2.5331, -2.5107], device='mps:0')\n",
      "mean: tensor(-2.5790, device='mps:0')\n",
      "iter_dt 1.08s; iter 55: train loss 0.83644 temperature: 7.74999999999999\n",
      "mean_logits tensor([-2.7348, -2.2601, -2.5488, -2.4635, -2.2580, -2.4361, -2.8609, -2.7316,\n",
      "        -2.4645, -2.3697, -2.7665, -2.6798, -2.6790, -2.3738, -2.6438, -2.5997,\n",
      "        -2.2290, -2.4463, -2.4896, -2.4578, -2.5313, -2.5132, -2.5118, -2.5795,\n",
      "        -2.6790, -2.8409, -2.6748, -2.4666, -2.2175, -2.1711, -2.4880, -2.1638,\n",
      "        -2.1470, -2.5568, -2.7190, -2.4719, -2.6637, -2.5310, -2.1698, -2.2537,\n",
      "        -2.0940, -2.7119, -2.6027, -2.4535, -2.3356, -2.2372, -2.5890, -2.8131,\n",
      "        -2.5638, -2.3584], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5983, -2.4977, -2.6018, -2.6122, -2.5582, -2.6054, -2.5475, -2.5893,\n",
      "        -2.6093, -2.4965, -2.5930, -2.5860, -2.5821, -2.5472, -2.5623, -2.6102,\n",
      "        -2.5341, -2.5939, -2.5851, -2.5192, -2.5995, -2.5378, -2.5901, -2.5552,\n",
      "        -2.5880, -2.5456, -2.5975, -2.5393, -2.5976, -2.5933, -2.5886, -2.5593,\n",
      "        -2.5789, -2.5738, -2.5867, -2.5784, -2.5977, -2.5860, -2.6056, -2.5676,\n",
      "        -2.5189, -2.5936, -2.5893, -2.5939, -2.5996, -2.6062, -2.5945, -2.6084,\n",
      "        -2.6027, -2.5869], device='mps:0')\n",
      "mean: tensor(-2.5778, device='mps:0')\n",
      "iter_dt 1.24s; iter 56: train loss 0.86884 temperature: 7.79999999999999\n",
      "mean_logits tensor([-2.6982, -2.4272, -2.4991, -2.6981, -2.5611, -2.3884, -2.4482, -2.3233,\n",
      "        -2.6755, -2.3826, -2.6361, -2.4702, -2.7155, -2.5435, -2.6370, -2.3499,\n",
      "        -2.5818, -2.6890, -3.0191, -2.5321, -2.4045, -2.5912, -2.2237, -2.2846,\n",
      "        -2.3895, -2.8418, -2.4736, -2.1085, -2.3041, -2.4112, -2.6860, -2.3163,\n",
      "        -2.8363, -2.2179, -2.4297, -2.4662, -2.7338, -2.4939, -2.5558, -2.1059,\n",
      "        -2.4245, -2.6914, -2.3836, -2.4634, -2.5186, -2.6140, -2.2878, -2.6035,\n",
      "        -2.2074, -2.4126], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6095, -2.5873, -2.6080, -2.5662, -2.5876, -2.6034, -2.6117, -2.5814,\n",
      "        -2.6089, -2.5965, -2.6082, -2.5754, -2.6071, -2.4922, -2.5993, -2.5893,\n",
      "        -2.5376, -2.5443, -2.5989, -2.4930, -2.5469, -2.5901, -2.5794, -2.5944,\n",
      "        -2.5900, -2.5691, -2.5062, -2.6075, -2.4397, -2.6053, -2.6087, -2.5957,\n",
      "        -2.5324, -2.5969, -2.6070, -2.5829, -2.5830, -2.6056, -2.6024, -2.4921,\n",
      "        -2.5027, -2.5858, -2.5348, -2.5430, -2.5847, -2.5791, -2.6030, -2.6097,\n",
      "        -2.6060, -2.6024], device='mps:0')\n",
      "mean: tensor(-2.5758, device='mps:0')\n",
      "iter_dt 1.18s; iter 57: train loss 0.79027 temperature: 7.84999999999999\n",
      "mean_logits tensor([-2.3698, -2.3299, -2.4971, -2.1928, -2.4622, -2.7945, -2.0791, -2.4106,\n",
      "        -2.6398, -2.2902, -2.7392, -2.4556, -2.8441, -2.6505, -2.3317, -2.2721,\n",
      "        -2.4708, -2.5123, -2.3025, -2.7794, -2.5266, -2.4313, -2.4713, -2.5132,\n",
      "        -2.4248, -2.4130, -2.4080, -2.6196, -2.5086, -2.5942, -2.5424, -2.8258,\n",
      "        -2.4721, -2.2338, -2.6920, -2.7959, -2.5879, -2.4775, -2.5482, -2.7279,\n",
      "        -2.6020, -2.6129, -2.1129, -2.3459, -2.2542, -2.4370, -2.4078, -2.6823,\n",
      "        -2.3708, -2.7303], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4931, -2.6061, -2.6075, -2.6088, -2.5427, -2.5749, -2.5671, -2.5325,\n",
      "        -2.5834, -2.5879, -2.5832, -2.5671, -2.5912, -2.5909, -2.5992, -2.6059,\n",
      "        -2.5435, -2.6092, -2.6040, -2.5795, -2.5712, -2.6035, -2.6076, -2.6043,\n",
      "        -2.5680, -2.5889, -2.5989, -2.5918, -2.6001, -2.5898, -2.5893, -2.5992,\n",
      "        -2.5856, -2.5697, -2.6090, -2.6081, -2.5943, -2.5766, -2.6014, -2.5478,\n",
      "        -2.6076, -2.5901, -2.6063, -2.5798, -2.5169, -2.5902, -2.5876, -2.5450,\n",
      "        -2.5166, -2.5472], device='mps:0')\n",
      "mean: tensor(-2.5814, device='mps:0')\n",
      "iter_dt 1.25s; iter 58: train loss 0.68658 temperature: 7.89999999999999\n",
      "mean_logits tensor([-2.6526, -2.7257, -2.4575, -2.5804, -2.5357, -2.5834, -2.3567, -2.4011,\n",
      "        -2.6054, -2.3209, -2.2974, -2.6944, -2.3609, -2.5805, -2.4888, -2.2473,\n",
      "        -2.4811, -2.8937, -2.3746, -2.5694, -2.1985, -2.4416, -2.7237, -2.5772,\n",
      "        -2.7262, -2.4785, -2.4296, -2.6485, -2.3407, -2.5624, -2.6064, -2.5601,\n",
      "        -2.6127, -2.5459, -2.2473, -2.2972, -2.1179, -2.4952, -2.8014, -2.6176,\n",
      "        -2.4882, -2.1314, -2.3481, -2.3851, -2.5794, -2.5200, -2.4795, -2.6594,\n",
      "        -2.5093, -2.7781], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5912, -2.6091, -2.5992, -2.6084, -2.5860, -2.5749, -2.5922, -2.6019,\n",
      "        -2.5697, -2.6064, -2.5458, -2.5556, -2.6040, -2.5879, -2.6067, -2.6026,\n",
      "        -2.5967, -2.5859, -2.6083, -2.5909, -2.5495, -2.6075, -2.5593, -2.5856,\n",
      "        -2.5925, -2.5260, -2.5380, -2.6109, -2.5913, -2.5441, -2.5851, -2.5486,\n",
      "        -2.5827, -2.5880, -2.5819, -2.5893, -2.5962, -2.6024, -2.5906, -2.5157,\n",
      "        -2.5326, -2.5488, -2.5490, -2.6029, -2.5889, -2.5981, -2.5956, -2.5944,\n",
      "        -2.5570, -2.5746], device='mps:0')\n",
      "mean: tensor(-2.5810, device='mps:0')\n",
      "iter_dt 1.13s; iter 59: train loss 0.67313 temperature: 7.9499999999999895\n",
      "mean_logits tensor([-2.8279, -2.4852, -2.4425, -2.4226, -2.6744, -2.1196, -2.4791, -2.4135,\n",
      "        -2.4993, -2.8286, -2.5137, -2.6366, -2.5396, -2.2533, -2.3394, -2.7730,\n",
      "        -2.4972, -2.3683, -2.4779, -2.5247, -2.4599, -2.8183, -2.4274, -2.6238,\n",
      "        -2.3530, -2.2828, -2.1177, -2.4625, -2.6428, -2.5014, -2.4457, -2.7604,\n",
      "        -2.7352, -2.6700, -2.4218, -2.5535, -2.5959, -2.6446, -2.5786, -2.7089,\n",
      "        -2.7107, -2.5400, -2.2177, -2.5503, -2.5944, -2.2224, -2.4147, -2.6466,\n",
      "        -2.7546, -2.3536], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5628, -2.5382, -2.5248, -2.5903, -2.5783, -2.5994, -2.5986, -2.5500,\n",
      "        -2.6041, -2.5936, -2.6062, -2.5747, -2.6081, -2.5105, -2.6036, -2.6115,\n",
      "        -2.6077, -2.6072, -2.5938, -2.6033, -2.5839, -2.5409, -2.5987, -2.5982,\n",
      "        -2.5804, -2.6060, -2.5358, -2.5991, -2.5691, -2.5815, -2.5546, -2.5894,\n",
      "        -2.5955, -2.5858, -2.5283, -2.6001, -2.6070, -2.5872, -2.5140, -2.6047,\n",
      "        -2.6074, -2.5203, -2.5990, -2.6070, -2.5982, -2.5329, -2.6059, -2.5490,\n",
      "        -2.6012, -2.6010], device='mps:0')\n",
      "mean: tensor(-2.5810, device='mps:0')\n",
      "iter_dt 1.15s; iter 60: train loss 0.83231 temperature: 7.999999999999989\n",
      "mean_logits tensor([-2.6617, -2.6870, -2.4698, -2.3793, -2.6935, -2.3584, -2.6933, -2.3711,\n",
      "        -2.2832, -2.7403, -2.5096, -2.7264, -2.6455, -2.2917, -2.4092, -2.7449,\n",
      "        -2.5675, -2.3911, -2.0363, -2.3338, -2.5052, -2.7020, -2.8233, -2.4905,\n",
      "        -2.3322, -2.2432, -2.4269, -2.3172, -2.7084, -2.4645, -2.7328, -2.9229,\n",
      "        -2.4326, -2.4822, -2.9093, -2.5461, -2.7289, -2.3948, -2.6727, -2.7719,\n",
      "        -2.3623, -2.2186, -2.4472, -2.7698, -2.5096, -2.5017, -2.4585, -2.6095,\n",
      "        -2.5733, -2.3312], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5311, -2.6088, -2.5795, -2.5893, -2.6053, -2.6028, -2.6079, -2.5073,\n",
      "        -2.6088, -2.5483, -2.6102, -2.5954, -2.6086, -2.5192, -2.6041, -2.5895,\n",
      "        -2.5867, -2.5721, -2.6076, -2.5528, -2.6052, -2.5704, -2.5835, -2.5953,\n",
      "        -2.4764, -2.6041, -2.5803, -2.5877, -2.5732, -2.5898, -2.5956, -2.6072,\n",
      "        -2.5466, -2.5939, -2.5958, -2.6069, -2.4967, -2.6023, -2.5964, -2.5533,\n",
      "        -2.5850, -2.6053, -2.5839, -2.5859, -2.5862, -2.6055, -2.5877, -2.5945,\n",
      "        -2.5805, -2.5336], device='mps:0')\n",
      "mean: tensor(-2.5809, device='mps:0')\n",
      "iter_dt 1.12s; iter 61: train loss 1.06119 temperature: 8.04999999999999\n",
      "mean_logits tensor([-2.5830, -2.4852, -2.9584, -2.4235, -2.4738, -2.7162, -2.4245, -2.2323,\n",
      "        -2.3052, -2.5102, -2.6481, -2.3307, -2.1962, -2.1406, -2.7436, -2.3654,\n",
      "        -2.5830, -2.4313, -2.6704, -2.5293, -2.6903, -2.7465, -2.7458, -2.5050,\n",
      "        -2.5630, -2.8886, -2.5338, -2.5597, -2.4287, -2.3097, -2.1713, -2.7776,\n",
      "        -2.8382, -2.4954, -2.3831, -3.0202, -2.4371, -2.6188, -2.6219, -2.6421,\n",
      "        -2.2302, -2.4638, -2.1578, -2.4774, -2.1060, -2.7101, -2.3172, -2.4701,\n",
      "        -2.4496, -2.7850], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5860, -2.5785, -2.6077, -2.5890, -2.6020, -2.6019, -2.5983, -2.5863,\n",
      "        -2.6064, -2.6114, -2.5590, -2.5965, -2.6016, -2.5731, -2.5998, -2.5026,\n",
      "        -2.6020, -2.5934, -2.5912, -2.6065, -2.5839, -2.6064, -2.5908, -2.6068,\n",
      "        -2.5983, -2.5825, -2.5882, -2.5728, -2.5847, -2.6002, -2.5858, -2.6046,\n",
      "        -2.5655, -2.6041, -2.5532, -2.5863, -2.5373, -2.5628, -2.5648, -2.5865,\n",
      "        -2.6074, -2.5483, -2.5558, -2.5964, -2.6076, -2.6042, -2.5978, -2.4806,\n",
      "        -2.5047, -2.5560], device='mps:0')\n",
      "mean: tensor(-2.5823, device='mps:0')\n",
      "iter_dt 1.10s; iter 62: train loss 0.75994 temperature: 8.09999999999999\n",
      "mean_logits tensor([-2.8513, -2.4365, -2.6290, -2.2219, -2.4976, -2.4942, -2.5589, -2.5131,\n",
      "        -2.5010, -2.4917, -2.3505, -2.2141, -2.3866, -2.3040, -2.4239, -2.1462,\n",
      "        -2.4832, -2.6520, -2.3453, -2.5654, -2.5442, -2.4303, -2.4528, -2.2237,\n",
      "        -2.4208, -2.3138, -2.3612, -2.4759, -2.5816, -2.3022, -2.1557, -2.4810,\n",
      "        -2.4820, -2.4006, -2.1512, -2.5811, -2.8561, -2.5507, -2.6416, -2.7984,\n",
      "        -2.4755, -2.4926, -2.5488, -2.5574, -2.1564, -2.6881, -2.4372, -2.6105,\n",
      "        -2.5259, -2.3500], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6060, -2.5928, -2.5869, -2.4585, -2.5977, -2.5749, -2.5790, -2.5568,\n",
      "        -2.5174, -2.5980, -2.5788, -2.6082, -2.5926, -2.5906, -2.5665, -2.5486,\n",
      "        -2.6138, -2.5952, -2.5925, -2.5593, -2.5897, -2.5986, -2.5411, -2.6082,\n",
      "        -2.5975, -2.5307, -2.5956, -2.5980, -2.5708, -2.5871, -2.5985, -2.6023,\n",
      "        -2.5451, -2.5764, -2.5253, -2.5901, -2.5521, -2.5564, -2.6083, -2.5915,\n",
      "        -2.5172, -2.5962, -2.6030, -2.5949, -2.5936, -2.5909, -2.6043, -2.5922,\n",
      "        -2.6011, -2.6076], device='mps:0')\n",
      "mean: tensor(-2.5796, device='mps:0')\n",
      "iter_dt 1.09s; iter 63: train loss 0.47319 temperature: 8.149999999999991\n",
      "mean_logits tensor([-2.6052, -2.5412, -2.1957, -2.2919, -2.4357, -2.6684, -2.2229, -2.5737,\n",
      "        -2.5499, -2.0893, -2.6608, -2.6297, -2.7032, -2.5329, -2.7393, -2.5698,\n",
      "        -2.4905, -2.6679, -2.4623, -2.4434, -2.7284, -2.6355, -2.5704, -2.3867,\n",
      "        -2.5662, -2.6953, -2.4845, -2.7639, -2.4748, -2.5577, -2.5120, -2.8505,\n",
      "        -2.7212, -2.7421, -2.6253, -2.5334, -2.5657, -2.6136, -2.6208, -2.8660,\n",
      "        -2.4763, -2.6024, -2.6235, -2.4902, -2.6238, -2.6815, -2.4425, -2.4931,\n",
      "        -2.6700, -2.5227], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6080, -2.5485, -2.6032, -2.5392, -2.5765, -2.6082, -2.5309, -2.5970,\n",
      "        -2.5907, -2.5944, -2.6081, -2.6000, -2.6047, -2.5800, -2.6080, -2.6070,\n",
      "        -2.5934, -2.5816, -2.5346, -2.6049, -2.6074, -2.5917, -2.5688, -2.5501,\n",
      "        -2.5740, -2.6107, -2.6090, -2.6060, -2.6040, -2.6102, -2.5892, -2.5461,\n",
      "        -2.6098, -2.5425, -2.6078, -2.5987, -2.6080, -2.5989, -2.6074, -2.5579,\n",
      "        -2.5610, -2.5703, -2.6075, -2.5400, -2.6106, -2.5613, -2.5988, -2.5973,\n",
      "        -2.5482, -2.6038], device='mps:0')\n",
      "mean: tensor(-2.5863, device='mps:0')\n",
      "iter_dt 1.11s; iter 64: train loss 0.63843 temperature: 8.199999999999992\n",
      "mean_logits tensor([-2.2425, -2.8331, -2.7212, -2.6433, -2.6553, -2.6128, -2.3213, -2.6315,\n",
      "        -2.6118, -2.6690, -2.7261, -2.6081, -2.5279, -2.2958, -2.5821, -2.4834,\n",
      "        -2.6941, -2.4366, -2.2867, -2.4807, -2.5521, -2.5213, -2.5853, -2.4080,\n",
      "        -2.2918, -2.5537, -2.5470, -2.5739, -2.8398, -2.6893, -2.3019, -2.2910,\n",
      "        -2.3651, -2.6897, -2.5794, -2.7843, -2.6260, -2.3075, -2.5824, -2.8150,\n",
      "        -2.3253, -2.2789, -2.3855, -2.5969, -2.4951, -2.2664, -2.7471, -2.3709,\n",
      "        -2.3662, -2.5702], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5931, -2.5846, -2.5875, -2.6076, -2.5904, -2.5552, -2.6065, -2.5680,\n",
      "        -2.6089, -2.5811, -2.5977, -2.5842, -2.5926, -2.5893, -2.5158, -2.5310,\n",
      "        -2.6040, -2.5855, -2.6055, -2.5427, -2.6059, -2.6000, -2.6033, -2.6010,\n",
      "        -2.5955, -2.5689, -2.5833, -2.5924, -2.6049, -2.6129, -2.5702, -2.6104,\n",
      "        -2.6071, -2.6075, -2.6000, -2.5991, -2.5830, -2.6040, -2.6083, -2.5858,\n",
      "        -2.5834, -2.6067, -2.5686, -2.6064, -2.5111, -2.5264, -2.5665, -2.5512,\n",
      "        -2.5589, -2.5926], device='mps:0')\n",
      "mean: tensor(-2.5849, device='mps:0')\n",
      "iter_dt 1.09s; iter 65: train loss 0.51418 temperature: 8.249999999999993\n",
      "mean_logits tensor([-2.4295, -2.5137, -2.7702, -2.7221, -2.5300, -2.4620, -2.4184, -2.6736,\n",
      "        -2.4004, -2.5407, -2.5912, -2.7149, -2.3952, -2.4869, -2.6386, -2.4785,\n",
      "        -2.2736, -2.1932, -2.8067, -2.5944, -2.7057, -2.5465, -2.5481, -2.6792,\n",
      "        -2.5975, -2.1739, -2.3871, -2.5375, -2.6296, -2.4486, -2.5022, -2.5050,\n",
      "        -2.5087, -2.3081, -2.6691, -2.6191, -2.5532, -2.6329, -2.9530, -2.3581,\n",
      "        -2.6329, -2.5085, -2.5480, -2.7857, -2.5084, -2.6950, -2.3754, -2.5216,\n",
      "        -2.5080, -2.7194], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6016, -2.5839, -2.5982, -2.5948, -2.5891, -2.5863, -2.5892, -2.6039,\n",
      "        -2.5979, -2.5763, -2.5616, -2.5881, -2.5455, -2.5336, -2.5886, -2.5888,\n",
      "        -2.6058, -2.5847, -2.6072, -2.6085, -2.6046, -2.5880, -2.5644, -2.5848,\n",
      "        -2.5850, -2.5671, -2.6002, -2.4779, -2.5871, -2.6019, -2.5849, -2.5878,\n",
      "        -2.5567, -2.5361, -2.5967, -2.6042, -2.5802, -2.5899, -2.5991, -2.5946,\n",
      "        -2.6082, -2.5922, -2.5397, -2.5997, -2.5879, -2.6066, -2.6025, -2.5806,\n",
      "        -2.6062, -2.5888], device='mps:0')\n",
      "mean: tensor(-2.5847, device='mps:0')\n",
      "iter_dt 1.11s; iter 66: train loss 0.57980 temperature: 8.299999999999994\n",
      "mean_logits tensor([-2.5678, -2.5511, -2.6024, -2.5468, -2.5265, -2.5363, -2.7272, -2.6062,\n",
      "        -2.3195, -2.2733, -2.4525, -2.7244, -2.2755, -2.6086, -2.5181, -2.4351,\n",
      "        -2.6275, -2.3644, -2.4975, -2.7423, -2.5935, -2.6000, -2.4558, -2.4098,\n",
      "        -2.7711, -2.4819, -2.3421, -2.0114, -2.6154, -2.2719, -2.5324, -2.3086,\n",
      "        -2.7123, -2.5365, -2.3432, -2.3558, -2.4495, -2.2922, -2.5348, -2.3359,\n",
      "        -2.6801, -2.6044, -2.4767, -2.3712, -2.4297, -2.6339, -2.7558, -2.4785,\n",
      "        -2.7039, -2.5979], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5851, -2.5989, -2.5980, -2.6074, -2.5717, -2.5988, -2.6072, -2.6158,\n",
      "        -2.5875, -2.5766, -2.6065, -2.5865, -2.6079, -2.6062, -2.5862, -2.5146,\n",
      "        -2.5945, -2.5897, -2.5947, -2.5951, -2.5873, -2.5858, -2.6065, -2.5782,\n",
      "        -2.5925, -2.6075, -2.6121, -2.5202, -2.5840, -2.5989, -2.6044, -2.5416,\n",
      "        -2.5916, -2.6081, -2.6031, -2.5984, -2.5898, -2.6068, -2.5964, -2.5996,\n",
      "        -2.5834, -2.5909, -2.5130, -2.6056, -2.5984, -2.5859, -2.5686, -2.6056,\n",
      "        -2.5945, -2.5691], device='mps:0')\n",
      "mean: tensor(-2.5891, device='mps:0')\n",
      "iter_dt 1.10s; iter 67: train loss 0.59141 temperature: 8.349999999999994\n",
      "mean_logits tensor([-2.4951, -2.2668, -2.6496, -2.7443, -2.4712, -2.7253, -2.6310, -2.6557,\n",
      "        -2.7110, -2.4306, -2.5949, -2.5048, -2.6819, -2.6265, -2.4676, -2.6022,\n",
      "        -2.7920, -2.4859, -2.9759, -2.6592, -2.5561, -2.5018, -2.5046, -2.3149,\n",
      "        -2.3048, -2.4675, -2.3789, -2.4189, -2.7165, -2.3757, -2.5920, -2.4750,\n",
      "        -2.6373, -2.5134, -2.4382, -2.7140, -2.6394, -2.7419, -2.4221, -2.4247,\n",
      "        -2.1768, -2.6159, -2.1597, -2.4426, -2.6631, -2.7001, -2.5148, -2.6074,\n",
      "        -2.3599, -2.3291], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6029, -2.5374, -2.5778, -2.5940, -2.5210, -2.5581, -2.5809, -2.6108,\n",
      "        -2.6081, -2.6055, -2.5984, -2.5404, -2.5983, -2.5813, -2.5388, -2.5961,\n",
      "        -2.5920, -2.6057, -2.5866, -2.6094, -2.6073, -2.5877, -2.5574, -2.5836,\n",
      "        -2.5759, -2.5878, -2.6082, -2.5850, -2.6094, -2.5971, -2.5901, -2.5916,\n",
      "        -2.5987, -2.5910, -2.6077, -2.5989, -2.5899, -2.5758, -2.6093, -2.6074,\n",
      "        -2.5833, -2.6071, -2.5837, -2.5875, -2.5757, -2.5981, -2.4821, -2.5941,\n",
      "        -2.5967, -2.5463], device='mps:0')\n",
      "mean: tensor(-2.5852, device='mps:0')\n",
      "iter_dt 1.08s; iter 68: train loss 0.59459 temperature: 8.399999999999995\n",
      "mean_logits tensor([-2.4229, -2.6255, -2.4954, -2.5506, -2.2546, -2.5682, -2.2354, -2.3218,\n",
      "        -2.3849, -2.6625, -2.4734, -2.1888, -2.5786, -2.5717, -2.3933, -2.5250,\n",
      "        -2.4191, -2.2567, -2.5290, -2.5771, -2.6353, -2.4131, -2.3832, -2.6178,\n",
      "        -2.5404, -2.3670, -2.5066, -2.3370, -2.6284, -2.5844, -2.5249, -2.8335,\n",
      "        -2.4077, -2.3020, -2.6873, -2.9292, -2.3925, -2.6562, -2.6664, -2.5579,\n",
      "        -2.6297, -2.5972, -2.6659, -2.4926, -2.5869, -2.4906, -2.4616, -2.7247,\n",
      "        -2.4149, -2.1951], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5946, -2.6028, -2.6060, -2.5529, -2.5066, -2.5778, -2.5706, -2.5969,\n",
      "        -2.5904, -2.5894, -2.5482, -2.6053, -2.5954, -2.5831, -2.5983, -2.5840,\n",
      "        -2.6060, -2.5928, -2.5487, -2.5715, -2.5931, -2.5879, -2.5382, -2.5699,\n",
      "        -2.5920, -2.5620, -2.5971, -2.5958, -2.6042, -2.5899, -2.5734, -2.5968,\n",
      "        -2.5717, -2.5873, -2.5773, -2.5800, -2.5420, -2.6065, -2.6050, -2.6082,\n",
      "        -2.5901, -2.4464, -2.5979, -2.5956, -2.5775, -2.5679, -2.6082, -2.5905,\n",
      "        -2.5357, -2.5815], device='mps:0')\n",
      "mean: tensor(-2.5798, device='mps:0')\n",
      "iter_dt 1.10s; iter 69: train loss 0.74621 temperature: 8.449999999999996\n",
      "mean_logits tensor([-2.4043, -2.7467, -2.1918, -2.4563, -2.2580, -2.7926, -2.3144, -2.5362,\n",
      "        -2.4107, -2.5211, -2.3931, -2.2631, -2.3976, -2.3685, -2.3799, -2.6416,\n",
      "        -2.3721, -2.5490, -2.4683, -2.7655, -2.8270, -2.3084, -2.4956, -2.7702,\n",
      "        -2.4582, -2.5252, -2.3231, -2.4448, -2.4287, -2.5064, -2.5249, -2.3322,\n",
      "        -2.2880, -2.6641, -2.4006, -2.4667, -2.2834, -2.7132, -2.4898, -2.5438,\n",
      "        -2.5557, -2.4298, -2.6185, -2.4544, -2.5139, -2.1753, -2.5912, -2.8130,\n",
      "        -2.5093, -2.5286], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6011, -2.5919, -2.4877, -2.6057, -2.5851, -2.5853, -2.6075, -2.5122,\n",
      "        -2.6063, -2.5863, -2.5142, -2.6022, -2.6054, -2.5819, -2.6077, -2.5992,\n",
      "        -2.5944, -2.5899, -2.5646, -2.5845, -2.5420, -2.5722, -2.5426, -2.5780,\n",
      "        -2.6067, -2.5840, -2.5982, -2.5868, -2.6023, -2.5793, -2.5860, -2.5929,\n",
      "        -2.6080, -2.4954, -2.5947, -2.5994, -2.6081, -2.5621, -2.5258, -2.5950,\n",
      "        -2.5867, -2.5832, -2.6090, -2.6075, -2.5989, -2.5923, -2.5377, -2.5990,\n",
      "        -2.5874, -2.6073], device='mps:0')\n",
      "mean: tensor(-2.5816, device='mps:0')\n",
      "iter_dt 1.10s; iter 70: train loss 0.77412 temperature: 8.499999999999996\n",
      "mean_logits tensor([-2.8045, -2.0640, -2.5882, -2.6255, -2.9820, -2.6777, -2.5262, -2.3953,\n",
      "        -2.4335, -2.4021, -2.6066, -2.5051, -2.4953, -2.6935, -2.6129, -2.5952,\n",
      "        -2.6836, -2.3209, -2.4301, -2.5741, -2.4752, -2.6406, -2.3142, -2.4394,\n",
      "        -2.5881, -2.5812, -2.8069, -2.3200, -2.7167, -2.3399, -2.4536, -2.4676,\n",
      "        -2.5971, -3.0455, -2.5055, -2.4643, -2.6947, -2.3766, -2.4659, -2.2383,\n",
      "        -2.6786, -2.4069, -2.5116, -2.7117, -2.6296, -2.6183, -2.8647, -2.5773,\n",
      "        -2.4341, -2.4155], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5981, -2.5354, -2.6113, -2.5347, -2.5953, -2.5965, -2.6059, -2.5956,\n",
      "        -2.6006, -2.5517, -2.5797, -2.5758, -2.5852, -2.6065, -2.6116, -2.5903,\n",
      "        -2.6016, -2.5870, -2.5980, -2.5934, -2.6070, -2.5345, -2.5490, -2.5562,\n",
      "        -2.5033, -2.5881, -2.5708, -2.5888, -2.5869, -2.5961, -2.5471, -2.5907,\n",
      "        -2.5832, -2.6006, -2.5981, -2.5567, -2.5754, -2.5779, -2.5899, -2.5877,\n",
      "        -2.5292, -2.5307, -2.6081, -2.5994, -2.5184, -2.5852, -2.6038, -2.5908,\n",
      "        -2.5998, -2.5968], device='mps:0')\n",
      "mean: tensor(-2.5801, device='mps:0')\n",
      "iter_dt 1.07s; iter 71: train loss 0.57418 temperature: 8.549999999999997\n",
      "mean_logits tensor([-2.3432, -2.5972, -2.4253, -2.7515, -2.1991, -2.3604, -2.4247, -2.7386,\n",
      "        -2.8164, -2.5534, -2.4688, -2.6159, -2.5691, -2.4726, -2.6729, -2.5314,\n",
      "        -2.7359, -2.4717, -2.6003, -2.3096, -2.6101, -2.5749, -2.4281, -2.7054,\n",
      "        -2.5568, -2.6037, -2.3735, -2.5043, -2.1120, -2.4978, -2.4882, -2.6181,\n",
      "        -2.5713, -2.6392, -2.5911, -2.5003, -2.4504, -2.5746, -2.6737, -2.4787,\n",
      "        -2.9759, -2.7504, -2.6001, -2.2822, -2.3634, -2.6494, -2.5164, -2.5988,\n",
      "        -2.2375, -2.2686], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5486, -2.6064, -2.6083, -2.6148, -2.5905, -2.5683, -2.6085, -2.5969,\n",
      "        -2.6070, -2.5817, -2.6006, -2.5997, -2.5752, -2.5462, -2.5910, -2.5906,\n",
      "        -2.6127, -2.4956, -2.5858, -2.5830, -2.5986, -2.6081, -2.5372, -2.6075,\n",
      "        -2.5988, -2.5528, -2.6048, -2.5234, -2.5742, -2.6029, -2.6082, -2.5821,\n",
      "        -2.5568, -2.6076, -2.5901, -2.5376, -2.5854, -2.5674, -2.5982, -2.6279,\n",
      "        -2.6061, -2.6088, -2.5508, -2.5897, -2.5430, -2.5688, -2.6056, -2.5971,\n",
      "        -2.5956, -2.5352], device='mps:0')\n",
      "mean: tensor(-2.5836, device='mps:0')\n",
      "iter_dt 1.14s; iter 72: train loss 0.43592 temperature: 8.599999999999998\n",
      "mean_logits tensor([-2.6112, -2.5025, -2.3923, -2.5032, -2.5240, -2.5573, -2.4893, -2.2147,\n",
      "        -2.8034, -2.5076, -2.6514, -2.4505, -2.3861, -2.4270, -2.6367, -2.8595,\n",
      "        -2.5772, -2.5438, -2.5860, -2.5268, -2.2726, -2.5233, -2.8144, -2.5291,\n",
      "        -2.6182, -2.5942, -2.4966, -2.6201, -2.5488, -2.4726, -2.7899, -2.6294,\n",
      "        -2.7472, -2.5118, -2.4536, -2.3880, -2.5848, -2.6753, -2.6720, -2.5184,\n",
      "        -2.5272, -2.7455, -2.5161, -2.4864, -2.6875, -2.3815, -2.4937, -2.5817,\n",
      "        -2.5029, -2.4204], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5984, -2.5919, -2.5463, -2.5999, -2.6019, -2.6086, -2.5936, -2.5583,\n",
      "        -2.6031, -2.6035, -2.5271, -2.6055, -2.5786, -2.5992, -2.6040, -2.5455,\n",
      "        -2.5360, -2.5972, -2.5927, -2.5801, -2.5755, -2.6071, -2.5112, -2.6128,\n",
      "        -2.5946, -2.5444, -2.5214, -2.5372, -2.5919, -2.5401, -2.5909, -2.5969,\n",
      "        -2.5901, -2.6050, -2.5935, -2.5894, -2.6060, -2.5826, -2.5877, -2.6061,\n",
      "        -2.5941, -2.5826, -2.6069, -2.5941, -2.5881, -2.5800, -2.5780, -2.6085,\n",
      "        -2.6035, -2.5465], device='mps:0')\n",
      "mean: tensor(-2.5828, device='mps:0')\n",
      "iter_dt 1.08s; iter 73: train loss 0.77378 temperature: 8.649999999999999\n",
      "mean_logits tensor([-2.8216, -2.6626, -3.0776, -2.5837, -2.3025, -2.6560, -2.8133, -2.5249,\n",
      "        -2.5004, -2.5845, -2.3415, -2.6320, -2.5574, -2.7970, -2.5511, -2.4040,\n",
      "        -2.4123, -2.5711, -2.2775, -2.6761, -2.5337, -2.3450, -2.7807, -2.6308,\n",
      "        -2.8678, -2.4546, -2.5138, -2.5656, -2.4859, -2.5197, -2.3002, -2.6911,\n",
      "        -2.4687, -2.5786, -2.3655, -2.3201, -2.5637, -2.3934, -2.3798, -2.5410,\n",
      "        -2.3499, -2.5113, -2.7701, -2.3745, -2.3534, -2.6058, -2.5830, -2.5930,\n",
      "        -2.3104, -2.6676], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5478, -2.5904, -2.5445, -2.5770, -2.5851, -2.5973, -2.6060, -2.5906,\n",
      "        -2.5767, -2.5742, -2.6074, -2.4936, -2.6047, -2.6069, -2.5810, -2.5868,\n",
      "        -2.5814, -2.5433, -2.5458, -2.6016, -2.5644, -2.5358, -2.6057, -2.6116,\n",
      "        -2.5815, -2.5851, -2.5368, -2.6062, -2.5860, -2.5952, -2.6077, -2.5967,\n",
      "        -2.5896, -2.5781, -2.5983, -2.5811, -2.5312, -2.5818, -2.6072, -2.5721,\n",
      "        -2.5560, -2.5929, -2.6069, -2.5996, -2.5570, -2.5591, -2.5455, -2.5970,\n",
      "        -2.5950, -2.5309], device='mps:0')\n",
      "mean: tensor(-2.5787, device='mps:0')\n",
      "iter_dt 1.08s; iter 74: train loss 0.58257 temperature: 8.7\n",
      "mean_logits tensor([-2.4458, -2.6258, -2.7270, -2.4381, -2.5316, -2.7705, -2.5733, -2.3598,\n",
      "        -2.7315, -2.6598, -2.5904, -2.2424, -2.2329, -2.4034, -2.4353, -2.7038,\n",
      "        -2.4767, -2.5120, -2.4989, -2.5789, -2.5727, -2.6714, -2.6862, -2.5000,\n",
      "        -2.3211, -2.5593, -2.6846, -2.4450, -2.5766, -2.4797, -2.4971, -2.5171,\n",
      "        -2.4435, -2.6269, -2.4353, -2.2731, -2.7255, -2.5640, -2.5259, -2.7589,\n",
      "        -2.4967, -2.2729, -2.2804, -2.4427, -2.5280, -2.5902, -2.4577, -2.6499,\n",
      "        -2.4850, -2.0207], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5287, -2.6092, -2.5808, -2.5854, -2.6007, -2.5886, -2.5908, -2.6061,\n",
      "        -2.5722, -2.5511, -2.5740, -2.4636, -2.5963, -2.5772, -2.6073, -2.5466,\n",
      "        -2.5980, -2.5922, -2.5979, -2.5721, -2.5953, -2.5913, -2.5900, -2.5999,\n",
      "        -2.6065, -2.5772, -2.5471, -2.5904, -2.5949, -2.5965, -2.5851, -2.6095,\n",
      "        -2.5792, -2.5940, -2.5719, -2.6071, -2.5125, -2.5726, -2.5864, -2.4729,\n",
      "        -2.5224, -2.6006, -2.5806, -2.5593, -2.5675, -2.6044, -2.5936, -2.6072,\n",
      "        -2.6082, -2.5967], device='mps:0')\n",
      "mean: tensor(-2.5792, device='mps:0')\n",
      "iter_dt 1.09s; iter 75: train loss 0.76968 temperature: 8.75\n",
      "mean_logits tensor([-2.6134, -2.5079, -2.4799, -2.6727, -2.4896, -2.5220, -2.4872, -2.5814,\n",
      "        -2.4048, -2.6874, -2.9923, -2.4275, -2.3966, -2.5297, -2.7181, -2.7409,\n",
      "        -2.9362, -2.4848, -2.5331, -2.7872, -2.8725, -2.4878, -2.7964, -2.6676,\n",
      "        -2.0887, -2.6018, -2.6588, -2.2572, -2.3968, -2.6835, -2.5871, -2.3824,\n",
      "        -2.6186, -2.4625, -2.6202, -2.7057, -2.5592, -2.4239, -2.2221, -2.4136,\n",
      "        -2.6682, -2.3870, -2.5034, -2.4054, -2.4165, -2.5744, -2.3009, -2.6639,\n",
      "        -2.5432, -2.7138], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6036, -2.5889, -2.6005, -2.6024, -2.5645, -2.5854, -2.6076, -2.4943,\n",
      "        -2.6073, -2.6049, -2.5362, -2.6022, -2.6061, -2.5626, -2.6044, -2.5914,\n",
      "        -2.6000, -2.4807, -2.5994, -2.6081, -2.5863, -2.6076, -2.6079, -2.6031,\n",
      "        -2.6108, -2.5848, -2.6124, -2.6117, -2.5498, -2.5919, -2.5990, -2.6007,\n",
      "        -2.5992, -2.6080, -2.5603, -2.6078, -2.6083, -2.5983, -2.5979, -2.6080,\n",
      "        -2.6103, -2.5932, -2.6060, -2.5344, -2.6019, -2.5455, -2.6081, -2.5743,\n",
      "        -2.5591, -2.5870], device='mps:0')\n",
      "mean: tensor(-2.5885, device='mps:0')\n",
      "iter_dt 1.11s; iter 76: train loss 0.83116 temperature: 8.8\n",
      "mean_logits tensor([-2.9470, -2.5027, -2.7653, -3.2424, -2.6506, -2.7576, -2.4294, -2.6251,\n",
      "        -2.4651, -2.5417, -2.3991, -2.4832, -2.7868, -2.7935, -2.4643, -2.5032,\n",
      "        -2.6009, -2.2939, -2.6994, -2.5871, -2.6420, -2.4437, -2.7593, -2.6026,\n",
      "        -2.4759, -2.6039, -2.6345, -2.4805, -2.7612, -2.6169, -2.6593, -2.7062,\n",
      "        -2.4627, -2.6593, -2.4118, -2.3812, -2.6081, -2.5586, -2.6430, -2.7536,\n",
      "        -2.5205, -2.5433, -2.7895, -2.3753, -2.6134, -2.6686, -2.4893, -2.6656,\n",
      "        -2.6921, -2.7156], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5987, -2.5737, -2.6039, -2.6079, -2.5944, -2.5977, -2.5959, -2.5648,\n",
      "        -2.5877, -2.5975, -2.5348, -2.5400, -2.6070, -2.5935, -2.5210, -2.6107,\n",
      "        -2.5938, -2.5915, -2.5663, -2.6102, -2.6035, -2.6029, -2.5929, -2.4798,\n",
      "        -2.5880, -2.5425, -2.5944, -2.5523, -2.5879, -2.6052, -2.5678, -2.5484,\n",
      "        -2.6105, -2.6085, -2.5782, -2.5120, -2.6056, -2.5936, -2.5906, -2.5814,\n",
      "        -2.5704, -2.6020, -2.5810, -2.5906, -2.5802, -2.5329, -2.6090, -2.6077,\n",
      "        -2.6055, -2.5971], device='mps:0')\n",
      "mean: tensor(-2.5823, device='mps:0')\n",
      "iter_dt 1.10s; iter 77: train loss 0.78655 temperature: 8.850000000000001\n",
      "mean_logits tensor([-2.7155, -2.3995, -2.8820, -2.7895, -2.3421, -2.4047, -2.2757, -2.8429,\n",
      "        -2.7402, -2.6164, -2.8794, -2.6127, -2.3879, -2.4701, -2.5470, -2.5753,\n",
      "        -2.5803, -2.8450, -2.5847, -2.3731, -2.3563, -2.4244, -2.7454, -2.4401,\n",
      "        -2.7395, -2.4140, -2.4519, -2.5345, -2.7795, -2.5457, -2.5555, -2.6457,\n",
      "        -2.5503, -2.6656, -2.6570, -2.6741, -2.6157, -3.0351, -2.7642, -2.8643,\n",
      "        -2.4045, -2.7404, -2.5020, -2.5290, -2.5763, -2.4281, -2.6323, -2.7867,\n",
      "        -2.7270, -2.6134], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5893, -2.5205, -2.5975, -2.5834, -2.5820, -2.5859, -2.6090, -2.5684,\n",
      "        -2.5882, -2.6040, -2.5820, -2.6063, -2.6000, -2.5458, -2.5861, -2.6086,\n",
      "        -2.5988, -2.5851, -2.4878, -2.5849, -2.5906, -2.5281, -2.5695, -2.6082,\n",
      "        -2.5984, -2.5417, -2.5935, -2.5950, -2.5459, -2.5875, -2.5860, -2.5992,\n",
      "        -2.5971, -2.5925, -2.5990, -2.6060, -2.5894, -2.6073, -2.5886, -2.5758,\n",
      "        -2.5937, -2.6044, -2.6078, -2.5949, -2.5949, -2.6067, -2.6070, -2.5868,\n",
      "        -2.5602, -2.5861], device='mps:0')\n",
      "mean: tensor(-2.5851, device='mps:0')\n",
      "iter_dt 1.12s; iter 78: train loss 0.65691 temperature: 8.900000000000002\n",
      "mean_logits tensor([-2.3993, -2.6896, -3.0513, -2.4818, -2.5842, -2.5949, -2.4185, -2.4709,\n",
      "        -2.4729, -2.4288, -2.4417, -2.5810, -2.6902, -2.7339, -2.5491, -2.6561,\n",
      "        -2.9016, -2.3732, -2.6849, -2.5531, -2.3917, -2.6329, -2.6915, -2.7567,\n",
      "        -2.4334, -2.5338, -2.2893, -2.4388, -2.4210, -2.3049, -2.6131, -2.2303,\n",
      "        -2.5694, -2.6196, -2.6252, -2.3949, -2.7183, -2.6536, -2.4399, -2.5834,\n",
      "        -2.4192, -2.5321, -2.4097, -2.6929, -2.6264, -2.3027, -2.3233, -2.5215,\n",
      "        -2.6026, -2.7527], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6073, -2.6075, -2.5887, -2.5878, -2.5768, -2.5857, -2.6023, -2.5456,\n",
      "        -2.5424, -2.5911, -2.4929, -2.5911, -2.5989, -2.5932, -2.5654, -2.6034,\n",
      "        -2.5786, -2.6090, -2.5912, -2.5647, -2.6030, -2.5350, -2.5944, -2.5875,\n",
      "        -2.5973, -2.5471, -2.5833, -2.5908, -2.5998, -2.5727, -2.5931, -2.5743,\n",
      "        -2.5409, -2.6050, -2.6010, -2.5873, -2.5852, -2.5894, -2.6152, -2.5919,\n",
      "        -2.5994, -2.5747, -2.5972, -2.6080, -2.5833, -2.5996, -2.5942, -2.4928,\n",
      "        -2.5814, -2.5896], device='mps:0')\n",
      "mean: tensor(-2.5828, device='mps:0')\n",
      "iter_dt 1.08s; iter 79: train loss 0.52990 temperature: 8.950000000000003\n",
      "mean_logits tensor([-2.6079, -2.5939, -2.6481, -2.6660, -2.6395, -2.4025, -2.7187, -2.5550,\n",
      "        -2.6737, -2.4419, -2.5958, -2.6038, -2.5880, -2.7113, -2.5560, -2.5335,\n",
      "        -2.9282, -2.3052, -2.6457, -2.5013, -2.4994, -2.5157, -2.6287, -2.5879,\n",
      "        -2.4886, -2.4817, -2.5023, -2.5794, -2.7482, -2.7382, -2.4649, -2.2797,\n",
      "        -2.3077, -2.6980, -2.3519, -2.6908, -2.3010, -2.6664, -2.8026, -2.3671,\n",
      "        -2.7454, -2.4693, -2.6960, -2.4670, -2.5360, -2.7126, -2.1951, -2.4059,\n",
      "        -2.2526, -2.6883], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6100, -2.4869, -2.6048, -2.6059, -2.5899, -2.5909, -2.5882, -2.6059,\n",
      "        -2.5903, -2.6080, -2.5744, -2.6079, -2.6076, -2.6059, -2.5753, -2.5533,\n",
      "        -2.5944, -2.5880, -2.5428, -2.6098, -2.5462, -2.5887, -2.6079, -2.5895,\n",
      "        -2.5454, -2.5811, -2.5491, -2.5772, -2.5657, -2.6058, -2.5943, -2.6084,\n",
      "        -2.6078, -2.6083, -2.6017, -2.5607, -2.5393, -2.5985, -2.5948, -2.6092,\n",
      "        -2.6046, -2.5570, -2.5965, -2.5504, -2.5350, -2.5733, -2.5694, -2.5586,\n",
      "        -2.5957, -2.6047], device='mps:0')\n",
      "mean: tensor(-2.5833, device='mps:0')\n",
      "iter_dt 1.11s; iter 80: train loss 0.55550 temperature: 9.000000000000004\n",
      "mean_logits tensor([-2.6025, -2.3810, -2.4288, -2.5890, -2.6238, -2.6975, -2.7445, -2.9253,\n",
      "        -2.4684, -2.5802, -2.4441, -2.4343, -2.6421, -2.7332, -2.7023, -2.5958,\n",
      "        -2.6181, -2.4874, -2.6301, -2.7770, -2.6283, -2.5462, -2.2857, -2.4068,\n",
      "        -2.3730, -2.5682, -2.5391, -2.8622, -2.2841, -2.3713, -2.6214, -2.6448,\n",
      "        -2.7593, -2.8147, -2.5795, -2.4473, -2.6478, -2.5621, -2.7084, -2.4715,\n",
      "        -2.4585, -2.5429, -2.5357, -2.4662, -2.6599, -2.4291, -2.0762, -2.6718,\n",
      "        -2.5812, -2.6304], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6076, -2.5853, -2.5846, -2.6095, -2.5842, -2.5715, -2.5932, -2.6084,\n",
      "        -2.6071, -2.5864, -2.5665, -2.6083, -2.5257, -2.5910, -2.6048, -2.5917,\n",
      "        -2.6041, -2.6091, -2.6104, -2.5427, -2.5870, -2.5856, -2.5633, -2.6101,\n",
      "        -2.5143, -2.5766, -2.5892, -2.5718, -2.6062, -2.5688, -2.6089, -2.5989,\n",
      "        -2.6031, -2.6059, -2.5973, -2.5504, -2.5429, -2.5442, -2.4963, -2.6001,\n",
      "        -2.6058, -2.5861, -2.5987, -2.4772, -2.5765, -2.5971, -2.5907, -2.6070,\n",
      "        -2.6012, -2.5569], device='mps:0')\n",
      "mean: tensor(-2.5822, device='mps:0')\n",
      "iter_dt 1.10s; iter 81: train loss 0.57766 temperature: 9.050000000000004\n",
      "mean_logits tensor([-2.6489, -2.3537, -2.5294, -2.5410, -2.6688, -2.2899, -2.6514, -2.4842,\n",
      "        -2.3027, -2.3652, -2.5600, -2.5924, -2.3927, -2.8818, -2.2755, -2.5800,\n",
      "        -2.6592, -2.7901, -2.2433, -2.5628, -2.5398, -2.4164, -2.4049, -2.5414,\n",
      "        -2.4688, -2.6071, -2.6978, -2.5810, -2.6437, -2.4038, -2.7354, -2.7185,\n",
      "        -2.5729, -2.3311, -2.7049, -2.7343, -2.3293, -2.4754, -2.4905, -2.5106,\n",
      "        -2.8330, -2.5219, -2.7234, -2.8739, -2.5990, -2.2847, -2.7318, -2.4656,\n",
      "        -2.6891, -2.5531], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6019, -2.6088, -2.6034, -2.5983, -2.5906, -2.5369, -2.5995, -2.5790,\n",
      "        -2.6077, -2.5989, -2.6060, -2.6088, -2.4849, -2.5907, -2.5460, -2.5940,\n",
      "        -2.5999, -2.5745, -2.5914, -2.5168, -2.5843, -2.5957, -2.5454, -2.6053,\n",
      "        -2.5443, -2.5884, -2.6082, -2.6065, -2.6048, -2.6137, -2.5854, -2.6078,\n",
      "        -2.5804, -2.5882, -2.6144, -2.6093, -2.6073, -2.6083, -2.5952, -2.5928,\n",
      "        -2.5907, -2.5759, -2.5866, -2.5911, -2.5991, -2.5973, -2.6035, -2.5916,\n",
      "        -2.6046, -2.5989], device='mps:0')\n",
      "mean: tensor(-2.5893, device='mps:0')\n",
      "iter_dt 1.12s; iter 82: train loss 0.53858 temperature: 9.100000000000005\n",
      "mean_logits tensor([-2.5213, -2.7270, -2.7225, -2.5935, -2.5824, -2.4535, -2.5404, -2.5903,\n",
      "        -2.5620, -2.4810, -2.4831, -2.5440, -2.8072, -2.8261, -2.1098, -2.5906,\n",
      "        -2.2498, -2.2965, -2.4759, -2.5392, -2.6261, -2.5415, -2.2388, -2.4890,\n",
      "        -2.5891, -2.4313, -2.8491, -2.3863, -2.5637, -2.4794, -2.2297, -2.5140,\n",
      "        -2.6707, -2.3217, -2.7935, -2.5486, -2.5330, -2.5265, -2.5757, -2.3998,\n",
      "        -2.6294, -2.7248, -2.6740, -2.5433, -2.4957, -2.6501, -2.5372, -2.3251,\n",
      "        -2.3920, -2.7077], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6048, -2.5743, -2.6069, -2.5737, -2.5963, -2.6104, -2.5572, -2.5904,\n",
      "        -2.6085, -2.5878, -2.5995, -2.6054, -2.5927, -2.6046, -2.5572, -2.6074,\n",
      "        -2.5858, -2.5956, -2.6085, -2.5773, -2.5848, -2.4859, -2.5336, -2.5405,\n",
      "        -2.5613, -2.5856, -2.5989, -2.5653, -2.5849, -2.6081, -2.5532, -2.5729,\n",
      "        -2.6085, -2.6040, -2.6022, -2.6079, -2.5968, -2.5996, -2.5890, -2.6077,\n",
      "        -2.5981, -2.6037, -2.5534, -2.5925, -2.6080, -2.5942, -2.5449, -2.5892,\n",
      "        -2.6078, -2.5614], device='mps:0')\n",
      "mean: tensor(-2.5858, device='mps:0')\n",
      "iter_dt 1.29s; iter 83: train loss 0.47904 temperature: 9.150000000000006\n",
      "mean_logits tensor([-2.5258, -2.5142, -2.6215, -2.5585, -2.5668, -2.4122, -2.2027, -2.4085,\n",
      "        -2.6852, -2.5764, -2.6529, -2.6871, -2.6352, -2.8257, -2.6120, -2.5834,\n",
      "        -2.6513, -2.4197, -2.6653, -2.7041, -2.5302, -2.6263, -2.3371, -2.7995,\n",
      "        -2.7458, -2.3592, -2.4170, -2.6156, -2.6583, -2.7185, -2.5713, -2.3633,\n",
      "        -2.3359, -2.5488, -2.4409, -2.6331, -2.7437, -2.5011, -2.4195, -2.4117,\n",
      "        -2.8136, -2.6212, -2.4669, -2.3535, -2.3060, -2.6259, -2.6880, -2.4654,\n",
      "        -2.4238, -2.5428], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5999, -2.4996, -2.5980, -2.5985, -2.6037, -2.6028, -2.5994, -2.5864,\n",
      "        -2.5183, -2.6072, -2.6068, -2.5988, -2.6020, -2.5900, -2.6059, -2.6046,\n",
      "        -2.5987, -2.6068, -2.6080, -2.5583, -2.5795, -2.6084, -2.5113, -2.5707,\n",
      "        -2.6095, -2.5848, -2.5824, -2.6002, -2.5895, -2.5872, -2.6040, -2.6022,\n",
      "        -2.5701, -2.6034, -2.5845, -2.5959, -2.5897, -2.5942, -2.5932, -2.5931,\n",
      "        -2.5883, -2.5783, -2.6119, -2.6039, -2.5866, -2.5952, -2.6079, -2.6046,\n",
      "        -2.6001, -2.5963], device='mps:0')\n",
      "mean: tensor(-2.5904, device='mps:0')\n",
      "iter_dt 1.10s; iter 84: train loss 0.78981 temperature: 9.200000000000006\n",
      "mean_logits tensor([-2.5949, -2.3979, -2.4822, -2.3482, -2.7017, -2.2545, -2.4602, -2.7207,\n",
      "        -2.7323, -2.4545, -2.4009, -2.5870, -2.5973, -2.5691, -2.5222, -2.4508,\n",
      "        -2.6428, -2.2677, -2.3966, -2.6727, -2.4900, -2.6733, -2.2754, -2.0472,\n",
      "        -2.2777, -2.6173, -2.6303, -2.4159, -2.4673, -2.4239, -2.4016, -2.5695,\n",
      "        -2.6395, -2.2048, -2.7830, -2.4020, -2.3080, -2.6705, -2.0956, -2.7199,\n",
      "        -2.7143, -2.6959, -2.4541, -2.3705, -2.8307, -2.1157, -2.5189, -2.5531,\n",
      "        -2.7865, -2.5686], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5828, -2.5847, -2.5522, -2.5324, -2.5618, -2.5774, -2.5265, -2.6031,\n",
      "        -2.5443, -2.5879, -2.6058, -2.5852, -2.5874, -2.5736, -2.5962, -2.5878,\n",
      "        -2.5593, -2.5780, -2.5859, -2.5728, -2.5944, -2.5359, -2.5484, -2.6044,\n",
      "        -2.5594, -2.6027, -2.5943, -2.5766, -2.5815, -2.5946, -2.5907, -2.5841,\n",
      "        -2.5955, -2.6086, -2.6083, -2.5868, -2.5926, -2.6003, -2.5980, -2.5293,\n",
      "        -2.5880, -2.5795, -2.5877, -2.5914, -2.5975, -2.6076, -2.6066, -2.5831,\n",
      "        -2.5751, -2.6022], device='mps:0')\n",
      "mean: tensor(-2.5818, device='mps:0')\n",
      "iter_dt 1.11s; iter 85: train loss 0.73094 temperature: 9.250000000000007\n",
      "mean_logits tensor([-2.4729, -2.3934, -2.8106, -2.6491, -2.4303, -2.3834, -2.8762, -2.7306,\n",
      "        -2.4276, -2.5609, -2.5494, -2.5643, -2.4951, -2.5880, -2.7582, -2.6281,\n",
      "        -2.7184, -2.3519, -2.4904, -2.5400, -2.6220, -2.7624, -2.5530, -2.6788,\n",
      "        -2.4536, -2.5152, -2.6597, -2.3413, -2.5053, -2.7570, -2.5513, -2.3555,\n",
      "        -2.1180, -2.6039, -2.9197, -2.2861, -2.5010, -2.5146, -2.4535, -2.1152,\n",
      "        -2.4143, -2.4202, -2.5239, -2.2093, -2.5460, -2.6037, -2.1718, -2.6461,\n",
      "        -2.4758, -2.3916], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6073, -2.6081, -2.5459, -2.6060, -2.5942, -2.6085, -2.5958, -2.6153,\n",
      "        -2.5588, -2.5830, -2.6036, -2.5391, -2.5912, -2.5903, -2.5993, -2.5844,\n",
      "        -2.5553, -2.6082, -2.5906, -2.5378, -2.5898, -2.5759, -2.5921, -2.6079,\n",
      "        -2.6009, -2.5905, -2.6068, -2.5537, -2.5913, -2.6083, -2.5912, -2.5873,\n",
      "        -2.5971, -2.5902, -2.5421, -2.5979, -2.6072, -2.5757, -2.5217, -2.6056,\n",
      "        -2.5511, -2.5678, -2.5957, -2.5624, -2.5503, -2.6087, -2.5967, -2.5967,\n",
      "        -2.5834, -2.5235], device='mps:0')\n",
      "mean: tensor(-2.5838, device='mps:0')\n",
      "iter_dt 1.12s; iter 86: train loss 0.73611 temperature: 9.300000000000008\n",
      "mean_logits tensor([-2.4793, -2.2203, -2.4316, -2.2364, -2.5225, -2.9553, -2.2772, -2.6671,\n",
      "        -2.5510, -2.5508, -2.5074, -2.6975, -2.3633, -2.7792, -2.2704, -2.6114,\n",
      "        -2.5339, -2.5234, -2.4297, -2.5659, -2.6337, -2.7109, -2.6721, -2.7274,\n",
      "        -2.5193, -2.0386, -2.5056, -2.3047, -2.6424, -2.3004, -2.3864, -2.5115,\n",
      "        -2.4900, -2.4024, -2.4240, -2.4871, -2.3796, -2.6089, -2.3008, -2.4111,\n",
      "        -2.6455, -2.4085, -2.5863, -2.5405, -2.6526, -2.7865, -2.6363, -2.4982,\n",
      "        -2.5945, -2.2301], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5858, -2.6040, -2.5731, -2.5918, -2.6055, -2.5816, -2.6054, -2.6088,\n",
      "        -2.5834, -2.5974, -2.6063, -2.5751, -2.6044, -2.6084, -2.5747, -2.5759,\n",
      "        -2.6015, -2.5919, -2.5772, -2.5985, -2.5878, -2.5945, -2.5008, -2.5973,\n",
      "        -2.6103, -2.6058, -2.5877, -2.5927, -2.5878, -2.5836, -2.5335, -2.5162,\n",
      "        -2.5797, -2.5899, -2.6073, -2.5606, -2.6023, -2.5861, -2.5729, -2.5799,\n",
      "        -2.5842, -2.6058, -2.6076, -2.6084, -2.5490, -2.6087, -2.5972, -2.5732,\n",
      "        -2.5916, -2.6078], device='mps:0')\n",
      "mean: tensor(-2.5872, device='mps:0')\n",
      "iter_dt 1.09s; iter 87: train loss 0.71705 temperature: 9.350000000000009\n",
      "mean_logits tensor([-2.2960, -2.3980, -2.6695, -2.4340, -2.0078, -2.5854, -2.1873, -2.6703,\n",
      "        -2.4795, -2.6416, -2.3238, -2.4858, -2.2929, -2.6589, -2.4032, -2.7495,\n",
      "        -2.3116, -2.5092, -2.7693, -2.6856, -2.8443, -2.5746, -2.4535, -2.5183,\n",
      "        -2.5426, -2.1433, -2.5528, -2.2542, -2.7430, -2.4492, -2.6052, -2.4428,\n",
      "        -2.4351, -2.5535, -2.6311, -2.2650, -2.4270, -2.5514, -2.8115, -2.3984,\n",
      "        -2.4322, -2.5502, -2.6552, -2.4766, -2.4427, -2.6167, -2.5247, -2.3349,\n",
      "        -2.4094, -2.3399], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6094, -2.5994, -2.6013, -2.5955, -2.6023, -2.5783, -2.6109, -2.6093,\n",
      "        -2.5960, -2.5815, -2.5759, -2.5983, -2.5321, -2.5696, -2.5820, -2.5605,\n",
      "        -2.5882, -2.5585, -2.5412, -2.5940, -2.6077, -2.5882, -2.6123, -2.5883,\n",
      "        -2.5894, -2.5290, -2.5066, -2.6030, -2.5796, -2.6080, -2.5829, -2.5711,\n",
      "        -2.5913, -2.5995, -2.5947, -2.5357, -2.5629, -2.5926, -2.6020, -2.6044,\n",
      "        -2.6118, -2.6035, -2.5979, -2.5492, -2.5970, -2.5860, -2.5936, -2.5086,\n",
      "        -2.6056, -2.5783], device='mps:0')\n",
      "mean: tensor(-2.5833, device='mps:0')\n",
      "iter_dt 1.11s; iter 88: train loss 0.61872 temperature: 9.40000000000001\n",
      "mean_logits tensor([-2.2970, -2.6513, -2.8605, -2.6584, -2.5128, -2.3377, -2.5797, -2.6730,\n",
      "        -2.4570, -2.6535, -2.5131, -2.6613, -2.5643, -2.5237, -2.3620, -2.6053,\n",
      "        -2.8113, -2.8555, -2.5586, -2.4675, -2.4924, -2.8317, -2.3920, -2.4354,\n",
      "        -2.4036, -2.7002, -2.6260, -2.4571, -2.7770, -2.3358, -2.4133, -2.5361,\n",
      "        -2.5822, -2.7075, -2.5643, -2.7002, -2.2870, -2.6940, -2.5554, -2.9206,\n",
      "        -2.5910, -2.3681, -2.4323, -2.1123, -2.6724, -2.5550, -2.4244, -2.8097,\n",
      "        -2.6007, -2.6363], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5721, -2.5873, -2.5978, -2.5947, -2.5485, -2.6092, -2.6081, -2.5846,\n",
      "        -2.6014, -2.5897, -2.5469, -2.5993, -2.5926, -2.6108, -2.5990, -2.5502,\n",
      "        -2.6055, -2.5981, -2.5857, -2.5004, -2.6082, -2.6085, -2.5464, -2.6079,\n",
      "        -2.5898, -2.5522, -2.5861, -2.6059, -2.5966, -2.5971, -2.6027, -2.5931,\n",
      "        -2.6084, -2.5510, -2.6030, -2.5946, -2.5094, -2.6015, -2.6080, -2.6075,\n",
      "        -2.5811, -2.4926, -2.5992, -2.6057, -2.5976, -2.6067, -2.5250, -2.5965,\n",
      "        -2.5924, -2.5008], device='mps:0')\n",
      "mean: tensor(-2.5831, device='mps:0')\n",
      "iter_dt 1.10s; iter 89: train loss 0.49381 temperature: 9.45000000000001\n",
      "mean_logits tensor([-2.6321, -2.3333, -2.5564, -2.2448, -2.6650, -2.4721, -2.8415, -2.4274,\n",
      "        -2.3978, -2.4295, -2.4328, -2.6850, -2.5802, -2.6056, -2.7518, -2.5557,\n",
      "        -2.5154, -2.3604, -2.4642, -2.6471, -2.4948, -2.7228, -2.5370, -2.5597,\n",
      "        -2.3200, -2.5549, -2.5882, -2.7205, -2.6714, -2.5559, -2.7255, -2.6536,\n",
      "        -2.6848, -2.4223, -2.6814, -2.5751, -2.8018, -2.5089, -2.4533, -2.6244,\n",
      "        -2.7356, -2.6618, -2.5967, -2.4711, -2.4489, -2.1747, -2.5009, -2.5006,\n",
      "        -2.5585, -2.6017], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6003, -2.5953, -2.5891, -2.5742, -2.5325, -2.5771, -2.4582, -2.5914,\n",
      "        -2.6107, -2.5969, -2.5110, -2.5852, -2.5630, -2.5964, -2.5951, -2.6103,\n",
      "        -2.6052, -2.5760, -2.5962, -2.6045, -2.5574, -2.5660, -2.6069, -2.6068,\n",
      "        -2.6062, -2.5945, -2.6048, -2.5776, -2.5979, -2.6107, -2.6072, -2.6028,\n",
      "        -2.6028, -2.6027, -2.6008, -2.5738, -2.5555, -2.6059, -2.6122, -2.5661,\n",
      "        -2.5644, -2.6090, -2.5901, -2.5389, -2.6057, -2.5973, -2.5695, -2.6081,\n",
      "        -2.6030, -2.6070], device='mps:0')\n",
      "mean: tensor(-2.5864, device='mps:0')\n",
      "iter_dt 1.08s; iter 90: train loss 0.57446 temperature: 9.50000000000001\n",
      "mean_logits tensor([-2.6258, -2.9266, -2.6104, -2.5855, -2.5533, -2.5058, -2.4940, -2.3604,\n",
      "        -2.6756, -2.2946, -2.3709, -2.6606, -2.4659, -2.2223, -2.3911, -2.6360,\n",
      "        -2.5594, -2.9327, -2.6097, -2.4304, -2.5452, -2.3897, -2.5818, -2.5458,\n",
      "        -2.5074, -2.5920, -2.4211, -2.6169, -2.4208, -2.5893, -2.4625, -2.3848,\n",
      "        -2.4698, -2.2175, -2.3884, -2.3804, -2.4069, -2.4388, -2.5722, -2.7294,\n",
      "        -2.7388, -2.5931, -2.5656, -2.6330, -2.4638, -2.6103, -2.3839, -2.3921,\n",
      "        -2.5573, -2.4997], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5990, -2.5878, -2.6042, -2.5909, -2.6072, -2.5469, -2.6048, -2.5559,\n",
      "        -2.5745, -2.5444, -2.5900, -2.5646, -2.5797, -2.5995, -2.5833, -2.6082,\n",
      "        -2.6048, -2.5841, -2.5900, -2.5776, -2.6082, -2.6014, -2.5480, -2.5960,\n",
      "        -2.6059, -2.5898, -2.5909, -2.6045, -2.6092, -2.5979, -2.5799, -2.5716,\n",
      "        -2.5826, -2.6059, -2.5927, -2.6091, -2.5981, -2.5707, -2.5850, -2.6082,\n",
      "        -2.5379, -2.5965, -2.5949, -2.5868, -2.5511, -2.6059, -2.6047, -2.5985,\n",
      "        -2.5607, -2.6007], device='mps:0')\n",
      "mean: tensor(-2.5878, device='mps:0')\n",
      "iter_dt 1.15s; iter 91: train loss 0.47724 temperature: 9.550000000000011\n",
      "mean_logits tensor([-2.4566, -2.6201, -2.2503, -2.7321, -2.5489, -2.5778, -2.6099, -2.5365,\n",
      "        -2.5723, -2.7281, -2.5785, -2.6867, -2.6292, -2.4848, -2.5222, -2.6886,\n",
      "        -2.6545, -2.3978, -2.5026, -2.3947, -2.7892, -2.2652, -2.4643, -2.3316,\n",
      "        -2.4968, -2.5739, -2.6605, -2.7679, -2.8271, -2.5259, -2.5307, -2.5776,\n",
      "        -2.4884, -2.7177, -2.7312, -2.7175, -2.2461, -2.4062, -2.4601, -2.6352,\n",
      "        -2.5325, -2.5377, -2.5249, -2.4672, -2.6169, -2.2332, -2.6595, -2.4715,\n",
      "        -2.2751, -2.5940], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5378, -2.6062, -2.6060, -2.5937, -2.6050, -2.5468, -2.5972, -2.5888,\n",
      "        -2.5815, -2.6013, -2.5389, -2.6073, -2.5929, -2.5805, -2.4463, -2.5898,\n",
      "        -2.6115, -2.5450, -2.5882, -2.5948, -2.6079, -2.5990, -2.6104, -2.6079,\n",
      "        -2.6009, -2.5806, -2.6061, -2.5976, -2.6054, -2.5356, -2.5923, -2.5528,\n",
      "        -2.5976, -2.6068, -2.6079, -2.6074, -2.6102, -2.5970, -2.5967, -2.5313,\n",
      "        -2.6099, -2.5310, -2.6011, -2.6080, -2.5922, -2.6094, -2.5891, -2.5533,\n",
      "        -2.6031, -2.5843], device='mps:0')\n",
      "mean: tensor(-2.5859, device='mps:0')\n",
      "iter_dt 1.10s; iter 92: train loss 0.50843 temperature: 9.600000000000012\n",
      "mean_logits tensor([-2.4057, -2.5450, -2.8878, -2.6079, -2.2563, -2.4889, -2.4659, -2.6353,\n",
      "        -2.4171, -2.2676, -2.4998, -2.4251, -2.5187, -2.6207, -2.5029, -2.2619,\n",
      "        -2.5018, -2.6948, -2.5931, -2.5766, -2.4331, -2.4992, -2.6991, -2.5909,\n",
      "        -2.4265, -2.5551, -2.3636, -2.3038, -2.5392, -2.4144, -2.6637, -2.6802,\n",
      "        -2.4823, -2.7529, -2.6451, -2.3372, -2.5323, -2.3599, -2.3773, -2.7308,\n",
      "        -2.6037, -2.4573, -2.5602, -2.6434, -2.6696, -2.7227, -2.4104, -2.5754,\n",
      "        -2.4402, -2.4592], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5877, -2.6029, -2.5442, -2.6047, -2.5610, -2.5988, -2.5926, -2.6079,\n",
      "        -2.5842, -2.5966, -2.6026, -2.5521, -2.5951, -2.6073, -2.6075, -2.5978,\n",
      "        -2.5869, -2.6056, -2.5874, -2.5854, -2.5927, -2.6069, -2.6023, -2.5942,\n",
      "        -2.6048, -2.5428, -2.5752, -2.6039, -2.5884, -2.6070, -2.5817, -2.6068,\n",
      "        -2.5588, -2.5953, -2.5798, -2.5832, -2.5968, -2.5877, -2.6029, -2.5911,\n",
      "        -2.6080, -2.6091, -2.5991, -2.5935, -2.5918, -2.5752, -2.6104, -2.5731,\n",
      "        -2.5887, -2.5870], device='mps:0')\n",
      "mean: tensor(-2.5909, device='mps:0')\n",
      "iter_dt 1.11s; iter 93: train loss 0.31393 temperature: 9.650000000000013\n",
      "mean_logits tensor([-2.6860, -2.7042, -2.2560, -2.6627, -2.5172, -2.7235, -2.4108, -2.6937,\n",
      "        -2.4782, -2.6373, -2.5118, -2.5666, -2.4296, -2.4768, -2.6031, -2.7325,\n",
      "        -2.5283, -2.5440, -2.7200, -2.5970, -2.4315, -2.5184, -2.2533, -2.6538,\n",
      "        -2.6626, -2.5481, -2.4561, -2.6503, -2.7537, -2.5754, -2.5832, -2.3485,\n",
      "        -2.6950, -2.5672, -2.5068, -2.5245, -2.4519, -2.5122, -2.6398, -2.6129,\n",
      "        -2.6169, -2.5519, -2.5973, -2.3976, -2.5710, -2.3178, -2.5428, -2.6284,\n",
      "        -2.3398, -2.7238], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5787, -2.5650, -2.5486, -2.5853, -2.5955, -2.5835, -2.5310, -2.5992,\n",
      "        -2.5336, -2.5160, -2.6070, -2.6064, -2.5972, -2.5630, -2.5370, -2.5805,\n",
      "        -2.5914, -2.5864, -2.5973, -2.6081, -2.5972, -2.5604, -2.5953, -2.6090,\n",
      "        -2.5613, -2.6105, -2.5860, -2.5952, -2.5865, -2.6083, -2.5467, -2.5490,\n",
      "        -2.5904, -2.6094, -2.5809, -2.5678, -2.5714, -2.6017, -2.5991, -2.5741,\n",
      "        -2.6037, -2.5923, -2.5812, -2.5829, -2.5869, -2.5614, -2.5926, -2.5919,\n",
      "        -2.5812, -2.6105], device='mps:0')\n",
      "mean: tensor(-2.5819, device='mps:0')\n",
      "iter_dt 1.08s; iter 94: train loss 0.56844 temperature: 9.700000000000014\n",
      "mean_logits tensor([-2.7104, -2.1868, -2.5644, -2.8067, -2.4241, -2.8900, -2.7252, -2.5814,\n",
      "        -2.6573, -2.6793, -2.2511, -2.2535, -2.5460, -2.5618, -2.4730, -2.5837,\n",
      "        -2.7454, -2.5730, -2.5856, -2.6747, -2.5402, -2.3764, -2.8123, -2.6595,\n",
      "        -2.5510, -2.4580, -2.4767, -2.4565, -2.7219, -2.5921, -2.7580, -2.2898,\n",
      "        -2.5134, -2.2256, -2.6249, -2.6572, -2.6815, -2.5153, -2.3512, -2.3579,\n",
      "        -2.5196, -2.8370, -2.5585, -2.4409, -2.6763, -2.5995, -2.6543, -2.5065,\n",
      "        -2.3166, -2.6283], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6075, -2.6069, -2.6019, -2.5836, -2.5976, -2.6004, -2.6083, -2.5488,\n",
      "        -2.5995, -2.5865, -2.5931, -2.5486, -2.5860, -2.5482, -2.5929, -2.5949,\n",
      "        -2.5785, -2.5978, -2.6037, -2.5988, -2.6090, -2.5685, -2.5926, -2.6039,\n",
      "        -2.5961, -2.6084, -2.5913, -2.6071, -2.5991, -2.5851, -2.5858, -2.5445,\n",
      "        -2.5914, -2.6063, -2.6084, -2.5923, -2.6078, -2.5714, -2.5989, -2.5582,\n",
      "        -2.5900, -2.6088, -2.5585, -2.6061, -2.6019, -2.5385, -2.6036, -2.5827,\n",
      "        -2.5648, -2.5932], device='mps:0')\n",
      "mean: tensor(-2.5892, device='mps:0')\n",
      "iter_dt 1.09s; iter 95: train loss 0.41845 temperature: 9.750000000000014\n",
      "mean_logits tensor([-2.7456, -2.4678, -2.3644, -2.7253, -2.6122, -2.6809, -2.7960, -2.5819,\n",
      "        -2.4367, -2.6051, -2.7462, -2.6387, -2.4756, -2.6308, -2.4671, -2.5471,\n",
      "        -2.5299, -2.5304, -2.4843, -2.4740, -2.6557, -2.4975, -2.4701, -2.6068,\n",
      "        -2.6312, -2.6731, -2.5775, -2.4163, -2.9662, -2.5179, -2.5529, -2.6540,\n",
      "        -2.5693, -2.7602, -2.6402, -2.5237, -2.5972, -2.6572, -2.5095, -2.5309,\n",
      "        -2.5338, -2.3592, -2.5054, -2.4649, -2.2736, -2.5685, -2.3547, -2.5678,\n",
      "        -2.4017, -2.7351], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6037, -2.5501, -2.6188, -2.6102, -2.5769, -2.6024, -2.6082, -2.5871,\n",
      "        -2.5940, -2.5872, -2.6058, -2.5487, -2.6085, -2.5960, -2.5925, -2.5908,\n",
      "        -2.6092, -2.5678, -2.5939, -2.5990, -2.6076, -2.5921, -2.6024, -2.5962,\n",
      "        -2.5988, -2.5669, -2.6086, -2.5457, -2.5461, -2.5897, -2.5848, -2.5886,\n",
      "        -2.6058, -2.6083, -2.6064, -2.6080, -2.5835, -2.6094, -2.6056, -2.6081,\n",
      "        -2.5558, -2.5931, -2.5875, -2.5921, -2.5582, -2.5978, -2.6074, -2.5874,\n",
      "        -2.6126, -2.6081], device='mps:0')\n",
      "mean: tensor(-2.5923, device='mps:0')\n",
      "iter_dt 1.08s; iter 96: train loss 0.56190 temperature: 9.800000000000015\n",
      "mean_logits tensor([-2.3535, -2.7971, -2.6995, -2.2684, -2.8247, -2.3217, -2.5355, -2.2209,\n",
      "        -2.6613, -2.3757, -2.4670, -2.5967, -2.6336, -2.5461, -2.5047, -2.5885,\n",
      "        -2.5025, -2.5951, -2.6781, -2.2581, -2.7279, -2.3400, -2.5743, -2.5163,\n",
      "        -2.5073, -2.5194, -2.8718, -2.4898, -2.5981, -2.4363, -2.5829, -2.7236,\n",
      "        -2.7207, -2.3933, -2.6336, -2.5963, -2.6275, -2.5862, -2.6294, -2.4980,\n",
      "        -2.5742, -2.7861, -2.4682, -2.7240, -2.3677, -2.7734, -2.2691, -2.3133,\n",
      "        -2.5240, -2.7062], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6077, -2.5912, -2.6080, -2.5970, -2.6069, -2.5809, -2.5291, -2.5289,\n",
      "        -2.5789, -2.5187, -2.6079, -2.5852, -2.5584, -2.6100, -2.6050, -2.5923,\n",
      "        -2.5900, -2.6062, -2.5985, -2.5890, -2.6071, -2.6081, -2.5556, -2.5993,\n",
      "        -2.6009, -2.6120, -2.5852, -2.5503, -2.6040, -2.5827, -2.5979, -2.5919,\n",
      "        -2.5050, -2.5874, -2.6103, -2.5979, -2.6061, -2.5845, -2.6098, -2.6057,\n",
      "        -2.6008, -2.5897, -2.6009, -2.5934, -2.6071, -2.5946, -2.6050, -2.5429,\n",
      "        -2.5947, -2.6080], device='mps:0')\n",
      "mean: tensor(-2.5886, device='mps:0')\n",
      "iter_dt 1.10s; iter 97: train loss 0.56384 temperature: 9.850000000000016\n",
      "mean_logits tensor([-2.1205, -2.5494, -2.3940, -2.9144, -2.4210, -2.6404, -2.4081, -2.4377,\n",
      "        -2.6680, -2.5892, -2.6482, -2.4072, -2.7180, -2.5019, -2.5256, -2.5376,\n",
      "        -2.5792, -2.5526, -2.5394, -2.5532, -2.5697, -2.7130, -2.6177, -2.6536,\n",
      "        -2.5040, -2.2972, -2.6022, -2.4821, -2.6499, -2.6503, -2.0979, -2.5092,\n",
      "        -2.4680, -2.5647, -2.3475, -2.1176, -2.5462, -2.5137, -2.3871, -2.7298,\n",
      "        -2.2399, -2.6238, -2.7479, -2.7219, -2.7585, -2.5069, -2.6049, -2.7895,\n",
      "        -2.6227, -2.5199], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6040, -2.6085, -2.6068, -2.5981, -2.5938, -2.6082, -2.5322, -2.5977,\n",
      "        -2.5974, -2.6080, -2.6025, -2.5568, -2.6083, -2.6080, -2.5921, -2.6063,\n",
      "        -2.6062, -2.5910, -2.5865, -2.6076, -2.6067, -2.6058, -2.5975, -2.6106,\n",
      "        -2.5716, -2.5755, -2.6011, -2.6059, -2.6104, -2.6014, -2.5570, -2.6018,\n",
      "        -2.6080, -2.5892, -2.5079, -2.5986, -2.6075, -2.5889, -2.5898, -2.6067,\n",
      "        -2.5943, -2.5933, -2.5902, -2.6032, -2.5874, -2.6048, -2.5571, -2.5965,\n",
      "        -2.5945, -2.5986], device='mps:0')\n",
      "mean: tensor(-2.5936, device='mps:0')\n",
      "iter_dt 1.09s; iter 98: train loss 0.50697 temperature: 9.900000000000016\n",
      "mean_logits tensor([-2.5775, -2.5649, -2.7633, -2.6246, -2.5738, -2.5838, -2.3401, -2.5735,\n",
      "        -2.5215, -2.4960, -2.7626, -2.4879, -2.3116, -2.5884, -2.4401, -2.3357,\n",
      "        -2.6844, -2.7337, -2.6259, -2.5982, -2.4602, -2.4847, -2.7922, -2.5490,\n",
      "        -2.6982, -2.3904, -2.8996, -2.6159, -2.3724, -2.7232, -2.3230, -2.6151,\n",
      "        -2.5261, -2.6332, -2.4172, -2.1751, -2.7932, -2.5533, -2.6309, -2.7971,\n",
      "        -2.5459, -2.8216, -2.4772, -2.8268, -2.5596, -2.5383, -2.5995, -2.5848,\n",
      "        -2.8039, -2.4964], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5531, -2.5988, -2.5980, -2.6015, -2.6014, -2.5977, -2.6045, -2.5965,\n",
      "        -2.5878, -2.6081, -2.5749, -2.5973, -2.5886, -2.5963, -2.5845, -2.5727,\n",
      "        -2.6103, -2.6107, -2.5920, -2.5964, -2.6098, -2.5986, -2.6003, -2.6049,\n",
      "        -2.6081, -2.5559, -2.5945, -2.5948, -2.5907, -2.5818, -2.5284, -2.6077,\n",
      "        -2.6071, -2.5694, -2.5981, -2.5021, -2.5953, -2.5411, -2.5878, -2.5902,\n",
      "        -2.5907, -2.5845, -2.5464, -2.5898, -2.5883, -2.5944, -2.6011, -2.6039,\n",
      "        -2.5887, -2.5162], device='mps:0')\n",
      "mean: tensor(-2.5868, device='mps:0')\n",
      "iter_dt 1.09s; iter 99: train loss 0.45526 temperature: 9.950000000000017\n",
      "mean_logits tensor([-2.5121, -2.4719, -2.5094, -2.4427, -2.3446, -2.5965, -2.5421, -2.4703,\n",
      "        -2.6700, -2.5577, -2.6343, -2.8589, -2.6387, -2.7208, -2.5900, -2.6137,\n",
      "        -2.7808, -2.4270, -2.3344, -2.6302, -2.5332, -2.5022, -2.7387, -2.5688,\n",
      "        -2.6146, -2.6672, -2.6860, -2.6115, -2.2133, -2.3077, -2.4941, -2.4415,\n",
      "        -2.5984, -2.8140, -2.5164, -2.7748, -2.5936, -2.5890, -2.7625, -2.6713,\n",
      "        -2.7113, -2.6485, -2.4859, -2.3536, -2.6845, -2.6560, -2.3024, -2.3273,\n",
      "        -2.6923, -2.5148], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6075, -2.5941, -2.5691, -2.5872, -2.5436, -2.5604, -2.6057, -2.6049,\n",
      "        -2.5849, -2.6022, -2.6086, -2.5938, -2.6066, -2.6002, -2.5294, -2.6021,\n",
      "        -2.5860, -2.5902, -2.6018, -2.5786, -2.5547, -2.5835, -2.5657, -2.5853,\n",
      "        -2.6109, -2.5991, -2.6106, -2.6202, -2.5930, -2.5521, -2.5492, -2.5904,\n",
      "        -2.5994, -2.6073, -2.5482, -2.5978, -2.6071, -2.6130, -2.5405, -2.6118,\n",
      "        -2.5877, -2.6077, -2.5762, -2.5919, -2.5945, -2.5987, -2.6010, -2.6027,\n",
      "        -2.6036, -2.6030], device='mps:0')\n",
      "mean: tensor(-2.5893, device='mps:0')\n",
      "current_prefixes: [7278 4037 5557 4534 4632 6985  380 4805 4101 4404 4883  611  346 1045\n",
      " 2273 6235 5773 2879  256  465 6084 8286  375 5500  264  814   67 8921\n",
      "   67 4136 4385 6604  200 1773 2049 8494   86 3932 2808 2015]\n",
      "layer: 9 starts running\n",
      "number of parameters: 91.99M\n",
      "running on device mps\n",
      "iter_dt 0.00s; iter 0: train loss 5.29535 temperature: 5\n",
      "mean_logits tensor([-1.8878, -1.7489, -1.7625, -2.0760, -2.0526, -2.0095, -2.2527, -1.7451,\n",
      "        -2.2685, -2.2440, -1.9690, -1.7560, -2.1516, -1.8649, -1.9172, -2.0299,\n",
      "        -1.6228, -2.2892, -1.7609, -2.0411, -1.7842, -2.1375, -2.1232, -1.9675,\n",
      "        -2.0112, -2.0041, -2.1827, -1.9972, -1.8616, -1.9513, -2.2566, -1.9119,\n",
      "        -1.8847, -2.2440, -1.9208, -1.7982, -2.1536, -1.9362, -1.8443, -2.1786,\n",
      "        -2.1254, -1.9408, -2.1980, -1.8440, -2.2399, -2.0079, -1.9380, -2.1435,\n",
      "        -1.5645, -2.0541], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6060, -2.6349, -2.6279, -2.5557, -2.6294, -2.6206, -2.6112, -2.6056,\n",
      "        -2.6335, -2.5527, -2.5871, -2.5681, -2.5569, -2.6063, -2.5729, -2.5899,\n",
      "        -2.6264, -2.6167, -2.6243, -2.6196, -2.6264, -2.5894, -2.6277, -2.6286,\n",
      "        -2.6008, -2.5944, -2.6251, -2.6299, -2.6284, -2.6175, -2.6283, -2.6138,\n",
      "        -2.6277, -2.6195, -2.5974, -2.5589, -2.5710, -2.6284, -2.6049, -2.6296,\n",
      "        -2.6049, -2.6159, -2.5746, -2.5502, -2.6235, -2.6252, -2.6293, -2.6294,\n",
      "        -2.5880, -2.6215], device='mps:0')\n",
      "mean: tensor(-2.6071, device='mps:0')\n",
      "iter_dt 1695864634.50s; iter 1: train loss 5.56237 temperature: 5.05\n",
      "mean_logits tensor([-1.5989, -1.8829, -1.9904, -2.2926, -1.9648, -2.0103, -1.8042, -1.6396,\n",
      "        -1.8074, -1.9442, -2.2132, -2.4602, -2.2459, -2.0376, -1.7205, -1.9838,\n",
      "        -2.1442, -2.1585, -2.1164, -1.7209, -2.2124, -1.9242, -1.8810, -1.2372,\n",
      "        -1.9017, -1.7923, -2.0095, -2.0168, -2.0817, -1.5781, -2.0128, -2.3590,\n",
      "        -2.5173, -1.5532, -1.9404, -1.8293, -1.9544, -2.1596, -2.0858, -2.2178,\n",
      "        -2.3657, -1.7988, -1.8906, -2.2184, -1.6807, -2.0576, -1.4232, -2.1236,\n",
      "        -1.7479, -1.9219], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6253, -2.5712, -2.6189, -2.6224, -2.6242, -2.5589, -2.6095, -2.5939,\n",
      "        -2.5691, -2.5868, -2.6227, -2.6008, -2.5606, -2.6129, -2.5352, -2.6261,\n",
      "        -2.5567, -2.6322, -2.6155, -2.6055, -2.5971, -2.5803, -2.6126, -2.6137,\n",
      "        -2.6121, -2.6244, -2.6267, -2.5726, -2.6081, -2.6056, -2.6235, -2.6109,\n",
      "        -2.6284, -2.5826, -2.6222, -2.6163, -2.6226, -2.5393, -2.6059, -2.6208,\n",
      "        -2.6146, -2.6116, -2.5635, -2.5767, -2.5522, -2.6246, -2.6301, -2.6227,\n",
      "        -2.6220, -2.6281], device='mps:0')\n",
      "mean: tensor(-2.6024, device='mps:0')\n",
      "iter_dt 1.44s; iter 2: train loss 5.27690 temperature: 5.1\n",
      "mean_logits tensor([-2.1737, -1.9061, -2.0302, -2.1240, -2.0861, -1.5047, -1.6599, -2.0496,\n",
      "        -1.8982, -2.0376, -1.7717, -2.5130, -2.1325, -1.8427, -2.1474, -1.8638,\n",
      "        -1.3359, -2.4273, -1.8879, -2.1937, -1.9370, -1.6798, -2.3268, -1.9984,\n",
      "        -1.5064, -2.0092, -1.8290, -1.8065, -1.7200, -1.9404, -2.0231, -2.1823,\n",
      "        -1.8745, -2.3221, -2.3654, -2.3047, -1.8614, -1.6263, -1.8456, -1.7858,\n",
      "        -2.5100, -1.8506, -2.0649, -2.0846, -1.7276, -2.1429, -2.2560, -1.8924,\n",
      "        -1.9402, -1.9554], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6159, -2.6114, -2.5911, -2.6263, -2.5723, -2.5800, -2.5960, -2.5617,\n",
      "        -2.5451, -2.6259, -2.6288, -2.6157, -2.6171, -2.5810, -2.5501, -2.6210,\n",
      "        -2.5661, -2.6298, -2.6157, -2.6265, -2.6298, -2.6146, -2.6251, -2.6016,\n",
      "        -2.6285, -2.6175, -2.6172, -2.6301, -2.5765, -2.5487, -2.6089, -2.5923,\n",
      "        -2.6295, -2.6159, -2.5177, -2.5479, -2.6292, -2.5851, -2.5477, -2.5167,\n",
      "        -2.6242, -2.5344, -2.5745, -2.6267, -2.6244, -2.6249, -2.5998, -2.4709,\n",
      "        -2.6166, -2.6292], device='mps:0')\n",
      "mean: tensor(-2.5957, device='mps:0')\n",
      "iter_dt 1.10s; iter 3: train loss 4.87740 temperature: 5.1499999999999995\n",
      "mean_logits tensor([-1.9676, -2.2502, -1.8596, -1.9258, -2.1209, -1.8050, -1.7925, -2.1771,\n",
      "        -1.8524, -1.7449, -2.1636, -2.0096, -2.2293, -1.6333, -2.0631, -2.3995,\n",
      "        -2.0170, -2.4319, -2.2618, -1.9386, -1.9416, -1.9828, -1.5102, -2.0879,\n",
      "        -2.0124, -2.0993, -1.9336, -1.9478, -2.1457, -2.3093, -2.1334, -1.7840,\n",
      "        -1.9290, -1.6555, -1.9218, -2.2992, -2.1855, -2.1224, -1.6824, -1.5761,\n",
      "        -2.4291, -2.1408, -2.1371, -1.7049, -2.1155, -2.0766, -2.0476, -2.1434,\n",
      "        -2.1092, -1.7741], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5584, -2.6294, -2.6179, -2.5904, -2.6253, -2.5736, -2.5470, -2.6192,\n",
      "        -2.6297, -2.6163, -2.6097, -2.5753, -2.6292, -2.5786, -2.6216, -2.6076,\n",
      "        -2.6271, -2.6149, -2.6283, -2.6088, -2.5400, -2.5769, -2.5916, -2.6087,\n",
      "        -2.6167, -2.6143, -2.6254, -2.6240, -2.6106, -2.6031, -2.6267, -2.6291,\n",
      "        -2.5998, -2.6220, -2.5756, -2.5176, -2.6069, -2.5602, -2.5375, -2.5664,\n",
      "        -2.5326, -2.5915, -2.6198, -2.5508, -2.5970, -2.5183, -2.6098, -2.6105,\n",
      "        -2.6090, -2.6307], device='mps:0')\n",
      "mean: tensor(-2.5966, device='mps:0')\n",
      "iter_dt 1.29s; iter 4: train loss 4.23299 temperature: 5.199999999999999\n",
      "mean_logits tensor([-2.4133, -2.0322, -1.6486, -1.9919, -2.1168, -2.1787, -2.0924, -2.0254,\n",
      "        -2.0950, -1.8746, -1.6586, -1.6668, -2.5789, -2.2358, -1.8321, -2.0203,\n",
      "        -2.2612, -2.0928, -1.6625, -2.2219, -1.8165, -1.9862, -1.9952, -2.0696,\n",
      "        -2.0901, -2.2020, -2.3957, -2.1385, -2.1180, -1.9616, -1.8799, -2.0939,\n",
      "        -2.4725, -2.0567, -2.0507, -2.1707, -2.1885, -1.9202, -2.3162, -2.0091,\n",
      "        -1.9021, -2.2571, -2.3787, -2.0323, -2.1029, -2.1218, -1.8976, -1.9570,\n",
      "        -2.8504, -2.4798], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6282, -2.6254, -2.5671, -2.6120, -2.6252, -2.6250, -2.6111, -2.5865,\n",
      "        -2.6054, -2.6132, -2.6276, -2.5993, -2.6059, -2.6287, -2.5479, -2.6246,\n",
      "        -2.6278, -2.6096, -2.6281, -2.6003, -2.5387, -2.6296, -2.5495, -2.6286,\n",
      "        -2.5421, -2.6268, -2.6286, -2.6049, -2.6245, -2.6119, -2.6288, -2.6294,\n",
      "        -2.6151, -2.6126, -2.6205, -2.6165, -2.5483, -2.5542, -2.6004, -2.5838,\n",
      "        -2.5718, -2.6294, -2.5496, -2.6288, -2.5676, -2.5631, -2.6294, -2.6017,\n",
      "        -2.6142, -2.6295], device='mps:0')\n",
      "mean: tensor(-2.6036, device='mps:0')\n",
      "iter_dt 1.28s; iter 5: train loss 3.70901 temperature: 5.249999999999999\n",
      "mean_logits tensor([-2.0614, -1.8315, -2.2941, -2.1389, -2.0521, -2.0035, -2.1939, -1.8011,\n",
      "        -2.1072, -1.8670, -2.4425, -2.5800, -2.4524, -2.5614, -1.9630, -2.5324,\n",
      "        -1.9527, -1.7505, -2.4508, -2.0201, -2.0539, -2.0955, -1.9420, -2.2924,\n",
      "        -2.2976, -2.3147, -2.4078, -1.7613, -1.6257, -2.4126, -1.9738, -2.2639,\n",
      "        -1.7996, -2.2172, -2.4202, -2.5237, -1.6660, -2.1688, -2.2591, -2.4601,\n",
      "        -2.2998, -2.3276, -2.1787, -2.0028, -1.8155, -2.0392, -1.8447, -1.8584,\n",
      "        -2.0080, -2.2204], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5769, -2.6242, -2.6284, -2.6045, -2.5745, -2.5453, -2.6289, -2.6249,\n",
      "        -2.6177, -2.5619, -2.5725, -2.6293, -2.6161, -2.5881, -2.6180, -2.6123,\n",
      "        -2.6186, -2.6217, -2.6283, -2.6243, -2.5610, -2.5839, -2.5715, -2.5360,\n",
      "        -2.6290, -2.5856, -2.5129, -2.6285, -2.6289, -2.6287, -2.6000, -2.6255,\n",
      "        -2.5760, -2.6282, -2.6032, -2.6009, -2.5822, -2.6283, -2.5339, -2.5584,\n",
      "        -2.6254, -2.6258, -2.6267, -2.5188, -2.5705, -2.6182, -2.6227, -2.5843,\n",
      "        -2.5820, -2.6294], device='mps:0')\n",
      "mean: tensor(-2.5985, device='mps:0')\n",
      "iter_dt 1.18s; iter 6: train loss 2.88178 temperature: 5.299999999999999\n",
      "mean_logits tensor([-2.2231, -2.1117, -2.1930, -2.2036, -2.5445, -1.7323, -2.0444, -2.0869,\n",
      "        -2.3555, -2.2457, -2.1746, -2.1131, -2.6223, -2.0433, -2.1659, -2.5457,\n",
      "        -2.1903, -2.4454, -2.3039, -2.1027, -2.0600, -1.9534, -1.8083, -2.1452,\n",
      "        -2.3344, -2.3102, -2.2012, -2.2154, -2.2884, -2.0810, -1.8706, -2.1595,\n",
      "        -2.0539, -2.1844, -2.6819, -2.5075, -1.8176, -2.1120, -2.3174, -2.4621,\n",
      "        -2.3679, -1.9977, -2.2165, -2.3564, -1.9660, -2.4311, -2.2467, -2.1422,\n",
      "        -2.1857, -2.2799], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5730, -2.6256, -2.6020, -2.5490, -2.6202, -2.6178, -2.5531, -2.5553,\n",
      "        -2.5936, -2.5699, -2.5621, -2.6219, -2.6067, -2.6043, -2.5633, -2.5407,\n",
      "        -2.5893, -2.6316, -2.6249, -2.6297, -2.5487, -2.5618, -2.6144, -2.6260,\n",
      "        -2.6065, -2.6288, -2.6200, -2.5793, -2.6162, -2.5325, -2.5687, -2.5741,\n",
      "        -2.6294, -2.6307, -2.6295, -2.6072, -2.6256, -2.6295, -2.5508, -2.6138,\n",
      "        -2.6291, -2.6107, -2.6296, -2.5558, -2.6171, -2.6165, -2.6290, -2.6251,\n",
      "        -2.6077, -2.5923], device='mps:0')\n",
      "mean: tensor(-2.5988, device='mps:0')\n",
      "iter_dt 1.17s; iter 7: train loss 3.07182 temperature: 5.349999999999999\n",
      "mean_logits tensor([-2.3712, -2.6706, -2.2083, -2.6683, -2.2983, -2.7798, -2.4480, -2.3816,\n",
      "        -2.1360, -1.8928, -2.5406, -1.9996, -1.9640, -2.6483, -2.0783, -2.3149,\n",
      "        -2.1721, -2.4047, -2.2801, -2.0259, -1.9750, -2.4331, -1.6022, -2.5661,\n",
      "        -2.1509, -1.9630, -2.3952, -1.9509, -1.5631, -2.4131, -2.0283, -2.2659,\n",
      "        -2.1200, -2.1744, -2.5383, -1.9558, -2.0364, -2.6365, -1.6300, -1.8469,\n",
      "        -2.3408, -2.6026, -1.6263, -1.7515, -2.4477, -2.3171, -2.6565, -2.3842,\n",
      "        -2.2911, -1.9779], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6135, -2.6129, -2.6153, -2.6179, -2.5291, -2.5775, -2.6296, -2.6198,\n",
      "        -2.5923, -2.6259, -2.5647, -2.6158, -2.6022, -2.6190, -2.5597, -2.5742,\n",
      "        -2.5698, -2.6268, -2.5595, -2.6284, -2.6290, -2.6056, -2.6257, -2.6007,\n",
      "        -2.5802, -2.6216, -2.6132, -2.6270, -2.4837, -2.6186, -2.6216, -2.5834,\n",
      "        -2.5451, -2.5565, -2.6290, -2.6286, -2.6274, -2.5723, -2.5422, -2.6267,\n",
      "        -2.6300, -2.6285, -2.5794, -2.6275, -2.6290, -2.5679, -2.6162, -2.6193,\n",
      "        -2.5656, -2.6270], device='mps:0')\n",
      "mean: tensor(-2.5996, device='mps:0')\n",
      "iter_dt 1.14s; iter 8: train loss 3.42759 temperature: 5.399999999999999\n",
      "mean_logits tensor([-2.5032, -2.1195, -2.5640, -2.5216, -2.4902, -2.5430, -1.7595, -2.1038,\n",
      "        -3.1142, -1.9290, -1.8066, -2.7220, -1.8411, -2.2405, -2.5201, -2.1971,\n",
      "        -2.3872, -2.0731, -2.2022, -2.3943, -1.3007, -1.8396, -1.8623, -1.9530,\n",
      "        -1.7024, -2.5334, -2.2530, -2.3467, -2.2682, -2.5374, -2.5226, -2.1907,\n",
      "        -2.2031, -1.9883, -2.8269, -2.0943, -1.9319, -2.1713, -2.5713, -2.3069,\n",
      "        -2.3188, -1.8278, -2.2269, -2.2575, -2.2072, -2.7787, -2.2218, -2.1772,\n",
      "        -2.1480, -1.8168], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6274, -2.6099, -2.6222, -2.5719, -2.6180, -2.6249, -2.6259, -2.6026,\n",
      "        -2.6124, -2.6295, -2.6019, -2.5969, -2.5783, -2.6290, -2.6129, -2.6093,\n",
      "        -2.5740, -2.6297, -2.6266, -2.6176, -2.6262, -2.6106, -2.6114, -2.5731,\n",
      "        -2.6079, -2.6277, -2.6036, -2.6074, -2.6233, -2.6141, -2.6097, -2.5574,\n",
      "        -2.6255, -2.6230, -2.5691, -2.6048, -2.5554, -2.5457, -2.6247, -2.5738,\n",
      "        -2.6287, -2.6180, -2.6236, -2.5766, -2.6130, -2.6293, -2.6249, -2.6167,\n",
      "        -2.6266, -2.5807], device='mps:0')\n",
      "mean: tensor(-2.6071, device='mps:0')\n",
      "iter_dt 1.27s; iter 9: train loss 2.52039 temperature: 5.449999999999998\n",
      "mean_logits tensor([-2.5809, -2.3351, -2.0262, -2.6782, -1.9688, -2.1325, -2.2850, -2.1091,\n",
      "        -2.6723, -2.2451, -2.0458, -2.3551, -2.0148, -2.0579, -2.2811, -2.3678,\n",
      "        -2.3478, -2.3908, -2.2074, -2.3486, -2.2030, -2.1764, -2.0637, -2.3685,\n",
      "        -3.1247, -2.2391, -2.0764, -2.3144, -2.5426, -2.6001, -2.6900, -2.2825,\n",
      "        -2.3862, -1.9443, -2.4706, -2.4376, -2.4422, -2.2261, -1.9115, -2.8766,\n",
      "        -1.7824, -2.7501, -2.7747, -3.0167, -2.2445, -2.0179, -2.8044, -2.1054,\n",
      "        -2.4938, -2.1229], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6275, -2.5599, -2.5511, -2.5772, -2.5377, -2.6197, -2.5629, -2.5693,\n",
      "        -2.6300, -2.6273, -2.6068, -2.5762, -2.6032, -2.6305, -2.5181, -2.6293,\n",
      "        -2.6074, -2.6291, -2.5634, -2.6267, -2.6300, -2.6191, -2.6064, -2.6196,\n",
      "        -2.6300, -2.5896, -2.6095, -2.6118, -2.5942, -2.6015, -2.6197, -2.6263,\n",
      "        -2.6080, -2.5702, -2.6295, -2.6289, -2.5682, -2.5586, -2.5441, -2.5717,\n",
      "        -2.6253, -2.6197, -2.6295, -2.6159, -2.6129, -2.6230, -2.5900, -2.6238,\n",
      "        -2.5539, -2.5712], device='mps:0')\n",
      "mean: tensor(-2.5991, device='mps:0')\n",
      "iter_dt 1.24s; iter 10: train loss 2.66709 temperature: 5.499999999999998\n",
      "mean_logits tensor([-2.0789, -2.3022, -1.8118, -2.6060, -2.9448, -1.9555, -2.7181, -2.7564,\n",
      "        -2.7293, -3.0235, -2.3044, -2.4331, -2.5852, -1.9567, -2.2729, -2.0600,\n",
      "        -2.1570, -1.9436, -2.6311, -1.8453, -2.2134, -2.4630, -2.1333, -2.6307,\n",
      "        -2.5499, -2.2576, -2.3130, -2.2614, -2.8117, -1.9111, -2.6307, -2.8194,\n",
      "        -1.9467, -2.4209, -2.1197, -3.1031, -2.6334, -2.2550, -1.9083, -2.6062,\n",
      "        -2.8953, -2.3489, -2.0817, -2.3868, -3.0247, -2.3519, -2.2238, -2.3844,\n",
      "        -2.7191, -2.2149], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6186, -2.6147, -2.6173, -2.6264, -2.6294, -2.6119, -2.6016, -2.6196,\n",
      "        -2.6273, -2.5832, -2.6148, -2.6036, -2.5656, -2.6278, -2.6256, -2.6262,\n",
      "        -2.6254, -2.5533, -2.5901, -2.5757, -2.6266, -2.6254, -2.5893, -2.5939,\n",
      "        -2.6270, -2.6156, -2.5772, -2.6172, -2.6295, -2.5596, -2.6250, -2.6302,\n",
      "        -2.6158, -2.6294, -2.6133, -2.6198, -2.6112, -2.6281, -2.5515, -2.6197,\n",
      "        -2.6266, -2.5760, -2.6302, -2.6308, -2.6296, -2.6247, -2.5395, -2.6209,\n",
      "        -2.6096, -2.6260], device='mps:0')\n",
      "mean: tensor(-2.6095, device='mps:0')\n",
      "iter_dt 1.21s; iter 11: train loss 2.63730 temperature: 5.549999999999998\n",
      "mean_logits tensor([-2.5243, -2.4510, -2.3745, -2.7085, -2.4086, -2.5140, -2.2810, -2.3782,\n",
      "        -2.3653, -2.3255, -2.6931, -2.3446, -1.8307, -2.8826, -2.1695, -2.3833,\n",
      "        -2.0439, -1.8614, -2.4539, -2.2382, -2.3602, -2.5459, -2.6493, -2.3899,\n",
      "        -2.6120, -3.1254, -2.2813, -2.9332, -2.4351, -2.8157, -2.5477, -2.6225,\n",
      "        -2.6229, -1.8492, -2.3645, -2.2345, -2.2593, -2.0222, -2.2196, -2.2292,\n",
      "        -2.3030, -2.3528, -2.1459, -1.9612, -3.1345, -2.1355, -2.6507, -2.3547,\n",
      "        -2.3717, -3.2585], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6291, -2.6304, -2.6194, -2.6290, -2.5863, -2.6178, -2.6271, -2.5199,\n",
      "        -2.6298, -2.6171, -2.6177, -2.6285, -2.5730, -2.6290, -2.6216, -2.6284,\n",
      "        -2.6023, -2.6017, -2.6191, -2.5599, -2.6259, -2.5613, -2.6263, -2.6299,\n",
      "        -2.6174, -2.5965, -2.6291, -2.6198, -2.5650, -2.6131, -2.6195, -2.5276,\n",
      "        -2.6184, -2.5987, -2.6095, -2.6279, -2.6290, -2.6120, -2.5931, -2.6295,\n",
      "        -2.6296, -2.6289, -2.6288, -2.5760, -2.6198, -2.5456, -2.6216, -2.6197,\n",
      "        -2.6254, -2.6272], device='mps:0')\n",
      "mean: tensor(-2.6092, device='mps:0')\n",
      "iter_dt 1.13s; iter 12: train loss 1.45295 temperature: 5.599999999999998\n",
      "mean_logits tensor([-2.9298, -2.3066, -2.8929, -2.2443, -2.1418, -2.4646, -2.6020, -2.3021,\n",
      "        -2.5841, -2.2991, -2.4802, -2.5904, -2.3105, -1.9776, -2.5323, -2.4610,\n",
      "        -2.5224, -2.5131, -2.0669, -2.7387, -2.5758, -2.3062, -2.3455, -2.4873,\n",
      "        -2.4321, -2.5158, -2.5970, -2.5769, -2.1163, -2.4204, -2.9514, -2.2666,\n",
      "        -2.7204, -2.3653, -2.4944, -2.3688, -2.3756, -2.1326, -2.5890, -2.5775,\n",
      "        -2.6310, -1.9807, -2.0908, -2.8408, -1.8793, -2.8617, -2.4700, -2.5350,\n",
      "        -2.5733, -2.4824], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6300, -2.5986, -2.6174, -2.4947, -2.6271, -2.6226, -2.6130, -2.6176,\n",
      "        -2.5678, -2.5508, -2.5529, -2.6072, -2.6127, -2.6245, -2.6265, -2.6295,\n",
      "        -2.5904, -2.5598, -2.5738, -2.5912, -2.6070, -2.5643, -2.5676, -2.6289,\n",
      "        -2.6143, -2.6044, -2.6287, -2.6289, -2.5667, -2.5771, -2.5755, -2.6291,\n",
      "        -2.6095, -2.6126, -2.6212, -2.6271, -2.6311, -2.6245, -2.6183, -2.6197,\n",
      "        -2.5114, -2.5802, -2.6193, -2.6007, -2.6194, -2.6300, -2.6278, -2.6257,\n",
      "        -2.6261, -2.6180], device='mps:0')\n",
      "mean: tensor(-2.6025, device='mps:0')\n",
      "iter_dt 1.19s; iter 13: train loss 2.23850 temperature: 5.649999999999998\n",
      "mean_logits tensor([-1.6823, -2.5981, -2.1394, -2.3118, -2.5606, -2.2571, -2.0030, -2.0417,\n",
      "        -2.4200, -2.4676, -2.7196, -2.2890, -2.2961, -2.0907, -2.2451, -2.6291,\n",
      "        -1.9453, -2.1662, -2.2934, -2.4104, -2.8544, -2.3652, -2.1553, -2.3074,\n",
      "        -2.1785, -1.9004, -2.1112, -2.2828, -2.9593, -2.6233, -2.5434, -2.7125,\n",
      "        -2.3619, -2.7217, -2.7063, -2.5412, -2.3298, -2.7016, -2.0862, -2.7446,\n",
      "        -2.4961, -2.0354, -2.3208, -2.9344, -2.2765, -2.3480, -2.3270, -2.4532,\n",
      "        -2.9866, -2.1958], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6134, -2.5426, -2.6322, -2.6274, -2.5832, -2.6268, -2.5615, -2.6289,\n",
      "        -2.6193, -2.6140, -2.6259, -2.6150, -2.5714, -2.6245, -2.6280, -2.5746,\n",
      "        -2.5725, -2.6247, -2.6234, -2.6293, -2.5519, -2.5797, -2.6174, -2.6196,\n",
      "        -2.5590, -2.6229, -2.6273, -2.6301, -2.6082, -2.6285, -2.6268, -2.6079,\n",
      "        -2.6123, -2.5388, -2.6269, -2.6240, -2.6347, -2.6298, -2.5648, -2.5564,\n",
      "        -2.6306, -2.5765, -2.6229, -2.6165, -2.5947, -2.5415, -2.6209, -2.6269,\n",
      "        -2.5856, -2.6180], device='mps:0')\n",
      "mean: tensor(-2.6048, device='mps:0')\n",
      "iter_dt 1.16s; iter 14: train loss 1.63633 temperature: 5.6999999999999975\n",
      "mean_logits tensor([-2.6664, -2.4747, -2.1279, -2.1870, -2.6367, -2.0511, -2.2612, -2.2928,\n",
      "        -2.5728, -2.6766, -2.5414, -2.2246, -2.2571, -2.4395, -2.8156, -2.1320,\n",
      "        -2.7294, -2.6267, -2.7315, -2.3863, -2.5935, -2.5114, -2.6612, -3.2539,\n",
      "        -2.4014, -2.5777, -2.4150, -1.9652, -2.3149, -2.5543, -2.5487, -2.7719,\n",
      "        -2.7245, -2.3547, -2.2688, -2.1512, -2.5643, -2.3595, -2.1560, -2.4280,\n",
      "        -2.3774, -2.6873, -2.1484, -2.4151, -2.6155, -2.4379, -2.5362, -2.4432,\n",
      "        -2.3204, -2.2117], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6176, -2.3630, -2.6296, -2.6151, -2.6229, -2.6174, -2.5819, -2.6255,\n",
      "        -2.6179, -2.5693, -2.6168, -2.6229, -2.6293, -2.5995, -2.6305, -2.6294,\n",
      "        -2.6152, -2.6255, -2.6286, -2.6282, -2.6188, -2.5585, -2.6271, -2.6191,\n",
      "        -2.6158, -2.6055, -2.6254, -2.6038, -2.6289, -2.6104, -2.6267, -2.6294,\n",
      "        -2.6180, -2.5277, -2.6079, -2.6096, -2.6219, -2.5599, -2.6187, -2.6076,\n",
      "        -2.6262, -2.6027, -2.5472, -2.6239, -2.6261, -2.6181, -2.6297, -2.6277,\n",
      "        -2.6174, -2.6258], device='mps:0')\n",
      "mean: tensor(-2.6074, device='mps:0')\n",
      "iter_dt 1.16s; iter 15: train loss 1.74847 temperature: 5.749999999999997\n",
      "mean_logits tensor([-2.3877, -2.4112, -2.7876, -2.7092, -1.9909, -2.2284, -1.7845, -2.2843,\n",
      "        -2.7129, -2.1763, -2.3910, -2.5037, -2.2700, -2.3041, -2.4623, -2.4137,\n",
      "        -2.6004, -2.0944, -2.1994, -2.6124, -2.0747, -2.6322, -2.5897, -2.5615,\n",
      "        -2.5385, -2.2566, -2.9870, -2.6141, -2.7738, -2.3896, -2.6882, -2.3043,\n",
      "        -2.1151, -2.4396, -2.4383, -2.1725, -2.5945, -2.3013, -2.1840, -2.3602,\n",
      "        -2.3680, -2.1502, -2.3043, -2.1042, -2.0821, -2.0935, -2.6146, -2.5051,\n",
      "        -2.3962, -2.2653], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6167, -2.5523, -2.6277, -2.6270, -2.5436, -2.6212, -2.6246, -2.6268,\n",
      "        -2.5992, -2.4816, -2.5696, -2.6158, -2.6354, -2.6156, -2.6289, -2.5603,\n",
      "        -2.6296, -2.5668, -2.6245, -2.5733, -2.6305, -2.5663, -2.6294, -2.5796,\n",
      "        -2.6288, -2.6196, -2.5687, -2.6290, -2.5423, -2.5653, -2.6251, -2.5682,\n",
      "        -2.6253, -2.6191, -2.6180, -2.6261, -2.6257, -2.6189, -2.5949, -2.6301,\n",
      "        -2.5582, -2.6243, -2.6075, -2.6260, -2.6097, -2.6198, -2.5631, -2.6306,\n",
      "        -2.6247, -2.5226], device='mps:0')\n",
      "mean: tensor(-2.6008, device='mps:0')\n",
      "iter_dt 1.09s; iter 16: train loss 1.72782 temperature: 5.799999999999997\n",
      "mean_logits tensor([-2.5034, -2.5248, -2.5217, -2.4043, -2.4247, -2.4420, -1.9315, -2.1302,\n",
      "        -1.7953, -2.2124, -2.4618, -2.9370, -2.6042, -2.4826, -2.5465, -2.3552,\n",
      "        -2.3147, -2.3857, -2.3117, -2.4024, -2.3423, -2.6707, -2.7376, -2.3964,\n",
      "        -2.0267, -2.1902, -1.8778, -2.8310, -2.8621, -1.9776, -2.6805, -2.5577,\n",
      "        -2.2628, -2.4410, -2.7037, -2.1390, -2.3460, -2.2285, -2.2887, -2.4822,\n",
      "        -2.6983, -2.3775, -2.4937, -2.1028, -2.4144, -2.5950, -2.2445, -2.4233,\n",
      "        -2.5305, -2.1104], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6189, -2.6337, -2.6265, -2.6142, -2.6159, -2.5756, -2.5557, -2.5824,\n",
      "        -2.6093, -2.6298, -2.6173, -2.6298, -2.5749, -2.6115, -2.6300, -2.6292,\n",
      "        -2.6290, -2.6189, -2.6297, -2.4892, -2.6270, -2.6291, -2.6294, -2.6153,\n",
      "        -2.6255, -2.6103, -2.6230, -2.6288, -2.6056, -2.6198, -2.5791, -2.6280,\n",
      "        -2.5863, -2.6086, -2.6267, -2.6301, -2.6324, -2.6277, -2.5689, -2.6013,\n",
      "        -2.6279, -2.5945, -2.5711, -2.5976, -2.6173, -2.6277, -2.6169, -2.6290,\n",
      "        -2.6209, -2.6174], device='mps:0')\n",
      "mean: tensor(-2.6109, device='mps:0')\n",
      "iter_dt 1.12s; iter 17: train loss 1.36934 temperature: 5.849999999999997\n",
      "mean_logits tensor([-2.8580, -2.2128, -2.2135, -2.5708, -2.6557, -2.4785, -2.5710, -2.8469,\n",
      "        -2.1915, -2.3324, -2.4310, -2.4057, -2.1246, -2.3634, -2.6425, -2.5835,\n",
      "        -2.3113, -2.1067, -2.5253, -2.4763, -2.6667, -2.3979, -2.2503, -2.6639,\n",
      "        -2.7436, -2.3347, -2.6288, -2.2875, -2.1720, -2.2244, -2.3827, -2.7943,\n",
      "        -2.2709, -2.5339, -2.2634, -2.4916, -2.7449, -1.7647, -2.4777, -2.3207,\n",
      "        -2.4340, -2.3275, -2.3145, -2.0855, -2.2549, -2.5406, -2.5157, -2.2235,\n",
      "        -2.8459, -2.3486], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6265, -2.5790, -2.5459, -2.6204, -2.5744, -2.5745, -2.6295, -2.6016,\n",
      "        -2.5041, -2.6296, -2.6011, -2.6190, -2.5494, -2.6294, -2.6197, -2.5475,\n",
      "        -2.6292, -2.6118, -2.6130, -2.6096, -2.5970, -2.6022, -2.6237, -2.6199,\n",
      "        -2.6205, -2.6250, -2.6261, -2.5186, -2.5722, -2.6046, -2.6122, -2.6031,\n",
      "        -2.5655, -2.6241, -2.6293, -2.6058, -2.6226, -2.6287, -2.6223, -2.6289,\n",
      "        -2.5984, -2.6101, -2.5714, -2.6297, -2.5717, -2.6302, -2.5595, -2.6291,\n",
      "        -2.6288, -2.6130], device='mps:0')\n",
      "mean: tensor(-2.6022, device='mps:0')\n",
      "iter_dt 1.08s; iter 18: train loss 1.15454 temperature: 5.899999999999997\n",
      "mean_logits tensor([-2.3072, -2.3533, -2.4974, -2.7825, -2.3138, -2.6244, -2.4522, -2.4363,\n",
      "        -2.5821, -2.1342, -2.7059, -2.6624, -2.2127, -2.5967, -2.5290, -2.3653,\n",
      "        -2.1635, -2.5871, -2.1960, -2.6714, -2.5549, -2.6729, -2.5600, -2.7042,\n",
      "        -2.3945, -3.0577, -2.5658, -2.0149, -2.4382, -2.4863, -2.2727, -2.1849,\n",
      "        -2.6217, -2.6178, -2.2548, -2.6031, -2.6266, -2.5511, -2.2408, -2.5073,\n",
      "        -2.2206, -2.8239, -2.6382, -2.5742, -1.9596, -2.5620, -2.4913, -2.3285,\n",
      "        -2.4693, -2.3906], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5763, -2.6255, -2.6135, -2.6290, -2.6042, -2.5850, -2.5805, -2.5818,\n",
      "        -2.6304, -2.5664, -2.6289, -2.6240, -2.5721, -2.6074, -2.6061, -2.6115,\n",
      "        -2.6292, -2.6037, -2.6288, -2.6278, -2.6285, -2.5764, -2.6343, -2.6221,\n",
      "        -2.6159, -2.6193, -2.6198, -2.6272, -2.6156, -2.6214, -2.5953, -2.6116,\n",
      "        -2.6198, -2.6240, -2.6124, -2.6293, -2.6193, -2.6291, -2.5729, -2.6278,\n",
      "        -2.6049, -2.6114, -2.5679, -2.6188, -2.5594, -2.6075, -2.6270, -2.6257,\n",
      "        -2.6299, -2.6315], device='mps:0')\n",
      "mean: tensor(-2.6108, device='mps:0')\n",
      "iter_dt 1.10s; iter 19: train loss 1.65119 temperature: 5.949999999999997\n",
      "mean_logits tensor([-2.5583, -2.4532, -2.4604, -2.9576, -2.7181, -2.6194, -2.9198, -2.0601,\n",
      "        -2.7799, -2.5867, -2.1865, -2.4840, -2.3707, -2.1425, -2.6749, -2.7125,\n",
      "        -1.9920, -2.4778, -2.5638, -3.0261, -2.2772, -2.3710, -2.2997, -2.1687,\n",
      "        -2.6578, -2.6283, -2.2281, -2.5527, -2.2294, -2.2228, -2.3209, -2.0752,\n",
      "        -2.2269, -2.7144, -2.4380, -2.2529, -2.7574, -2.8601, -2.4864, -2.1510,\n",
      "        -2.6055, -2.4333, -2.3694, -2.8664, -2.1785, -2.6361, -2.3558, -2.5281,\n",
      "        -3.0085, -2.5026], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5683, -2.6283, -2.6137, -2.6120, -2.5726, -2.6178, -2.6286, -2.5232,\n",
      "        -2.5504, -2.5771, -2.5963, -2.6295, -2.6291, -2.5705, -2.6094, -2.6262,\n",
      "        -2.5670, -2.5526, -2.6083, -2.5885, -2.6294, -2.6267, -2.6168, -2.6057,\n",
      "        -2.6294, -2.6284, -2.6132, -2.6299, -2.6072, -2.6296, -2.5681, -2.6168,\n",
      "        -2.6043, -2.6248, -2.6266, -2.5620, -2.5912, -2.5532, -2.6122, -2.6235,\n",
      "        -2.6021, -2.6300, -2.6216, -2.6293, -2.6201, -2.6104, -2.6192, -2.6254,\n",
      "        -2.6284, -2.6297], device='mps:0')\n",
      "mean: tensor(-2.6057, device='mps:0')\n",
      "iter_dt 1.08s; iter 20: train loss 1.55180 temperature: 5.9999999999999964\n",
      "mean_logits tensor([-2.6333, -2.4990, -2.2975, -2.8174, -2.4226, -2.4279, -2.1461, -2.4167,\n",
      "        -2.0802, -2.6881, -2.1822, -2.6296, -2.0983, -2.5012, -2.6507, -2.5961,\n",
      "        -2.0876, -2.4304, -2.3480, -2.4780, -2.5366, -2.2629, -2.5431, -2.8108,\n",
      "        -2.8613, -2.5057, -1.7842, -2.2495, -2.2932, -2.4148, -2.2683, -2.4688,\n",
      "        -2.9907, -2.2605, -2.7812, -2.9655, -2.3755, -2.2770, -2.7266, -2.3566,\n",
      "        -2.3384, -2.7108, -2.1583, -2.8143, -2.3412, -2.8425, -2.3369, -2.5452,\n",
      "        -2.7945, -2.4070], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6285, -2.6196, -2.5701, -2.6184, -2.6124, -2.6163, -2.6090, -2.5718,\n",
      "        -2.6208, -2.6283, -2.6152, -2.5534, -2.6233, -2.6036, -2.6151, -2.6162,\n",
      "        -2.5759, -2.6302, -2.5676, -2.6060, -2.6251, -2.5870, -2.6096, -2.6194,\n",
      "        -2.6270, -2.6291, -2.6041, -2.6286, -2.6222, -2.6272, -2.6056, -2.6145,\n",
      "        -2.6164, -2.6164, -2.6180, -2.6264, -2.6136, -2.6116, -2.6288, -2.6295,\n",
      "        -2.6265, -2.6273, -2.5973, -2.5765, -2.6175, -2.6154, -2.5652, -2.6224,\n",
      "        -2.6162, -2.6171], device='mps:0')\n",
      "mean: tensor(-2.6109, device='mps:0')\n",
      "iter_dt 1.10s; iter 21: train loss 1.38730 temperature: 6.049999999999996\n",
      "mean_logits tensor([-2.5390, -2.7269, -2.5869, -2.6303, -2.9561, -2.4769, -2.4981, -2.6705,\n",
      "        -2.7351, -2.6361, -2.5957, -2.5873, -2.8043, -2.7550, -2.2234, -2.4048,\n",
      "        -2.4332, -2.8131, -2.9506, -2.6943, -2.5937, -2.6381, -2.8694, -2.7993,\n",
      "        -2.8748, -2.5886, -2.6460, -2.7480, -2.6004, -3.0939, -2.3327, -2.0011,\n",
      "        -2.8833, -2.1652, -2.6927, -1.8052, -2.7196, -2.5355, -2.5875, -2.3660,\n",
      "        -2.3980, -2.2985, -2.3621, -2.5147, -2.0242, -2.5320, -2.0887, -2.5666,\n",
      "        -2.1838, -2.6086], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6111, -2.6294, -2.6257, -2.5633, -2.5794, -2.6181, -2.5681, -2.5810,\n",
      "        -2.6253, -2.6265, -2.6295, -2.6295, -2.6184, -2.6202, -2.5856, -2.6254,\n",
      "        -2.6060, -2.6295, -2.6014, -2.6258, -2.6148, -2.6172, -2.6300, -2.5722,\n",
      "        -2.6166, -2.5543, -2.6067, -2.6294, -2.6197, -2.6276, -2.6055, -2.6004,\n",
      "        -2.6097, -2.5493, -2.5637, -2.6182, -2.6196, -2.6004, -2.6279, -2.6211,\n",
      "        -2.5553, -2.6296, -2.5479, -2.6183, -2.6283, -2.6321, -2.5423, -2.6289,\n",
      "        -2.6290, -2.6186], device='mps:0')\n",
      "mean: tensor(-2.6067, device='mps:0')\n",
      "iter_dt 1.12s; iter 22: train loss 1.29670 temperature: 6.099999999999996\n",
      "mean_logits tensor([-2.5080, -2.1862, -2.7792, -2.4064, -2.2312, -2.2993, -2.8122, -2.3339,\n",
      "        -2.7167, -2.6375, -1.9376, -2.9431, -2.4373, -2.7143, -2.5344, -2.9603,\n",
      "        -2.8107, -2.4138, -2.4904, -2.4618, -2.3764, -2.2994, -2.2454, -2.6878,\n",
      "        -2.3116, -2.4643, -2.6482, -2.5923, -1.7169, -2.7831, -2.3184, -2.8584,\n",
      "        -2.6321, -2.7177, -2.8983, -2.7482, -2.5816, -2.3399, -2.5745, -2.2945,\n",
      "        -2.2053, -2.4673, -2.5301, -2.7594, -2.1596, -2.6841, -2.4953, -2.4900,\n",
      "        -2.6654, -2.3745], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6203, -2.6292, -2.6295, -2.6254, -2.6099, -2.6080, -2.6271, -2.6056,\n",
      "        -2.6048, -2.6263, -2.6286, -2.6300, -2.5483, -2.6269, -2.5767, -2.6189,\n",
      "        -2.6024, -2.5533, -2.6184, -2.6067, -2.6188, -2.5826, -2.5625, -2.6292,\n",
      "        -2.6301, -2.6288, -2.6300, -2.6301, -2.6114, -2.6134, -2.5094, -2.6194,\n",
      "        -2.6110, -2.5709, -2.6299, -2.6198, -2.6096, -2.5799, -2.4259, -2.5595,\n",
      "        -2.6242, -2.5784, -2.6190, -2.5843, -2.5989, -2.5765, -2.6225, -2.6270,\n",
      "        -2.6247, -2.6268], device='mps:0')\n",
      "mean: tensor(-2.6030, device='mps:0')\n",
      "iter_dt 1.10s; iter 23: train loss 1.20621 temperature: 6.149999999999996\n",
      "mean_logits tensor([-2.5961, -2.5148, -2.8123, -2.5232, -2.8091, -2.3596, -2.6098, -2.7158,\n",
      "        -2.5137, -2.0657, -2.5181, -2.1646, -2.2651, -2.7516, -2.4903, -2.1383,\n",
      "        -2.9696, -2.2173, -2.3846, -2.7349, -2.4106, -2.7483, -2.1702, -2.5000,\n",
      "        -2.8391, -2.6676, -2.1295, -2.6597, -2.6017, -2.5898, -2.6382, -2.6389,\n",
      "        -2.5153, -2.0827, -2.6935, -2.9066, -2.8120, -2.2821, -2.4111, -2.3808,\n",
      "        -2.3012, -2.3632, -2.7352, -2.4909, -2.1046, -2.6564, -2.2382, -2.6648,\n",
      "        -2.5173, -2.6468], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5964, -2.6290, -2.5404, -2.5915, -2.6153, -2.5732, -2.6219, -2.6284,\n",
      "        -2.6080, -2.6277, -2.6137, -2.6223, -2.6023, -2.6295, -2.6168, -2.6154,\n",
      "        -2.6265, -2.6266, -2.6270, -2.6179, -2.5647, -2.5953, -2.6034, -2.6286,\n",
      "        -2.6287, -2.6140, -2.6299, -2.6285, -2.5579, -2.6290, -2.5679, -2.5224,\n",
      "        -2.6199, -2.5119, -2.6295, -2.5585, -2.6074, -2.5587, -2.5689, -2.6245,\n",
      "        -2.5777, -2.5862, -2.6268, -2.6189, -2.6083, -2.6086, -2.6164, -2.6338,\n",
      "        -2.6282, -2.6235], device='mps:0')\n",
      "mean: tensor(-2.6042, device='mps:0')\n",
      "iter_dt 1.09s; iter 24: train loss 1.21976 temperature: 6.199999999999996\n",
      "mean_logits tensor([-2.8886, -2.5764, -2.3823, -2.9135, -2.6341, -2.4506, -2.6572, -2.4177,\n",
      "        -2.5326, -2.3310, -2.7987, -2.6491, -2.7204, -2.2756, -2.6678, -2.4787,\n",
      "        -2.9250, -2.7246, -2.8811, -2.4592, -2.4180, -3.0016, -2.9355, -2.9413,\n",
      "        -2.7258, -2.0873, -2.7548, -2.4432, -2.7827, -2.6323, -2.7045, -2.1849,\n",
      "        -2.5631, -2.6936, -2.3371, -2.0669, -2.2587, -2.4131, -2.8802, -2.4603,\n",
      "        -2.4031, -2.5110, -2.5957, -2.7901, -2.7296, -2.3910, -2.8127, -2.6975,\n",
      "        -2.5491, -2.5691], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6283, -2.5678, -2.6288, -2.6096, -2.6286, -2.5840, -2.6298, -2.5559,\n",
      "        -2.5915, -2.5732, -2.6328, -2.6153, -2.6295, -2.6293, -2.6296, -2.6258,\n",
      "        -2.5655, -2.6065, -2.6183, -2.6227, -2.6293, -2.5740, -2.6286, -2.6295,\n",
      "        -2.5914, -2.6060, -2.6134, -2.6289, -2.6265, -2.4941, -2.5966, -2.6214,\n",
      "        -2.6298, -2.6299, -2.6198, -2.5644, -2.6280, -2.6293, -2.6259, -2.6072,\n",
      "        -2.5253, -2.6141, -2.6186, -2.6243, -2.5632, -2.5389, -2.5826, -2.6169,\n",
      "        -2.6272, -2.6198], device='mps:0')\n",
      "mean: tensor(-2.6056, device='mps:0')\n",
      "iter_dt 1.13s; iter 25: train loss 1.60859 temperature: 6.249999999999996\n",
      "mean_logits tensor([-2.5809, -2.7418, -2.6687, -2.1872, -2.3552, -2.7734, -2.8712, -2.7453,\n",
      "        -2.6943, -2.2971, -2.9056, -2.3679, -2.4725, -2.4509, -2.4614, -2.1768,\n",
      "        -2.7940, -2.7609, -2.6322, -2.7941, -2.9500, -2.3935, -2.5451, -2.0497,\n",
      "        -2.6079, -2.9651, -2.8172, -2.5807, -2.9343, -1.8569, -3.0098, -2.7525,\n",
      "        -2.2705, -2.4757, -2.6326, -2.4560, -2.3972, -2.3948, -2.1032, -2.9493,\n",
      "        -2.1345, -2.4530, -2.4648, -2.5052, -2.9953, -2.6388, -2.4431, -2.5952,\n",
      "        -2.3272, -2.4813], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6043, -2.5929, -2.6289, -2.6269, -2.5796, -2.5946, -2.6270, -2.6222,\n",
      "        -2.6094, -2.6151, -2.5554, -2.6143, -2.5622, -2.6286, -2.6265, -2.6233,\n",
      "        -2.6190, -2.6293, -2.6133, -2.6265, -2.6292, -2.6269, -2.6056, -2.6064,\n",
      "        -2.5741, -2.6176, -2.6157, -2.6137, -2.5749, -2.6149, -2.6196, -2.6266,\n",
      "        -2.6244, -2.6292, -2.6294, -2.5402, -2.5720, -2.6184, -2.6212, -2.6277,\n",
      "        -2.6100, -2.6269, -2.6055, -2.6039, -2.6188, -2.6288, -2.6302, -2.6288,\n",
      "        -2.5531, -2.6298], device='mps:0')\n",
      "mean: tensor(-2.6104, device='mps:0')\n",
      "iter_dt 1.13s; iter 26: train loss 0.97454 temperature: 6.299999999999995\n",
      "mean_logits tensor([-2.3315, -2.4427, -2.4233, -2.5507, -2.2261, -2.5119, -2.9428, -2.4401,\n",
      "        -2.7486, -2.4111, -2.3454, -2.4968, -2.5318, -2.3462, -2.4573, -2.6230,\n",
      "        -2.4467, -2.9384, -2.3411, -2.4500, -2.9665, -2.5374, -2.6407, -2.2809,\n",
      "        -2.4763, -2.3011, -2.8521, -2.5710, -2.5517, -2.4947, -2.5791, -2.8228,\n",
      "        -2.1222, -2.6178, -2.5046, -2.4767, -2.7626, -2.6933, -2.5669, -2.4143,\n",
      "        -2.3825, -2.7879, -2.3365, -2.5085, -2.2142, -2.5610, -2.1865, -2.4468,\n",
      "        -2.5803, -2.8021], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5910, -2.6249, -2.6255, -2.5087, -2.5821, -2.5753, -2.6188, -2.6183,\n",
      "        -2.6161, -2.6270, -2.5761, -2.6187, -2.6260, -2.6109, -2.6304, -2.6257,\n",
      "        -2.5850, -2.6178, -2.5744, -2.5759, -2.6225, -2.6079, -2.6188, -2.6224,\n",
      "        -2.5571, -2.6077, -2.6056, -2.5808, -2.6042, -2.6295, -2.6273, -2.6266,\n",
      "        -2.6018, -2.6174, -2.5952, -2.6269, -2.6137, -2.6035, -2.5420, -2.6016,\n",
      "        -2.5858, -2.5941, -2.5764, -2.6272, -2.6304, -2.6235, -2.6195, -2.5705,\n",
      "        -2.6261, -2.6352], device='mps:0')\n",
      "mean: tensor(-2.6046, device='mps:0')\n",
      "iter_dt 1.17s; iter 27: train loss 1.23347 temperature: 6.349999999999995\n",
      "mean_logits tensor([-2.4655, -2.7659, -2.7093, -2.8888, -2.2658, -2.7479, -2.7714, -2.7761,\n",
      "        -2.9289, -2.6927, -2.2248, -2.1947, -2.4016, -2.1974, -2.3451, -2.4084,\n",
      "        -2.9291, -2.5954, -2.4484, -2.5984, -2.4765, -2.4803, -2.7179, -2.3625,\n",
      "        -2.3705, -2.6833, -2.7232, -2.3267, -2.5304, -2.9464, -2.3359, -2.2086,\n",
      "        -2.6301, -2.5972, -2.6697, -2.7480, -2.1436, -2.6003, -2.5870, -2.7477,\n",
      "        -2.5450, -2.5190, -2.7302, -2.8451, -2.8107, -2.9416, -2.4887, -2.4771,\n",
      "        -1.9281, -2.7259], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5675, -2.6058, -2.6189, -2.6046, -2.6146, -2.6171, -2.6309, -2.5984,\n",
      "        -2.6344, -2.6077, -2.5814, -2.6252, -2.6126, -2.6295, -2.6113, -2.6259,\n",
      "        -2.6214, -2.6294, -2.5935, -2.5994, -2.6256, -2.5864, -2.5563, -2.5494,\n",
      "        -2.6134, -2.6292, -2.5882, -2.5632, -2.6190, -2.6077, -2.6290, -2.6259,\n",
      "        -2.6284, -2.6269, -2.6290, -2.6244, -2.6277, -2.6124, -2.6286, -2.6296,\n",
      "        -2.6314, -2.6296, -2.6076, -2.6193, -2.6301, -2.5396, -2.6064, -2.6163,\n",
      "        -2.6179, -2.6209], device='mps:0')\n",
      "mean: tensor(-2.6110, device='mps:0')\n",
      "iter_dt 1.11s; iter 28: train loss 0.89590 temperature: 6.399999999999995\n",
      "mean_logits tensor([-2.3925, -2.7452, -2.6541, -2.5903, -2.5389, -2.6337, -2.4786, -2.6711,\n",
      "        -2.3702, -2.2053, -2.4246, -2.4522, -2.6836, -2.7381, -2.4233, -2.6355,\n",
      "        -2.5817, -2.2387, -2.6739, -2.5409, -2.7374, -2.4820, -2.0840, -1.7583,\n",
      "        -2.3346, -2.6455, -2.2547, -2.8683, -2.2198, -2.2005, -2.2638, -2.6616,\n",
      "        -2.2817, -2.5448, -2.6482, -2.5435, -2.6962, -2.5594, -2.6456, -2.6983,\n",
      "        -2.4806, -2.5509, -2.5392, -2.4245, -2.7996, -2.5565, -2.1793, -2.7117,\n",
      "        -2.4349, -2.6382], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6291, -2.5897, -2.5650, -2.6294, -2.5794, -2.6240, -2.6108, -2.5797,\n",
      "        -2.6135, -2.6288, -2.5709, -2.6300, -2.6266, -2.6121, -2.6136, -2.6167,\n",
      "        -2.6285, -2.5628, -2.5968, -2.6240, -2.6272, -2.6305, -2.5771, -2.6293,\n",
      "        -2.5134, -2.6279, -2.5285, -2.6259, -2.6152, -2.6293, -2.6074, -2.6164,\n",
      "        -2.5920, -2.6148, -2.6034, -2.6250, -2.6301, -2.5870, -2.6098, -2.6084,\n",
      "        -2.6163, -2.5529, -2.6137, -2.5033, -2.6285, -2.6012, -2.6168, -2.6123,\n",
      "        -2.6295, -2.6191], device='mps:0')\n",
      "mean: tensor(-2.6045, device='mps:0')\n",
      "iter_dt 1.12s; iter 29: train loss 1.37271 temperature: 6.449999999999995\n",
      "mean_logits tensor([-2.6723, -2.2597, -2.7953, -2.4873, -2.5431, -2.4088, -2.9065, -2.2063,\n",
      "        -2.3331, -2.5409, -2.8258, -2.8947, -2.6049, -2.6477, -2.6601, -2.6314,\n",
      "        -2.1652, -2.7574, -2.4029, -2.3932, -2.6985, -2.4430, -2.4883, -2.3408,\n",
      "        -2.2751, -2.3890, -2.4343, -2.0666, -2.2911, -2.4731, -2.5180, -2.1895,\n",
      "        -2.7140, -2.4807, -2.5577, -2.5291, -3.0017, -2.4636, -2.4166, -2.5465,\n",
      "        -2.6427, -1.9052, -2.8625, -2.2328, -2.2520, -2.4892, -2.5835, -2.8163,\n",
      "        -3.0074, -2.7906], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5438, -2.6290, -2.6188, -2.5763, -2.5710, -2.6137, -2.6293, -2.5795,\n",
      "        -2.6277, -2.6297, -2.5994, -2.6185, -2.6195, -2.6272, -2.5804, -2.6110,\n",
      "        -2.6087, -2.5772, -2.6291, -2.6029, -2.6254, -2.5716, -2.6242, -2.6187,\n",
      "        -2.6153, -2.6287, -2.6078, -2.5478, -2.6202, -2.6182, -2.5748, -2.6206,\n",
      "        -2.6190, -2.6240, -2.6196, -2.6033, -2.6196, -2.6080, -2.6269, -2.6267,\n",
      "        -2.5691, -2.6219, -2.6276, -2.6234, -2.5959, -2.6188, -2.6196, -2.5595,\n",
      "        -2.5788, -2.6278], device='mps:0')\n",
      "mean: tensor(-2.6071, device='mps:0')\n",
      "iter_dt 1.08s; iter 30: train loss 1.03056 temperature: 6.499999999999995\n",
      "mean_logits tensor([-2.6397, -2.2056, -2.6794, -2.7410, -2.4313, -2.7551, -2.5095, -2.7030,\n",
      "        -2.3270, -2.6893, -2.3572, -2.3789, -2.3587, -2.3309, -2.4888, -1.9995,\n",
      "        -2.3116, -2.4360, -2.7052, -2.2922, -2.2731, -2.2457, -2.8797, -2.2261,\n",
      "        -2.6109, -2.5694, -2.4183, -2.6500, -2.4199, -2.6861, -2.4305, -2.8744,\n",
      "        -2.5819, -2.7113, -2.3196, -2.5096, -2.5106, -2.6380, -2.4138, -2.5213,\n",
      "        -2.2142, -2.1233, -2.3915, -2.4027, -2.4371, -2.3768, -2.6194, -2.4119,\n",
      "        -2.7741, -2.8839], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6185, -2.6074, -2.5474, -2.6333, -2.5699, -2.6131, -2.5815, -2.6137,\n",
      "        -2.6278, -2.6301, -2.6120, -2.6197, -2.5690, -2.6289, -2.6291, -2.6196,\n",
      "        -2.5990, -2.5606, -2.6204, -2.6132, -2.6145, -2.6262, -2.6194, -2.6283,\n",
      "        -2.6062, -2.5580, -2.6079, -2.6260, -2.6299, -2.6283, -2.6198, -2.6257,\n",
      "        -2.6188, -2.6216, -2.6269, -2.6326, -2.6126, -2.6290, -2.6171, -2.6134,\n",
      "        -2.5606, -2.6267, -2.6023, -2.5548, -2.5879, -2.5597, -2.5321, -2.5522,\n",
      "        -2.6164, -2.6300], device='mps:0')\n",
      "mean: tensor(-2.6060, device='mps:0')\n",
      "iter_dt 1.07s; iter 31: train loss 0.99632 temperature: 6.5499999999999945\n",
      "mean_logits tensor([-2.3614, -2.2057, -2.4207, -2.5896, -2.4786, -2.4403, -2.3939, -2.4748,\n",
      "        -2.5295, -2.5126, -2.5740, -2.6939, -2.2805, -2.1132, -2.5388, -2.6237,\n",
      "        -2.1229, -2.0996, -2.4989, -2.4480, -2.4919, -2.1705, -2.4527, -2.7559,\n",
      "        -2.5488, -2.5687, -2.3202, -2.8038, -2.5903, -1.9222, -2.6783, -2.3177,\n",
      "        -2.4225, -2.6340, -2.5780, -2.6789, -2.2991, -2.2152, -2.4226, -2.4676,\n",
      "        -2.9170, -2.2815, -2.4187, -2.5581, -2.6415, -2.4860, -2.5226, -2.5959,\n",
      "        -2.3109, -2.6801], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6292, -2.6188, -2.6080, -2.6264, -2.6293, -2.6160, -2.6258, -2.5518,\n",
      "        -2.6067, -2.6290, -2.6239, -2.6171, -2.5552, -2.6026, -2.6246, -2.5794,\n",
      "        -2.5638, -2.6279, -2.6128, -2.5778, -2.6297, -2.5777, -2.5968, -2.6275,\n",
      "        -2.5599, -2.6123, -2.6080, -2.6289, -2.6190, -2.6004, -2.5647, -2.6296,\n",
      "        -2.6099, -2.6206, -2.6291, -2.6294, -2.5467, -2.5925, -2.6030, -2.6291,\n",
      "        -2.6296, -2.6025, -2.6122, -2.6135, -2.5843, -2.6090, -2.6274, -2.6289,\n",
      "        -2.6218, -2.6164], device='mps:0')\n",
      "mean: tensor(-2.6077, device='mps:0')\n",
      "iter_dt 1.16s; iter 32: train loss 0.85694 temperature: 6.599999999999994\n",
      "mean_logits tensor([-2.6994, -2.7324, -2.5629, -2.4578, -2.5152, -2.5221, -2.4951, -2.2682,\n",
      "        -2.6580, -2.5956, -2.7163, -2.4297, -2.7067, -2.5460, -2.6418, -2.5914,\n",
      "        -2.5611, -2.7464, -2.6534, -2.0662, -2.1614, -2.2408, -2.4624, -2.6983,\n",
      "        -2.4879, -2.3268, -2.3564, -2.7124, -2.2443, -2.5466, -2.7367, -2.2613,\n",
      "        -2.2658, -2.4564, -2.8612, -2.5745, -2.1308, -2.6517, -2.7705, -2.4387,\n",
      "        -2.2929, -2.4643, -2.4451, -2.3912, -2.5713, -2.5724, -2.5241, -2.4616,\n",
      "        -2.3533, -2.4063], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6295, -2.6168, -2.6300, -2.6033, -2.5189, -2.6295, -2.6263, -2.6163,\n",
      "        -2.6268, -2.6027, -2.6250, -2.5882, -2.6235, -2.6300, -2.6288, -2.6279,\n",
      "        -2.5637, -2.6289, -2.6082, -2.6240, -2.5742, -2.6203, -2.5997, -2.6302,\n",
      "        -2.6243, -2.6191, -2.6301, -2.6268, -2.6009, -2.6281, -2.6079, -2.5988,\n",
      "        -2.6155, -2.6282, -2.5558, -2.6260, -2.6247, -2.6291, -2.5545, -2.5790,\n",
      "        -2.6205, -2.6256, -2.6231, -2.5557, -2.6297, -2.6253, -2.5956, -2.5878,\n",
      "        -2.6192, -2.6301], device='mps:0')\n",
      "mean: tensor(-2.6107, device='mps:0')\n",
      "iter_dt 1.08s; iter 33: train loss 1.03864 temperature: 6.649999999999994\n",
      "mean_logits tensor([-2.4186, -2.5327, -2.8037, -2.3648, -2.5796, -2.5322, -2.3056, -2.6753,\n",
      "        -2.7285, -2.6699, -2.5433, -2.1457, -2.3419, -2.6881, -2.4349, -2.2987,\n",
      "        -2.4511, -2.2957, -2.3588, -2.0821, -2.8981, -2.7862, -2.4782, -2.2353,\n",
      "        -2.7058, -2.1837, -2.7169, -2.5701, -2.7306, -2.7218, -2.5173, -2.5648,\n",
      "        -2.5324, -2.3633, -2.2321, -2.5598, -2.6829, -2.3267, -2.6618, -2.2441,\n",
      "        -2.6617, -2.7632, -2.2359, -2.5215, -2.2238, -2.8861, -2.3184, -2.3715,\n",
      "        -2.7975, -2.5243], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5809, -2.6279, -2.6165, -2.5845, -2.6285, -2.5965, -2.5595, -2.6162,\n",
      "        -2.6125, -2.6288, -2.6263, -2.6292, -2.6126, -2.5933, -2.6294, -2.6096,\n",
      "        -2.5902, -2.5981, -2.6293, -2.6247, -2.6283, -2.6288, -2.6134, -2.6141,\n",
      "        -2.6307, -2.6272, -2.6197, -2.6191, -2.6277, -2.5755, -2.6142, -2.6195,\n",
      "        -2.6303, -2.6191, -2.5784, -2.6195, -2.5952, -2.6192, -2.6277, -2.6254,\n",
      "        -2.6188, -2.6116, -2.5482, -2.5851, -2.6080, -2.5912, -2.6293, -2.6286,\n",
      "        -2.6287, -2.5018], device='mps:0')\n",
      "mean: tensor(-2.6096, device='mps:0')\n",
      "iter_dt 1.08s; iter 34: train loss 1.21743 temperature: 6.699999999999994\n",
      "mean_logits tensor([-2.1046, -2.2697, -2.7287, -2.3111, -2.6463, -2.1825, -2.1338, -2.5277,\n",
      "        -2.4989, -2.7454, -2.3423, -2.6033, -2.4988, -2.5763, -2.4106, -2.2537,\n",
      "        -2.7146, -2.4540, -2.7578, -2.2945, -2.0720, -2.5195, -2.8337, -2.8578,\n",
      "        -2.8371, -2.5126, -2.6266, -2.8917, -2.1792, -2.6681, -2.5379, -2.5966,\n",
      "        -2.7858, -2.1231, -2.4012, -2.5522, -2.6760, -2.5589, -2.2298, -2.6489,\n",
      "        -2.0967, -2.5421, -2.7355, -2.3657, -2.7301, -2.4791, -2.6206, -2.1866,\n",
      "        -2.8274, -2.5678], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6047, -2.6023, -2.6296, -2.6150, -2.5716, -2.6178, -2.6167, -2.6270,\n",
      "        -2.6286, -2.6273, -2.6123, -2.6298, -2.6294, -2.6074, -2.6339, -2.6270,\n",
      "        -2.5632, -2.5918, -2.6170, -2.6284, -2.6176, -2.6004, -2.6285, -2.6052,\n",
      "        -2.5956, -2.6113, -2.6271, -2.6186, -2.5644, -2.6274, -2.6149, -2.5554,\n",
      "        -2.6197, -2.6260, -2.6073, -2.6155, -2.6159, -2.6294, -2.6122, -2.6296,\n",
      "        -2.6163, -2.6296, -2.6168, -2.6190, -2.6033, -2.6296, -2.6161, -2.6291,\n",
      "        -2.5818, -2.6046], device='mps:0')\n",
      "mean: tensor(-2.6130, device='mps:0')\n",
      "iter_dt 1.08s; iter 35: train loss 0.86151 temperature: 6.749999999999994\n",
      "mean_logits tensor([-2.4190, -2.3638, -2.4015, -2.4327, -2.4785, -2.6159, -2.4956, -2.5113,\n",
      "        -2.3061, -2.5511, -2.7930, -2.4795, -2.8924, -2.4041, -2.6638, -2.2494,\n",
      "        -2.6368, -2.3836, -2.4270, -2.3204, -2.5131, -2.7429, -2.7572, -2.3073,\n",
      "        -2.5023, -2.3742, -2.7196, -2.2813, -2.2654, -2.6528, -2.6525, -2.5683,\n",
      "        -2.5356, -2.6840, -2.4960, -2.7042, -2.5238, -2.6750, -2.6194, -2.6249,\n",
      "        -2.5953, -2.3312, -3.0185, -2.2649, -2.3033, -2.3909, -2.4040, -2.5344,\n",
      "        -2.6612, -2.1476], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5630, -2.6267, -2.6159, -2.6206, -2.6270, -2.6170, -2.6008, -2.6077,\n",
      "        -2.6118, -2.6194, -2.5986, -2.6351, -2.6037, -2.6022, -2.6037, -2.6276,\n",
      "        -2.5745, -2.5996, -2.6077, -2.5614, -2.6179, -2.6265, -2.6289, -2.6348,\n",
      "        -2.6072, -2.6060, -2.6059, -2.6071, -2.5545, -2.6081, -2.5745, -2.5606,\n",
      "        -2.6340, -2.6191, -2.6189, -2.6063, -2.6122, -2.6144, -2.6271, -2.6265,\n",
      "        -2.6135, -2.6290, -2.6180, -2.5516, -2.6308, -2.6244, -2.6205, -2.6276,\n",
      "        -2.6199, -2.5770], device='mps:0')\n",
      "mean: tensor(-2.6085, device='mps:0')\n",
      "iter_dt 1.07s; iter 36: train loss 0.83602 temperature: 6.799999999999994\n",
      "mean_logits tensor([-2.1894, -2.4706, -2.6065, -2.7385, -2.8179, -2.6374, -2.6640, -2.6102,\n",
      "        -2.6855, -2.6940, -2.6068, -2.4753, -2.6788, -2.7499, -2.6504, -2.6397,\n",
      "        -2.5959, -2.1752, -2.5134, -2.8244, -2.4074, -2.2688, -2.8013, -2.4121,\n",
      "        -2.4990, -2.6574, -2.0538, -2.3460, -2.4577, -2.4759, -2.8802, -2.6561,\n",
      "        -2.4919, -2.4392, -2.5040, -2.6549, -2.4645, -2.5269, -2.6926, -2.2846,\n",
      "        -2.2753, -2.8031, -1.9816, -2.4252, -2.4779, -2.5753, -2.6516, -2.2979,\n",
      "        -2.6880, -2.5110], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6275, -2.6283, -2.6203, -2.5659, -2.6194, -2.6296, -2.6288, -2.5880,\n",
      "        -2.6054, -2.6303, -2.6009, -2.6281, -2.6145, -2.6267, -2.6139, -2.6052,\n",
      "        -2.6034, -2.5754, -2.6152, -2.6192, -2.6083, -2.5549, -2.5924, -2.5395,\n",
      "        -2.6188, -2.6300, -2.6289, -2.5685, -2.6139, -2.6122, -2.6220, -2.6011,\n",
      "        -2.6168, -2.6076, -2.6225, -2.6258, -2.6048, -2.6294, -2.6063, -2.6174,\n",
      "        -2.6298, -2.6188, -2.6296, -2.6277, -2.6276, -2.5960, -2.5970, -2.6052,\n",
      "        -2.6202, -2.6180], device='mps:0')\n",
      "mean: tensor(-2.6107, device='mps:0')\n",
      "iter_dt 1.11s; iter 37: train loss 0.76757 temperature: 6.849999999999993\n",
      "mean_logits tensor([-2.4152, -2.4527, -2.8083, -2.7949, -2.4475, -2.4140, -2.1681, -2.6324,\n",
      "        -2.7286, -2.3952, -2.3072, -2.1581, -2.3692, -2.7084, -2.5152, -2.4842,\n",
      "        -2.5436, -2.8579, -2.5811, -2.6333, -2.6331, -2.3831, -2.6253, -2.6013,\n",
      "        -2.6567, -2.6631, -2.4234, -2.4013, -2.6669, -2.5119, -2.4842, -2.4347,\n",
      "        -2.2578, -2.3705, -2.3025, -2.5874, -2.6784, -2.6727, -2.6406, -2.5028,\n",
      "        -2.2792, -2.4817, -2.4455, -2.0906, -2.5904, -2.6230, -2.2427, -2.5528,\n",
      "        -2.6302, -2.5513], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6123, -2.5972, -2.6299, -2.6241, -2.6068, -2.5966, -2.6258, -2.6198,\n",
      "        -2.6130, -2.5607, -2.6044, -2.6290, -2.5763, -2.6300, -2.6020, -2.6116,\n",
      "        -2.6048, -2.5848, -2.6211, -2.6065, -2.4720, -2.5701, -2.6134, -2.6137,\n",
      "        -2.6256, -2.5660, -2.6297, -2.5847, -2.6172, -2.6210, -2.6174, -2.6291,\n",
      "        -2.5796, -2.6285, -2.6163, -2.5793, -2.6180, -2.6154, -2.6197, -2.6175,\n",
      "        -2.6127, -2.6161, -2.6299, -2.6292, -2.5909, -2.5853, -2.6047, -2.6263,\n",
      "        -2.6288, -2.6135], device='mps:0')\n",
      "mean: tensor(-2.6066, device='mps:0')\n",
      "iter_dt 1.10s; iter 38: train loss 1.05780 temperature: 6.899999999999993\n",
      "mean_logits tensor([-2.5422, -2.4345, -2.5567, -2.5604, -2.4752, -2.3455, -2.5867, -2.4341,\n",
      "        -2.5671, -2.6951, -2.3134, -2.7486, -2.1750, -2.3548, -2.5539, -2.5418,\n",
      "        -2.7019, -2.7456, -2.4363, -2.6116, -2.3851, -2.5098, -2.2375, -2.9363,\n",
      "        -2.3895, -2.7932, -2.2380, -2.3436, -2.5870, -2.3349, -2.5733, -2.8142,\n",
      "        -2.6436, -2.0850, -2.5036, -2.5809, -2.5698, -2.5929, -2.4532, -2.9028,\n",
      "        -2.3866, -2.5091, -2.9152, -2.4659, -2.7746, -2.8203, -2.3222, -2.5255,\n",
      "        -2.4731, -3.0779], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6240, -2.6281, -2.6113, -2.6112, -2.6300, -2.5588, -2.6254, -2.6270,\n",
      "        -2.6299, -2.6192, -2.6290, -2.6152, -2.5355, -2.6157, -2.6192, -2.5540,\n",
      "        -2.5966, -2.6287, -2.6075, -2.6030, -2.6051, -2.6124, -2.6255, -2.6271,\n",
      "        -2.6194, -2.6195, -2.6254, -2.6024, -2.6124, -2.6067, -2.6294, -2.5867,\n",
      "        -2.6118, -2.6099, -2.5631, -2.6065, -2.6236, -2.6020, -2.5973, -2.5827,\n",
      "        -2.6233, -2.6288, -2.6227, -2.6123, -2.6079, -2.6131, -2.6279, -2.6160,\n",
      "        -2.5987, -2.6292], device='mps:0')\n",
      "mean: tensor(-2.6104, device='mps:0')\n",
      "iter_dt 1.09s; iter 39: train loss 1.14989 temperature: 6.949999999999993\n",
      "mean_logits tensor([-2.9968, -2.7677, -1.9964, -2.1873, -2.8818, -2.2071, -2.5798, -2.4431,\n",
      "        -2.6771, -2.6876, -2.8107, -2.5863, -2.8036, -2.4488, -2.5089, -2.3421,\n",
      "        -2.6645, -2.4161, -2.3498, -2.1531, -2.3769, -2.5621, -2.8442, -2.8417,\n",
      "        -2.5495, -2.5316, -2.9716, -2.4854, -2.3905, -2.4282, -2.3342, -2.2925,\n",
      "        -2.5224, -2.6936, -2.3955, -2.3413, -2.3106, -2.6141, -2.4411, -2.4147,\n",
      "        -2.6292, -2.5556, -2.6864, -2.7211, -2.6010, -2.7863, -2.5820, -2.6174,\n",
      "        -2.3900, -2.9661], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6126, -2.6076, -2.6295, -2.6277, -2.6286, -2.6196, -2.5819, -2.5709,\n",
      "        -2.6271, -2.6195, -2.6009, -2.5828, -2.6263, -2.5764, -2.5702, -2.6251,\n",
      "        -2.6109, -2.5329, -2.6229, -2.6117, -2.6143, -2.5724, -2.6173, -2.6301,\n",
      "        -2.5613, -2.5908, -2.6131, -2.6088, -2.6288, -2.5952, -2.6084, -2.6203,\n",
      "        -2.6287, -2.6293, -2.6239, -2.6116, -2.6195, -2.6115, -2.6203, -2.5594,\n",
      "        -2.6282, -2.6096, -2.6180, -2.6299, -2.6033, -2.6123, -2.6329, -2.6171,\n",
      "        -2.6194, -2.6200], device='mps:0')\n",
      "mean: tensor(-2.6088, device='mps:0')\n",
      "iter_dt 1.10s; iter 40: train loss 0.91351 temperature: 6.999999999999993\n",
      "mean_logits tensor([-2.6474, -2.2404, -2.4331, -2.7702, -2.6309, -2.8484, -2.7337, -2.6453,\n",
      "        -2.8227, -2.7433, -2.4033, -2.6246, -2.3607, -2.2690, -2.2088, -2.4410,\n",
      "        -2.4696, -2.8482, -2.4950, -2.5927, -2.1314, -2.3168, -2.6906, -2.3951,\n",
      "        -2.8545, -2.6927, -2.8324, -2.3154, -2.6874, -2.6886, -2.7144, -2.7792,\n",
      "        -2.6855, -2.5620, -2.7179, -2.3075, -2.8700, -2.4184, -2.4644, -2.3366,\n",
      "        -2.7216, -2.3644, -2.5707, -2.8394, -2.3857, -2.4772, -2.7709, -2.7576,\n",
      "        -2.4481, -2.6189], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6297, -2.6046, -2.6290, -2.6078, -2.6014, -2.5889, -2.6165, -2.5787,\n",
      "        -2.6195, -2.5993, -2.6156, -2.6212, -2.6301, -2.6163, -2.5163, -2.6272,\n",
      "        -2.6039, -2.6126, -2.5971, -2.6140, -2.6298, -2.6297, -2.6247, -2.6071,\n",
      "        -2.6347, -2.6223, -2.5931, -2.6290, -2.6150, -2.6231, -2.5686, -2.6193,\n",
      "        -2.6026, -2.5921, -2.6172, -2.6309, -2.5997, -2.6191, -2.6070, -2.6171,\n",
      "        -2.6176, -2.5955, -2.6020, -2.6285, -2.6077, -2.5568, -2.6268, -2.5368,\n",
      "        -2.6253, -2.6041], device='mps:0')\n",
      "mean: tensor(-2.6083, device='mps:0')\n",
      "iter_dt 1.10s; iter 41: train loss 1.19368 temperature: 7.049999999999993\n",
      "mean_logits tensor([-2.1881, -2.9813, -2.4382, -2.6806, -2.5759, -2.6038, -2.6851, -2.6730,\n",
      "        -2.9144, -2.8040, -2.3886, -2.1645, -2.5001, -2.5048, -2.8854, -2.3147,\n",
      "        -2.5816, -2.6011, -2.4290, -2.4935, -2.3081, -2.5195, -2.2088, -2.2145,\n",
      "        -2.6347, -2.4121, -2.5315, -2.3803, -2.2507, -2.2319, -2.8429, -2.5562,\n",
      "        -2.0121, -2.0422, -2.3096, -2.3243, -2.7852, -2.4704, -2.6646, -2.7981,\n",
      "        -2.6251, -2.3401, -2.2622, -2.4668, -2.5685, -2.6401, -2.4598, -2.4667,\n",
      "        -2.6025, -2.4789], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6289, -2.5953, -2.6291, -2.6061, -2.5922, -2.6244, -2.6144, -2.5977,\n",
      "        -2.6291, -2.6273, -2.6019, -2.6283, -2.6168, -2.6268, -2.5628, -2.5525,\n",
      "        -2.6277, -2.6217, -2.6291, -2.5573, -2.6240, -2.6262, -2.5685, -2.6049,\n",
      "        -2.6107, -2.5629, -2.6181, -2.6073, -2.5992, -2.5517, -2.5652, -2.5608,\n",
      "        -2.6257, -2.5900, -2.5891, -2.6218, -2.6137, -2.6253, -2.6144, -2.6297,\n",
      "        -2.6120, -2.6083, -2.6253, -2.6110, -2.6172, -2.5967, -2.6208, -2.5782,\n",
      "        -2.6297, -2.6290], device='mps:0')\n",
      "mean: tensor(-2.6061, device='mps:0')\n",
      "iter_dt 1.11s; iter 42: train loss 0.91050 temperature: 7.0999999999999925\n",
      "mean_logits tensor([-2.3895, -2.6008, -2.6139, -2.6884, -2.7977, -2.4063, -2.2084, -2.5722,\n",
      "        -2.1324, -2.4663, -2.2163, -2.1578, -2.5271, -2.5731, -2.6941, -2.6589,\n",
      "        -2.5304, -2.4962, -2.7450, -2.4166, -2.7561, -2.4989, -2.5892, -2.3929,\n",
      "        -2.2892, -2.5549, -2.6858, -2.6694, -2.2985, -2.3015, -2.4563, -2.2200,\n",
      "        -2.2980, -2.4826, -2.5965, -2.6645, -2.2989, -2.6837, -2.9976, -2.6018,\n",
      "        -2.5272, -2.4577, -2.4495, -2.5674, -2.1656, -2.4422, -2.6609, -2.2139,\n",
      "        -2.4097, -2.4871], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6082, -2.6108, -2.6294, -2.6292, -2.6156, -2.5567, -2.6282, -2.5405,\n",
      "        -2.6000, -2.6050, -2.6010, -2.6285, -2.5427, -2.6291, -2.5912, -2.6064,\n",
      "        -2.6343, -2.5386, -2.6301, -2.6127, -2.6350, -2.5994, -2.6093, -2.5413,\n",
      "        -2.6057, -2.6129, -2.5209, -2.6252, -2.5190, -2.6227, -2.5639, -2.6019,\n",
      "        -2.6052, -2.6265, -2.6196, -2.5712, -2.6272, -2.6120, -2.6129, -2.5931,\n",
      "        -2.6013, -2.6181, -2.6079, -2.6059, -2.6101, -2.6128, -2.6075, -2.5794,\n",
      "        -2.6150, -2.6253], device='mps:0')\n",
      "mean: tensor(-2.6009, device='mps:0')\n",
      "iter_dt 1.09s; iter 43: train loss 0.71397 temperature: 7.149999999999992\n",
      "mean_logits tensor([-2.3660, -2.8110, -2.3546, -2.6799, -2.4671, -2.5181, -2.6524, -2.3544,\n",
      "        -2.6734, -2.7343, -2.6863, -2.5324, -2.3392, -2.7215, -2.4843, -2.4283,\n",
      "        -2.8007, -2.5662, -2.6418, -2.4620, -2.2254, -2.1971, -2.4079, -2.8210,\n",
      "        -2.5506, -2.5185, -2.5208, -2.6581, -2.5070, -2.5287, -2.6492, -2.4821,\n",
      "        -2.3065, -2.2106, -2.3834, -2.5179, -2.4856, -2.7285, -2.6232, -2.6844,\n",
      "        -2.7197, -2.2300, -2.1928, -2.6149, -2.6518, -2.7432, -2.8189, -2.6360,\n",
      "        -2.4367, -2.3788], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6205, -2.6064, -2.6074, -2.5532, -2.6067, -2.6141, -2.6122, -2.6220,\n",
      "        -2.6087, -2.6290, -2.6206, -2.6191, -2.5552, -2.6345, -2.6339, -2.5579,\n",
      "        -2.6293, -2.6061, -2.6284, -2.6198, -2.6250, -2.6044, -2.6304, -2.5949,\n",
      "        -2.5927, -2.6193, -2.5771, -2.6197, -2.6072, -2.5511, -2.6256, -2.5638,\n",
      "        -2.6290, -2.6294, -2.6207, -2.6171, -2.6155, -2.5782, -2.6083, -2.6347,\n",
      "        -2.6290, -2.6141, -2.5634, -2.6175, -2.5431, -2.6300, -2.6075, -2.5494,\n",
      "        -2.6081, -2.6064], device='mps:0')\n",
      "mean: tensor(-2.6059, device='mps:0')\n",
      "iter_dt 1.10s; iter 44: train loss 0.81680 temperature: 7.199999999999992\n",
      "mean_logits tensor([-2.2997, -2.1550, -2.8325, -2.4255, -2.5895, -2.6898, -2.4114, -2.6531,\n",
      "        -2.6723, -2.6977, -2.6511, -2.6132, -2.5541, -2.6177, -2.6689, -2.8009,\n",
      "        -2.7745, -2.5842, -2.6994, -2.4988, -2.2649, -2.4392, -2.4636, -2.3461,\n",
      "        -2.4543, -2.8538, -2.2959, -2.3610, -2.6364, -2.3921, -2.4751, -2.6046,\n",
      "        -2.5477, -2.5668, -2.4320, -2.6507, -2.1608, -2.3701, -2.8569, -2.8625,\n",
      "        -2.4671, -2.6916, -2.4534, -2.6572, -2.2424, -2.5056, -2.8921, -2.4130,\n",
      "        -2.1825, -2.5812], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5888, -2.5703, -2.6251, -2.4625, -2.6171, -2.6177, -2.6287, -2.6293,\n",
      "        -2.5628, -2.6205, -2.6077, -2.6127, -2.6083, -2.5973, -2.6050, -2.5745,\n",
      "        -2.5732, -2.5768, -2.6244, -2.5935, -2.6247, -2.5538, -2.5473, -2.6123,\n",
      "        -2.6174, -2.6296, -2.6293, -2.6143, -2.6251, -2.6320, -2.5808, -2.6095,\n",
      "        -2.6222, -2.6147, -2.6072, -2.6151, -2.5791, -2.6290, -2.6267, -2.6050,\n",
      "        -2.5868, -2.6292, -2.6080, -2.6312, -2.5487, -2.6081, -2.5717, -2.6255,\n",
      "        -2.6286, -2.6307], device='mps:0')\n",
      "mean: tensor(-2.6028, device='mps:0')\n",
      "iter_dt 1.09s; iter 45: train loss 0.71416 temperature: 7.249999999999992\n",
      "mean_logits tensor([-2.5675, -2.8255, -2.2583, -2.7825, -2.7243, -2.6546, -2.9915, -2.6838,\n",
      "        -2.5193, -2.5625, -2.5694, -2.4957, -2.4286, -2.4786, -2.1839, -2.7022,\n",
      "        -2.6150, -2.5981, -2.3405, -2.7378, -2.6997, -2.4892, -2.6774, -2.8768,\n",
      "        -2.5416, -2.1491, -2.6992, -2.6598, -2.6709, -2.8126, -2.7996, -2.5481,\n",
      "        -2.5829, -2.5292, -2.5378, -2.7969, -2.7130, -2.5090, -2.5021, -2.5083,\n",
      "        -2.5144, -2.5624, -2.4755, -2.7447, -2.2195, -2.7284, -2.5991, -2.6125,\n",
      "        -2.7564, -2.2426], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5709, -2.6171, -2.6211, -2.6253, -2.6275, -2.5929, -2.6298, -2.6293,\n",
      "        -2.6026, -2.6284, -2.6211, -2.6271, -2.5677, -2.6299, -2.6291, -2.6298,\n",
      "        -2.6080, -2.6084, -2.6300, -2.6067, -2.6257, -2.6280, -2.6077, -2.6204,\n",
      "        -2.6264, -2.5984, -2.6193, -2.6295, -2.6197, -2.6290, -2.6264, -2.6156,\n",
      "        -2.6257, -2.6152, -2.6255, -2.6080, -2.5974, -2.6106, -2.6286, -2.5844,\n",
      "        -2.6272, -2.6102, -2.5403, -2.6162, -2.5937, -2.5914, -2.6150, -2.5523,\n",
      "        -2.5856, -2.6280], device='mps:0')\n",
      "mean: tensor(-2.6121, device='mps:0')\n",
      "iter_dt 1.09s; iter 46: train loss 0.65745 temperature: 7.299999999999992\n",
      "mean_logits tensor([-2.3702, -2.6547, -2.4594, -2.6125, -2.3907, -2.5781, -2.8219, -2.7153,\n",
      "        -2.7050, -2.7174, -2.7173, -2.7195, -2.5452, -2.8577, -2.7469, -2.6754,\n",
      "        -2.4839, -2.7429, -2.6907, -2.5607, -2.5544, -2.4602, -2.5798, -2.4257,\n",
      "        -2.5835, -2.4970, -2.3361, -2.6613, -2.6135, -2.7274, -2.4868, -2.4442,\n",
      "        -2.5930, -2.1629, -2.3758, -2.1520, -2.0851, -2.4706, -2.6673, -2.4011,\n",
      "        -2.2793, -2.3151, -2.6247, -2.5234, -2.6192, -2.6284, -2.6010, -2.3714,\n",
      "        -2.5036, -2.3570], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6195, -2.6248, -2.6246, -2.5913, -2.6154, -2.6277, -2.6264, -2.6096,\n",
      "        -2.6129, -2.5497, -2.6301, -2.5846, -2.6077, -2.6300, -2.6298, -2.6273,\n",
      "        -2.6074, -2.6285, -2.6251, -2.5624, -2.6073, -2.6187, -2.6255, -2.6258,\n",
      "        -2.6000, -2.5834, -2.6263, -2.5123, -2.5664, -2.5564, -2.6187, -2.6234,\n",
      "        -2.6083, -2.6006, -2.5744, -2.5446, -2.6201, -2.6249, -2.6168, -2.6051,\n",
      "        -2.6171, -2.5629, -2.6291, -2.6067, -2.6256, -2.5713, -2.5755, -2.5898,\n",
      "        -2.5888, -2.6170], device='mps:0')\n",
      "mean: tensor(-2.6036, device='mps:0')\n",
      "iter_dt 1.12s; iter 47: train loss 0.81321 temperature: 7.349999999999992\n",
      "mean_logits tensor([-2.4947, -2.6248, -2.6868, -2.7267, -2.7876, -2.8634, -2.5051, -2.2900,\n",
      "        -2.5579, -2.5717, -2.3177, -2.3838, -2.6304, -2.3701, -2.4875, -2.1511,\n",
      "        -2.4678, -2.8430, -2.6189, -2.5229, -2.4416, -2.5663, -2.3971, -2.8084,\n",
      "        -2.5868, -2.5539, -2.5716, -2.4474, -2.6434, -2.0413, -2.7261, -2.4340,\n",
      "        -2.4595, -2.8058, -2.4475, -2.5045, -2.6534, -2.7670, -2.6039, -2.5618,\n",
      "        -2.5655, -2.5841, -2.8899, -2.6529, -2.3163, -2.7132, -1.9257, -2.3880,\n",
      "        -2.6100, -2.5538], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6280, -2.5772, -2.6079, -2.6106, -2.6279, -2.6068, -2.5699, -2.6280,\n",
      "        -2.6256, -2.6205, -2.6264, -2.5582, -2.6283, -2.6274, -2.6153, -2.6198,\n",
      "        -2.6155, -2.6228, -2.6269, -2.6341, -2.6193, -2.6293, -2.6064, -2.6194,\n",
      "        -2.6285, -2.6259, -2.6218, -2.5768, -2.5615, -2.6266, -2.6057, -2.6142,\n",
      "        -2.6155, -2.5886, -2.5769, -2.6081, -2.5786, -2.6147, -2.6189, -2.6038,\n",
      "        -2.6070, -2.6088, -2.6059, -2.6050, -2.5361, -2.6282, -2.6185, -2.6046,\n",
      "        -2.6279, -2.6279], device='mps:0')\n",
      "mean: tensor(-2.6097, device='mps:0')\n",
      "iter_dt 1.11s; iter 48: train loss 1.30438 temperature: 7.3999999999999915\n",
      "mean_logits tensor([-2.5523, -2.7699, -2.6481, -2.4821, -2.7496, -2.3439, -2.3345, -2.0725,\n",
      "        -2.4753, -2.3901, -2.4912, -2.8993, -2.5816, -2.8569, -2.6581, -2.4243,\n",
      "        -2.8565, -2.8287, -2.9407, -2.7319, -2.5433, -2.5137, -2.4344, -2.8219,\n",
      "        -2.4041, -2.2135, -2.5663, -2.5577, -2.6649, -2.3780, -2.4358, -2.5761,\n",
      "        -2.8093, -2.3541, -2.6564, -2.2562, -2.0707, -2.1167, -2.6270, -2.6200,\n",
      "        -2.7194, -2.2559, -2.6278, -2.8369, -2.2864, -2.3813, -2.5325, -2.3129,\n",
      "        -2.3765, -1.9188], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6192, -2.5589, -2.6272, -2.6142, -2.4482, -2.6258, -2.6134, -2.6261,\n",
      "        -2.6248, -2.6156, -2.6201, -2.6082, -2.6191, -2.6165, -2.6191, -2.5541,\n",
      "        -2.6143, -2.6080, -2.5655, -2.6154, -2.5698, -2.6266, -2.6214, -2.6193,\n",
      "        -2.5869, -2.6259, -2.6256, -2.6286, -2.6193, -2.6277, -2.5892, -2.4827,\n",
      "        -2.5551, -2.6143, -2.6282, -2.5949, -2.6079, -2.5900, -2.6329, -2.6290,\n",
      "        -2.6283, -2.5717, -2.6156, -2.6207, -2.6285, -2.6296, -2.5769, -2.6286,\n",
      "        -2.6250, -2.6299], device='mps:0')\n",
      "mean: tensor(-2.6049, device='mps:0')\n",
      "iter_dt 1.10s; iter 49: train loss 0.75761 temperature: 7.449999999999991\n",
      "mean_logits tensor([-2.4919, -2.7145, -2.7421, -2.4077, -2.8039, -2.7904, -2.4890, -2.5535,\n",
      "        -2.4000, -2.5720, -2.2515, -2.5469, -2.7787, -2.6208, -2.5287, -2.4368,\n",
      "        -2.5953, -2.5035, -2.5774, -2.4181, -2.3893, -2.6368, -2.6765, -2.2296,\n",
      "        -2.5647, -2.7867, -2.6543, -2.3176, -2.5742, -2.6209, -2.6504, -2.1805,\n",
      "        -2.7038, -2.3807, -2.4956, -2.8065, -2.3660, -2.4534, -2.5306, -2.2670,\n",
      "        -2.3249, -2.5084, -2.5061, -2.5129, -2.2737, -2.1817, -2.2576, -2.4246,\n",
      "        -2.7951, -2.7042], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5615, -2.6069, -2.6282, -2.6301, -2.6054, -2.6092, -2.5908, -2.5949,\n",
      "        -2.6284, -2.6294, -2.6286, -2.6294, -2.6304, -2.5784, -2.6296, -2.5646,\n",
      "        -2.6261, -2.6255, -2.6224, -2.6107, -2.5893, -2.5616, -2.5345, -2.6264,\n",
      "        -2.5887, -2.6055, -2.5963, -2.6111, -2.6273, -2.6177, -2.5779, -2.6118,\n",
      "        -2.5762, -2.5887, -2.6269, -2.6060, -2.5630, -2.6289, -2.6084, -2.4897,\n",
      "        -2.6068, -2.5766, -2.5772, -2.5601, -2.6259, -2.6290, -2.6249, -2.6144,\n",
      "        -2.6121, -2.6182], device='mps:0')\n",
      "mean: tensor(-2.6022, device='mps:0')\n",
      "iter_dt 1.10s; iter 50: train loss 0.67343 temperature: 7.499999999999991\n",
      "mean_logits tensor([-2.6493, -2.6860, -2.5247, -2.6106, -2.7857, -2.5628, -2.4821, -2.1676,\n",
      "        -2.3984, -2.5792, -2.5573, -2.6450, -2.4437, -2.5928, -2.7163, -2.4297,\n",
      "        -2.7969, -2.5112, -2.6722, -2.6502, -2.5485, -2.6201, -2.7889, -2.7645,\n",
      "        -2.6721, -2.4428, -2.1622, -2.4051, -2.3475, -2.5736, -2.6703, -2.6103,\n",
      "        -2.5002, -2.2087, -2.1773, -2.5895, -2.8647, -2.7465, -2.5292, -2.5714,\n",
      "        -2.5620, -2.6064, -2.6573, -2.8264, -2.6386, -2.7830, -2.5668, -2.8972,\n",
      "        -2.6533, -2.5283], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5915, -2.6174, -2.6288, -2.5692, -2.6141, -2.6097, -2.6109, -2.6043,\n",
      "        -2.6289, -2.6063, -2.6300, -2.6287, -2.6241, -2.6178, -2.6082, -2.6203,\n",
      "        -2.4946, -2.5761, -2.6033, -2.6219, -2.6132, -2.6125, -2.6079, -2.6051,\n",
      "        -2.5952, -2.5900, -2.5653, -2.6295, -2.5941, -2.6259, -2.6178, -2.5666,\n",
      "        -2.5921, -2.6170, -2.5788, -2.6167, -2.5522, -2.6100, -2.6303, -2.6268,\n",
      "        -2.5449, -2.6282, -2.6073, -2.5645, -2.6288, -2.6284, -2.5895, -2.5892,\n",
      "        -2.6084, -2.5976], device='mps:0')\n",
      "mean: tensor(-2.6028, device='mps:0')\n",
      "iter_dt 1.09s; iter 51: train loss 0.64953 temperature: 7.549999999999991\n",
      "mean_logits tensor([-2.4158, -2.5712, -2.6711, -2.6923, -2.6963, -2.3441, -2.6813, -2.7736,\n",
      "        -2.4996, -2.4701, -2.4445, -2.6513, -2.6268, -2.7148, -2.7458, -2.5147,\n",
      "        -2.6203, -2.5502, -2.5450, -2.6046, -2.6609, -2.4957, -2.4232, -2.4070,\n",
      "        -2.7274, -2.5713, -2.7318, -2.7178, -2.5654, -2.8350, -2.3760, -2.5517,\n",
      "        -2.4211, -2.5884, -2.7515, -1.9985, -2.4765, -2.2494, -2.5661, -2.1022,\n",
      "        -2.5384, -2.7148, -2.5402, -2.6290, -2.5911, -2.1642, -2.5420, -2.3815,\n",
      "        -2.3901, -2.3970], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6115, -2.6187, -2.6070, -2.5763, -2.6056, -2.6244, -2.6029, -2.6149,\n",
      "        -2.6071, -2.5746, -2.5706, -2.5355, -2.6221, -2.6129, -2.6296, -2.5645,\n",
      "        -2.6295, -2.6262, -2.6114, -2.6298, -2.6182, -2.5991, -2.6040, -2.6280,\n",
      "        -2.6279, -2.6157, -2.5696, -2.6205, -2.6250, -2.5941, -2.6131, -2.6264,\n",
      "        -2.6146, -2.5557, -2.6175, -2.6069, -2.6288, -2.6232, -2.6253, -2.6265,\n",
      "        -2.6155, -2.5501, -2.6291, -2.6178, -2.6301, -2.5442, -2.5525, -2.5797,\n",
      "        -2.6073, -2.6200], device='mps:0')\n",
      "mean: tensor(-2.6052, device='mps:0')\n",
      "iter_dt 1.08s; iter 52: train loss 1.16374 temperature: 7.599999999999991\n",
      "mean_logits tensor([-2.4816, -2.8616, -2.5745, -2.2967, -2.8312, -2.3197, -2.6679, -2.4922,\n",
      "        -2.2696, -2.6164, -2.1240, -2.5370, -2.2449, -2.3849, -2.7269, -2.5298,\n",
      "        -2.6036, -2.7976, -2.1301, -2.2776, -2.4645, -2.3146, -2.6227, -2.4473,\n",
      "        -2.4802, -2.2338, -2.5776, -2.3742, -2.7982, -2.3836, -2.5550, -2.4096,\n",
      "        -2.5052, -2.3146, -2.5832, -2.6504, -2.5787, -2.4795, -2.7246, -2.5187,\n",
      "        -2.7966, -2.2470, -2.1047, -2.3001, -2.4512, -2.4842, -3.1196, -2.7748,\n",
      "        -2.4112, -2.5256], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6292, -2.6246, -2.6296, -2.6253, -2.6288, -2.6118, -2.5194, -2.6180,\n",
      "        -2.6255, -2.6104, -2.5923, -2.6299, -2.5723, -2.5652, -2.6262, -2.5625,\n",
      "        -2.6271, -2.5664, -2.5233, -2.6107, -2.6299, -2.6162, -2.6178, -2.6207,\n",
      "        -2.6074, -2.6088, -2.5820, -2.6079, -2.6290, -2.6049, -2.6207, -2.5898,\n",
      "        -2.6285, -2.6158, -2.6295, -2.6285, -2.5753, -2.6109, -2.6268, -2.5761,\n",
      "        -2.6256, -2.6283, -2.6137, -2.6302, -2.6174, -2.6235, -2.6231, -2.6239,\n",
      "        -2.6314, -2.6273], device='mps:0')\n",
      "mean: tensor(-2.6094, device='mps:0')\n",
      "iter_dt 1.08s; iter 53: train loss 0.77712 temperature: 7.649999999999991\n",
      "mean_logits tensor([-2.6299, -2.3868, -2.2408, -2.6023, -2.7762, -2.5196, -2.3792, -2.3590,\n",
      "        -2.6777, -2.7298, -2.2290, -2.7139, -2.7942, -2.3235, -2.7036, -2.4823,\n",
      "        -2.7141, -2.4515, -2.4614, -2.4334, -2.4720, -2.3068, -2.6047, -2.6794,\n",
      "        -2.5006, -2.5186, -2.5889, -2.4707, -2.5548, -2.5048, -2.3010, -2.3302,\n",
      "        -2.9184, -2.2915, -2.5389, -2.0292, -2.5537, -2.3308, -2.5986, -2.6866,\n",
      "        -2.7193, -2.8388, -2.5988, -2.5813, -2.5109, -2.4900, -2.6401, -2.5185,\n",
      "        -2.5943, -2.4101], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6293, -2.6046, -2.6069, -2.6290, -2.5770, -2.6270, -2.6162, -2.6293,\n",
      "        -2.5751, -2.6292, -2.6295, -2.6160, -2.6266, -2.6242, -2.5822, -2.6162,\n",
      "        -2.6197, -2.6194, -2.6177, -2.6291, -2.6294, -2.6286, -2.6332, -2.6179,\n",
      "        -2.6265, -2.6295, -2.6280, -2.6232, -2.6295, -2.6190, -2.6046, -2.6166,\n",
      "        -2.6268, -2.5996, -2.6286, -2.6104, -2.5807, -2.6300, -2.6182, -2.6288,\n",
      "        -2.6199, -2.6254, -2.6081, -2.6289, -2.6293, -2.5451, -2.6098, -2.6163,\n",
      "        -2.6157, -2.5953], device='mps:0')\n",
      "mean: tensor(-2.6161, device='mps:0')\n",
      "iter_dt 1.07s; iter 54: train loss 0.71672 temperature: 7.69999999999999\n",
      "mean_logits tensor([-2.8159, -2.3879, -2.7485, -2.6585, -2.6731, -2.5048, -2.7205, -2.5191,\n",
      "        -2.5654, -2.7786, -2.6354, -2.5712, -2.6406, -2.6511, -2.7722, -2.5634,\n",
      "        -2.6348, -2.4437, -2.4184, -2.5130, -2.6002, -2.5540, -2.7272, -2.5023,\n",
      "        -2.8411, -2.1947, -2.6377, -2.6052, -2.3561, -2.4102, -2.8752, -2.8506,\n",
      "        -2.4746, -2.2459, -2.3720, -2.5962, -2.8656, -2.7651, -2.7248, -2.3088,\n",
      "        -2.6602, -2.3221, -2.1904, -2.4875, -2.5523, -2.6583, -2.3518, -2.6273,\n",
      "        -2.5135, -2.9181], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6075, -2.5740, -2.6094, -2.6076, -2.6137, -2.6043, -2.6042, -2.6327,\n",
      "        -2.5560, -2.6186, -2.6343, -2.6163, -2.5578, -2.6295, -2.6190, -2.6294,\n",
      "        -2.6283, -2.6291, -2.5558, -2.5455, -2.5778, -2.6108, -2.6243, -2.6116,\n",
      "        -2.6265, -2.5693, -2.6188, -2.6282, -2.6118, -2.5771, -2.6148, -2.6279,\n",
      "        -2.6274, -2.6306, -2.6175, -2.6086, -2.5768, -2.6262, -2.5639, -2.6251,\n",
      "        -2.6154, -2.5036, -2.6258, -2.5982, -2.6134, -2.6201, -2.6294, -2.5472,\n",
      "        -2.6007, -2.6296], device='mps:0')\n",
      "mean: tensor(-2.6046, device='mps:0')\n",
      "iter_dt 1.09s; iter 55: train loss 0.69298 temperature: 7.74999999999999\n",
      "mean_logits tensor([-2.2875, -2.5007, -2.6811, -2.5423, -2.5914, -2.5388, -2.3637, -2.6914,\n",
      "        -2.8724, -2.5132, -2.4721, -2.4449, -2.4674, -2.7322, -2.4138, -2.9025,\n",
      "        -2.6736, -2.4297, -2.1225, -2.7264, -2.6607, -2.6983, -2.2929, -2.3919,\n",
      "        -2.5572, -2.5433, -2.6254, -2.7503, -2.5008, -2.2513, -2.5674, -2.6664,\n",
      "        -2.6766, -2.3279, -2.5264, -2.4146, -2.5931, -2.6825, -2.8561, -2.8495,\n",
      "        -2.6235, -2.5942, -2.5112, -2.3795, -2.7420, -2.3472, -2.7275, -2.7043,\n",
      "        -2.7815, -2.4493], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6280, -2.6231, -2.6150, -2.6174, -2.6262, -2.6293, -2.6017, -2.6182,\n",
      "        -2.6288, -2.6086, -2.6292, -2.6171, -2.6124, -2.6280, -2.5706, -2.6217,\n",
      "        -2.6044, -2.6294, -2.6165, -2.6077, -2.6337, -2.6292, -2.6131, -2.6083,\n",
      "        -2.6294, -2.6157, -2.5982, -2.6181, -2.5868, -2.6037, -2.5520, -2.6239,\n",
      "        -2.6291, -2.6020, -2.6105, -2.6274, -2.6241, -2.5858, -2.6097, -2.6283,\n",
      "        -2.6032, -2.6279, -2.6283, -2.6155, -2.6261, -2.6284, -2.6280, -2.6149,\n",
      "        -2.6304, -2.6266], device='mps:0')\n",
      "mean: tensor(-2.6158, device='mps:0')\n",
      "iter_dt 1.33s; iter 56: train loss 0.78578 temperature: 7.79999999999999\n",
      "mean_logits tensor([-2.7246, -2.4606, -2.6239, -2.5953, -2.7948, -2.3183, -2.7074, -2.4082,\n",
      "        -2.9775, -2.7026, -2.4556, -2.5964, -2.3777, -2.3098, -2.4191, -2.5972,\n",
      "        -2.5214, -2.6636, -2.6491, -2.5787, -2.3022, -2.5435, -2.5740, -2.8872,\n",
      "        -2.4305, -2.5442, -2.5759, -2.9465, -2.5648, -2.5852, -2.9005, -2.4702,\n",
      "        -2.4809, -2.4043, -2.6189, -2.6232, -2.6590, -2.5636, -2.4615, -2.0495,\n",
      "        -2.5467, -2.6225, -2.6705, -2.5322, -2.4960, -2.3196, -2.5101, -2.5479,\n",
      "        -2.6251, -2.2039], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6170, -2.6184, -2.6281, -2.6145, -2.6102, -2.5566, -2.6098, -2.6296,\n",
      "        -2.6287, -2.6295, -2.6243, -2.5845, -2.5789, -2.6294, -2.6065, -2.6030,\n",
      "        -2.6172, -2.6280, -2.6168, -2.6165, -2.6291, -2.6019, -2.6031, -2.5893,\n",
      "        -2.6233, -2.6175, -2.6269, -2.6256, -2.6289, -2.6130, -2.5973, -2.5657,\n",
      "        -2.6290, -2.6047, -2.6281, -2.6175, -2.6106, -2.6345, -2.6245, -2.6202,\n",
      "        -2.6311, -2.5475, -2.6203, -2.6293, -2.6265, -2.6257, -2.6296, -2.6224,\n",
      "        -2.6284, -2.6111], device='mps:0')\n",
      "mean: tensor(-2.6142, device='mps:0')\n",
      "iter_dt 1.26s; iter 57: train loss 0.56812 temperature: 7.84999999999999\n",
      "mean_logits tensor([-2.3377, -2.7851, -2.6591, -2.4772, -2.4872, -2.1839, -2.5771, -2.7053,\n",
      "        -2.5918, -2.6764, -2.7230, -2.4376, -2.6999, -2.5697, -2.6728, -2.5133,\n",
      "        -2.4687, -2.6326, -2.5628, -2.7323, -2.4913, -2.6207, -2.6263, -2.5216,\n",
      "        -2.6739, -2.4882, -2.5786, -2.5197, -2.6264, -2.3323, -2.6195, -2.4738,\n",
      "        -2.6626, -2.3167, -2.6044, -2.7481, -2.3216, -2.4327, -2.8039, -2.5456,\n",
      "        -2.7403, -2.7474, -2.9446, -2.4923, -2.3179, -2.4405, -2.6992, -2.7698,\n",
      "        -2.4980, -2.8229], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6023, -2.6113, -2.6277, -2.5928, -2.6101, -2.6283, -2.6290, -2.5721,\n",
      "        -2.5546, -2.6287, -2.6272, -2.5829, -2.6162, -2.6165, -2.6198, -2.6292,\n",
      "        -2.6246, -2.5930, -2.6292, -2.6070, -2.6159, -2.6115, -2.6326, -2.6122,\n",
      "        -2.6325, -2.6270, -2.5650, -2.6139, -2.5538, -2.6081, -2.5968, -2.6165,\n",
      "        -2.6006, -2.6301, -2.6294, -2.6234, -2.6042, -2.6139, -2.6131, -2.6087,\n",
      "        -2.6124, -2.6037, -2.6277, -2.6276, -2.6096, -2.6260, -2.6001, -2.6291,\n",
      "        -2.6290, -2.6194], device='mps:0')\n",
      "mean: tensor(-2.6119, device='mps:0')\n",
      "iter_dt 1.13s; iter 58: train loss 0.87720 temperature: 7.89999999999999\n",
      "mean_logits tensor([-2.5822, -2.7533, -2.7560, -2.5721, -2.4413, -2.5511, -2.4586, -2.6848,\n",
      "        -2.6040, -2.6643, -2.4701, -2.6359, -2.6640, -2.4935, -2.2595, -2.4391,\n",
      "        -2.4500, -2.4129, -2.9214, -2.9157, -2.8796, -2.9747, -2.2361, -2.6540,\n",
      "        -2.5414, -2.8082, -2.4710, -2.2594, -2.4951, -2.7127, -2.4310, -2.8622,\n",
      "        -2.3907, -2.4496, -2.5932, -2.3577, -2.5231, -2.5012, -2.5208, -2.3898,\n",
      "        -2.3051, -2.8778, -2.5504, -2.6137, -2.4692, -2.3690, -2.5569, -2.6713,\n",
      "        -2.2974, -2.4049], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6288, -2.6277, -2.6119, -2.6191, -2.5822, -2.5869, -2.6287, -2.6286,\n",
      "        -2.6060, -2.6109, -2.6271, -2.6113, -2.6295, -2.6292, -2.5907, -2.6191,\n",
      "        -2.5995, -2.6247, -2.6281, -2.6149, -2.5914, -2.5574, -2.6137, -2.6258,\n",
      "        -2.6268, -2.5718, -2.5658, -2.5601, -2.6292, -2.6184, -2.6159, -2.6295,\n",
      "        -2.6277, -2.6294, -2.6137, -2.6048, -2.6135, -2.5933, -2.6062, -2.5867,\n",
      "        -2.6275, -2.6290, -2.6126, -2.6045, -2.6256, -2.6196, -2.5840, -2.6267,\n",
      "        -2.5894, -2.5547], device='mps:0')\n",
      "mean: tensor(-2.6092, device='mps:0')\n",
      "iter_dt 1.14s; iter 59: train loss 0.72462 temperature: 7.9499999999999895\n",
      "mean_logits tensor([-2.9728, -2.6768, -2.3987, -2.3078, -2.6698, -2.8454, -2.7836, -2.6432,\n",
      "        -2.6581, -2.7527, -2.7434, -2.7492, -2.0979, -2.4156, -2.8237, -2.4148,\n",
      "        -2.5911, -2.7836, -2.3444, -2.6548, -2.3059, -2.6723, -2.5172, -2.4029,\n",
      "        -2.5334, -2.4141, -2.7605, -2.3429, -2.6012, -2.5068, -2.6293, -2.6519,\n",
      "        -2.5108, -2.6365, -2.6505, -2.4897, -2.3501, -2.4170, -2.5761, -2.6516,\n",
      "        -2.4776, -2.6767, -2.4865, -2.2575, -2.6455, -2.6983, -2.3271, -2.7267,\n",
      "        -2.5225, -2.7884], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5744, -2.6246, -2.6273, -2.6306, -2.5999, -2.6157, -2.6300, -2.6142,\n",
      "        -2.5764, -2.6111, -2.6287, -2.6161, -2.6301, -2.5973, -2.6282, -2.5604,\n",
      "        -2.6281, -2.6164, -2.6283, -2.6289, -2.5046, -2.6266, -2.6178, -2.6050,\n",
      "        -2.5728, -2.6276, -2.6290, -2.6269, -2.6275, -2.6124, -2.6284, -2.6275,\n",
      "        -2.6055, -2.6056, -2.6249, -2.6288, -2.6227, -2.6167, -2.6095, -2.6096,\n",
      "        -2.6192, -2.6281, -2.6137, -2.5775, -2.6199, -2.6071, -2.6258, -2.6149,\n",
      "        -2.6071, -2.6291], device='mps:0')\n",
      "mean: tensor(-2.6128, device='mps:0')\n",
      "iter_dt 1.13s; iter 60: train loss 0.75504 temperature: 7.999999999999989\n",
      "mean_logits tensor([-2.4964, -2.6976, -2.6307, -2.7421, -2.1258, -2.2561, -2.4794, -2.4258,\n",
      "        -2.5284, -2.3405, -2.4432, -2.0539, -2.5579, -2.5455, -2.6499, -2.8030,\n",
      "        -2.6395, -2.6778, -2.5384, -2.5316, -2.4418, -2.5402, -2.4434, -2.1921,\n",
      "        -2.6086, -2.4438, -2.5157, -2.3643, -2.4598, -2.4481, -2.6176, -2.2318,\n",
      "        -2.5238, -2.8317, -2.4800, -2.8077, -2.6070, -2.6778, -2.6012, -2.6178,\n",
      "        -2.6957, -2.5818, -2.5211, -2.6281, -2.5436, -2.7104, -2.2328, -2.9335,\n",
      "        -2.8032, -2.4867], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5820, -2.6177, -2.5737, -2.6283, -2.6084, -2.6208, -2.6161, -2.6220,\n",
      "        -2.6271, -2.6260, -2.6265, -2.5760, -2.6169, -2.6258, -2.6325, -2.6211,\n",
      "        -2.6194, -2.5825, -2.6258, -2.6083, -2.5494, -2.5967, -2.6280, -2.5471,\n",
      "        -2.6288, -2.6060, -2.6286, -2.6200, -2.6279, -2.5765, -2.6283, -2.6190,\n",
      "        -2.5784, -2.6223, -2.6249, -2.5983, -2.6272, -2.6269, -2.6180, -2.6168,\n",
      "        -2.5717, -2.6276, -2.6291, -2.5886, -2.6296, -2.6237, -2.6293, -2.6029,\n",
      "        -2.6022, -2.6181], device='mps:0')\n",
      "mean: tensor(-2.6110, device='mps:0')\n",
      "iter_dt 1.19s; iter 61: train loss 0.63513 temperature: 8.04999999999999\n",
      "mean_logits tensor([-2.5524, -2.5744, -2.6491, -3.0035, -2.6449, -2.7122, -2.6019, -2.4592,\n",
      "        -2.6012, -2.3745, -2.5496, -2.7633, -2.4075, -2.5314, -2.5582, -2.2628,\n",
      "        -2.5592, -2.7734, -2.3935, -2.7804, -2.6258, -2.3413, -2.6282, -2.5245,\n",
      "        -2.7284, -2.5612, -2.6066, -2.3677, -2.4231, -2.4246, -2.7143, -2.9221,\n",
      "        -2.7248, -2.3129, -2.6218, -2.4792, -2.6289, -2.4384, -2.5637, -2.4264,\n",
      "        -2.5840, -2.3723, -2.3816, -2.7266, -2.4818, -2.3370, -2.5579, -2.7705,\n",
      "        -2.5723, -2.7604], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5604, -2.6245, -2.5716, -2.5774, -2.6165, -2.6294, -2.6124, -2.5638,\n",
      "        -2.6302, -2.6234, -2.6249, -2.6222, -2.6123, -2.6276, -2.6016, -2.6111,\n",
      "        -2.6091, -2.6071, -2.5562, -2.6135, -2.6138, -2.6157, -2.5534, -2.6269,\n",
      "        -2.6286, -2.6284, -2.5790, -2.6279, -2.6264, -2.6204, -2.6263, -2.6285,\n",
      "        -2.5940, -2.6291, -2.6277, -2.6275, -2.6282, -2.6127, -2.6142, -2.6270,\n",
      "        -2.5829, -2.6157, -2.5623, -2.6285, -2.6217, -2.4468, -2.6279, -2.6247,\n",
      "        -2.5498, -2.6275], device='mps:0')\n",
      "mean: tensor(-2.6064, device='mps:0')\n",
      "iter_dt 1.13s; iter 62: train loss 0.75555 temperature: 8.09999999999999\n",
      "mean_logits tensor([-2.8385, -2.4589, -2.4834, -2.5088, -2.3473, -2.6840, -2.5757, -2.5448,\n",
      "        -2.3751, -2.4344, -2.6404, -2.5758, -2.2679, -2.5379, -2.5764, -2.5394,\n",
      "        -2.7039, -2.3524, -2.4474, -2.6943, -2.4684, -2.5881, -2.3329, -2.3182,\n",
      "        -2.3027, -2.5580, -2.5557, -2.2349, -2.2127, -2.4128, -2.4497, -2.5432,\n",
      "        -2.4860, -2.7496, -2.3445, -2.5263, -2.6832, -2.5692, -2.8142, -2.6483,\n",
      "        -2.7610, -2.5508, -2.7690, -2.4832, -2.4247, -3.0004, -2.6250, -2.7500,\n",
      "        -2.6454, -2.7867], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6282, -2.6297, -2.6076, -2.6072, -2.6208, -2.5836, -2.6174, -2.6125,\n",
      "        -2.6291, -2.6050, -2.6216, -2.6171, -2.6171, -2.6282, -2.6250, -2.6115,\n",
      "        -2.6160, -2.6159, -2.6211, -2.6286, -2.6266, -2.6196, -2.5907, -2.6263,\n",
      "        -2.6153, -2.6293, -2.6097, -2.6284, -2.6271, -2.6050, -2.5627, -2.6037,\n",
      "        -2.6270, -2.5828, -2.6068, -2.6286, -2.6159, -2.6281, -2.6223, -2.6287,\n",
      "        -2.6262, -2.6274, -2.6202, -2.6141, -2.6128, -2.6037, -2.6255, -2.6256,\n",
      "        -2.6246, -2.6078], device='mps:0')\n",
      "mean: tensor(-2.6163, device='mps:0')\n",
      "iter_dt 1.13s; iter 63: train loss 0.67486 temperature: 8.149999999999991\n",
      "mean_logits tensor([-2.5617, -2.6310, -2.5464, -2.6559, -2.6639, -2.6183, -2.7825, -2.7327,\n",
      "        -2.5114, -2.2589, -2.4022, -2.9220, -2.4063, -2.4345, -2.7118, -2.5731,\n",
      "        -2.5002, -2.7681, -2.4396, -2.8555, -2.8083, -2.3753, -2.7458, -2.4625,\n",
      "        -2.5521, -2.6634, -2.8000, -2.9063, -2.5175, -2.4964, -2.4105, -2.6526,\n",
      "        -2.5762, -2.8498, -2.8331, -2.7086, -2.6269, -2.5495, -2.4615, -2.6028,\n",
      "        -2.4758, -2.4400, -2.6325, -2.7589, -2.6042, -2.5563, -2.3144, -2.5306,\n",
      "        -2.4561, -2.8585], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6299, -2.6096, -2.6111, -2.6255, -2.5539, -2.6191, -2.6161, -2.6282,\n",
      "        -2.5617, -2.6276, -2.6146, -2.6292, -2.6033, -2.6197, -2.5829, -2.6235,\n",
      "        -2.5997, -2.6288, -2.6302, -2.6293, -2.6151, -2.6177, -2.6281, -2.6271,\n",
      "        -2.6196, -2.6185, -2.5696, -2.6122, -2.5944, -2.6164, -2.6179, -2.6048,\n",
      "        -2.6107, -2.5755, -2.6311, -2.5890, -2.6152, -2.6292, -2.6214, -2.5947,\n",
      "        -2.6272, -2.6230, -2.6155, -2.6277, -2.6294, -2.5962, -2.6070, -2.6267,\n",
      "        -2.5650, -2.5896], device='mps:0')\n",
      "mean: tensor(-2.6112, device='mps:0')\n",
      "iter_dt 1.09s; iter 64: train loss 0.66497 temperature: 8.199999999999992\n",
      "mean_logits tensor([-2.3405, -2.4452, -2.8505, -2.5714, -2.6011, -2.3582, -2.4028, -2.5721,\n",
      "        -2.5779, -2.6933, -2.3910, -2.4267, -2.7975, -2.4222, -2.6282, -2.6782,\n",
      "        -2.6735, -2.4864, -2.3391, -2.3680, -2.8725, -2.6111, -2.7291, -2.3719,\n",
      "        -2.3633, -2.4434, -2.5414, -2.5591, -2.5880, -2.8227, -2.5974, -2.4659,\n",
      "        -2.7811, -2.5141, -2.9473, -2.6558, -2.5945, -2.4227, -2.5335, -2.5775,\n",
      "        -2.5624, -2.4608, -2.5239, -2.5876, -2.4690, -2.3219, -2.4426, -2.1697,\n",
      "        -2.3623, -2.6458], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6167, -2.5587, -2.5913, -2.6233, -2.6243, -2.6272, -2.6239, -2.6220,\n",
      "        -2.6211, -2.6129, -2.6261, -2.6198, -2.6262, -2.5351, -2.6173, -2.6074,\n",
      "        -2.6241, -2.6086, -2.6292, -2.5736, -2.6245, -2.6272, -2.6118, -2.6106,\n",
      "        -2.5660, -2.6050, -2.6180, -2.6301, -2.6300, -2.6266, -2.5529, -2.6283,\n",
      "        -2.6264, -2.5571, -2.6289, -2.6188, -2.6278, -2.6103, -2.6067, -2.6199,\n",
      "        -2.5608, -2.6263, -2.6244, -2.6196, -2.6179, -2.6256, -2.6344, -2.6296,\n",
      "        -2.5486, -2.6268], device='mps:0')\n",
      "mean: tensor(-2.6106, device='mps:0')\n",
      "iter_dt 1.14s; iter 65: train loss 0.67407 temperature: 8.249999999999993\n",
      "mean_logits tensor([-2.4302, -2.7623, -2.5177, -2.6686, -2.5230, -2.2967, -2.7844, -2.4691,\n",
      "        -2.6725, -2.0456, -2.4933, -2.4718, -2.4875, -2.8119, -2.3736, -2.3181,\n",
      "        -2.4318, -2.7116, -2.6514, -2.3742, -2.5397, -2.7584, -2.4687, -2.4567,\n",
      "        -2.5786, -2.2187, -2.8320, -2.6940, -2.5307, -2.5552, -2.6381, -2.4970,\n",
      "        -2.9610, -2.6900, -2.6806, -2.6033, -2.6208, -2.3808, -2.4779, -2.5591,\n",
      "        -2.4260, -2.6006, -2.4753, -2.7947, -2.5336, -2.6385, -2.5069, -2.3586,\n",
      "        -2.6202, -2.6611], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6125, -2.6214, -2.5468, -2.6141, -2.6288, -2.6080, -2.6243, -2.6139,\n",
      "        -2.6273, -2.6208, -2.6019, -2.6118, -2.6306, -2.6143, -2.6090, -2.6306,\n",
      "        -2.6295, -2.6297, -2.6274, -2.6101, -2.5844, -2.6342, -2.6289, -2.5825,\n",
      "        -2.6209, -2.6106, -2.6304, -2.6286, -2.6251, -2.6093, -2.6166, -2.6122,\n",
      "        -2.6112, -2.6133, -2.6286, -2.6004, -2.6237, -2.6208, -2.6291, -2.5473,\n",
      "        -2.6268, -2.5515, -2.6193, -2.5896, -2.6244, -2.6290, -2.6195, -2.5944,\n",
      "        -2.6154, -2.6283], device='mps:0')\n",
      "mean: tensor(-2.6134, device='mps:0')\n",
      "iter_dt 1.16s; iter 66: train loss 0.67739 temperature: 8.299999999999994\n",
      "mean_logits tensor([-2.4489, -2.0871, -2.1888, -2.6829, -2.8281, -2.5926, -2.4621, -2.5788,\n",
      "        -2.6994, -2.6182, -2.8122, -2.6301, -2.3574, -2.4847, -2.3445, -2.7194,\n",
      "        -2.6032, -2.5806, -2.5299, -2.6469, -2.6228, -2.4888, -2.5754, -2.6987,\n",
      "        -2.8065, -2.8926, -2.6978, -2.8683, -2.6184, -2.7376, -2.4837, -2.5056,\n",
      "        -2.3889, -2.3971, -2.2720, -2.4619, -2.4834, -2.4887, -2.3797, -2.7261,\n",
      "        -2.5121, -2.5485, -2.5401, -2.5313, -2.4520, -2.5173, -2.6581, -2.4624,\n",
      "        -2.6545, -2.5548], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6335, -2.6212, -2.6167, -2.6256, -2.5594, -2.6280, -2.6257, -2.6129,\n",
      "        -2.6246, -2.6225, -2.5769, -2.6141, -2.6266, -2.6259, -2.6195, -2.6263,\n",
      "        -2.6283, -2.6124, -2.6116, -2.6232, -2.6218, -2.5994, -2.5694, -2.6300,\n",
      "        -2.6276, -2.6259, -2.6283, -2.6068, -2.6165, -2.5695, -2.6285, -2.6259,\n",
      "        -2.6196, -2.6112, -2.6094, -2.6282, -2.6073, -2.5967, -2.6302, -2.5675,\n",
      "        -2.5688, -2.6193, -2.6119, -2.6350, -2.6176, -2.6220, -2.6049, -2.6199,\n",
      "        -2.6272, -2.6296], device='mps:0')\n",
      "mean: tensor(-2.6142, device='mps:0')\n",
      "iter_dt 1.11s; iter 67: train loss 0.51821 temperature: 8.349999999999994\n",
      "mean_logits tensor([-2.8111, -2.6918, -2.5412, -2.4350, -2.4677, -2.3965, -2.6495, -2.5140,\n",
      "        -2.6522, -2.5771, -2.6054, -2.5541, -2.7383, -2.5012, -2.5756, -2.3766,\n",
      "        -2.6525, -2.4626, -2.5478, -2.7554, -2.7770, -2.6142, -2.4131, -2.5408,\n",
      "        -2.7187, -2.5837, -2.4050, -2.8402, -2.5160, -2.4029, -2.4794, -2.7764,\n",
      "        -2.5779, -2.4626, -2.6341, -2.4899, -2.3678, -2.5129, -2.4368, -2.3639,\n",
      "        -2.3105, -2.4733, -2.6930, -2.5613, -2.7397, -2.4531, -2.2680, -2.3838,\n",
      "        -2.5212, -2.5324], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6267, -2.6198, -2.6268, -2.6113, -2.6136, -2.6174, -2.6294, -2.6143,\n",
      "        -2.6256, -2.5445, -2.6246, -2.6050, -2.5926, -2.6287, -2.6118, -2.6262,\n",
      "        -2.5996, -2.6237, -2.6009, -2.6126, -2.6195, -2.6294, -2.6289, -2.6280,\n",
      "        -2.6214, -2.6231, -2.6294, -2.6137, -2.6276, -2.6233, -2.6286, -2.6278,\n",
      "        -2.6205, -2.5740, -2.6231, -2.6160, -2.6142, -2.6244, -2.6291, -2.6263,\n",
      "        -2.6220, -2.6289, -2.6239, -2.6109, -2.6257, -2.5767, -2.6158, -2.6228,\n",
      "        -2.5279, -2.6281], device='mps:0')\n",
      "mean: tensor(-2.6153, device='mps:0')\n",
      "iter_dt 1.10s; iter 68: train loss 0.57277 temperature: 8.399999999999995\n",
      "mean_logits tensor([-2.7272, -2.7667, -2.5649, -2.8018, -2.4544, -2.5304, -2.6178, -2.6653,\n",
      "        -2.5961, -2.3438, -2.3770, -2.3354, -2.3738, -2.6467, -2.4656, -2.6619,\n",
      "        -2.5170, -2.3806, -2.5850, -2.3238, -2.6281, -2.7252, -2.5929, -2.7252,\n",
      "        -2.7570, -2.4127, -2.9020, -2.5280, -2.4050, -2.4248, -2.5541, -2.5590,\n",
      "        -2.7084, -2.3936, -2.6075, -2.4354, -2.4222, -2.5504, -2.4215, -2.4935,\n",
      "        -2.4150, -2.6506, -2.6051, -2.5582, -2.7709, -2.3745, -2.1640, -2.5036,\n",
      "        -2.6583, -2.4829], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6257, -2.6241, -2.6194, -2.6280, -2.6127, -2.6162, -2.6254, -2.6086,\n",
      "        -2.6174, -2.6129, -2.6147, -2.6255, -2.6089, -2.6126, -2.6263, -2.6294,\n",
      "        -2.6299, -2.6079, -2.5020, -2.6245, -2.6124, -2.6288, -2.5535, -2.6293,\n",
      "        -2.6221, -2.6132, -2.6288, -2.6051, -2.6290, -2.6283, -2.6258, -2.6144,\n",
      "        -2.6287, -2.6082, -2.6155, -2.5972, -2.6054, -2.6204, -2.6163, -2.5686,\n",
      "        -2.6209, -2.6268, -2.6275, -2.6068, -2.6294, -2.6283, -2.5930, -2.6237,\n",
      "        -2.6193, -2.6288], device='mps:0')\n",
      "mean: tensor(-2.6145, device='mps:0')\n",
      "iter_dt 1.08s; iter 69: train loss 0.69473 temperature: 8.449999999999996\n",
      "mean_logits tensor([-2.6373, -2.7590, -2.5259, -2.8040, -2.7155, -2.4993, -2.2735, -2.6233,\n",
      "        -2.8224, -2.5853, -2.3445, -2.6615, -2.4033, -2.1573, -2.4094, -2.2306,\n",
      "        -2.3139, -2.6748, -2.5028, -2.4232, -2.5276, -2.6191, -2.6882, -2.5695,\n",
      "        -2.6710, -2.4441, -2.9575, -2.4408, -2.6161, -2.5536, -2.5394, -2.5407,\n",
      "        -2.6215, -2.5346, -2.3696, -2.7902, -2.7452, -2.6185, -2.8504, -2.5091,\n",
      "        -2.4186, -2.9192, -2.4463, -2.6107, -2.5620, -2.4774, -2.4642, -2.5861,\n",
      "        -2.5662, -2.4801], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6047, -2.6295, -2.6288, -2.5847, -2.6034, -2.6035, -2.5707, -2.6263,\n",
      "        -2.6104, -2.6281, -2.6218, -2.6162, -2.6173, -2.6276, -2.5660, -2.6180,\n",
      "        -2.6159, -2.6266, -2.6158, -2.6289, -2.6202, -2.6270, -2.6281, -2.6146,\n",
      "        -2.6288, -2.6280, -2.6287, -2.5762, -2.5678, -2.6173, -2.6127, -2.6151,\n",
      "        -2.6136, -2.6292, -2.6254, -2.6192, -2.6283, -2.6098, -2.6295, -2.6139,\n",
      "        -2.6286, -2.6255, -2.6044, -2.6153, -2.6192, -2.6271, -2.6295, -2.6340,\n",
      "        -2.6274, -2.6200], device='mps:0')\n",
      "mean: tensor(-2.6162, device='mps:0')\n",
      "iter_dt 1.10s; iter 70: train loss 0.62231 temperature: 8.499999999999996\n",
      "mean_logits tensor([-2.5108, -2.4738, -2.4563, -2.4588, -2.5274, -2.6546, -2.5124, -2.8888,\n",
      "        -2.4436, -2.4769, -2.5967, -2.2697, -2.7005, -2.7032, -2.7273, -2.4273,\n",
      "        -2.3013, -2.0243, -2.5785, -2.5841, -2.4642, -2.7792, -2.5218, -2.6734,\n",
      "        -2.3616, -2.6903, -2.7012, -2.9091, -2.5920, -2.3134, -2.6230, -2.6540,\n",
      "        -2.3910, -2.5576, -2.4616, -2.5021, -2.7114, -2.6303, -2.4949, -2.5411,\n",
      "        -2.6959, -2.5358, -2.5644, -2.5893, -2.8145, -2.5396, -2.7906, -2.3430,\n",
      "        -2.5605, -2.4848], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6268, -2.6048, -2.5643, -2.6180, -2.5819, -2.6283, -2.5591, -2.6274,\n",
      "        -2.5329, -2.6359, -2.6342, -2.6175, -2.6285, -2.6246, -2.6286, -2.6286,\n",
      "        -2.5692, -2.6048, -2.6125, -2.6223, -2.5985, -2.6248, -2.6289, -2.5626,\n",
      "        -2.6293, -2.5583, -2.5439, -2.6091, -2.6043, -2.6245, -2.6180, -2.6246,\n",
      "        -2.6292, -2.6279, -2.5663, -2.6289, -2.6295, -2.6288, -2.6197, -2.6281,\n",
      "        -2.6212, -2.6283, -2.6266, -2.6293, -2.6202, -2.5987, -2.6063, -2.6258,\n",
      "        -2.6234, -2.6301], device='mps:0')\n",
      "mean: tensor(-2.6109, device='mps:0')\n",
      "iter_dt 1.20s; iter 71: train loss 0.66838 temperature: 8.549999999999997\n",
      "mean_logits tensor([-2.4723, -2.6508, -2.7331, -2.3796, -2.3075, -2.2016, -2.5485, -2.4853,\n",
      "        -2.3647, -2.6411, -2.5614, -2.7406, -2.4491, -2.3152, -2.3993, -2.6279,\n",
      "        -2.6016, -2.3808, -2.5102, -2.5516, -2.3421, -2.8213, -2.5537, -2.7753,\n",
      "        -2.6967, -2.9458, -2.6931, -2.4965, -2.5846, -2.3495, -2.6704, -2.4385,\n",
      "        -2.5843, -2.5757, -2.4954, -2.5509, -2.4169, -2.3984, -2.6751, -2.6324,\n",
      "        -2.5806, -2.3619, -2.6637, -2.4960, -2.8676, -2.3872, -2.8354, -2.6261,\n",
      "        -2.4420, -2.5523], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6286, -2.5652, -2.6064, -2.6141, -2.6128, -2.6173, -2.6246, -2.6189,\n",
      "        -2.6137, -2.6217, -2.5929, -2.6123, -2.6284, -2.5475, -2.6294, -2.6261,\n",
      "        -2.6000, -2.6165, -2.6272, -2.6132, -2.6189, -2.6053, -2.6273, -2.6212,\n",
      "        -2.6304, -2.6072, -2.6342, -2.6144, -2.6119, -2.5680, -2.6287, -2.6286,\n",
      "        -2.6006, -2.6267, -2.6247, -2.6142, -2.6199, -2.6284, -2.6214, -2.6160,\n",
      "        -2.6258, -2.6042, -2.6295, -2.6377, -2.6161, -2.6116, -2.6026, -2.6291,\n",
      "        -2.6256, -2.6032], device='mps:0')\n",
      "mean: tensor(-2.6150, device='mps:0')\n",
      "iter_dt 1.23s; iter 72: train loss 0.50517 temperature: 8.599999999999998\n",
      "mean_logits tensor([-2.7712, -2.4797, -2.6016, -2.4255, -2.5845, -2.7178, -2.5242, -2.5354,\n",
      "        -2.2276, -2.5806, -2.7296, -2.3084, -2.8803, -2.5553, -2.6194, -2.6803,\n",
      "        -2.4383, -2.6200, -2.1006, -2.3903, -2.6023, -2.5720, -2.5923, -2.5243,\n",
      "        -2.6419, -2.6041, -2.6327, -2.7092, -2.5844, -2.5153, -2.4197, -2.5790,\n",
      "        -2.5708, -2.6306, -2.4426, -2.4125, -2.6878, -2.4046, -2.3803, -2.5614,\n",
      "        -2.3807, -2.7758, -2.5935, -2.4945, -2.5747, -2.6343, -2.5312, -2.7724,\n",
      "        -2.4456, -2.7347], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5762, -2.6287, -2.6295, -2.6128, -2.6286, -2.5714, -2.5411, -2.6226,\n",
      "        -2.6148, -2.6137, -2.6188, -2.6080, -2.6295, -2.5635, -2.6291, -2.6256,\n",
      "        -2.6106, -2.6271, -2.6249, -2.6149, -2.6285, -2.6141, -2.6158, -2.6246,\n",
      "        -2.6243, -2.6188, -2.6286, -2.6173, -2.5802, -2.6269, -2.6240, -2.6311,\n",
      "        -2.6063, -2.6091, -2.6085, -2.6202, -2.6165, -2.5712, -2.6198, -2.6166,\n",
      "        -2.6281, -2.6241, -2.6239, -2.6247, -2.6189, -2.6296, -2.5715, -2.6348,\n",
      "        -2.6297, -2.6251], device='mps:0')\n",
      "mean: tensor(-2.6141, device='mps:0')\n",
      "iter_dt 1.15s; iter 73: train loss 0.43104 temperature: 8.649999999999999\n",
      "mean_logits tensor([-2.4772, -2.6791, -2.5304, -2.5595, -2.5853, -2.4846, -2.6205, -2.7434,\n",
      "        -2.6518, -2.5439, -2.7147, -2.5328, -2.6576, -2.3945, -2.4783, -2.7351,\n",
      "        -2.8489, -2.5240, -2.6185, -2.3746, -2.6283, -2.5412, -2.5931, -2.7247,\n",
      "        -2.4718, -2.8122, -2.5063, -2.7097, -2.4756, -2.6868, -2.4037, -2.4767,\n",
      "        -2.1510, -2.5108, -2.7767, -2.3698, -2.5426, -2.6057, -2.6091, -2.8172,\n",
      "        -2.7507, -2.5102, -2.6019, -2.5817, -2.4072, -2.8090, -2.5916, -2.5868,\n",
      "        -2.6336, -2.6299], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6289, -2.6217, -2.6051, -2.6224, -2.6238, -2.6038, -2.6137, -2.6289,\n",
      "        -2.6295, -2.5814, -2.6156, -2.6032, -2.6281, -2.5973, -2.5998, -2.6290,\n",
      "        -2.6253, -2.6140, -2.6033, -2.6147, -2.6097, -2.6347, -2.6268, -2.6155,\n",
      "        -2.6286, -2.6202, -2.5595, -2.6063, -2.6296, -2.6169, -2.6030, -2.6188,\n",
      "        -2.6059, -2.6172, -2.6276, -2.6302, -2.6319, -2.6103, -2.6192, -2.5591,\n",
      "        -2.6285, -2.6162, -2.6238, -2.5657, -2.6256, -2.6289, -2.6165, -2.5917,\n",
      "        -2.6343, -2.5841], device='mps:0')\n",
      "mean: tensor(-2.6135, device='mps:0')\n",
      "iter_dt 1.19s; iter 74: train loss 0.59717 temperature: 8.7\n",
      "mean_logits tensor([-2.7207, -2.6052, -2.5266, -2.7446, -2.8361, -2.7539, -2.7705, -2.5244,\n",
      "        -2.7176, -2.6294, -2.7530, -2.5088, -2.7140, -2.6071, -2.4007, -2.6212,\n",
      "        -2.5018, -2.6706, -2.7460, -2.2759, -2.6889, -2.7745, -2.4473, -2.5466,\n",
      "        -2.6233, -2.5082, -2.7436, -2.5797, -2.6877, -2.8773, -2.8147, -2.7890,\n",
      "        -2.5116, -2.6530, -2.8235, -2.6121, -2.6610, -2.8288, -2.3993, -2.5508,\n",
      "        -2.7106, -2.4784, -2.7538, -2.4170, -2.0682, -2.5960, -2.8027, -2.4541,\n",
      "        -2.6049, -2.8630], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5535, -2.6291, -2.6198, -2.6262, -2.6220, -2.6296, -2.6113, -2.6283,\n",
      "        -2.6204, -2.6088, -2.6190, -2.6134, -2.6190, -2.6027, -2.5550, -2.6249,\n",
      "        -2.6277, -2.5519, -2.6284, -2.6114, -2.5782, -2.6282, -2.6284, -2.6151,\n",
      "        -2.5694, -2.6119, -2.6210, -2.6116, -2.6297, -2.6266, -2.6289, -2.6159,\n",
      "        -2.6180, -2.6292, -2.6286, -2.6139, -2.6333, -2.6264, -2.6284, -2.6135,\n",
      "        -2.6271, -2.6131, -2.6299, -2.5724, -2.6288, -2.6203, -2.6122, -2.6291,\n",
      "        -2.6118, -2.6281], device='mps:0')\n",
      "mean: tensor(-2.6146, device='mps:0')\n",
      "iter_dt 1.10s; iter 75: train loss 0.58496 temperature: 8.75\n",
      "mean_logits tensor([-2.6123, -2.5322, -2.6272, -2.5243, -2.6131, -2.6932, -2.6713, -2.3952,\n",
      "        -2.3288, -2.2869, -2.8606, -2.5852, -2.7751, -2.5434, -2.6730, -2.4579,\n",
      "        -2.6514, -2.5666, -2.6170, -2.5421, -2.6067, -2.4499, -2.5789, -2.7890,\n",
      "        -2.3328, -2.3599, -2.7522, -2.3447, -2.1504, -2.7545, -2.7535, -2.5466,\n",
      "        -2.3791, -2.5450, -2.6409, -2.4873, -2.6494, -2.7703, -2.7097, -2.6531,\n",
      "        -2.4979, -2.7045, -2.2236, -2.3215, -2.5883, -2.4322, -2.7508, -2.5401,\n",
      "        -2.6859, -2.4689], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6289, -2.6194, -2.6122, -2.6165, -2.5698, -2.6291, -2.6250, -2.6258,\n",
      "        -2.6283, -2.6305, -2.6155, -2.6316, -2.6129, -2.6123, -2.6288, -2.5861,\n",
      "        -2.6303, -2.6253, -2.6288, -2.6189, -2.6278, -2.6291, -2.6288, -2.5762,\n",
      "        -2.6273, -2.6286, -2.6106, -2.6299, -2.6282, -2.6325, -2.6268, -2.6247,\n",
      "        -2.6295, -2.6266, -2.6296, -2.6066, -2.6143, -2.6287, -2.6276, -2.6195,\n",
      "        -2.6143, -2.6153, -2.5553, -2.6232, -2.6248, -2.5536, -2.6296, -2.6177,\n",
      "        -2.6337, -2.5739], device='mps:0')\n",
      "mean: tensor(-2.6174, device='mps:0')\n",
      "iter_dt 1.11s; iter 76: train loss 0.85487 temperature: 8.8\n",
      "mean_logits tensor([-2.8569, -2.6392, -2.5193, -2.7292, -2.9096, -2.5847, -2.4618, -2.4463,\n",
      "        -2.7158, -2.4730, -2.5624, -2.6353, -2.7498, -2.8147, -2.7393, -2.6642,\n",
      "        -2.3843, -2.8435, -2.4986, -2.5613, -2.3159, -2.6848, -2.4716, -2.2622,\n",
      "        -2.4973, -2.5895, -2.5858, -2.4827, -2.6208, -2.6768, -2.5728, -2.7034,\n",
      "        -2.3764, -2.5123, -2.5499, -2.6183, -2.8211, -3.0115, -2.9336, -2.8959,\n",
      "        -2.5909, -2.6261, -2.5778, -2.4495, -2.5008, -2.3846, -3.0216, -2.6890,\n",
      "        -2.7637, -2.4735], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6296, -2.6264, -2.6294, -2.6255, -2.6130, -2.6181, -2.6119, -2.6282,\n",
      "        -2.6346, -2.6267, -2.6270, -2.6297, -2.6167, -2.6123, -2.5854, -2.6259,\n",
      "        -2.6281, -2.6283, -2.6191, -2.6337, -2.6238, -2.6235, -2.6096, -2.6222,\n",
      "        -2.6296, -2.6279, -2.6188, -2.6296, -2.6182, -2.6266, -2.6294, -2.5792,\n",
      "        -2.6214, -2.6355, -2.6303, -2.6297, -2.6347, -2.6284, -2.6184, -2.6285,\n",
      "        -2.6263, -2.6064, -2.6378, -2.6192, -2.6034, -2.6010, -2.6278, -2.6244,\n",
      "        -2.6155, -2.6150], device='mps:0')\n",
      "mean: tensor(-2.6218, device='mps:0')\n",
      "iter_dt 1.09s; iter 77: train loss 0.54591 temperature: 8.850000000000001\n",
      "mean_logits tensor([-2.2885, -2.4597, -2.7186, -2.1602, -2.6708, -2.4633, -2.5243, -2.7478,\n",
      "        -2.8086, -2.5286, -2.5807, -2.6151, -2.0700, -2.5439, -2.4122, -2.4926,\n",
      "        -2.6089, -2.7990, -2.6377, -2.4123, -2.5782, -2.7440, -2.6802, -2.8855,\n",
      "        -2.6033, -2.6305, -2.4468, -2.6502, -2.5612, -2.7032, -2.3670, -2.7916,\n",
      "        -2.3687, -2.5811, -2.4101, -2.4830, -2.7121, -2.4840, -2.4801, -2.5689,\n",
      "        -2.5639, -2.4218, -2.3963, -2.5622, -2.4323, -2.4565, -2.4950, -2.5060,\n",
      "        -2.7104, -2.6332], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6266, -2.5931, -2.6287, -2.6185, -2.5853, -2.6253, -2.6289, -2.6226,\n",
      "        -2.6245, -2.5773, -2.6301, -2.6160, -2.5090, -2.5797, -2.5553, -2.6126,\n",
      "        -2.5721, -2.6295, -2.6179, -2.6189, -2.6226, -2.6285, -2.6281, -2.6271,\n",
      "        -2.6013, -2.6305, -2.6294, -2.6293, -2.6183, -2.6347, -2.6299, -2.6277,\n",
      "        -2.6300, -2.5897, -2.6292, -2.6213, -2.6325, -2.6126, -2.6220, -2.6212,\n",
      "        -2.6166, -2.5547, -2.6291, -2.6062, -2.6242, -2.6234, -2.5437, -2.6099,\n",
      "        -2.6196, -2.6003], device='mps:0')\n",
      "mean: tensor(-2.6113, device='mps:0')\n",
      "iter_dt 1.16s; iter 78: train loss 0.53753 temperature: 8.900000000000002\n",
      "mean_logits tensor([-2.6403, -2.4858, -2.5466, -2.3842, -2.6040, -2.6834, -2.6706, -2.6168,\n",
      "        -2.7846, -2.5432, -2.3440, -2.7677, -2.5356, -2.7482, -2.5030, -2.4257,\n",
      "        -2.3373, -2.5317, -2.6397, -2.3430, -2.3556, -2.5355, -2.2688, -2.5812,\n",
      "        -2.3657, -2.2977, -2.6327, -2.6140, -2.6271, -2.5142, -2.8006, -2.6793,\n",
      "        -2.7220, -2.6320, -2.1078, -2.7180, -2.6430, -2.5476, -2.4812, -2.4428,\n",
      "        -2.8212, -2.4908, -2.6775, -2.7364, -2.5361, -2.5162, -2.6686, -2.7143,\n",
      "        -2.7055, -2.4468], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6291, -2.6266, -2.6299, -2.6293, -2.6251, -2.6247, -2.6295, -2.5495,\n",
      "        -2.6263, -2.6214, -2.6264, -2.6341, -2.6155, -2.6303, -2.6236, -2.6185,\n",
      "        -2.6266, -2.6281, -2.5875, -2.6276, -2.6282, -2.5748, -2.6276, -2.6303,\n",
      "        -2.5873, -2.6080, -2.6208, -2.6195, -2.6284, -2.6171, -2.6157, -2.6054,\n",
      "        -2.6287, -2.6248, -2.5660, -2.6065, -2.6284, -2.6185, -2.6297, -2.5780,\n",
      "        -2.6168, -2.6269, -2.6287, -2.6174, -2.6248, -2.6288, -2.6218, -2.6204,\n",
      "        -2.6321, -2.6238], device='mps:0')\n",
      "mean: tensor(-2.6179, device='mps:0')\n",
      "iter_dt 1.13s; iter 79: train loss 0.65483 temperature: 8.950000000000003\n",
      "mean_logits tensor([-2.8402, -2.6180, -2.4634, -2.4260, -2.6515, -2.4856, -2.1277, -2.2811,\n",
      "        -2.6443, -2.7789, -2.5143, -2.5807, -2.3763, -2.6897, -2.5103, -2.7183,\n",
      "        -2.3182, -2.5249, -2.4597, -2.7551, -2.4429, -2.6875, -2.6818, -2.2276,\n",
      "        -2.6942, -2.5537, -2.4303, -2.4239, -2.5884, -2.6542, -2.8494, -2.8050,\n",
      "        -2.6156, -2.7026, -2.6779, -2.5625, -2.5223, -2.6145, -2.7604, -2.6667,\n",
      "        -2.3223, -2.6605, -2.5373, -2.6616, -2.4266, -2.7853, -2.6322, -2.8443,\n",
      "        -2.2959, -2.8665], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6130, -2.6280, -2.6100, -2.6278, -2.6166, -2.6252, -2.6294, -2.5622,\n",
      "        -2.6212, -2.6337, -2.6311, -2.6196, -2.6281, -2.6296, -2.6108, -2.6197,\n",
      "        -2.6166, -2.6291, -2.6290, -2.6253, -2.6263, -2.6025, -2.6276, -2.6178,\n",
      "        -2.6279, -2.6262, -2.6073, -2.6255, -2.6052, -2.6166, -2.6347, -2.6277,\n",
      "        -2.6294, -2.6269, -2.6281, -2.6056, -2.6294, -2.6057, -2.6095, -2.6014,\n",
      "        -2.6216, -2.6143, -2.6038, -2.6124, -2.6296, -2.6263, -2.6094, -2.6318,\n",
      "        -2.6064, -2.6328], device='mps:0')\n",
      "mean: tensor(-2.6195, device='mps:0')\n",
      "iter_dt 1.43s; iter 80: train loss 0.50099 temperature: 9.000000000000004\n",
      "mean_logits tensor([-2.8214, -2.6765, -2.6618, -2.2567, -2.6580, -2.7132, -2.4993, -2.5794,\n",
      "        -2.3710, -2.6228, -2.8975, -2.6388, -2.5758, -2.5636, -2.6053, -2.3441,\n",
      "        -2.7479, -2.7049, -2.8036, -2.5874, -2.4634, -2.4837, -2.5053, -2.7660,\n",
      "        -2.4306, -2.6277, -2.3854, -2.6273, -2.4838, -2.7561, -2.4142, -2.7920,\n",
      "        -2.6741, -2.7508, -2.6823, -2.8176, -2.4891, -2.7615, -2.5304, -2.5414,\n",
      "        -2.3324, -2.5953, -2.5367, -2.5720, -2.6607, -2.7105, -2.4606, -2.6808,\n",
      "        -2.6595, -2.4293], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5790, -2.6291, -2.6240, -2.6219, -2.6290, -2.6145, -2.6199, -2.6162,\n",
      "        -2.6300, -2.6033, -2.6232, -2.6294, -2.6286, -2.5924, -2.6291, -2.5985,\n",
      "        -2.6176, -2.6175, -2.6274, -2.6162, -2.6210, -2.6266, -2.6107, -2.6168,\n",
      "        -2.5819, -2.6200, -2.6196, -2.6288, -2.6162, -2.6251, -2.5682, -2.6296,\n",
      "        -2.6179, -2.5804, -2.6037, -2.6180, -2.6100, -2.6055, -2.6186, -2.6266,\n",
      "        -2.6355, -2.5614, -2.5878, -2.6235, -2.5756, -2.6148, -2.6112, -2.6127,\n",
      "        -2.6140, -2.6187], device='mps:0')\n",
      "mean: tensor(-2.6129, device='mps:0')\n",
      "iter_dt 1.11s; iter 81: train loss 0.77358 temperature: 9.050000000000004\n",
      "mean_logits tensor([-2.3920, -2.3161, -2.6590, -2.6603, -2.6043, -2.6155, -2.5929, -2.5968,\n",
      "        -2.7228, -2.3675, -2.2378, -2.4638, -2.5446, -2.8281, -2.8760, -2.6043,\n",
      "        -2.8434, -2.5936, -2.7746, -2.5955, -2.5576, -2.6473, -2.6479, -2.5278,\n",
      "        -2.4840, -2.6022, -2.8435, -2.9596, -2.6243, -2.8073, -2.5772, -2.3637,\n",
      "        -2.5770, -2.5566, -2.7185, -2.6138, -2.7883, -2.9341, -2.7369, -2.2341,\n",
      "        -2.7491, -2.8143, -2.3627, -2.4334, -2.3911, -2.3413, -2.6753, -2.6515,\n",
      "        -2.7544, -2.4751], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6191, -2.6252, -2.6263, -2.6302, -2.6148, -2.6142, -2.6300, -2.6238,\n",
      "        -2.6268, -2.6235, -2.6149, -2.5548, -2.6147, -2.6143, -2.6192, -2.6155,\n",
      "        -2.6280, -2.6296, -2.6122, -2.6263, -2.6271, -2.6277, -2.6239, -2.6264,\n",
      "        -2.6270, -2.6271, -2.6274, -2.5692, -2.6109, -2.6216, -2.6247, -2.6286,\n",
      "        -2.6284, -2.6103, -2.6073, -2.6150, -2.6092, -2.6288, -2.6128, -2.6267,\n",
      "        -2.6250, -2.6196, -2.6304, -2.6120, -2.6180, -2.6298, -2.6140, -2.6268,\n",
      "        -2.6130, -2.5708], device='mps:0')\n",
      "mean: tensor(-2.6181, device='mps:0')\n",
      "iter_dt 1.10s; iter 82: train loss 0.61175 temperature: 9.100000000000005\n",
      "mean_logits tensor([-2.5968, -2.4819, -2.5275, -2.5535, -2.5759, -2.5116, -2.3645, -2.3841,\n",
      "        -2.6140, -2.7513, -2.4058, -2.5217, -2.5637, -2.4709, -2.9318, -2.7099,\n",
      "        -2.7717, -2.3936, -2.5800, -2.4327, -2.6310, -2.7213, -2.3649, -2.5251,\n",
      "        -2.8221, -2.5198, -2.7815, -2.6860, -2.8022, -2.5792, -2.7950, -2.5057,\n",
      "        -2.7319, -2.8978, -2.6927, -2.3785, -2.5536, -2.5000, -2.7259, -2.5851,\n",
      "        -2.6130, -2.6625, -2.4494, -2.5886, -2.3608, -2.6978, -2.8009, -2.1816,\n",
      "        -2.7519, -2.5985], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6181, -2.6071, -2.6065, -2.6070, -2.6136, -2.6289, -2.6291, -2.6283,\n",
      "        -2.6247, -2.6261, -2.6062, -2.6299, -2.6256, -2.6268, -2.6261, -2.6169,\n",
      "        -2.5771, -2.6203, -2.6012, -2.6154, -2.6238, -2.6184, -2.6248, -2.6247,\n",
      "        -2.6279, -2.6123, -2.6274, -2.5973, -2.6270, -2.6185, -2.6207, -2.6230,\n",
      "        -2.6191, -2.6210, -2.6097, -2.6169, -2.6286, -2.6164, -2.6256, -2.5758,\n",
      "        -2.5589, -2.6249, -2.6217, -2.6254, -2.6261, -2.6257, -2.6053, -2.6061,\n",
      "        -2.6161, -2.5757], device='mps:0')\n",
      "mean: tensor(-2.6156, device='mps:0')\n",
      "iter_dt 1.09s; iter 83: train loss 0.51018 temperature: 9.150000000000006\n",
      "mean_logits tensor([-2.4604, -2.4242, -2.6125, -2.3952, -2.4738, -2.6615, -2.5189, -2.4322,\n",
      "        -2.2427, -2.7211, -2.4311, -2.8596, -2.8337, -2.7832, -2.6117, -2.5647,\n",
      "        -2.6683, -2.3351, -2.6150, -2.6111, -2.7322, -2.6503, -2.6537, -2.4139,\n",
      "        -2.4093, -2.5400, -2.4739, -2.7122, -2.4918, -2.6975, -2.4972, -2.7622,\n",
      "        -2.5577, -2.3139, -2.6776, -2.4748, -2.6181, -2.7972, -2.6980, -2.3892,\n",
      "        -2.4797, -2.5766, -2.5768, -2.4371, -2.4747, -2.7569, -2.4664, -2.6539,\n",
      "        -2.6805, -2.7139], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5876, -2.5944, -2.6183, -2.6297, -2.6055, -2.6030, -2.6292, -2.5883,\n",
      "        -2.6301, -2.6261, -2.5758, -2.6207, -2.6123, -2.6118, -2.6012, -2.6253,\n",
      "        -2.6158, -2.6302, -2.6285, -2.6130, -2.6162, -2.6355, -2.6250, -2.6295,\n",
      "        -2.6282, -2.6160, -2.6105, -2.6267, -2.6285, -2.6258, -2.6123, -2.6208,\n",
      "        -2.6176, -2.5876, -2.6120, -2.6348, -2.6045, -2.6091, -2.6163, -2.6209,\n",
      "        -2.6139, -2.5900, -2.6282, -2.6354, -2.6173, -2.5408, -2.5543, -2.6335,\n",
      "        -2.6074, -2.6279], device='mps:0')\n",
      "mean: tensor(-2.6135, device='mps:0')\n",
      "iter_dt 1.11s; iter 84: train loss 0.66922 temperature: 9.200000000000006\n",
      "mean_logits tensor([-2.3691, -2.6888, -2.6422, -2.4330, -2.8737, -2.3069, -2.5954, -2.5952,\n",
      "        -2.8078, -2.4572, -2.8892, -2.8472, -2.5281, -2.8602, -2.6805, -2.5884,\n",
      "        -2.5907, -2.7830, -2.6572, -2.6318, -2.6786, -2.2504, -2.9048, -2.5306,\n",
      "        -2.8641, -2.6850, -2.7051, -2.6249, -2.6670, -2.3753, -2.8069, -2.6093,\n",
      "        -2.5309, -2.7724, -2.5508, -2.6356, -2.6865, -2.7626, -2.4609, -2.5790,\n",
      "        -2.5657, -2.5920, -2.4184, -2.7302, -2.2578, -2.4918, -2.5041, -2.4205,\n",
      "        -2.6940, -2.4354], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6236, -2.6294, -2.5522, -2.6277, -2.6249, -2.6180, -2.6172, -2.6285,\n",
      "        -2.6166, -2.6284, -2.6120, -2.6296, -2.6229, -2.6285, -2.6343, -2.6291,\n",
      "        -2.6277, -2.6286, -2.5684, -2.6209, -2.6274, -2.5957, -2.6296, -2.6301,\n",
      "        -2.6258, -2.6176, -2.6292, -2.6120, -2.6144, -2.6276, -2.6155, -2.5855,\n",
      "        -2.6289, -2.6028, -2.6260, -2.6202, -2.6208, -2.6154, -2.6241, -2.6141,\n",
      "        -2.5909, -2.6299, -2.6159, -2.6295, -2.6173, -2.6298, -2.6277, -2.6209,\n",
      "        -2.6201, -2.6224], device='mps:0')\n",
      "mean: tensor(-2.6187, device='mps:0')\n",
      "iter_dt 1.12s; iter 85: train loss 0.50446 temperature: 9.250000000000007\n",
      "mean_logits tensor([-2.5559, -2.4135, -2.6428, -2.2854, -2.4003, -2.7223, -2.5690, -2.4519,\n",
      "        -2.3102, -2.5666, -2.2792, -2.6480, -2.7253, -2.7116, -2.7585, -2.5131,\n",
      "        -2.6399, -2.5023, -2.5858, -2.8441, -2.4296, -2.5010, -2.5493, -2.3964,\n",
      "        -2.5487, -2.6158, -2.5883, -2.5871, -2.4455, -2.4876, -2.7926, -2.5131,\n",
      "        -2.6772, -2.6853, -2.5353, -2.7981, -2.7061, -2.5478, -2.8158, -2.7321,\n",
      "        -2.5087, -2.5607, -2.6015, -2.4193, -2.8117, -2.6590, -2.5869, -2.7565,\n",
      "        -2.4308, -2.3782], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6276, -2.6148, -2.6077, -2.6142, -2.5659, -2.6289, -2.5708, -2.6302,\n",
      "        -2.6253, -2.6162, -2.6151, -2.5421, -2.6346, -2.6002, -2.6256, -2.6258,\n",
      "        -2.6314, -2.6136, -2.5520, -2.6135, -2.6128, -2.5361, -2.6204, -2.6186,\n",
      "        -2.6220, -2.6064, -2.6290, -2.6194, -2.6293, -2.6093, -2.6181, -2.6302,\n",
      "        -2.6279, -2.6205, -2.6177, -2.6283, -2.6249, -2.6191, -2.6246, -2.5605,\n",
      "        -2.6233, -2.6275, -2.6284, -2.6274, -2.5983, -2.6272, -2.6336, -2.6217,\n",
      "        -2.6182, -2.6197], device='mps:0')\n",
      "mean: tensor(-2.6131, device='mps:0')\n",
      "iter_dt 1.17s; iter 86: train loss 0.61314 temperature: 9.300000000000008\n",
      "mean_logits tensor([-2.7531, -2.4691, -2.6174, -2.4980, -2.4625, -2.5561, -2.5997, -2.7016,\n",
      "        -2.3834, -2.6330, -2.8260, -2.3203, -2.4217, -2.7812, -2.5560, -2.7872,\n",
      "        -2.4970, -2.5342, -2.5778, -2.5871, -2.3846, -2.5080, -2.4739, -2.5441,\n",
      "        -2.7414, -2.3934, -2.2374, -2.5019, -2.9484, -2.7197, -2.6778, -2.4600,\n",
      "        -2.8810, -2.5580, -2.3906, -2.4020, -2.4175, -2.7302, -2.4923, -2.2321,\n",
      "        -2.3939, -2.5743, -2.5020, -2.4161, -2.6352, -2.6490, -2.6985, -2.2980,\n",
      "        -2.4882, -2.6995], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5935, -2.5443, -2.6270, -2.6157, -2.5990, -2.6297, -2.6107, -2.5875,\n",
      "        -2.6174, -2.5681, -2.6302, -2.5726, -2.6275, -2.6274, -2.6279, -2.6238,\n",
      "        -2.5527, -2.6278, -2.6262, -2.6105, -2.6087, -2.6307, -2.5494, -2.6249,\n",
      "        -2.6244, -2.6057, -2.6268, -2.6271, -2.6120, -2.6186, -2.6179, -2.6168,\n",
      "        -2.6299, -2.6339, -2.5694, -2.5764, -2.5569, -2.6265, -2.5759, -2.6193,\n",
      "        -2.6265, -2.6300, -2.5309, -2.6105, -2.6174, -2.6131, -2.5956, -2.5725,\n",
      "        -2.6288, -2.6195], device='mps:0')\n",
      "mean: tensor(-2.6063, device='mps:0')\n",
      "iter_dt 1.16s; iter 87: train loss 0.81280 temperature: 9.350000000000009\n",
      "mean_logits tensor([-2.3883, -2.5434, -2.5555, -2.6851, -2.4911, -2.8586, -2.4902, -2.5591,\n",
      "        -2.7403, -2.5924, -2.4174, -2.6839, -2.7702, -2.7098, -2.5235, -2.9557,\n",
      "        -2.7047, -2.6313, -2.7841, -2.1769, -2.8600, -2.3462, -2.3823, -2.7240,\n",
      "        -2.4582, -2.1358, -2.8693, -2.8524, -2.9450, -2.5970, -2.6177, -2.7349,\n",
      "        -2.5805, -2.5632, -2.7313, -2.5908, -2.6980, -2.4989, -2.8369, -2.6611,\n",
      "        -2.3649, -2.3705, -2.8330, -2.7110, -2.5363, -2.6265, -2.5838, -2.7903,\n",
      "        -2.6010, -2.7275], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6288, -2.6012, -2.6289, -2.6248, -2.6171, -2.6167, -2.6297, -2.6154,\n",
      "        -2.6290, -2.6269, -2.6160, -2.6273, -2.6256, -2.6285, -2.6271, -2.6275,\n",
      "        -2.6095, -2.6303, -2.6293, -2.6153, -2.6272, -2.6123, -2.6133, -2.6285,\n",
      "        -2.6293, -2.5989, -2.6255, -2.6229, -2.6257, -2.6286, -2.6291, -2.6154,\n",
      "        -2.6287, -2.6288, -2.6346, -2.6251, -2.6186, -2.6300, -2.6177, -2.6040,\n",
      "        -2.6255, -2.6303, -2.5421, -2.6089, -2.5495, -2.6269, -2.5520, -2.6186,\n",
      "        -2.6229, -2.5797], device='mps:0')\n",
      "mean: tensor(-2.6171, device='mps:0')\n",
      "iter_dt 1.10s; iter 88: train loss 0.62409 temperature: 9.40000000000001\n",
      "mean_logits tensor([-2.8767, -2.5905, -2.7753, -2.7379, -2.7135, -2.6993, -2.5913, -2.5863,\n",
      "        -2.4943, -2.5557, -2.2369, -2.5146, -2.4975, -2.6788, -2.5346, -2.4593,\n",
      "        -2.4461, -2.8425, -2.3729, -2.4949, -2.5428, -2.2629, -2.4288, -2.4455,\n",
      "        -2.6679, -2.5488, -2.8423, -2.5208, -2.3076, -2.3353, -2.4362, -2.4650,\n",
      "        -2.8615, -2.4204, -2.5244, -2.6834, -2.4386, -2.6553, -2.8586, -2.5494,\n",
      "        -2.4279, -2.6713, -2.4871, -2.7281, -2.4490, -2.4894, -2.5327, -2.7545,\n",
      "        -2.3749, -2.4024], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6244, -2.6133, -2.6283, -2.6247, -2.6245, -2.6306, -2.6261, -2.6179,\n",
      "        -2.6124, -2.6210, -2.6006, -2.6293, -2.6290, -2.6291, -2.6063, -2.5938,\n",
      "        -2.6284, -2.6291, -2.6095, -2.6229, -2.6015, -2.6057, -2.6123, -2.5745,\n",
      "        -2.6306, -2.6283, -2.6348, -2.6255, -2.6043, -2.6080, -2.6072, -2.6138,\n",
      "        -2.6247, -2.5736, -2.5636, -2.5922, -2.6295, -2.6279, -2.5789, -2.6243,\n",
      "        -2.6147, -2.6092, -2.6221, -2.6296, -2.6346, -2.6290, -2.6219, -2.6152,\n",
      "        -2.5737, -2.5779], device='mps:0')\n",
      "mean: tensor(-2.6138, device='mps:0')\n",
      "iter_dt 1.09s; iter 89: train loss 0.48377 temperature: 9.45000000000001\n",
      "mean_logits tensor([-2.6667, -2.6028, -2.6898, -2.6289, -2.2250, -2.6007, -2.5926, -2.6969,\n",
      "        -2.6223, -2.5280, -2.3436, -2.5960, -2.3486, -2.6888, -2.3719, -2.5065,\n",
      "        -2.5590, -2.5596, -2.3037, -2.3968, -2.5269, -2.5512, -2.5825, -2.5323,\n",
      "        -2.5778, -2.7242, -2.5897, -2.7018, -2.8277, -2.7386, -2.4085, -2.5388,\n",
      "        -2.4407, -2.3282, -2.6148, -2.5657, -2.6859, -2.7543, -2.7587, -2.5088,\n",
      "        -2.5927, -2.4575, -2.5636, -2.4947, -2.8410, -2.6940, -2.4730, -2.4848,\n",
      "        -2.7488, -2.4966], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6191, -2.6291, -2.6191, -2.6056, -2.6271, -2.6298, -2.5948, -2.6274,\n",
      "        -2.6284, -2.6227, -2.6225, -2.6283, -2.6173, -2.5880, -2.6284, -2.6136,\n",
      "        -2.6160, -2.6295, -2.6182, -2.6277, -2.6070, -2.6270, -2.6049, -2.6031,\n",
      "        -2.6165, -2.6106, -2.6322, -2.5753, -2.5689, -2.5988, -2.6167, -2.6302,\n",
      "        -2.6344, -2.6016, -2.6200, -2.6262, -2.6116, -2.6213, -2.5908, -2.6207,\n",
      "        -2.5831, -2.6055, -2.6172, -2.5770, -2.6282, -2.6288, -2.5776, -2.6297,\n",
      "        -2.6284, -2.6262], device='mps:0')\n",
      "mean: tensor(-2.6142, device='mps:0')\n",
      "iter_dt 1.08s; iter 90: train loss 0.65668 temperature: 9.50000000000001\n",
      "mean_logits tensor([-2.4618, -2.7498, -2.5467, -2.5339, -2.2601, -2.6769, -2.4407, -2.2414,\n",
      "        -2.4549, -2.5441, -2.8520, -2.5201, -2.3453, -2.5640, -2.5983, -2.6519,\n",
      "        -2.5593, -2.4126, -2.5840, -2.8731, -2.5615, -2.6962, -2.5825, -2.3365,\n",
      "        -2.5412, -2.6506, -2.3551, -2.3634, -2.5560, -2.6518, -2.7872, -2.7049,\n",
      "        -2.3562, -2.5308, -2.2263, -2.4718, -2.5321, -2.3697, -2.5390, -2.6958,\n",
      "        -2.6770, -2.5563, -2.3842, -2.7287, -2.4552, -2.4304, -2.7152, -2.4200,\n",
      "        -2.4980, -2.7728], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6155, -2.6071, -2.6045, -2.6131, -2.6031, -2.6258, -2.6269, -2.6246,\n",
      "        -2.6267, -2.5641, -2.6162, -2.6276, -2.6290, -2.6278, -2.6276, -2.5891,\n",
      "        -2.6023, -2.6274, -2.6208, -2.6290, -2.6250, -2.6285, -2.6296, -2.6267,\n",
      "        -2.6279, -2.6173, -2.6292, -2.6173, -2.6169, -2.6163, -2.5521, -2.6237,\n",
      "        -2.6295, -2.6285, -2.6284, -2.6018, -2.6252, -2.6302, -2.5544, -2.6291,\n",
      "        -2.6283, -2.6113, -2.6124, -2.6341, -2.6236, -2.6327, -2.6239, -2.6190,\n",
      "        -2.6166, -2.6167], device='mps:0')\n",
      "mean: tensor(-2.6173, device='mps:0')\n",
      "iter_dt 1.09s; iter 91: train loss 0.38867 temperature: 9.550000000000011\n",
      "mean_logits tensor([-2.4494, -2.5287, -2.7744, -2.6252, -2.7670, -2.6410, -2.6165, -2.6219,\n",
      "        -2.7310, -2.5886, -2.5792, -2.6472, -2.5884, -2.7247, -2.3156, -2.4315,\n",
      "        -2.6754, -2.5480, -2.8381, -2.2845, -2.4706, -2.8282, -2.4446, -2.6159,\n",
      "        -2.5714, -2.5653, -2.5033, -2.5444, -2.6175, -2.6679, -2.4469, -2.8432,\n",
      "        -2.7140, -2.6186, -2.5744, -2.5142, -2.5874, -2.4739, -2.7469, -2.5235,\n",
      "        -2.7066, -2.5871, -2.5019, -2.5713, -2.7668, -2.4057, -2.7755, -2.4028,\n",
      "        -2.4506, -2.6825], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5549, -2.6279, -2.6147, -2.6050, -2.6250, -2.6190, -2.6251, -2.6157,\n",
      "        -2.6190, -2.6262, -2.6137, -2.6184, -2.6301, -2.6292, -2.6045, -2.6154,\n",
      "        -2.6253, -2.6146, -2.6237, -2.6177, -2.6275, -2.6230, -2.5676, -2.6132,\n",
      "        -2.6293, -2.6279, -2.5764, -2.6301, -2.6286, -2.6293, -2.6064, -2.6285,\n",
      "        -2.6273, -2.6034, -2.6289, -2.6294, -2.6130, -2.6235, -2.6138, -2.6295,\n",
      "        -2.6262, -2.6116, -2.6050, -2.6160, -2.6253, -2.6303, -2.6204, -2.6241,\n",
      "        -2.5719, -2.6221], device='mps:0')\n",
      "mean: tensor(-2.6167, device='mps:0')\n",
      "iter_dt 1.08s; iter 92: train loss 0.51519 temperature: 9.600000000000012\n",
      "mean_logits tensor([-2.4443, -2.6393, -2.4733, -2.6694, -2.7409, -2.4997, -2.4549, -2.5667,\n",
      "        -2.4492, -2.5091, -2.6903, -2.7267, -2.5743, -2.6327, -2.4792, -2.5978,\n",
      "        -2.6620, -2.4686, -2.6901, -2.5037, -2.5796, -2.4260, -2.7690, -2.2690,\n",
      "        -2.3987, -2.6177, -2.7145, -2.5584, -2.4890, -2.7404, -2.8930, -2.4433,\n",
      "        -2.4226, -2.4937, -2.5311, -2.4110, -2.7302, -2.5952, -2.4560, -2.5983,\n",
      "        -2.9112, -2.8752, -2.7827, -2.5590, -2.4365, -2.7830, -2.5932, -2.4910,\n",
      "        -2.6322, -2.4139], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6075, -2.6031, -2.6216, -2.6280, -2.6150, -2.6056, -2.6258, -2.6344,\n",
      "        -2.6343, -2.6055, -2.5943, -2.6157, -2.6288, -2.6262, -2.6168, -2.6304,\n",
      "        -2.5588, -2.6271, -2.6260, -2.6256, -2.5707, -2.6280, -2.6293, -2.5923,\n",
      "        -2.6166, -2.6282, -2.6162, -2.6277, -2.6113, -2.6291, -2.6331, -2.6271,\n",
      "        -2.6234, -2.6297, -2.6205, -2.6212, -2.6055, -2.5989, -2.5769, -2.6219,\n",
      "        -2.6188, -2.6236, -2.6296, -2.5953, -2.6280, -2.6298, -2.6297, -2.5199,\n",
      "        -2.6195, -2.6268], device='mps:0')\n",
      "mean: tensor(-2.6152, device='mps:0')\n",
      "iter_dt 1.11s; iter 93: train loss 0.55306 temperature: 9.650000000000013\n",
      "mean_logits tensor([-2.2901, -2.5118, -2.6164, -2.5379, -2.6443, -2.3278, -2.7101, -2.5654,\n",
      "        -2.4549, -2.7690, -2.6060, -2.3657, -2.4017, -2.6648, -2.3647, -2.2959,\n",
      "        -2.4548, -2.6314, -2.5503, -2.6222, -2.7754, -2.7327, -2.2652, -2.6502,\n",
      "        -2.5716, -2.7464, -2.4737, -2.5860, -2.5101, -2.4252, -2.5976, -2.6218,\n",
      "        -2.3315, -2.7411, -2.5427, -2.4812, -2.8410, -2.6553, -2.6629, -2.4154,\n",
      "        -2.5773, -2.5826, -2.4008, -2.5929, -2.5276, -2.4592, -2.4481, -2.6421,\n",
      "        -2.2948, -2.6591], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6248, -2.6276, -2.6126, -2.6148, -2.6256, -2.6246, -2.6294, -2.5996,\n",
      "        -2.6160, -2.6267, -2.6279, -2.6302, -2.6115, -2.6277, -2.6255, -2.6272,\n",
      "        -2.6308, -2.6287, -2.6103, -2.6100, -2.6132, -2.6088, -2.6199, -2.6277,\n",
      "        -2.5722, -2.6237, -2.6295, -2.6300, -2.6303, -2.6287, -2.6154, -2.6288,\n",
      "        -2.6119, -2.6024, -2.6287, -2.6167, -2.6246, -2.6121, -2.6280, -2.6099,\n",
      "        -2.6277, -2.6285, -2.6177, -2.6046, -2.6276, -2.6291, -2.6261, -2.6157,\n",
      "        -2.6253, -2.6273], device='mps:0')\n",
      "mean: tensor(-2.6205, device='mps:0')\n",
      "iter_dt 1.08s; iter 94: train loss 0.47485 temperature: 9.700000000000014\n",
      "mean_logits tensor([-2.3738, -2.4549, -2.4626, -2.5641, -2.5394, -2.4466, -2.4398, -2.7564,\n",
      "        -2.6581, -2.7843, -2.7115, -2.5960, -2.4056, -2.5240, -2.6538, -2.5578,\n",
      "        -2.1665, -2.6469, -2.3069, -2.7072, -2.4368, -2.8049, -2.2479, -2.6137,\n",
      "        -2.4060, -2.7038, -2.4299, -2.6815, -2.6550, -2.5908, -2.5493, -2.6654,\n",
      "        -2.5669, -2.5547, -2.6960, -2.4523, -2.5476, -2.6394, -2.6743, -2.4496,\n",
      "        -2.6098, -2.3965, -2.6363, -2.6871, -2.5635, -2.6157, -2.7322, -2.3749,\n",
      "        -2.3114, -2.5435], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6118, -2.6300, -2.6148, -2.6288, -2.6102, -2.6286, -2.6291, -2.6285,\n",
      "        -2.6306, -2.6062, -2.6243, -2.6163, -2.6276, -2.6287, -2.6262, -2.6250,\n",
      "        -2.6229, -2.6122, -2.6226, -2.6279, -2.6221, -2.6283, -2.5015, -2.6250,\n",
      "        -2.6037, -2.6184, -2.6291, -2.6120, -2.6231, -2.6256, -2.5964, -2.6291,\n",
      "        -2.6114, -2.6297, -2.6293, -2.6194, -2.6293, -2.6292, -2.6238, -2.6263,\n",
      "        -2.6176, -2.6185, -2.6293, -2.6296, -2.6063, -2.6303, -2.6278, -2.6134,\n",
      "        -2.6121, -2.6234], device='mps:0')\n",
      "mean: tensor(-2.6195, device='mps:0')\n",
      "iter_dt 1.08s; iter 95: train loss 0.60144 temperature: 9.750000000000014\n",
      "mean_logits tensor([-2.9273, -2.5688, -2.7397, -2.8033, -2.5590, -2.5148, -2.3605, -2.4182,\n",
      "        -2.8177, -2.6541, -2.5221, -2.4908, -2.2737, -2.5285, -2.4847, -2.9048,\n",
      "        -2.4894, -2.4455, -2.6396, -2.4423, -2.8303, -2.4622, -2.5104, -2.4679,\n",
      "        -2.2499, -2.3768, -2.4027, -2.6049, -2.5517, -2.4876, -2.6141, -2.9115,\n",
      "        -2.5310, -2.6158, -2.6935, -2.6060, -2.4666, -2.6074, -2.3592, -2.5991,\n",
      "        -2.5805, -2.5018, -2.7253, -2.4161, -2.6362, -2.5696, -2.5850, -2.4783,\n",
      "        -2.6816, -2.6477], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6177, -2.6247, -2.6284, -2.6268, -2.6354, -2.6258, -2.6289, -2.6043,\n",
      "        -2.6298, -2.6270, -2.6286, -2.6131, -2.6194, -2.6155, -2.6130, -2.6306,\n",
      "        -2.6292, -2.5727, -2.5539, -2.5712, -2.6291, -2.6285, -2.6186, -2.6295,\n",
      "        -2.6198, -2.5668, -2.6297, -2.6222, -2.5893, -2.6201, -2.6265, -2.6289,\n",
      "        -2.6287, -2.6250, -2.6289, -2.6299, -2.6241, -2.6040, -2.6030, -2.6138,\n",
      "        -2.6017, -2.6155, -2.6245, -2.6104, -2.6275, -2.6273, -2.6169, -2.6116,\n",
      "        -2.5767, -2.6189], device='mps:0')\n",
      "mean: tensor(-2.6159, device='mps:0')\n",
      "iter_dt 1.08s; iter 96: train loss 0.45813 temperature: 9.800000000000015\n",
      "mean_logits tensor([-2.6351, -2.5009, -2.5617, -2.4692, -2.4839, -2.6672, -2.3698, -2.3002,\n",
      "        -2.7940, -2.3303, -2.5475, -2.5700, -2.5644, -2.4440, -2.6271, -2.6407,\n",
      "        -2.6944, -2.5071, -2.4782, -2.5462, -2.7299, -2.7504, -2.7951, -2.3510,\n",
      "        -2.6740, -2.5795, -2.2473, -2.7874, -2.5844, -2.6699, -2.4686, -2.7415,\n",
      "        -2.4280, -2.4011, -2.6062, -2.7257, -2.6477, -2.7064, -2.4005, -2.6946,\n",
      "        -2.3574, -2.5636, -2.6161, -2.4182, -2.5877, -2.5587, -2.7387, -2.7138,\n",
      "        -2.6105, -2.5491], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6289, -2.6250, -2.6219, -2.6265, -2.6073, -2.6279, -2.6189, -2.6273,\n",
      "        -2.6258, -2.6120, -2.6249, -2.6152, -2.6159, -2.6286, -2.6290, -2.6287,\n",
      "        -2.6236, -2.6258, -2.6276, -2.6285, -2.5956, -2.6126, -2.6344, -2.6271,\n",
      "        -2.6296, -2.6302, -2.6239, -2.6278, -2.6223, -2.6163, -2.6171, -2.6192,\n",
      "        -2.5600, -2.5984, -2.6278, -2.6092, -2.6276, -2.6176, -2.5761, -2.6194,\n",
      "        -2.6290, -2.6197, -2.6258, -2.6198, -2.6317, -2.6288, -2.6176, -2.6089,\n",
      "        -2.6290, -2.6289], device='mps:0')\n",
      "mean: tensor(-2.6200, device='mps:0')\n",
      "iter_dt 1.09s; iter 97: train loss 0.33637 temperature: 9.850000000000016\n",
      "mean_logits tensor([-2.5148, -2.4715, -2.5835, -2.7187, -2.6814, -2.6411, -2.6316, -2.5815,\n",
      "        -2.7105, -2.7412, -2.4914, -2.4429, -2.5802, -2.4784, -2.8033, -2.6351,\n",
      "        -2.6284, -2.6640, -2.5683, -2.5606, -2.7234, -2.4666, -2.6394, -2.6216,\n",
      "        -2.6131, -2.4476, -2.8327, -2.5146, -2.2666, -2.3650, -2.6276, -2.5983,\n",
      "        -2.5991, -2.7249, -2.5407, -2.6193, -2.4706, -2.7429, -2.7264, -2.4752,\n",
      "        -2.6288, -2.3336, -2.6108, -2.4988, -2.4942, -2.5566, -2.5065, -2.7643,\n",
      "        -2.6185, -2.7365], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6001, -2.6284, -2.6224, -2.5782, -2.5548, -2.6136, -2.6290, -2.6235,\n",
      "        -2.6283, -2.6266, -2.6111, -2.5663, -2.6157, -2.6258, -2.6286, -2.6263,\n",
      "        -2.6152, -2.6034, -2.6152, -2.5704, -2.6225, -2.6291, -2.6291, -2.6141,\n",
      "        -2.5551, -2.6248, -2.6287, -2.5762, -2.6228, -2.6263, -2.6257, -2.6305,\n",
      "        -2.6255, -2.6316, -2.6294, -2.6226, -2.6285, -2.6178, -2.6294, -2.6156,\n",
      "        -2.6284, -2.6120, -2.6010, -2.6053, -2.6085, -2.6140, -2.6289, -2.6289,\n",
      "        -2.6179, -2.6302], device='mps:0')\n",
      "mean: tensor(-2.6149, device='mps:0')\n",
      "iter_dt 1.08s; iter 98: train loss 0.54012 temperature: 9.900000000000016\n",
      "mean_logits tensor([-2.4672, -2.6615, -2.6100, -2.7040, -2.6012, -2.7110, -2.6378, -2.6064,\n",
      "        -2.6855, -2.5263, -2.2315, -2.6782, -2.5359, -2.5789, -2.4705, -2.5704,\n",
      "        -2.6943, -2.6838, -2.2809, -2.6541, -2.5614, -2.3090, -2.3767, -2.6392,\n",
      "        -2.4421, -2.5989, -2.4243, -2.4952, -2.5381, -2.2709, -2.6477, -2.7278,\n",
      "        -2.4791, -2.8792, -2.6594, -2.4305, -2.6431, -2.7301, -2.6597, -2.5110,\n",
      "        -2.5093, -2.4502, -2.8646, -2.8322, -2.5113, -2.8194, -2.3671, -2.3470,\n",
      "        -2.4226, -2.7393], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6132, -2.6301, -2.6290, -2.6277, -2.5670, -2.6298, -2.6292, -2.6294,\n",
      "        -2.6273, -2.6262, -2.5662, -2.6281, -2.6060, -2.6157, -2.6292, -2.6292,\n",
      "        -2.6339, -2.6170, -2.5844, -2.6188, -2.5594, -2.6295, -2.6150, -2.6236,\n",
      "        -2.6244, -2.6213, -2.6302, -2.6268, -2.6288, -2.6168, -2.6150, -2.6253,\n",
      "        -2.6289, -2.6105, -2.6229, -2.5884, -2.6297, -2.6215, -2.6258, -2.5964,\n",
      "        -2.6294, -2.6181, -2.6225, -2.6242, -2.5654, -2.6101, -2.6020, -2.6066,\n",
      "        -2.6335, -2.6199], device='mps:0')\n",
      "mean: tensor(-2.6162, device='mps:0')\n",
      "iter_dt 1.12s; iter 99: train loss 0.59450 temperature: 9.950000000000017\n",
      "mean_logits tensor([-2.7394, -2.3686, -2.2836, -2.4796, -2.5922, -2.6701, -2.6820, -2.2444,\n",
      "        -2.6519, -2.5480, -2.7940, -2.4463, -2.9465, -2.6601, -2.5396, -2.6429,\n",
      "        -2.5318, -2.5556, -2.7923, -2.4970, -2.4153, -2.4781, -2.5048, -2.6179,\n",
      "        -2.4879, -2.4107, -2.5246, -2.4842, -2.6198, -2.6436, -2.4812, -2.7135,\n",
      "        -2.4977, -2.6035, -2.5998, -2.9626, -2.5553, -2.4261, -2.4858, -2.3513,\n",
      "        -2.6746, -2.5951, -2.9424, -2.6243, -2.5323, -2.5414, -2.5030, -2.5547,\n",
      "        -2.5263, -2.5422], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6219, -2.6175, -2.5814, -2.6284, -2.6262, -2.6150, -2.6218, -2.6286,\n",
      "        -2.6181, -2.6302, -2.6105, -2.6353, -2.6287, -2.6276, -2.6185, -2.6273,\n",
      "        -2.6276, -2.5687, -2.6263, -2.6186, -2.6121, -2.6272, -2.6305, -2.6093,\n",
      "        -2.6264, -2.6292, -2.6111, -2.6295, -2.5695, -2.6273, -2.6288, -2.6332,\n",
      "        -2.6219, -2.6129, -2.6278, -2.6218, -2.6035, -2.6082, -2.6043, -2.5572,\n",
      "        -2.6286, -2.6046, -2.6128, -2.6288, -2.6290, -2.6297, -2.6190, -2.6119,\n",
      "        -2.6131, -2.6311], device='mps:0')\n",
      "mean: tensor(-2.6176, device='mps:0')\n",
      "current_prefixes: [7278 4037 5557 4534 4632 6985  380 4805 4101 4404 4883  611  346 1045\n",
      " 2273 6235 5773 2879  256  465 6084 8286  375 5500  264  814   67 8921\n",
      "   67 4136 4385 6604  200 1773 2049 8494   86 3932 2808 2015 1661 1504\n",
      " 4149 1661 3803]\n",
      "layer: 10 starts running\n",
      "number of parameters: 91.99M\n",
      "running on device mps\n",
      "iter_dt 0.00s; iter 0: train loss 4.37806 temperature: 5\n",
      "mean_logits tensor([-2.0805, -2.0150, -1.7184, -2.1262, -2.3059, -2.0486, -2.0911, -2.0070,\n",
      "        -2.1485, -1.5426, -1.8482, -2.1064, -2.6479, -2.2030, -1.7430, -2.2073,\n",
      "        -2.0579, -1.8249, -2.6129, -2.4296, -2.2877, -2.2555, -1.8214, -1.8286,\n",
      "        -1.9344, -2.6472, -2.1702, -2.2126, -1.9619, -1.8709, -2.3126, -1.9419,\n",
      "        -1.9266, -1.6913, -1.9814, -2.3244, -1.7680, -1.8722, -2.3052, -1.9756,\n",
      "        -2.2090, -1.7127, -2.1719, -2.1696, -2.0865, -2.4408, -2.1517, -2.1710,\n",
      "        -2.2377, -2.2817], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6213, -2.6354, -2.5791, -2.6365, -2.6303, -2.6114, -2.6382, -2.6280,\n",
      "        -2.6344, -2.5880, -2.5659, -2.5938, -2.6369, -2.6269, -2.5029, -2.6349,\n",
      "        -2.6168, -2.5859, -2.6198, -2.5633, -2.6369, -2.6262, -2.6371, -2.5918,\n",
      "        -2.6226, -2.6180, -2.6372, -2.5590, -2.6375, -2.6273, -2.6346, -2.6157,\n",
      "        -2.5542, -2.5679, -2.6202, -2.6363, -2.5977, -2.5795, -2.6242, -2.6295,\n",
      "        -2.6308, -2.6284, -2.6347, -2.6367, -2.5852, -2.6360, -2.6378, -2.6298,\n",
      "        -2.6372, -2.6346], device='mps:0')\n",
      "mean: tensor(-2.6139, device='mps:0')\n",
      "iter_dt 1695864750.27s; iter 1: train loss 4.91244 temperature: 5.05\n",
      "mean_logits tensor([-2.0524, -2.3858, -2.1572, -1.8967, -2.0439, -2.1230, -2.0347, -2.1598,\n",
      "        -1.7638, -1.9073, -1.8912, -2.3110, -2.1111, -2.0766, -1.9315, -1.6936,\n",
      "        -1.5882, -2.3202, -1.9617, -1.6848, -1.9816, -2.1241, -2.0772, -1.9482,\n",
      "        -2.1767, -1.8525, -2.3064, -2.2409, -2.1824, -1.9452, -1.8250, -1.9380,\n",
      "        -2.0201, -2.1944, -2.2698, -2.2434, -1.5964, -1.8488, -1.6626, -1.9473,\n",
      "        -1.6900, -2.1613, -1.9216, -2.0926, -2.3161, -2.2079, -2.6677, -1.8982,\n",
      "        -2.0704, -1.7299], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5813, -2.5966, -2.5635, -2.5849, -2.5301, -2.6042, -2.6204, -2.6335,\n",
      "        -2.6206, -2.5544, -2.6227, -2.6213, -2.6025, -2.6122, -2.6182, -2.6368,\n",
      "        -2.6261, -2.5779, -2.5594, -2.5372, -2.6361, -2.6348, -2.6334, -2.6269,\n",
      "        -2.6312, -2.6145, -2.5676, -2.5858, -2.6356, -2.5761, -2.6365, -2.5195,\n",
      "        -2.6152, -2.6356, -2.6343, -2.6365, -2.5004, -2.6316, -2.6228, -2.5911,\n",
      "        -2.5835, -2.6279, -2.6353, -2.5680, -2.5848, -2.5748, -2.6003, -2.6366,\n",
      "        -2.6204, -2.6377], device='mps:0')\n",
      "mean: tensor(-2.6028, device='mps:0')\n",
      "iter_dt 1.14s; iter 2: train loss 4.28734 temperature: 5.1\n",
      "mean_logits tensor([-1.8776, -2.1608, -2.0300, -2.2699, -1.9058, -2.5456, -2.2189, -2.3408,\n",
      "        -1.9114, -2.2757, -1.9305, -2.2182, -2.2084, -2.0433, -1.8604, -2.2487,\n",
      "        -2.3188, -2.5044, -2.2239, -2.3712, -2.0146, -2.4286, -1.9835, -1.7095,\n",
      "        -1.9257, -1.8893, -2.3167, -2.0131, -1.9325, -2.1485, -2.3122, -1.5449,\n",
      "        -1.8594, -1.2280, -1.9816, -1.8374, -2.0148, -2.0560, -1.9213, -2.4039,\n",
      "        -1.7699, -2.0596, -2.1617, -1.9209, -2.4391, -1.8799, -1.9798, -2.2993,\n",
      "        -2.5310, -1.9311], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6050, -2.5934, -2.6018, -2.6216, -2.6372, -2.6327, -2.6048, -2.5460,\n",
      "        -2.6103, -2.6354, -2.6361, -2.6378, -2.6223, -2.6292, -2.5663, -2.5721,\n",
      "        -2.6304, -2.6292, -2.5958, -2.5973, -2.6222, -2.6355, -2.5019, -2.4968,\n",
      "        -2.6271, -2.6372, -2.6181, -2.6330, -2.6288, -2.6378, -2.6007, -2.5827,\n",
      "        -2.6214, -2.5618, -2.5526, -2.5549, -2.6109, -2.6360, -2.6368, -2.6308,\n",
      "        -2.5229, -2.6329, -2.6363, -2.5465, -2.6377, -2.5810, -2.6376, -2.6179,\n",
      "        -2.5669, -2.6297], device='mps:0')\n",
      "mean: tensor(-2.6048, device='mps:0')\n",
      "iter_dt 1.10s; iter 3: train loss 4.24480 temperature: 5.1499999999999995\n",
      "mean_logits tensor([-2.4359, -2.3274, -1.7311, -2.2622, -1.9579, -1.7747, -1.9466, -2.3139,\n",
      "        -2.0358, -2.4646, -1.9589, -1.8169, -1.9758, -2.2356, -2.1727, -2.1907,\n",
      "        -2.5181, -2.1226, -2.1498, -1.7699, -2.2770, -2.1441, -2.0466, -2.1466,\n",
      "        -1.9881, -2.5319, -2.5313, -1.9008, -1.6252, -1.9624, -2.2521, -2.1289,\n",
      "        -1.8010, -2.3840, -1.8367, -2.1828, -2.2384, -2.0676, -1.9137, -2.1400,\n",
      "        -2.4103, -1.7311, -1.9281, -2.0936, -2.1102, -2.0528, -2.4957, -2.3319,\n",
      "        -1.8249, -1.9165], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6378, -2.5610, -2.6366, -2.6367, -2.6378, -2.6407, -2.6361, -2.5606,\n",
      "        -2.6345, -2.6222, -2.6246, -2.6324, -2.6190, -2.6378, -2.6370, -2.6318,\n",
      "        -2.6038, -2.6224, -2.6332, -2.5259, -2.5223, -2.6370, -2.6222, -2.6367,\n",
      "        -2.6362, -2.5591, -2.6337, -2.5921, -2.6371, -2.6277, -2.6381, -2.6357,\n",
      "        -2.5916, -2.6349, -2.5112, -2.6072, -2.6371, -2.6377, -2.6323, -2.6326,\n",
      "        -2.6291, -2.5957, -2.6372, -2.5688, -2.5500, -2.5702, -2.5856, -2.6388,\n",
      "        -2.5692, -2.6223], device='mps:0')\n",
      "mean: tensor(-2.6120, device='mps:0')\n",
      "iter_dt 1.12s; iter 4: train loss 4.18248 temperature: 5.199999999999999\n",
      "mean_logits tensor([-1.9689, -2.0882, -1.7426, -2.2673, -2.6035, -2.1543, -2.3754, -1.7906,\n",
      "        -2.3793, -1.7840, -2.0983, -1.8116, -2.1627, -2.0778, -1.6940, -1.9621,\n",
      "        -2.2400, -1.6258, -2.0903, -2.0473, -2.3213, -2.0662, -2.3156, -1.8976,\n",
      "        -2.4799, -2.1287, -2.2923, -1.9189, -2.0670, -2.1126, -1.9331, -1.8754,\n",
      "        -2.1990, -2.3329, -2.8932, -2.1475, -2.5698, -1.9606, -2.3077, -2.1659,\n",
      "        -1.9134, -1.7461, -2.2217, -2.6609, -2.2935, -1.6606, -2.4210, -1.9687,\n",
      "        -2.2713, -1.9206], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5189, -2.6362, -2.6374, -2.6308, -2.5577, -2.6322, -2.6177, -2.6350,\n",
      "        -2.6015, -2.6339, -2.6007, -2.5980, -2.5987, -2.6032, -2.5749, -2.5701,\n",
      "        -2.6240, -2.5760, -2.6085, -2.6003, -2.6009, -2.6370, -2.5790, -2.6358,\n",
      "        -2.5632, -2.6170, -2.6259, -2.6370, -2.5524, -2.6171, -2.6343, -2.5779,\n",
      "        -2.5626, -2.5845, -2.6219, -2.5764, -2.5762, -2.6369, -2.6326, -2.5858,\n",
      "        -2.6347, -2.6294, -2.6330, -2.4613, -2.6376, -2.6314, -2.6350, -2.5760,\n",
      "        -2.6351, -2.6373], device='mps:0')\n",
      "mean: tensor(-2.6044, device='mps:0')\n",
      "iter_dt 1.11s; iter 5: train loss 3.15930 temperature: 5.249999999999999\n",
      "mean_logits tensor([-1.8668, -2.6528, -2.2610, -2.3585, -2.2373, -2.1651, -2.3190, -2.7235,\n",
      "        -1.8901, -2.2556, -2.3479, -2.1290, -1.7740, -1.8497, -2.1712, -2.3190,\n",
      "        -2.1963, -2.3410, -2.1151, -2.3806, -2.5764, -2.2827, -2.8711, -2.5354,\n",
      "        -1.9170, -2.1462, -2.0203, -1.9751, -2.7035, -2.4697, -2.1075, -2.5364,\n",
      "        -2.3028, -2.3222, -2.1476, -2.3709, -1.6178, -1.8398, -2.1601, -2.1629,\n",
      "        -2.1518, -1.8837, -2.0947, -2.2610, -2.3179, -1.9667, -2.2331, -2.0873,\n",
      "        -2.6444, -2.0072], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5771, -2.6247, -2.6070, -2.5874, -2.6378, -2.5525, -2.6171, -2.6347,\n",
      "        -2.6350, -2.6124, -2.5940, -2.5224, -2.6237, -2.5794, -2.6354, -2.6205,\n",
      "        -2.5916, -2.6309, -2.6256, -2.6374, -2.6397, -2.6372, -2.6147, -2.6391,\n",
      "        -2.5430, -2.5534, -2.6365, -2.6348, -2.5785, -2.6199, -2.6151, -2.6254,\n",
      "        -2.6367, -2.6303, -2.5558, -2.6340, -2.6375, -2.6334, -2.6372, -2.6376,\n",
      "        -2.6010, -2.6356, -2.6363, -2.6373, -2.6173, -2.5704, -2.6413, -2.5397,\n",
      "        -2.6315, -2.6360], device='mps:0')\n",
      "mean: tensor(-2.6127, device='mps:0')\n",
      "iter_dt 1.13s; iter 6: train loss 3.11142 temperature: 5.299999999999999\n",
      "mean_logits tensor([-1.6699, -2.1254, -1.5606, -2.0161, -2.2877, -2.6635, -2.5136, -2.6851,\n",
      "        -2.1512, -2.4949, -2.7325, -2.1309, -1.6936, -2.2583, -2.2726, -2.5767,\n",
      "        -2.5898, -2.2707, -1.8918, -2.3892, -1.9557, -2.2234, -2.4856, -2.3678,\n",
      "        -2.1779, -2.4299, -2.3664, -2.1442, -2.3039, -2.2901, -1.8831, -1.9620,\n",
      "        -2.1560, -2.3010, -2.2205, -2.4551, -2.2296, -2.5004, -2.5790, -2.2033,\n",
      "        -1.9763, -2.2573, -1.5985, -1.9705, -2.4189, -2.5130, -1.9024, -1.9918,\n",
      "        -2.1656, -2.0507], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5601, -2.6305, -2.6217, -2.5706, -2.5770, -2.6331, -2.6202, -2.5605,\n",
      "        -2.6241, -2.6210, -2.6177, -2.6151, -2.6280, -2.6201, -2.6123, -2.5749,\n",
      "        -2.6338, -2.5251, -2.6339, -2.6043, -2.6333, -2.6327, -2.5889, -2.6374,\n",
      "        -2.5772, -2.6373, -2.6322, -2.6174, -2.6351, -2.5714, -2.6363, -2.5983,\n",
      "        -2.6394, -2.5992, -2.5935, -2.6099, -2.6160, -2.6361, -2.5713, -2.6255,\n",
      "        -2.6374, -2.6173, -2.5644, -2.6344, -2.6365, -2.5546, -2.6173, -2.6359,\n",
      "        -2.5627, -2.6339], device='mps:0')\n",
      "mean: tensor(-2.6093, device='mps:0')\n",
      "iter_dt 1.11s; iter 7: train loss 2.50236 temperature: 5.349999999999999\n",
      "mean_logits tensor([-2.3422, -2.3267, -1.8920, -2.3542, -2.2590, -2.4088, -2.2323, -2.4592,\n",
      "        -2.3146, -1.7067, -2.1706, -2.0951, -2.2412, -2.2513, -2.2890, -2.3046,\n",
      "        -2.2674, -2.1493, -2.5541, -2.3167, -2.3974, -2.4929, -2.4005, -2.3061,\n",
      "        -2.3654, -2.6505, -2.4678, -2.5814, -2.0655, -2.4678, -2.0225, -2.2622,\n",
      "        -1.8479, -2.3994, -2.5367, -1.7932, -2.2355, -2.5599, -2.0699, -2.2581,\n",
      "        -2.1925, -1.9335, -2.2547, -2.3665, -2.4378, -2.5384, -2.1962, -2.1598,\n",
      "        -2.1835, -2.0430], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6369, -2.5738, -2.6190, -2.6001, -2.6232, -2.6091, -2.6359, -2.5866,\n",
      "        -2.6340, -2.5810, -2.5950, -2.5664, -2.6368, -2.6376, -2.5797, -2.6313,\n",
      "        -2.6358, -2.6202, -2.6368, -2.6355, -2.5753, -2.6181, -2.6179, -2.5721,\n",
      "        -2.6288, -2.6368, -2.6359, -2.6009, -2.6229, -2.6402, -2.6071, -2.6300,\n",
      "        -2.6195, -2.6341, -2.6306, -2.5929, -2.6210, -2.5501, -2.6301, -2.6369,\n",
      "        -2.6105, -2.6336, -2.6357, -2.6204, -2.6358, -2.6377, -2.6387, -2.6351,\n",
      "        -2.6344, -2.6309], device='mps:0')\n",
      "mean: tensor(-2.6178, device='mps:0')\n",
      "iter_dt 1.09s; iter 8: train loss 1.74404 temperature: 5.399999999999999\n",
      "mean_logits tensor([-2.5366, -2.4693, -2.5169, -2.9265, -2.6841, -2.6473, -2.3176, -2.2048,\n",
      "        -2.4049, -2.6908, -2.0768, -2.3963, -2.2709, -2.4250, -2.4262, -2.2184,\n",
      "        -2.2783, -2.3048, -2.3257, -1.8785, -2.6074, -2.4202, -1.9552, -2.4024,\n",
      "        -2.9948, -2.4159, -2.1229, -1.9611, -2.4825, -2.3434, -2.4173, -2.4938,\n",
      "        -2.2186, -2.0895, -2.7459, -2.2310, -3.0040, -2.2539, -2.2609, -2.5692,\n",
      "        -2.3442, -2.6477, -2.2643, -2.5978, -2.5803, -2.4664, -2.5224, -2.5623,\n",
      "        -2.6821, -2.3662], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6311, -2.6246, -2.6370, -2.6187, -2.6339, -2.6265, -2.6187, -2.6200,\n",
      "        -2.5742, -2.6192, -2.5916, -2.6267, -2.6119, -2.6214, -2.6282, -2.6359,\n",
      "        -2.5900, -2.5948, -2.6296, -2.6334, -2.6373, -2.5699, -2.6373, -2.6345,\n",
      "        -2.6301, -2.6407, -2.6397, -2.6248, -2.6309, -2.6136, -2.6203, -2.6365,\n",
      "        -2.5713, -2.6220, -2.6053, -2.6131, -2.6245, -2.6326, -2.5609, -2.6341,\n",
      "        -2.6222, -2.5712, -2.6207, -2.6327, -2.6290, -2.6175, -2.5871, -2.6328,\n",
      "        -2.6302, -2.6125], device='mps:0')\n",
      "mean: tensor(-2.6181, device='mps:0')\n",
      "iter_dt 1.09s; iter 9: train loss 2.12432 temperature: 5.449999999999998\n",
      "mean_logits tensor([-2.4208, -2.6520, -2.6481, -2.7333, -2.2059, -2.5462, -2.4091, -2.4029,\n",
      "        -2.3966, -2.0638, -2.8176, -2.7036, -2.6597, -2.5036, -2.0669, -2.6793,\n",
      "        -2.5688, -2.0565, -2.4461, -2.0876, -2.4528, -2.0207, -2.7527, -2.1138,\n",
      "        -2.5127, -2.5526, -2.2523, -2.6263, -2.2251, -2.4697, -2.7666, -2.9230,\n",
      "        -1.9338, -2.0710, -2.4952, -2.0941, -2.0634, -2.4271, -2.4899, -2.5846,\n",
      "        -2.0874, -2.3567, -3.0391, -2.5982, -2.1559, -2.5451, -2.4286, -3.2367,\n",
      "        -2.5843, -2.3064], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6363, -2.6350, -2.5785, -2.6197, -2.6185, -2.6375, -2.6286, -2.6375,\n",
      "        -2.6353, -2.6308, -2.6351, -2.6065, -2.6279, -2.6318, -2.6362, -2.6194,\n",
      "        -2.6029, -2.6149, -2.6302, -2.6243, -2.6366, -2.6329, -2.6265, -2.6303,\n",
      "        -2.6200, -2.5761, -2.6370, -2.5714, -2.6157, -2.5985, -2.6371, -2.6268,\n",
      "        -2.6026, -2.5799, -2.6311, -2.6182, -2.6277, -2.6327, -2.6375, -2.6062,\n",
      "        -2.5742, -2.6182, -2.6334, -2.6358, -2.6056, -2.5890, -2.6397, -2.6360,\n",
      "        -2.6300, -2.6360], device='mps:0')\n",
      "mean: tensor(-2.6206, device='mps:0')\n",
      "iter_dt 1.09s; iter 10: train loss 2.75587 temperature: 5.499999999999998\n",
      "mean_logits tensor([-2.3032, -2.4791, -2.6848, -2.7434, -1.8891, -2.2702, -2.1975, -2.5886,\n",
      "        -1.8777, -2.4701, -2.2918, -2.4825, -2.7195, -2.7387, -2.4351, -1.8776,\n",
      "        -2.4450, -2.7103, -2.3588, -2.7767, -3.3208, -1.9512, -2.7262, -2.8871,\n",
      "        -2.5249, -2.2361, -2.3836, -2.3622, -2.5240, -1.9632, -2.6747, -2.3845,\n",
      "        -2.8854, -3.1872, -2.7540, -2.7517, -2.3827, -2.5524, -2.4506, -1.9509,\n",
      "        -2.2358, -2.7423, -2.6040, -2.2944, -2.7048, -1.9262, -2.1203, -1.8884,\n",
      "        -2.1193, -2.4320], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6044, -2.5681, -2.6353, -2.6275, -2.6359, -2.5878, -2.6300, -2.6203,\n",
      "        -2.6355, -2.6265, -2.6305, -2.6361, -2.5598, -2.6164, -2.6354, -2.6154,\n",
      "        -2.6089, -2.6234, -2.6170, -2.6161, -2.6329, -2.6180, -2.6264, -2.6192,\n",
      "        -2.6339, -2.6229, -2.6373, -2.6213, -2.6347, -2.6364, -2.6357, -2.6180,\n",
      "        -2.6346, -2.5790, -2.6200, -2.6081, -2.5727, -2.6298, -2.6264, -2.6342,\n",
      "        -2.6366, -2.6356, -2.6387, -2.6065, -2.6311, -2.5264, -2.6177, -2.6373,\n",
      "        -2.6365, -2.5623], device='mps:0')\n",
      "mean: tensor(-2.6180, device='mps:0')\n",
      "iter_dt 1.09s; iter 11: train loss 1.08214 temperature: 5.549999999999998\n",
      "mean_logits tensor([-2.5606, -2.5261, -2.6234, -2.7257, -2.5144, -2.7674, -2.9048, -2.8407,\n",
      "        -2.7309, -2.8664, -2.5680, -2.6036, -2.6654, -2.4309, -2.6818, -2.5251,\n",
      "        -2.7479, -2.3783, -2.3762, -2.3882, -2.7279, -2.5797, -2.3110, -2.2473,\n",
      "        -2.2734, -2.5561, -2.5023, -2.8799, -2.4105, -2.5452, -2.7645, -2.2249,\n",
      "        -2.3962, -2.7900, -2.5575, -2.5949, -2.2967, -2.9124, -1.7865, -2.3786,\n",
      "        -2.4651, -2.5551, -2.5258, -2.4406, -2.7429, -3.0533, -2.2811, -2.2817,\n",
      "        -2.7996, -2.4063], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6371, -2.6270, -2.6267, -2.6265, -2.6359, -2.6299, -2.6136, -2.6358,\n",
      "        -2.6214, -2.6331, -2.6182, -2.6240, -2.6183, -2.5632, -2.6310, -2.6086,\n",
      "        -2.5735, -2.5740, -2.5328, -2.6168, -2.6371, -2.6171, -2.6351, -2.5291,\n",
      "        -2.6097, -2.5878, -2.6409, -2.6359, -2.6303, -2.6207, -2.6137, -2.6275,\n",
      "        -2.5831, -2.6332, -2.6177, -2.6232, -2.6202, -2.6348, -2.5616, -2.6366,\n",
      "        -2.5066, -2.6285, -2.5743, -2.6370, -2.6357, -2.6250, -2.6331, -2.6348,\n",
      "        -2.6298, -2.6358], device='mps:0')\n",
      "mean: tensor(-2.6137, device='mps:0')\n",
      "iter_dt 1.08s; iter 12: train loss 1.56762 temperature: 5.599999999999998\n",
      "mean_logits tensor([-2.1905, -2.6469, -2.0466, -2.2861, -2.5767, -2.6863, -3.2041, -2.7497,\n",
      "        -2.4771, -2.6629, -2.8825, -2.9888, -2.3350, -2.4339, -2.2964, -2.1354,\n",
      "        -3.0018, -2.7522, -2.1739, -2.6489, -2.2188, -2.6690, -2.4709, -2.5302,\n",
      "        -2.5394, -2.8305, -2.3813, -2.6740, -2.1946, -2.2849, -2.8271, -2.5541,\n",
      "        -2.7333, -2.2079, -2.5087, -2.3955, -2.7043, -2.6992, -2.5196, -2.2118,\n",
      "        -2.4546, -2.2754, -2.5914, -2.8244, -1.9892, -2.4709, -2.6257, -2.5255,\n",
      "        -2.5150, -2.3852], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.4808, -2.6262, -2.5510, -2.6314, -2.6302, -2.6351, -2.6321, -2.6299,\n",
      "        -2.6336, -2.6200, -2.6263, -2.6347, -2.5969, -2.6260, -2.6354, -2.5960,\n",
      "        -2.6363, -2.5647, -2.6181, -2.6357, -2.6141, -2.6264, -2.5705, -2.6354,\n",
      "        -2.6349, -2.5750, -2.6244, -2.5653, -2.6170, -2.6365, -2.6279, -2.6359,\n",
      "        -2.6357, -2.5746, -2.6374, -2.6334, -2.6106, -2.5057, -2.6360, -2.5848,\n",
      "        -2.5549, -2.5849, -2.6370, -2.6251, -2.5698, -2.5457, -2.5959, -2.6321,\n",
      "        -2.5948, -2.6139], device='mps:0')\n",
      "mean: tensor(-2.6075, device='mps:0')\n",
      "iter_dt 1.06s; iter 13: train loss 2.28987 temperature: 5.649999999999998\n",
      "mean_logits tensor([-2.0272, -2.5707, -2.8358, -2.5941, -2.8903, -2.6918, -2.4067, -2.4392,\n",
      "        -2.2166, -2.7972, -3.0933, -2.7825, -2.4162, -2.5537, -2.5855, -2.7183,\n",
      "        -2.2893, -2.2845, -2.7848, -3.0624, -2.3540, -2.5479, -2.6151, -2.7610,\n",
      "        -1.8495, -2.8612, -2.6119, -3.1812, -2.3552, -2.9680, -2.6907, -2.6788,\n",
      "        -2.4508, -2.3337, -2.2331, -2.9410, -2.7229, -2.2426, -2.8056, -2.7723,\n",
      "        -2.6795, -2.5789, -2.0262, -2.6166, -2.4869, -2.2316, -2.4414, -3.2742,\n",
      "        -2.7084, -2.4037], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5737, -2.6345, -2.6356, -2.5741, -2.6227, -2.6311, -2.5647, -2.5984,\n",
      "        -2.6355, -2.6286, -2.5575, -2.5760, -2.6136, -2.5641, -2.6364, -2.6347,\n",
      "        -2.6130, -2.6203, -2.6373, -2.6062, -2.5945, -2.6074, -2.5684, -2.6364,\n",
      "        -2.6395, -2.6196, -2.5732, -2.6310, -2.6222, -2.6210, -2.6201, -2.6231,\n",
      "        -2.6174, -2.5823, -2.6005, -2.6176, -2.5710, -2.6262, -2.6134, -2.6310,\n",
      "        -2.6181, -2.6211, -2.6302, -2.5873, -2.5665, -2.5832, -2.6235, -2.6335,\n",
      "        -2.6355, -2.5935], device='mps:0')\n",
      "mean: tensor(-2.6093, device='mps:0')\n",
      "iter_dt 1.07s; iter 14: train loss 2.75243 temperature: 5.6999999999999975\n",
      "mean_logits tensor([-3.1856, -2.5626, -2.3051, -2.8209, -2.5689, -2.5136, -2.3325, -2.3457,\n",
      "        -2.3110, -2.0869, -2.7514, -2.5781, -2.2401, -2.2865, -2.7242, -2.8759,\n",
      "        -2.7992, -2.4145, -2.8143, -2.2595, -2.2643, -2.6934, -2.7839, -2.8387,\n",
      "        -2.5268, -3.2880, -2.3451, -2.5982, -2.5491, -2.8224, -2.9196, -2.3695,\n",
      "        -3.2912, -2.5209, -3.1573, -2.5518, -2.8513, -2.6520, -2.4701, -2.8774,\n",
      "        -2.8461, -3.0385, -2.4643, -2.6054, -3.0090, -2.4540, -2.4758, -1.8544,\n",
      "        -2.6855, -2.7908], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6366, -2.6126, -2.6264, -2.6374, -2.6385, -2.5926, -2.5639, -2.6321,\n",
      "        -2.5977, -2.5508, -2.6324, -2.6349, -2.5943, -2.6380, -2.6304, -2.6329,\n",
      "        -2.5115, -2.6367, -2.6169, -2.6327, -2.5352, -2.6366, -2.6351, -2.5374,\n",
      "        -2.6234, -2.6216, -2.6328, -2.6086, -2.6388, -2.6265, -2.6338, -2.6175,\n",
      "        -2.6370, -2.6321, -2.6325, -2.6374, -2.6295, -2.6170, -2.6349, -2.6241,\n",
      "        -2.6228, -2.6171, -2.5250, -2.6292, -2.6329, -2.6190, -2.6356, -2.6315,\n",
      "        -2.6187, -2.6312], device='mps:0')\n",
      "mean: tensor(-2.6161, device='mps:0')\n",
      "iter_dt 1.08s; iter 15: train loss 1.44370 temperature: 5.749999999999997\n",
      "mean_logits tensor([-2.6748, -2.4657, -2.6031, -2.0727, -2.6266, -2.6529, -2.7821, -2.3801,\n",
      "        -3.0934, -2.3079, -2.4895, -2.5242, -2.3613, -2.8234, -2.7398, -2.5761,\n",
      "        -2.8479, -2.3075, -2.7776, -2.3713, -2.5250, -2.6539, -2.2561, -2.5276,\n",
      "        -2.3869, -2.6770, -2.3355, -2.3338, -1.8973, -2.3012, -2.3761, -2.4916,\n",
      "        -2.3406, -2.3706, -2.2545, -2.1004, -2.6738, -2.8039, -2.3998, -2.4819,\n",
      "        -2.7128, -2.6344, -2.6212, -2.4498, -2.2484, -2.2136, -2.8893, -2.2771,\n",
      "        -2.2618, -2.6762], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6303, -2.6340, -2.5992, -2.5627, -2.6073, -2.6335, -2.6248, -2.6346,\n",
      "        -2.5800, -2.6318, -2.6380, -2.5643, -2.6129, -2.5708, -2.6350, -2.6284,\n",
      "        -2.6281, -2.6160, -2.6345, -2.6160, -2.6125, -2.6371, -2.6366, -2.6188,\n",
      "        -2.6360, -2.6282, -2.5588, -2.6016, -2.6345, -2.6269, -2.6304, -2.6330,\n",
      "        -2.6304, -2.6326, -2.6206, -2.6350, -2.5979, -2.5721, -2.6302, -2.6353,\n",
      "        -2.6246, -2.6291, -2.6345, -2.5620, -2.6048, -2.6323, -2.6226, -2.6252,\n",
      "        -2.6338, -2.5650], device='mps:0')\n",
      "mean: tensor(-2.6165, device='mps:0')\n",
      "iter_dt 1.10s; iter 16: train loss 1.35065 temperature: 5.799999999999997\n",
      "mean_logits tensor([-2.6303, -2.4325, -2.6597, -3.0577, -2.8909, -2.6362, -2.2856, -2.5001,\n",
      "        -2.6937, -2.4360, -2.4433, -2.7898, -2.5430, -2.2991, -2.3370, -2.7557,\n",
      "        -2.1249, -2.7133, -2.0588, -2.5961, -2.3164, -2.8498, -2.7064, -2.4946,\n",
      "        -2.2869, -2.9622, -2.8247, -2.4996, -2.6925, -2.1963, -2.5326, -2.8233,\n",
      "        -2.5295, -2.4762, -2.6753, -2.9734, -2.9725, -2.7021, -2.4423, -2.9150,\n",
      "        -2.3604, -2.5875, -2.2911, -2.3051, -2.5830, -2.7817, -2.8942, -2.8206,\n",
      "        -2.5708, -2.5871], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6171, -2.6307, -2.5631, -2.6315, -2.6363, -2.6335, -2.6046, -2.6266,\n",
      "        -2.6168, -2.6353, -2.6355, -2.6189, -2.6199, -2.6215, -2.6344, -2.6147,\n",
      "        -2.5917, -2.6352, -2.6356, -2.6290, -2.5535, -2.6304, -2.5974, -2.6300,\n",
      "        -2.6228, -2.6338, -2.6308, -2.6188, -2.6378, -2.6267, -2.6358, -2.6176,\n",
      "        -2.5685, -2.6326, -2.6342, -2.6101, -2.6163, -2.5947, -2.6182, -2.6287,\n",
      "        -2.6361, -2.6127, -2.5913, -2.6309, -2.6304, -2.6356, -2.6354, -2.6367,\n",
      "        -2.6064, -2.5770], device='mps:0')\n",
      "mean: tensor(-2.6193, device='mps:0')\n",
      "iter_dt 1.13s; iter 17: train loss 1.44063 temperature: 5.849999999999997\n",
      "mean_logits tensor([-2.7314, -2.5944, -2.0521, -2.7759, -2.6413, -2.5698, -2.5289, -2.3079,\n",
      "        -2.2069, -2.2694, -2.7995, -2.5555, -2.4264, -2.6585, -2.2898, -2.3029,\n",
      "        -2.8625, -2.5211, -2.8920, -2.6046, -2.5650, -3.0324, -2.9750, -2.3827,\n",
      "        -2.8684, -2.6589, -2.1320, -2.6215, -2.1342, -2.6492, -2.5602, -2.6497,\n",
      "        -2.0379, -2.3588, -2.4425, -2.0631, -3.0209, -2.5246, -2.4675, -2.3538,\n",
      "        -2.3814, -2.1373, -2.7697, -2.6586, -2.5418, -2.6365, -2.7547, -2.4856,\n",
      "        -2.4996, -2.3786], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6298, -2.6358, -2.6343, -2.6320, -2.6328, -2.6345, -2.6102, -2.6343,\n",
      "        -2.6331, -2.6345, -2.6168, -2.5752, -2.6362, -2.6195, -2.6193, -2.6322,\n",
      "        -2.6237, -2.6233, -2.6362, -2.6229, -2.5688, -2.6294, -2.6349, -2.5751,\n",
      "        -2.6268, -2.5866, -2.5728, -2.5551, -2.5711, -2.6219, -2.6315, -2.6291,\n",
      "        -2.6193, -2.6371, -2.6165, -2.6322, -2.6371, -2.6369, -2.6346, -2.5509,\n",
      "        -2.6363, -2.6177, -2.6144, -2.5677, -2.6080, -2.5789, -2.6285, -2.6273,\n",
      "        -2.6184, -2.6111], device='mps:0')\n",
      "mean: tensor(-2.6159, device='mps:0')\n",
      "iter_dt 1.14s; iter 18: train loss 1.45234 temperature: 5.899999999999997\n",
      "mean_logits tensor([-2.8972, -2.7357, -2.6606, -2.6588, -2.3663, -2.6071, -2.4880, -2.3836,\n",
      "        -2.3426, -2.6237, -2.2285, -2.6364, -2.8041, -2.3031, -2.5515, -2.3658,\n",
      "        -2.6813, -2.2158, -2.9862, -2.0796, -3.0047, -3.0692, -2.4307, -2.5761,\n",
      "        -2.2994, -2.4732, -2.4923, -2.7186, -2.2775, -2.6315, -2.7125, -1.8521,\n",
      "        -2.6540, -2.1460, -2.2652, -2.3727, -2.2204, -2.5135, -2.7667, -2.3634,\n",
      "        -2.6892, -2.2561, -2.6638, -2.7094, -2.4792, -2.3357, -2.5291, -2.8616,\n",
      "        -2.3398, -2.2081], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6365, -2.5987, -2.6188, -2.6211, -2.6136, -2.6227, -2.5340, -2.6199,\n",
      "        -2.6343, -2.6361, -2.6069, -2.6255, -2.6357, -2.6371, -2.6204, -2.6284,\n",
      "        -2.6378, -2.5780, -2.6369, -2.5996, -2.6166, -2.6346, -2.6258, -2.6372,\n",
      "        -2.5777, -2.5723, -2.5893, -2.6281, -2.6234, -2.6364, -2.6183, -2.6364,\n",
      "        -2.6220, -2.4888, -2.6379, -2.6351, -2.5517, -2.6197, -2.6066, -2.6373,\n",
      "        -2.6322, -2.6327, -2.6085, -2.5536, -2.5718, -2.6149, -2.6155, -2.6207,\n",
      "        -2.6272, -2.5867], device='mps:0')\n",
      "mean: tensor(-2.6120, device='mps:0')\n",
      "iter_dt 1.08s; iter 19: train loss 1.26256 temperature: 5.949999999999997\n",
      "mean_logits tensor([-2.5934, -2.5855, -2.1508, -2.5712, -2.8661, -2.9380, -2.2822, -2.3402,\n",
      "        -2.1352, -2.6941, -2.5032, -2.2374, -2.3948, -2.0838, -2.9411, -2.4034,\n",
      "        -2.6720, -2.3195, -2.4850, -2.5215, -2.5718, -2.4207, -2.6653, -2.7524,\n",
      "        -2.5498, -2.4415, -2.2246, -2.2471, -2.2145, -2.7805, -2.6128, -2.6922,\n",
      "        -2.3960, -2.5450, -2.5200, -2.2160, -2.0470, -2.8078, -2.6684, -2.1493,\n",
      "        -2.6330, -2.6994, -2.5068, -2.4564, -2.8605, -2.1923, -2.2713, -2.6827,\n",
      "        -2.5411, -2.6932], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6360, -2.6375, -2.6316, -2.6377, -2.5560, -2.6311, -2.6180, -2.6134,\n",
      "        -2.5707, -2.6357, -2.6200, -2.5756, -2.6304, -2.5935, -2.6383, -2.6221,\n",
      "        -2.5963, -2.6165, -2.6030, -2.6076, -2.6153, -2.6363, -2.6337, -2.6268,\n",
      "        -2.6219, -2.6380, -2.6323, -2.5553, -2.6130, -2.6216, -2.6011, -2.6163,\n",
      "        -2.5754, -2.5533, -2.6174, -2.6378, -2.6384, -2.6232, -2.6171, -2.5417,\n",
      "        -2.5534, -2.5786, -2.6175, -2.5813, -2.6340, -2.6280, -2.6376, -2.6100,\n",
      "        -2.6359, -2.6171], device='mps:0')\n",
      "mean: tensor(-2.6116, device='mps:0')\n",
      "iter_dt 1.10s; iter 20: train loss 1.15432 temperature: 5.9999999999999964\n",
      "mean_logits tensor([-2.5822, -2.7520, -2.5283, -2.8892, -2.4208, -2.6423, -2.3918, -2.3382,\n",
      "        -2.7679, -2.3656, -2.4717, -2.7819, -2.6635, -2.3561, -2.7068, -2.5135,\n",
      "        -2.7706, -2.5681, -2.4041, -2.2699, -2.0043, -2.6592, -2.6432, -2.4726,\n",
      "        -2.7113, -2.5723, -2.4217, -2.5249, -2.6106, -2.7125, -2.7915, -2.1981,\n",
      "        -2.4309, -2.7491, -2.6275, -2.5661, -2.2726, -2.4175, -2.6127, -2.7045,\n",
      "        -2.3777, -2.4265, -2.6180, -2.5424, -2.3392, -2.5328, -3.2275, -2.6298,\n",
      "        -2.0432, -2.4172], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6382, -2.6256, -2.5709, -2.6316, -2.6300, -2.5588, -2.6274, -2.6220,\n",
      "        -2.6351, -2.6140, -2.5809, -2.6108, -2.6371, -2.6377, -2.5817, -2.5932,\n",
      "        -2.6263, -2.6273, -2.6207, -2.6317, -2.5890, -2.6358, -2.6046, -2.6246,\n",
      "        -2.6013, -2.5774, -2.6092, -2.6080, -2.6385, -2.5651, -2.6375, -2.5956,\n",
      "        -2.6391, -2.6231, -2.6326, -2.6099, -2.5796, -2.5704, -2.6272, -2.5811,\n",
      "        -2.6371, -2.6147, -2.6350, -2.5852, -2.6090, -2.6143, -2.6151, -2.6363,\n",
      "        -2.6360, -2.5721], device='mps:0')\n",
      "mean: tensor(-2.6121, device='mps:0')\n",
      "iter_dt 1.11s; iter 21: train loss 1.67997 temperature: 6.049999999999996\n",
      "mean_logits tensor([-2.4613, -2.3486, -2.4189, -2.3496, -2.3326, -2.4571, -1.9036, -2.3360,\n",
      "        -2.4687, -2.4449, -2.3876, -2.5045, -2.0598, -2.3323, -2.3425, -2.7805,\n",
      "        -2.5292, -2.2574, -2.4901, -2.7963, -2.3594, -2.2619, -2.4062, -2.5077,\n",
      "        -2.2859, -2.4601, -2.4347, -2.9431, -2.9706, -2.4124, -2.0976, -2.6339,\n",
      "        -2.2742, -2.5731, -2.4310, -2.4734, -2.3460, -2.3629, -2.3803, -2.4137,\n",
      "        -2.5935, -2.1137, -2.8186, -2.0930, -2.4070, -2.3434, -2.2502, -1.7770,\n",
      "        -2.5387, -2.9709], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5812, -2.6309, -2.6351, -2.6267, -2.6338, -2.6315, -2.5571, -2.5487,\n",
      "        -2.5657, -2.6340, -2.6322, -2.6183, -2.6207, -2.6034, -2.6278, -2.5626,\n",
      "        -2.6429, -2.6289, -2.6092, -2.6350, -2.6202, -2.5863, -2.6317, -2.6184,\n",
      "        -2.6335, -2.5550, -2.6329, -2.6105, -2.5990, -2.6193, -2.6205, -2.5683,\n",
      "        -2.5977, -2.6359, -2.5618, -2.6285, -2.6001, -2.6183, -2.6168, -2.5643,\n",
      "        -2.6393, -2.6186, -2.6133, -2.6023, -2.6284, -2.6174, -2.6348, -2.6019,\n",
      "        -2.5701, -2.6167], device='mps:0')\n",
      "mean: tensor(-2.6098, device='mps:0')\n",
      "iter_dt 1.24s; iter 22: train loss 1.54035 temperature: 6.099999999999996\n",
      "mean_logits tensor([-2.3827, -2.3889, -2.3887, -2.5730, -2.1889, -2.6433, -2.5167, -2.7642,\n",
      "        -2.7650, -2.1393, -2.6309, -2.5714, -2.6485, -2.1566, -2.1496, -2.4473,\n",
      "        -2.3321, -1.6624, -2.3212, -2.0469, -2.8403, -2.3223, -2.5773, -1.9062,\n",
      "        -2.3523, -2.2909, -2.3198, -2.6611, -2.2311, -2.8583, -2.5325, -2.8002,\n",
      "        -2.3732, -2.6108, -2.2367, -2.4867, -2.2804, -2.6700, -2.4151, -2.5778,\n",
      "        -2.7976, -2.4097, -2.5315, -2.4240, -2.6884, -2.1976, -2.1474, -2.5251,\n",
      "        -2.7083, -2.3105], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6343, -2.6219, -2.6289, -2.6371, -2.5382, -2.6359, -2.6362, -2.6207,\n",
      "        -2.6344, -2.6374, -2.6199, -2.6312, -2.6359, -2.5577, -2.6347, -2.6243,\n",
      "        -2.6354, -2.6262, -2.6173, -2.6388, -2.6363, -2.6216, -2.5969, -2.6351,\n",
      "        -2.6364, -2.6333, -2.6272, -2.6027, -2.5840, -2.6158, -2.6063, -2.6355,\n",
      "        -2.6374, -2.6271, -2.5587, -2.6296, -2.6361, -2.5642, -2.6193, -2.6356,\n",
      "        -2.6189, -2.6324, -2.6213, -2.6157, -2.6198, -2.6080, -2.6279, -2.5358,\n",
      "        -2.5628, -2.6229], device='mps:0')\n",
      "mean: tensor(-2.6170, device='mps:0')\n",
      "iter_dt 1.23s; iter 23: train loss 1.11705 temperature: 6.149999999999996\n",
      "mean_logits tensor([-2.4125, -2.2831, -2.3151, -2.2777, -2.2686, -2.4200, -2.5326, -2.2664,\n",
      "        -2.5469, -2.4474, -2.6816, -2.3245, -2.7967, -2.5614, -2.4277, -2.4896,\n",
      "        -2.9191, -2.1900, -2.6868, -2.6522, -2.6204, -2.2865, -2.6780, -2.6143,\n",
      "        -2.1407, -2.4472, -2.3772, -2.5286, -2.5880, -2.6490, -2.3287, -2.6466,\n",
      "        -2.5516, -2.5236, -2.1638, -2.3956, -2.5107, -2.4975, -2.5366, -2.6021,\n",
      "        -2.2385, -2.9244, -2.4377, -2.4729, -2.3512, -2.3452, -2.3674, -2.0744,\n",
      "        -2.2833, -2.4226], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6110, -2.6391, -2.6390, -2.6257, -2.6234, -2.6340, -2.5455, -2.5541,\n",
      "        -2.6371, -2.6201, -2.6364, -2.5882, -2.6334, -2.6376, -2.6331, -2.6373,\n",
      "        -2.6325, -2.5359, -2.6201, -2.6267, -2.6313, -2.6333, -2.6067, -2.6338,\n",
      "        -2.6182, -2.6109, -2.5787, -2.5630, -2.6132, -2.6350, -2.6376, -2.5813,\n",
      "        -2.6362, -2.6368, -2.6298, -2.6181, -2.5820, -2.6312, -2.6371, -2.6098,\n",
      "        -2.5956, -2.6171, -2.6276, -2.6232, -2.6368, -2.6072, -2.6331, -2.6226,\n",
      "        -2.6360, -2.6348], device='mps:0')\n",
      "mean: tensor(-2.6174, device='mps:0')\n",
      "iter_dt 1.27s; iter 24: train loss 1.23930 temperature: 6.199999999999996\n",
      "mean_logits tensor([-2.6685, -2.2851, -2.6838, -2.1918, -2.1349, -2.4176, -2.6145, -2.9231,\n",
      "        -2.1973, -2.3333, -2.5198, -2.4927, -2.5907, -2.8355, -2.4844, -2.4271,\n",
      "        -2.5634, -2.6548, -2.4823, -2.6852, -1.9432, -2.4682, -2.4416, -2.6299,\n",
      "        -2.6139, -2.5603, -2.1224, -2.2603, -2.6302, -2.6728, -2.2458, -2.3642,\n",
      "        -2.3274, -2.7449, -2.2626, -2.2218, -2.6957, -2.3554, -2.5026, -2.2847,\n",
      "        -2.4856, -2.3022, -2.9241, -2.6950, -2.0599, -2.1355, -2.4346, -2.7226,\n",
      "        -2.6553, -2.3689], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5368, -2.6271, -2.5702, -2.5175, -2.4946, -2.6154, -2.6140, -2.6118,\n",
      "        -2.5598, -2.6360, -2.6363, -2.6298, -2.6374, -2.6074, -2.6181, -2.5554,\n",
      "        -2.5784, -2.6360, -2.6348, -2.6343, -2.6207, -2.6372, -2.6345, -2.6277,\n",
      "        -2.6362, -2.5664, -2.5911, -2.5981, -2.5788, -2.6182, -2.6173, -2.6161,\n",
      "        -2.6375, -2.6201, -2.6345, -2.6141, -2.6004, -2.5692, -2.6250, -2.6195,\n",
      "        -2.6034, -2.6076, -2.6371, -2.6342, -2.6277, -2.6322, -2.6253, -2.6374,\n",
      "        -2.6216, -2.5873], device='mps:0')\n",
      "mean: tensor(-2.6086, device='mps:0')\n",
      "iter_dt 1.25s; iter 25: train loss 1.33912 temperature: 6.249999999999996\n",
      "mean_logits tensor([-2.6668, -2.6299, -2.1525, -2.8603, -2.4539, -2.4500, -2.8646, -2.2471,\n",
      "        -2.1817, -2.4664, -2.3863, -2.7615, -2.1814, -2.5194, -2.0095, -2.3851,\n",
      "        -2.6116, -2.8523, -2.8500, -2.5501, -2.7339, -2.7608, -2.1986, -2.6269,\n",
      "        -2.2408, -2.5844, -2.4234, -2.3412, -2.3699, -2.0943, -2.1510, -2.2706,\n",
      "        -2.7015, -2.5143, -2.3448, -2.7727, -2.4922, -2.3681, -2.2070, -2.5376,\n",
      "        -2.6508, -2.4694, -2.5245, -2.1763, -2.5014, -2.7819, -2.2816, -2.5717,\n",
      "        -2.3392, -2.3744], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6190, -2.6181, -2.5919, -2.6190, -2.6178, -2.6355, -2.5663, -2.6185,\n",
      "        -2.5526, -2.6366, -2.6204, -2.5391, -2.6102, -2.6347, -2.6337, -2.6229,\n",
      "        -2.6208, -2.6142, -2.6252, -2.6363, -2.5757, -2.6373, -2.6393, -2.6254,\n",
      "        -2.5317, -2.5697, -2.6366, -2.6357, -2.6358, -2.5627, -2.6259, -2.6226,\n",
      "        -2.5710, -2.6148, -2.6190, -2.6361, -2.5940, -2.5262, -2.6337, -2.5588,\n",
      "        -2.6377, -2.6323, -2.5613, -2.6366, -2.5649, -2.6150, -2.6371, -2.5717,\n",
      "        -2.6329, -2.6374], device='mps:0')\n",
      "mean: tensor(-2.6082, device='mps:0')\n",
      "iter_dt 1.24s; iter 26: train loss 1.36961 temperature: 6.299999999999995\n",
      "mean_logits tensor([-2.5337, -2.7637, -2.0235, -1.9460, -2.1725, -2.5178, -2.7980, -2.0017,\n",
      "        -2.6895, -2.1953, -1.9869, -2.5499, -2.7474, -2.7071, -2.3247, -2.5847,\n",
      "        -2.1727, -2.4703, -2.5596, -2.3361, -2.4355, -2.3345, -2.6030, -2.4568,\n",
      "        -2.3147, -2.5394, -2.2661, -2.6709, -2.3467, -2.3533, -2.2134, -2.2570,\n",
      "        -2.4861, -2.5634, -2.4226, -2.5039, -1.8909, -2.4641, -2.5825, -2.5020,\n",
      "        -2.2933, -2.4638, -2.6810, -2.7404, -2.4347, -2.6711, -2.2615, -2.4467,\n",
      "        -2.4257, -2.4656], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6198, -2.6281, -2.5851, -2.5548, -2.6373, -2.5865, -2.6149, -2.6191,\n",
      "        -2.6251, -2.6071, -2.5740, -2.6170, -2.6363, -2.5764, -2.6130, -2.5787,\n",
      "        -2.6371, -2.6174, -2.6349, -2.5629, -2.6344, -2.6337, -2.6279, -2.6362,\n",
      "        -2.5595, -2.6359, -2.6358, -2.5484, -2.6169, -2.5709, -2.6381, -2.6356,\n",
      "        -2.6261, -2.6359, -2.6199, -2.6397, -2.6245, -2.6078, -2.6360, -2.6195,\n",
      "        -2.6374, -2.5833, -2.5780, -2.6259, -2.6279, -2.6332, -2.6363, -2.5948,\n",
      "        -2.5765, -2.6180], device='mps:0')\n",
      "mean: tensor(-2.6124, device='mps:0')\n",
      "iter_dt 1.12s; iter 27: train loss 0.89185 temperature: 6.349999999999995\n",
      "mean_logits tensor([-2.7329, -2.5259, -2.7162, -2.8865, -2.6309, -2.4479, -2.0608, -2.6116,\n",
      "        -2.5539, -2.5725, -2.4402, -2.1925, -2.7156, -2.4302, -2.5067, -2.5536,\n",
      "        -2.3329, -2.6671, -2.4979, -2.5044, -2.4809, -2.5942, -2.6039, -2.4720,\n",
      "        -2.4714, -2.7025, -2.3986, -2.1419, -2.6485, -2.5564, -2.0739, -2.4570,\n",
      "        -2.7494, -2.3834, -2.1688, -2.5341, -2.2077, -2.2998, -2.7247, -2.3541,\n",
      "        -2.4029, -2.6830, -2.4979, -2.6269, -2.6379, -2.3914, -2.0630, -2.7468,\n",
      "        -2.8199, -2.2952], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6120, -2.5982, -2.6258, -2.6348, -2.5666, -2.6186, -2.6072, -2.6128,\n",
      "        -2.6169, -2.6015, -2.6380, -2.6337, -2.6383, -2.6275, -2.5810, -2.6279,\n",
      "        -2.6233, -2.6349, -2.5977, -2.6377, -2.6378, -2.5735, -2.6344, -2.5622,\n",
      "        -2.5734, -2.5348, -2.5699, -2.6344, -2.5722, -2.5742, -2.6347, -2.6370,\n",
      "        -2.6244, -2.6236, -2.5552, -2.5720, -2.6338, -2.6284, -2.6375, -2.6360,\n",
      "        -2.5654, -2.6376, -2.6290, -2.6293, -2.6337, -2.5803, -2.4248, -2.6271,\n",
      "        -2.6372, -2.5381], device='mps:0')\n",
      "mean: tensor(-2.6057, device='mps:0')\n",
      "iter_dt 1.16s; iter 28: train loss 1.33631 temperature: 6.399999999999995\n",
      "mean_logits tensor([-2.2817, -2.2991, -2.3825, -2.4234, -2.1835, -2.2630, -2.4790, -2.6106,\n",
      "        -2.8295, -2.3269, -1.9178, -2.7301, -2.6990, -2.2590, -2.5450, -2.7153,\n",
      "        -2.5935, -2.7015, -1.9675, -2.4569, -2.4504, -2.1133, -2.6673, -2.8008,\n",
      "        -2.6930, -2.7143, -2.4652, -2.0455, -2.7303, -2.5982, -2.0789, -2.7861,\n",
      "        -2.5541, -2.5655, -2.5604, -1.8038, -2.5141, -2.6104, -2.5564, -2.7128,\n",
      "        -2.2675, -2.6212, -2.5284, -2.4886, -2.7393, -2.5072, -2.0890, -2.6601,\n",
      "        -2.7488, -2.5034], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6248, -2.6364, -2.6316, -2.5570, -2.6256, -2.6358, -2.5744, -2.6386,\n",
      "        -2.6364, -2.6275, -2.6334, -2.5722, -2.6328, -2.6125, -2.6280, -2.6319,\n",
      "        -2.6235, -2.6366, -2.6373, -2.6202, -2.5561, -2.6368, -2.6206, -2.6142,\n",
      "        -2.6232, -2.6188, -2.5410, -2.6336, -2.6276, -2.6099, -2.6196, -2.6118,\n",
      "        -2.6192, -2.5806, -2.5766, -2.6374, -2.6278, -2.6326, -2.6331, -2.5929,\n",
      "        -2.5796, -2.5750, -2.6134, -2.6341, -2.6280, -2.5901, -2.6252, -2.6154,\n",
      "        -2.6362, -2.6183], device='mps:0')\n",
      "mean: tensor(-2.6149, device='mps:0')\n",
      "iter_dt 1.29s; iter 29: train loss 1.32161 temperature: 6.449999999999995\n",
      "mean_logits tensor([-2.6788, -2.7544, -2.0688, -2.3785, -2.5554, -2.7064, -2.4733, -2.6540,\n",
      "        -2.9780, -2.8859, -1.9723, -2.6100, -2.6182, -2.0071, -2.3285, -2.5770,\n",
      "        -2.4687, -2.3612, -2.6358, -2.5705, -2.4087, -2.2083, -2.9813, -2.5174,\n",
      "        -2.5119, -2.7078, -2.7062, -2.3464, -2.6671, -2.6267, -2.5055, -2.1920,\n",
      "        -2.5326, -2.3501, -2.5211, -2.8191, -2.3569, -2.2257, -2.3200, -2.8067,\n",
      "        -2.2291, -2.6824, -2.7412, -2.4896, -2.3489, -2.9935, -2.5903, -2.6775,\n",
      "        -2.8345, -2.5315], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6373, -2.6351, -2.6173, -2.6335, -2.6262, -2.5986, -2.6367, -2.5730,\n",
      "        -2.5420, -2.6077, -2.5637, -2.6210, -2.6314, -2.6117, -2.6307, -2.6274,\n",
      "        -2.6249, -2.6360, -2.6356, -2.6164, -2.6359, -2.6019, -2.6355, -2.5822,\n",
      "        -2.5650, -2.6279, -2.6367, -2.6299, -2.6218, -2.6374, -2.5624, -2.6248,\n",
      "        -2.4948, -2.6169, -2.6279, -2.6158, -2.6311, -2.6360, -2.5720, -2.6357,\n",
      "        -2.6363, -2.6147, -2.6219, -2.5954, -2.6400, -2.6158, -2.6311, -2.6370,\n",
      "        -2.6068, -2.6290], device='mps:0')\n",
      "mean: tensor(-2.6145, device='mps:0')\n",
      "iter_dt 1.12s; iter 30: train loss 1.49276 temperature: 6.499999999999995\n",
      "mean_logits tensor([-2.4279, -2.4442, -2.5247, -1.9507, -2.3484, -2.6485, -2.5695, -2.4061,\n",
      "        -2.2939, -2.1153, -2.5470, -1.8671, -2.3065, -2.4271, -2.8742, -2.3163,\n",
      "        -2.6962, -2.1979, -2.7565, -2.9144, -2.5610, -2.5483, -2.2190, -2.2621,\n",
      "        -2.1956, -2.2930, -2.3172, -2.7268, -2.2901, -2.3850, -2.1570, -2.1933,\n",
      "        -2.3852, -2.1459, -2.1884, -2.5871, -2.4069, -2.4109, -2.2339, -2.6193,\n",
      "        -2.7190, -2.7361, -2.3140, -2.4313, -2.0852, -2.6513, -2.6538, -2.2878,\n",
      "        -2.4694, -2.3154], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5886, -2.6323, -2.6367, -2.5717, -2.5988, -2.6148, -2.5607, -2.6343,\n",
      "        -2.6143, -2.4471, -2.6192, -2.5188, -2.6217, -2.6284, -2.6357, -2.6112,\n",
      "        -2.6372, -2.6352, -2.6297, -2.6301, -2.6347, -2.6140, -2.5883, -2.6378,\n",
      "        -2.6203, -2.6323, -2.5661, -2.6391, -2.5810, -2.5693, -2.6262, -2.6367,\n",
      "        -2.5580, -2.6346, -2.6220, -2.6203, -2.6283, -2.6198, -2.5942, -2.6082,\n",
      "        -2.6378, -2.6028, -2.5584, -2.5809, -2.6361, -2.6272, -2.6345, -2.6366,\n",
      "        -2.6372, -2.6340], device='mps:0')\n",
      "mean: tensor(-2.6097, device='mps:0')\n",
      "iter_dt 1.13s; iter 31: train loss 1.30835 temperature: 6.5499999999999945\n",
      "mean_logits tensor([-2.3981, -2.5647, -2.4356, -2.9076, -2.7879, -2.4948, -2.6865, -2.0777,\n",
      "        -2.9189, -2.9912, -2.4759, -2.6332, -2.4679, -2.2201, -2.8328, -2.4595,\n",
      "        -2.4750, -2.6493, -2.7015, -2.7126, -2.5053, -2.6283, -2.5304, -2.8683,\n",
      "        -2.3786, -2.5074, -2.7555, -2.4638, -2.6753, -2.7441, -2.7799, -2.3287,\n",
      "        -2.7257, -2.7386, -2.4199, -2.7109, -2.0372, -1.9914, -2.4864, -2.0433,\n",
      "        -2.7807, -2.7452, -2.2634, -2.4737, -2.7098, -2.5704, -2.5063, -2.2771,\n",
      "        -2.8203, -2.7943], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6078, -2.6372, -2.6380, -2.6318, -2.6275, -2.6199, -2.6364, -2.6147,\n",
      "        -2.6355, -2.5616, -2.6293, -2.5933, -2.6361, -2.6305, -2.5846, -2.6197,\n",
      "        -2.6375, -2.6164, -2.6344, -2.5610, -2.6150, -2.6086, -2.6324, -2.6169,\n",
      "        -2.6222, -2.6309, -2.4567, -2.5780, -2.6252, -2.5786, -2.6135, -2.6143,\n",
      "        -2.6273, -2.5766, -2.6137, -2.6331, -2.6343, -2.6069, -2.6377, -2.6393,\n",
      "        -2.6256, -2.6325, -2.6360, -2.5726, -2.6083, -2.6351, -2.6328, -2.5955,\n",
      "        -2.5739, -2.5695], device='mps:0')\n",
      "mean: tensor(-2.6119, device='mps:0')\n",
      "iter_dt 1.12s; iter 32: train loss 1.09133 temperature: 6.599999999999994\n",
      "mean_logits tensor([-2.6391, -2.2385, -2.7507, -2.3030, -2.2745, -2.8721, -2.3600, -2.7506,\n",
      "        -2.8616, -2.5722, -2.4227, -2.5375, -2.5729, -2.5799, -2.3954, -2.5823,\n",
      "        -2.3757, -2.9684, -2.6773, -2.6239, -1.9805, -2.4878, -2.6029, -1.9313,\n",
      "        -2.3856, -2.4125, -2.5689, -2.2813, -2.7272, -2.6832, -2.6568, -2.8298,\n",
      "        -2.7160, -2.2009, -2.4698, -2.6210, -2.5358, -2.3327, -2.4142, -2.7334,\n",
      "        -2.5440, -2.5451, -2.4702, -2.3420, -2.2347, -2.5788, -2.4246, -2.3064,\n",
      "        -2.7710, -2.5600], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6278, -2.6182, -2.5997, -2.6322, -2.6337, -2.6276, -2.5905, -2.6214,\n",
      "        -2.5677, -2.6336, -2.5790, -2.5643, -2.5737, -2.6276, -2.5690, -2.6361,\n",
      "        -2.6274, -2.6258, -2.6301, -2.6341, -2.6333, -2.6086, -2.6076, -2.5994,\n",
      "        -2.6227, -2.6348, -2.6279, -2.6185, -2.6282, -2.5484, -2.5732, -2.6136,\n",
      "        -2.5531, -2.6215, -2.6224, -2.6368, -2.6292, -2.6310, -2.6074, -2.6249,\n",
      "        -2.6281, -2.5344, -2.6309, -2.6313, -2.6346, -2.5894, -2.5727, -2.5616,\n",
      "        -2.6330, -2.6362], device='mps:0')\n",
      "mean: tensor(-2.6103, device='mps:0')\n",
      "iter_dt 1.12s; iter 33: train loss 0.86155 temperature: 6.649999999999994\n",
      "mean_logits tensor([-2.7277, -2.7236, -2.8067, -2.8359, -2.6689, -2.5871, -2.6707, -2.2891,\n",
      "        -2.8539, -2.7083, -2.5292, -2.3750, -2.5399, -2.6739, -2.5479, -2.1270,\n",
      "        -2.4229, -2.8648, -2.6106, -2.3808, -2.1113, -2.3130, -2.6702, -2.7257,\n",
      "        -2.6506, -2.3612, -2.4720, -2.7279, -2.3554, -2.3649, -2.7542, -2.2171,\n",
      "        -2.4766, -2.5809, -2.6371, -2.4595, -2.5281, -2.6315, -2.8984, -2.5062,\n",
      "        -2.8435, -2.5159, -2.4918, -2.2282, -2.7797, -2.1974, -2.6213, -2.7055,\n",
      "        -2.6120, -2.6109], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5771, -2.5673, -2.6366, -2.6281, -2.5456, -2.5877, -2.6075, -2.6227,\n",
      "        -2.6310, -2.6354, -2.5320, -2.6326, -2.5508, -2.6289, -2.5578, -2.6343,\n",
      "        -2.6076, -2.6345, -2.6200, -2.5982, -2.5574, -2.5984, -2.6000, -2.6025,\n",
      "        -2.5615, -2.6377, -2.5993, -2.5715, -2.5740, -2.6212, -2.6361, -2.6359,\n",
      "        -2.6207, -2.6221, -2.5721, -2.5768, -2.6383, -2.6317, -2.6279, -2.6296,\n",
      "        -2.6153, -2.6355, -2.6329, -2.6083, -2.6124, -2.6025, -2.6123, -2.6233,\n",
      "        -2.6272, -2.6359], device='mps:0')\n",
      "mean: tensor(-2.6071, device='mps:0')\n",
      "iter_dt 1.08s; iter 34: train loss 1.16526 temperature: 6.699999999999994\n",
      "mean_logits tensor([-2.4688, -2.7665, -2.8475, -2.8196, -2.6505, -2.4779, -2.7124, -2.6151,\n",
      "        -2.6597, -2.7276, -2.3199, -2.6566, -2.6289, -2.3208, -2.4707, -2.1897,\n",
      "        -2.8391, -2.6238, -2.8435, -2.5574, -2.3438, -2.2660, -2.9185, -2.8028,\n",
      "        -2.2229, -2.1730, -2.8902, -2.6973, -2.6069, -2.4680, -1.9573, -2.6888,\n",
      "        -2.6747, -2.7310, -2.6993, -2.6935, -2.5830, -2.8014, -2.5897, -2.3822,\n",
      "        -2.6231, -2.4935, -2.7358, -2.6026, -2.4328, -2.8802, -2.5184, -2.2905,\n",
      "        -3.0026, -2.1579], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6325, -2.5807, -2.6311, -2.5818, -2.6233, -2.5708, -2.6373, -2.6307,\n",
      "        -2.6213, -2.5692, -2.6350, -2.5919, -2.5645, -2.6356, -2.6236, -2.5580,\n",
      "        -2.6276, -2.6153, -2.6003, -2.6297, -2.6377, -2.6344, -2.5939, -2.6363,\n",
      "        -2.4066, -2.6312, -2.5735, -2.6383, -2.5907, -2.6186, -2.5800, -2.5575,\n",
      "        -2.5753, -2.6219, -2.6316, -2.5229, -2.5741, -2.6239, -2.6313, -2.6268,\n",
      "        -2.5616, -2.6344, -2.6367, -2.6171, -2.6280, -2.6371, -2.6287, -2.6116,\n",
      "        -2.5532, -2.6225], device='mps:0')\n",
      "mean: tensor(-2.6039, device='mps:0')\n",
      "iter_dt 1.07s; iter 35: train loss 1.46343 temperature: 6.749999999999994\n",
      "mean_logits tensor([-2.7417, -2.4831, -2.5849, -2.3680, -2.9894, -2.9481, -2.2459, -2.8256,\n",
      "        -2.4924, -2.5225, -2.7927, -2.8059, -2.4727, -2.7493, -2.5206, -2.1806,\n",
      "        -2.2631, -2.4258, -2.6146, -2.4257, -2.8904, -2.7605, -2.2930, -2.4322,\n",
      "        -2.3921, -2.6550, -2.3140, -2.7142, -2.1504, -2.7025, -2.8404, -2.6037,\n",
      "        -2.3728, -2.2826, -2.5388, -2.7929, -2.5158, -2.8225, -2.2530, -2.3643,\n",
      "        -2.2418, -2.8925, -2.8066, -2.6834, -2.5575, -2.6723, -2.7869, -3.1967,\n",
      "        -2.6637, -2.4914], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6221, -2.6357, -2.6181, -2.5193, -2.6282, -2.6276, -2.6175, -2.5778,\n",
      "        -2.6378, -2.5759, -2.6191, -2.6335, -2.5963, -2.5743, -2.5281, -2.5486,\n",
      "        -2.6364, -2.5845, -2.6364, -2.6122, -2.6195, -2.6347, -2.6276, -2.6265,\n",
      "        -2.6310, -2.6351, -2.6298, -2.5692, -2.6361, -2.6251, -2.6340, -2.6373,\n",
      "        -2.6356, -2.6373, -2.5646, -2.6187, -2.6365, -2.5747, -2.6348, -2.6317,\n",
      "        -2.6227, -2.5630, -2.6345, -2.6192, -2.6367, -2.6340, -2.6378, -2.6263,\n",
      "        -2.6276, -2.5736], device='mps:0')\n",
      "mean: tensor(-2.6129, device='mps:0')\n",
      "iter_dt 1.12s; iter 36: train loss 1.03728 temperature: 6.799999999999994\n",
      "mean_logits tensor([-2.2425, -2.8754, -2.4849, -2.6702, -2.5914, -2.5509, -2.6079, -2.7876,\n",
      "        -2.8037, -2.8583, -2.4430, -2.6144, -2.1754, -2.3247, -2.7679, -2.5903,\n",
      "        -2.7754, -2.8502, -2.8776, -2.4953, -2.6145, -2.6884, -2.6361, -2.5379,\n",
      "        -2.5968, -2.6316, -2.7186, -2.7850, -2.3301, -2.3250, -2.4827, -2.6043,\n",
      "        -2.7553, -2.2252, -2.5246, -2.8589, -2.8948, -2.4748, -2.7993, -2.5266,\n",
      "        -2.5645, -2.7001, -2.4750, -2.1209, -2.6756, -2.5778, -3.0783, -2.6935,\n",
      "        -2.4869, -2.6293], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6375, -2.6264, -2.6372, -2.5645, -2.6374, -2.5771, -2.6117, -2.5744,\n",
      "        -2.6366, -2.5651, -2.5769, -2.6280, -2.5649, -2.6198, -2.6355, -2.5849,\n",
      "        -2.6260, -2.5996, -2.5692, -2.6356, -2.6341, -2.5734, -2.6191, -2.6357,\n",
      "        -2.6360, -2.5843, -2.6346, -2.6108, -2.6361, -2.6319, -2.6346, -2.6236,\n",
      "        -2.6225, -2.6346, -2.6118, -2.5762, -2.6373, -2.6259, -2.6316, -2.6339,\n",
      "        -2.5731, -2.5417, -2.5422, -2.6182, -2.6370, -2.6199, -2.6147, -2.6352,\n",
      "        -2.6351, -2.6201], device='mps:0')\n",
      "mean: tensor(-2.6115, device='mps:0')\n",
      "iter_dt 1.10s; iter 37: train loss 1.06199 temperature: 6.849999999999993\n",
      "mean_logits tensor([-2.1314, -2.5790, -2.5771, -2.5924, -2.7198, -2.3445, -2.6157, -2.1544,\n",
      "        -2.3761, -2.5723, -2.5058, -2.1809, -2.5764, -2.7400, -2.6561, -2.3299,\n",
      "        -2.4559, -2.7095, -2.5720, -2.7703, -2.5905, -2.9162, -2.5755, -2.8496,\n",
      "        -2.3455, -2.7165, -3.0217, -2.4211, -2.7463, -2.9502, -2.7430, -2.3412,\n",
      "        -2.4880, -3.0341, -2.3522, -2.5509, -2.7673, -2.5027, -2.5339, -2.6270,\n",
      "        -2.4424, -2.7394, -2.5734, -2.7654, -2.0902, -2.5534, -2.5638, -2.6607,\n",
      "        -2.4912, -2.5485], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6413, -2.5740, -2.6276, -2.6104, -2.6316, -2.6079, -2.6157, -2.6016,\n",
      "        -2.6347, -2.6371, -2.5516, -2.6319, -2.6321, -2.6360, -2.6362, -2.5809,\n",
      "        -2.6302, -2.6338, -2.6155, -2.6377, -2.6375, -2.5632, -2.5963, -2.6362,\n",
      "        -2.5706, -2.6369, -2.6311, -2.6363, -2.5696, -2.6369, -2.6346, -2.6277,\n",
      "        -2.5754, -2.6345, -2.6323, -2.6215, -2.6385, -2.6262, -2.6328, -2.6366,\n",
      "        -2.6331, -2.6368, -2.6037, -2.6360, -2.6208, -2.5216, -2.6335, -2.6315,\n",
      "        -2.6302, -2.6278], device='mps:0')\n",
      "mean: tensor(-2.6184, device='mps:0')\n",
      "iter_dt 1.08s; iter 38: train loss 0.94138 temperature: 6.899999999999993\n",
      "mean_logits tensor([-2.8536, -2.5276, -2.3419, -2.5127, -2.5755, -2.5166, -2.4345, -2.4651,\n",
      "        -2.5569, -2.8449, -2.6833, -2.4685, -2.5142, -2.4683, -2.7039, -2.6254,\n",
      "        -2.3009, -2.5582, -2.3705, -2.7941, -2.5738, -2.0471, -2.5430, -2.2595,\n",
      "        -2.6661, -2.6238, -2.3520, -2.2064, -2.2373, -2.5172, -2.7285, -2.2385,\n",
      "        -2.3833, -2.5712, -2.6198, -2.4891, -2.4646, -2.6357, -2.7061, -2.5215,\n",
      "        -2.3442, -2.2932, -2.0291, -2.6671, -2.1569, -2.6396, -2.8477, -2.9222,\n",
      "        -2.5251, -2.6820], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5753, -2.6102, -2.5889, -2.5836, -2.6335, -2.5763, -2.5944, -2.6362,\n",
      "        -2.6142, -2.6141, -2.6317, -2.5754, -2.5649, -2.6224, -2.5974, -2.6280,\n",
      "        -2.5863, -2.6343, -2.6356, -2.6360, -2.6389, -2.6094, -2.6380, -2.6258,\n",
      "        -2.5769, -2.6373, -2.5256, -2.6360, -2.5754, -2.6046, -2.6392, -2.6311,\n",
      "        -2.5996, -2.5782, -2.6355, -2.6201, -2.6370, -2.6265, -2.6102, -2.6270,\n",
      "        -2.6335, -2.6293, -2.5633, -2.6338, -2.5902, -2.6167, -2.6170, -2.6189,\n",
      "        -2.6378, -2.5768], device='mps:0')\n",
      "mean: tensor(-2.6106, device='mps:0')\n",
      "iter_dt 1.07s; iter 39: train loss 1.08432 temperature: 6.949999999999993\n",
      "mean_logits tensor([-2.6547, -2.9236, -2.5891, -2.6117, -2.5436, -2.6394, -2.7669, -2.1089,\n",
      "        -2.7231, -2.8239, -2.6482, -2.3684, -2.5027, -2.5791, -2.9373, -2.6268,\n",
      "        -2.8449, -2.6475, -2.5071, -2.6409, -2.2580, -2.4595, -2.7311, -2.3955,\n",
      "        -2.7924, -2.3723, -2.5939, -2.1313, -2.5828, -2.2534, -2.5093, -2.5084,\n",
      "        -2.4301, -2.6382, -2.3666, -2.4116, -2.4496, -2.4408, -2.6577, -2.0875,\n",
      "        -2.6557, -2.6253, -3.0523, -2.6809, -2.8190, -2.2650, -2.4956, -2.3455,\n",
      "        -2.6319, -2.8301], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6166, -2.5809, -2.6320, -2.6314, -2.6243, -2.6202, -2.6378, -2.5800,\n",
      "        -2.6100, -2.6374, -2.6169, -2.6081, -2.5353, -2.5600, -2.6233, -2.5724,\n",
      "        -2.6363, -2.5577, -2.6190, -2.6276, -2.6384, -2.6366, -2.6367, -2.5693,\n",
      "        -2.6344, -2.6146, -2.6156, -2.5981, -2.6357, -2.6372, -2.6292, -2.6217,\n",
      "        -2.5408, -2.6310, -2.6339, -2.6360, -2.6227, -2.6377, -2.6208, -2.6035,\n",
      "        -2.6076, -2.6201, -2.6344, -2.6130, -2.5702, -2.6386, -2.6178, -2.6394,\n",
      "        -2.6365, -2.4992], device='mps:0')\n",
      "mean: tensor(-2.6120, device='mps:0')\n",
      "iter_dt 1.08s; iter 40: train loss 0.86862 temperature: 6.999999999999993\n",
      "mean_logits tensor([-2.3695, -2.4008, -2.6115, -2.6642, -2.6971, -2.4907, -2.3896, -2.3659,\n",
      "        -3.0655, -2.3798, -2.3971, -2.7989, -2.4646, -2.6268, -2.6506, -2.4371,\n",
      "        -2.5751, -2.4565, -2.6900, -2.7701, -2.4516, -2.5276, -2.4451, -2.6254,\n",
      "        -2.6846, -2.4345, -2.4366, -2.5904, -2.3191, -2.4511, -2.3802, -2.5947,\n",
      "        -2.6019, -2.5346, -2.1899, -2.5370, -2.4803, -2.4711, -2.7380, -2.1416,\n",
      "        -2.5665, -2.1498, -2.3791, -2.5018, -2.6545, -2.4364, -2.6179, -2.1315,\n",
      "        -2.7209, -2.7789], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6131, -2.6226, -2.6373, -2.5730, -2.6345, -2.5676, -2.5676, -2.6179,\n",
      "        -2.6087, -2.6323, -2.6264, -2.6390, -2.6198, -2.5499, -2.5804, -2.6154,\n",
      "        -2.6207, -2.5554, -2.6369, -2.6157, -2.6177, -2.6246, -2.5766, -2.6036,\n",
      "        -2.5784, -2.6077, -2.6063, -2.6365, -2.6337, -2.6046, -2.6210, -2.6370,\n",
      "        -2.6347, -2.6364, -2.5815, -2.6316, -2.6346, -2.5755, -2.5780, -2.6370,\n",
      "        -2.5940, -2.5845, -2.6395, -2.6217, -2.6278, -2.5813, -2.6318, -2.5991,\n",
      "        -2.6366, -2.5742], device='mps:0')\n",
      "mean: tensor(-2.6096, device='mps:0')\n",
      "iter_dt 1.07s; iter 41: train loss 1.14590 temperature: 7.049999999999993\n",
      "mean_logits tensor([-2.4671, -2.6340, -2.6014, -2.7271, -2.7042, -2.7914, -2.4509, -2.6124,\n",
      "        -2.4175, -2.7464, -2.4135, -2.5255, -2.3256, -2.4620, -2.6132, -2.6822,\n",
      "        -2.9727, -2.9335, -2.6498, -2.5326, -2.6587, -2.2906, -2.8136, -2.8175,\n",
      "        -2.5710, -2.4082, -2.4286, -2.8775, -2.3456, -2.0349, -2.3833, -2.4269,\n",
      "        -2.7020, -2.5054, -2.7345, -3.0216, -2.2497, -2.8768, -2.7744, -2.2748,\n",
      "        -2.3153, -2.5920, -2.5637, -2.5670, -2.9813, -2.4859, -2.8715, -2.3259,\n",
      "        -2.5248, -2.4475], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6375, -2.6358, -2.6336, -2.6147, -2.6371, -2.6167, -2.6347, -2.6392,\n",
      "        -2.5772, -2.6336, -2.5563, -2.6350, -2.5762, -2.6349, -2.5614, -2.6212,\n",
      "        -2.6139, -2.6326, -2.6170, -2.6321, -2.6366, -2.6287, -2.6370, -2.6320,\n",
      "        -2.6132, -2.5787, -2.6375, -2.5353, -2.6203, -2.6189, -2.6353, -2.3955,\n",
      "        -2.6351, -2.5768, -2.5792, -2.6365, -2.5048, -2.6325, -2.5714, -2.6299,\n",
      "        -2.6083, -2.6367, -2.6268, -2.5624, -2.6050, -2.6379, -2.5644, -2.5623,\n",
      "        -2.5899, -2.6379], device='mps:0')\n",
      "mean: tensor(-2.6061, device='mps:0')\n",
      "iter_dt 1.07s; iter 42: train loss 1.09116 temperature: 7.0999999999999925\n",
      "mean_logits tensor([-2.4183, -2.3738, -2.5531, -2.5409, -2.5899, -2.6207, -2.4986, -2.5411,\n",
      "        -2.8307, -2.6560, -2.5354, -2.6190, -2.5865, -2.6270, -2.5539, -2.0804,\n",
      "        -2.8225, -2.9803, -2.4405, -2.9395, -2.2614, -2.4573, -2.3973, -2.5609,\n",
      "        -2.6452, -2.2102, -2.4749, -2.7919, -2.3024, -2.7036, -2.3856, -2.7485,\n",
      "        -2.4906, -2.4430, -2.3246, -2.7618, -2.4165, -2.7082, -1.9315, -2.3795,\n",
      "        -2.4106, -2.4629, -2.4775, -2.8950, -2.8406, -2.6138, -2.4884, -2.3499,\n",
      "        -2.3073, -2.5847], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6358, -2.6375, -2.6203, -2.6342, -2.6276, -2.6301, -2.6351, -2.6269,\n",
      "        -2.6372, -2.5451, -2.6165, -2.6394, -2.6248, -2.6217, -2.5978, -2.6232,\n",
      "        -2.6371, -2.6331, -2.6374, -2.5417, -2.6153, -2.5534, -2.5746, -2.6191,\n",
      "        -2.6274, -2.5913, -2.5828, -2.5551, -2.5646, -2.6018, -2.6352, -2.5665,\n",
      "        -2.6371, -2.6255, -2.6257, -2.6352, -2.6353, -2.5758, -2.6390, -2.5561,\n",
      "        -2.6058, -2.6400, -2.6170, -2.6183, -2.6156, -2.6055, -2.6002, -2.6116,\n",
      "        -2.6371, -2.5699], device='mps:0')\n",
      "mean: tensor(-2.6108, device='mps:0')\n",
      "iter_dt 1.09s; iter 43: train loss 0.90836 temperature: 7.149999999999992\n",
      "mean_logits tensor([-2.4172, -2.7298, -2.5814, -2.4609, -2.9778, -2.6358, -2.8259, -2.6467,\n",
      "        -2.6191, -2.7635, -2.3284, -2.7251, -2.5985, -2.6501, -2.5996, -2.6684,\n",
      "        -2.4295, -2.5550, -2.4658, -2.2338, -2.1933, -2.5209, -2.8855, -2.7387,\n",
      "        -2.5629, -2.8110, -2.6510, -2.5543, -2.9772, -2.5791, -2.3573, -2.5368,\n",
      "        -2.5293, -2.5761, -2.5754, -2.0883, -2.4881, -2.7023, -2.5768, -2.6470,\n",
      "        -2.5473, -2.6799, -2.2525, -2.1743, -2.5782, -2.2866, -2.5358, -2.2614,\n",
      "        -2.7068, -2.6172], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6388, -2.6251, -2.6332, -2.6360, -2.4978, -2.6224, -2.6034, -2.6011,\n",
      "        -2.6192, -2.6351, -2.6116, -2.6085, -2.6395, -2.5749, -2.6399, -2.5987,\n",
      "        -2.5588, -2.6162, -2.6374, -2.6187, -2.5975, -2.6295, -2.6300, -2.5502,\n",
      "        -2.6374, -2.6339, -2.6367, -2.5745, -2.6373, -2.6284, -2.5024, -2.6076,\n",
      "        -2.6217, -2.6317, -2.6385, -2.6204, -2.6330, -2.6218, -2.5804, -2.6150,\n",
      "        -2.6321, -2.6308, -2.5437, -2.6357, -2.6044, -2.6212, -2.6275, -2.6243,\n",
      "        -2.6171, -2.6120], device='mps:0')\n",
      "mean: tensor(-2.6119, device='mps:0')\n",
      "iter_dt 1.09s; iter 44: train loss 0.80663 temperature: 7.199999999999992\n",
      "mean_logits tensor([-2.2437, -2.2195, -2.5300, -2.7935, -2.9326, -2.7500, -2.4588, -2.5431,\n",
      "        -2.5028, -2.3085, -2.4717, -2.6198, -2.5919, -2.5841, -2.4105, -2.6919,\n",
      "        -2.6747, -2.5253, -2.2989, -2.7288, -2.2755, -2.4610, -2.5590, -2.7534,\n",
      "        -2.5393, -2.2326, -2.5122, -2.4978, -2.5794, -2.4798, -2.6414, -2.5716,\n",
      "        -2.0890, -2.6467, -2.7746, -2.4673, -2.6685, -2.5248, -2.4313, -2.4439,\n",
      "        -2.5592, -3.0874, -2.7857, -2.5278, -2.3987, -2.6509, -2.6984, -2.6238,\n",
      "        -2.3746, -2.7085], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6209, -2.6345, -2.6225, -2.6186, -2.6372, -2.6204, -2.5354, -2.6331,\n",
      "        -2.5980, -2.5915, -2.6386, -2.6218, -2.6192, -2.5909, -2.5488, -2.6041,\n",
      "        -2.6342, -2.5083, -2.6055, -2.6174, -2.6212, -2.6331, -2.5755, -2.6267,\n",
      "        -2.5815, -2.5633, -2.5552, -2.5782, -2.6222, -2.5354, -2.6305, -2.6324,\n",
      "        -2.6159, -2.6341, -2.6308, -2.6367, -2.6382, -2.6368, -2.5170, -2.5829,\n",
      "        -2.5788, -2.5980, -2.6316, -2.6168, -2.6289, -2.6344, -2.6304, -2.6289,\n",
      "        -2.5699, -2.6368], device='mps:0')\n",
      "mean: tensor(-2.6061, device='mps:0')\n",
      "iter_dt 1.06s; iter 45: train loss 0.67537 temperature: 7.249999999999992\n",
      "mean_logits tensor([-2.6402, -2.3206, -2.8888, -2.6799, -2.6485, -2.3170, -2.4749, -2.4273,\n",
      "        -2.5790, -2.5700, -2.9055, -2.3866, -2.4547, -2.4951, -2.7055, -2.8679,\n",
      "        -2.6162, -2.5299, -2.5753, -2.5417, -2.6893, -2.6124, -2.8283, -2.5414,\n",
      "        -2.8143, -2.8122, -2.6594, -2.8426, -2.4948, -2.3373, -2.7787, -2.6141,\n",
      "        -2.6145, -2.7297, -2.3957, -2.4010, -2.3859, -2.5392, -2.5824, -2.4349,\n",
      "        -2.5835, -2.3787, -2.5905, -2.4042, -2.8032, -2.6395, -2.4224, -2.4474,\n",
      "        -2.4873, -2.8985], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6366, -2.6314, -2.5768, -2.5999, -2.6277, -2.6319, -2.6152, -2.6338,\n",
      "        -2.6345, -2.5998, -2.6174, -2.6222, -2.6327, -2.6344, -2.6020, -2.6356,\n",
      "        -2.6314, -2.6368, -2.6370, -2.6314, -2.6193, -2.6148, -2.6164, -2.6220,\n",
      "        -2.6345, -2.6247, -2.6350, -2.6342, -2.6344, -2.6113, -2.6190, -2.6180,\n",
      "        -2.5919, -2.6314, -2.6218, -2.6253, -2.5638, -2.5787, -2.6342, -2.4978,\n",
      "        -2.5717, -2.6364, -2.6241, -2.5451, -2.6348, -2.6360, -2.5851, -2.6180,\n",
      "        -2.5471, -2.6275], device='mps:0')\n",
      "mean: tensor(-2.6145, device='mps:0')\n",
      "iter_dt 1.08s; iter 46: train loss 0.93344 temperature: 7.299999999999992\n",
      "mean_logits tensor([-2.5802, -2.3902, -2.6453, -2.8529, -2.1786, -2.7367, -2.5779, -2.6919,\n",
      "        -2.4183, -2.2680, -2.4326, -1.9313, -2.4741, -2.3593, -2.5646, -2.5960,\n",
      "        -2.6692, -2.6702, -2.6379, -2.6100, -2.6479, -2.3855, -2.7279, -2.5518,\n",
      "        -2.5238, -2.6191, -2.6697, -2.5457, -2.4191, -2.6466, -2.2253, -2.2455,\n",
      "        -2.5954, -2.4708, -2.4179, -2.4704, -2.3501, -2.6521, -2.6566, -2.4826,\n",
      "        -2.1387, -2.2875, -2.4283, -2.4359, -2.4038, -2.3946, -2.2436, -2.2609,\n",
      "        -2.6902, -2.5613], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6351, -2.6223, -2.6381, -2.6059, -2.6258, -2.6195, -2.5767, -2.6276,\n",
      "        -2.6382, -2.6233, -2.5781, -2.6273, -2.6053, -2.6333, -2.6259, -2.6344,\n",
      "        -2.6274, -2.6353, -2.5738, -2.6386, -2.6232, -2.6380, -2.6241, -2.5756,\n",
      "        -2.6279, -2.6166, -2.6370, -2.6386, -2.6381, -2.6093, -2.6100, -2.6292,\n",
      "        -2.6202, -2.6359, -2.5859, -2.6357, -2.6259, -2.5929, -2.6352, -2.6375,\n",
      "        -2.6346, -2.6365, -2.6261, -2.5769, -2.5781, -2.6290, -2.6375, -2.6346,\n",
      "        -2.6376, -2.6293], device='mps:0')\n",
      "mean: tensor(-2.6210, device='mps:0')\n",
      "iter_dt 1.08s; iter 47: train loss 1.10586 temperature: 7.349999999999992\n",
      "mean_logits tensor([-2.5786, -2.4568, -2.6585, -2.6240, -2.6176, -2.4988, -2.4708, -2.5281,\n",
      "        -2.5680, -2.4047, -2.5729, -2.4788, -2.6831, -2.5487, -2.3859, -2.3579,\n",
      "        -2.7744, -2.5455, -2.8779, -2.5434, -2.5306, -2.3893, -2.5607, -2.4750,\n",
      "        -2.4433, -2.3339, -2.4494, -2.2628, -2.3180, -2.4582, -2.4286, -2.7061,\n",
      "        -2.1879, -2.5354, -2.6283, -2.3238, -2.8603, -2.4863, -2.9203, -2.8677,\n",
      "        -2.5565, -2.4912, -2.0560, -2.6188, -3.0300, -2.9755, -2.3605, -2.8116,\n",
      "        -2.4863, -2.8252], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6222, -2.5871, -2.6348, -2.6285, -2.5821, -2.6213, -2.6322, -2.6177,\n",
      "        -2.6214, -2.6376, -2.5982, -2.6354, -2.6089, -2.6350, -2.6315, -2.5779,\n",
      "        -2.6170, -2.6139, -2.6207, -2.6162, -2.5876, -2.6172, -2.6285, -2.6379,\n",
      "        -2.6369, -2.6405, -2.6390, -2.6254, -2.6237, -2.6180, -2.6329, -2.6221,\n",
      "        -2.6028, -2.6326, -2.5567, -2.5752, -2.6186, -2.6246, -2.5544, -2.6064,\n",
      "        -2.5618, -2.6173, -2.6381, -2.6380, -2.6390, -2.5816, -2.6337, -2.5956,\n",
      "        -2.6380, -2.6165], device='mps:0')\n",
      "mean: tensor(-2.6156, device='mps:0')\n",
      "iter_dt 1.08s; iter 48: train loss 0.64662 temperature: 7.3999999999999915\n",
      "mean_logits tensor([-2.5213, -2.4308, -2.8514, -2.7012, -2.6205, -2.7627, -2.5716, -2.3164,\n",
      "        -2.7930, -2.5148, -2.6688, -2.6610, -2.5566, -2.5414, -2.6848, -2.4657,\n",
      "        -2.8075, -2.2044, -2.2678, -2.6145, -2.4165, -2.8110, -2.6077, -2.4815,\n",
      "        -2.4106, -2.5423, -2.6532, -2.3994, -2.2546, -2.7006, -2.7013, -2.4178,\n",
      "        -2.3647, -2.7743, -2.7040, -2.3615, -2.4991, -2.6814, -2.5394, -2.7167,\n",
      "        -2.6939, -2.5155, -2.3524, -2.4400, -2.7115, -2.6606, -2.4040, -2.5070,\n",
      "        -2.2948, -2.4280], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6373, -2.6180, -2.6281, -2.6174, -2.5787, -2.6154, -2.6202, -2.6354,\n",
      "        -2.6220, -2.5772, -2.5560, -2.6371, -2.6263, -2.6182, -2.6172, -2.6323,\n",
      "        -2.6375, -2.5985, -2.6350, -2.5692, -2.6341, -2.6393, -2.6270, -2.5715,\n",
      "        -2.6236, -2.6205, -2.5780, -2.6255, -2.6333, -2.6215, -2.6270, -2.5969,\n",
      "        -2.6347, -2.5550, -2.6223, -2.4415, -2.6366, -2.6254, -2.5954, -2.6217,\n",
      "        -2.6226, -2.6370, -2.6191, -2.6269, -2.6357, -2.6222, -2.5666, -2.6375,\n",
      "        -2.6373, -2.5808], device='mps:0')\n",
      "mean: tensor(-2.6119, device='mps:0')\n",
      "iter_dt 1.09s; iter 49: train loss 0.71091 temperature: 7.449999999999991\n",
      "mean_logits tensor([-2.4963, -2.6762, -2.5500, -2.4795, -3.0175, -2.6875, -2.3278, -2.4119,\n",
      "        -2.2276, -2.4850, -2.5159, -2.3611, -2.4861, -2.2724, -2.5802, -2.7954,\n",
      "        -2.5185, -2.5182, -2.9266, -2.5887, -2.4445, -2.5283, -2.4607, -2.5622,\n",
      "        -2.5736, -2.5482, -2.7202, -2.5005, -2.5356, -2.2261, -2.6094, -2.8325,\n",
      "        -2.7135, -2.4338, -2.3014, -2.6430, -2.8212, -2.4414, -2.5114, -2.2958,\n",
      "        -2.5745, -2.5944, -2.4539, -2.6900, -2.5732, -2.7388, -2.6613, -2.5616,\n",
      "        -2.7994, -2.5619], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6197, -2.5913, -2.6373, -2.6323, -2.5779, -2.5745, -2.5223, -2.5351,\n",
      "        -2.5949, -2.3891, -2.6343, -2.5587, -2.5480, -2.6242, -2.6247, -2.6209,\n",
      "        -2.6016, -2.6319, -2.6324, -2.6344, -2.6253, -2.5508, -2.5646, -2.5613,\n",
      "        -2.6253, -2.6287, -2.6361, -2.6251, -2.6270, -2.5688, -2.5558, -2.6214,\n",
      "        -2.6190, -2.6374, -2.6325, -2.6278, -2.6239, -2.6323, -2.5846, -2.6109,\n",
      "        -2.6235, -2.5610, -2.6266, -2.6327, -2.6222, -2.5926, -2.6059, -2.6375,\n",
      "        -2.6056, -2.6198], device='mps:0')\n",
      "mean: tensor(-2.6014, device='mps:0')\n",
      "iter_dt 1.09s; iter 50: train loss 0.85947 temperature: 7.499999999999991\n",
      "mean_logits tensor([-2.5016, -2.8588, -2.5346, -2.9361, -2.5852, -2.1340, -2.0429, -2.4338,\n",
      "        -2.2346, -2.4693, -2.5049, -2.3829, -2.7147, -2.3823, -2.4593, -2.6062,\n",
      "        -2.5665, -2.6872, -2.3760, -2.6790, -2.3927, -2.7174, -2.3761, -2.5382,\n",
      "        -2.7393, -2.7769, -2.4355, -2.8003, -2.3051, -2.7322, -2.6987, -2.7819,\n",
      "        -2.6972, -2.5954, -2.3627, -2.4572, -2.5128, -2.4618, -2.6894, -2.6403,\n",
      "        -2.3654, -2.6117, -2.4129, -2.6445, -2.4466, -2.8245, -2.3996, -2.4608,\n",
      "        -2.4583, -2.5171], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6257, -2.5828, -2.5626, -2.6372, -2.5948, -2.6336, -2.6350, -2.5570,\n",
      "        -2.5274, -2.6282, -2.5507, -2.6168, -2.6240, -2.6338, -2.6374, -2.6129,\n",
      "        -2.6359, -2.5690, -2.6353, -2.6401, -2.6026, -2.6248, -2.6087, -2.6386,\n",
      "        -2.6331, -2.6109, -2.6351, -2.6246, -2.6212, -2.6381, -2.5964, -2.3900,\n",
      "        -2.5692, -2.6142, -2.5572, -2.6370, -2.6139, -2.6041, -2.6079, -2.6154,\n",
      "        -2.6346, -2.6367, -2.5822, -2.6366, -2.6349, -2.6343, -2.6266, -2.5239,\n",
      "        -2.6174, -2.6204], device='mps:0')\n",
      "mean: tensor(-2.6066, device='mps:0')\n",
      "iter_dt 1.08s; iter 51: train loss 0.84244 temperature: 7.549999999999991\n",
      "mean_logits tensor([-2.6500, -2.6875, -2.3251, -2.7685, -2.3959, -2.5649, -2.4951, -2.5483,\n",
      "        -2.9979, -2.5426, -2.4342, -2.3480, -2.6533, -2.5724, -2.7804, -2.2767,\n",
      "        -2.2371, -2.3272, -2.3743, -2.9545, -2.7799, -2.3822, -2.5604, -2.3742,\n",
      "        -2.6342, -2.4252, -2.8618, -2.5001, -2.6233, -2.5063, -2.6363, -2.5836,\n",
      "        -2.4670, -2.5664, -2.7230, -2.2060, -2.4121, -2.4849, -2.5783, -2.2407,\n",
      "        -2.4942, -2.6783, -2.3481, -2.7029, -2.5496, -2.4989, -2.6624, -2.6762,\n",
      "        -2.5184, -2.5165], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6383, -2.6160, -2.6363, -2.6336, -2.6315, -2.6267, -2.6364, -2.6316,\n",
      "        -2.6168, -2.6173, -2.5751, -2.5892, -2.6374, -2.6258, -2.5633, -2.5876,\n",
      "        -2.6279, -2.6353, -2.6188, -2.6358, -2.6074, -2.5725, -2.6342, -2.6334,\n",
      "        -2.6038, -2.6250, -2.6316, -2.5802, -2.6379, -2.6391, -2.5964, -2.6374,\n",
      "        -2.4961, -2.5958, -2.5009, -2.6300, -2.6234, -2.6335, -2.5844, -2.6203,\n",
      "        -2.6376, -2.6232, -2.6229, -2.6352, -2.5588, -2.6364, -2.6312, -2.6210,\n",
      "        -2.6061, -2.6372], device='mps:0')\n",
      "mean: tensor(-2.6135, device='mps:0')\n",
      "iter_dt 1.09s; iter 52: train loss 0.74552 temperature: 7.599999999999991\n",
      "mean_logits tensor([-2.2538, -2.5671, -2.6627, -2.4202, -2.7146, -2.4851, -2.4321, -2.5125,\n",
      "        -2.7487, -2.4234, -2.7346, -2.4053, -2.6336, -2.6204, -2.8111, -2.6231,\n",
      "        -2.6314, -2.8301, -2.5458, -2.3029, -2.7348, -2.5213, -2.3682, -2.5891,\n",
      "        -2.2945, -1.9850, -2.3053, -2.6471, -2.3956, -2.5506, -2.8546, -2.5178,\n",
      "        -2.4789, -2.8177, -2.4942, -2.5169, -2.5747, -2.2391, -2.7034, -2.0630,\n",
      "        -2.6111, -2.7199, -2.6158, -2.5400, -2.4955, -2.6380, -2.6913, -2.5521,\n",
      "        -2.5162, -2.5872], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6381, -2.5746, -2.6366, -2.6374, -2.6375, -2.6090, -2.5516, -2.6375,\n",
      "        -2.6224, -2.5189, -2.6164, -2.6367, -2.6206, -2.5785, -2.6128, -2.6374,\n",
      "        -2.6219, -2.5929, -2.5904, -2.4775, -2.6191, -2.6038, -2.6164, -2.5691,\n",
      "        -2.6243, -2.6360, -2.6298, -2.6376, -2.6380, -2.6320, -2.6243, -2.6374,\n",
      "        -2.6218, -2.6321, -2.6359, -2.6366, -2.6189, -2.6397, -2.6291, -2.6237,\n",
      "        -2.6383, -2.6368, -2.6257, -2.6259, -2.5974, -2.6377, -2.6319, -2.6245,\n",
      "        -2.6371, -2.6257], device='mps:0')\n",
      "mean: tensor(-2.6167, device='mps:0')\n",
      "iter_dt 1.07s; iter 53: train loss 0.63796 temperature: 7.649999999999991\n",
      "mean_logits tensor([-2.4743, -2.7431, -2.5928, -2.4436, -2.5524, -2.5909, -2.4246, -2.5168,\n",
      "        -2.2071, -2.6088, -2.7558, -2.3134, -2.3664, -2.6165, -2.5328, -2.5446,\n",
      "        -2.6765, -2.4336, -2.7942, -2.4470, -2.5337, -2.7357, -2.5016, -2.7152,\n",
      "        -2.2243, -2.7138, -2.6346, -2.4378, -2.3592, -2.5734, -2.3575, -2.5240,\n",
      "        -2.5085, -2.4390, -2.5084, -2.6763, -2.9097, -2.7903, -2.3802, -2.5660,\n",
      "        -2.7211, -2.6605, -2.5682, -2.5196, -2.8164, -2.5526, -2.4510, -3.0044,\n",
      "        -2.6058, -2.4863], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6153, -2.6206, -2.6261, -2.6331, -2.5917, -2.6324, -2.6076, -2.6369,\n",
      "        -2.6003, -2.6358, -2.6370, -2.5503, -2.5786, -2.6198, -2.5707, -2.6370,\n",
      "        -2.6349, -2.5741, -2.5527, -2.6205, -2.5841, -2.6291, -2.5581, -2.6324,\n",
      "        -2.5710, -2.5967, -2.6202, -2.6366, -2.6179, -2.6373, -2.5957, -2.6175,\n",
      "        -2.5734, -2.6321, -2.6244, -2.6392, -2.6206, -2.6356, -2.6371, -2.6350,\n",
      "        -2.6169, -2.5996, -2.6192, -2.6377, -2.6372, -2.5784, -2.5761, -2.6191,\n",
      "        -2.6270, -2.6352], device='mps:0')\n",
      "mean: tensor(-2.6123, device='mps:0')\n",
      "iter_dt 1.07s; iter 54: train loss 1.05986 temperature: 7.69999999999999\n",
      "mean_logits tensor([-2.5987, -2.7426, -2.3809, -2.6495, -2.2751, -2.7435, -2.6658, -2.6392,\n",
      "        -2.3102, -2.3457, -2.9635, -2.1763, -2.6526, -2.6497, -2.5019, -2.5041,\n",
      "        -2.4044, -2.6968, -2.4276, -2.4414, -2.2532, -2.5891, -2.6498, -2.4894,\n",
      "        -2.5994, -2.4392, -3.0095, -2.1983, -2.8836, -2.5894, -2.4943, -2.6121,\n",
      "        -2.4686, -2.6705, -2.6699, -2.3259, -2.5407, -2.5278, -2.3027, -2.4692,\n",
      "        -2.7631, -2.3789, -2.6258, -2.5163, -2.8067, -2.7163, -2.3794, -2.5433,\n",
      "        -2.0056, -2.9289], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6209, -2.6012, -2.6276, -2.5997, -2.6377, -2.5891, -2.6279, -2.5767,\n",
      "        -2.6200, -2.5620, -2.6220, -2.6373, -2.6299, -2.6345, -2.6112, -2.6173,\n",
      "        -2.6333, -2.6070, -2.5903, -2.6307, -2.6370, -2.6053, -2.6382, -2.6348,\n",
      "        -2.2763, -2.6204, -2.6350, -2.6194, -2.6374, -2.6377, -2.6275, -2.6057,\n",
      "        -2.5678, -2.6335, -2.6198, -2.5998, -2.6341, -2.6294, -2.5680, -2.6283,\n",
      "        -2.6375, -2.6297, -2.6376, -2.6345, -2.5815, -2.6089, -2.5661, -2.5659,\n",
      "        -2.6372, -2.6367], device='mps:0')\n",
      "mean: tensor(-2.6093, device='mps:0')\n",
      "iter_dt 1.08s; iter 55: train loss 1.03036 temperature: 7.74999999999999\n",
      "mean_logits tensor([-2.3647, -2.7957, -2.3619, -2.6934, -2.4714, -2.3026, -2.5315, -2.2707,\n",
      "        -2.6409, -3.0191, -2.5973, -2.5075, -2.4227, -2.5493, -2.3356, -2.7352,\n",
      "        -2.7214, -2.7942, -2.7038, -2.3486, -2.6245, -2.3792, -2.3691, -2.3381,\n",
      "        -2.6922, -2.6549, -2.1589, -2.4514, -2.8398, -2.4232, -2.2830, -2.3504,\n",
      "        -2.5833, -2.4938, -2.8837, -2.3618, -2.4916, -2.4988, -2.3656, -2.2723,\n",
      "        -2.4274, -2.4120, -2.5299, -2.5869, -2.8678, -2.6941, -2.4676, -2.3158,\n",
      "        -2.5365, -2.3088], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6365, -2.6372, -2.6371, -2.6246, -2.6195, -2.5889, -2.5811, -2.6213,\n",
      "        -2.6203, -2.5698, -2.6136, -2.6334, -2.6371, -2.6343, -2.5704, -2.6313,\n",
      "        -2.5651, -2.6172, -2.5788, -2.6113, -2.6020, -2.6334, -2.5541, -2.5693,\n",
      "        -2.6308, -2.6270, -2.6068, -2.6371, -2.6346, -2.5807, -2.5865, -2.6178,\n",
      "        -2.6381, -2.6362, -2.6149, -2.6274, -2.6372, -2.6290, -2.6168, -2.6174,\n",
      "        -2.6173, -2.6335, -2.6374, -2.6368, -2.6194, -2.6345, -2.6369, -2.6307,\n",
      "        -2.6221, -2.6361], device='mps:0')\n",
      "mean: tensor(-2.6166, device='mps:0')\n",
      "iter_dt 1.09s; iter 56: train loss 0.68302 temperature: 7.79999999999999\n",
      "mean_logits tensor([-2.2328, -2.4444, -2.3938, -2.5338, -2.8244, -2.2649, -2.4338, -2.5697,\n",
      "        -2.7833, -2.7001, -2.5410, -2.7127, -2.7029, -2.6207, -2.5386, -2.5648,\n",
      "        -2.5130, -2.7746, -2.7244, -2.5504, -2.4521, -2.6166, -2.3216, -2.5785,\n",
      "        -2.3747, -2.6276, -2.4458, -2.6443, -2.8009, -2.5805, -2.0652, -2.3948,\n",
      "        -2.5044, -2.5469, -2.3848, -2.5160, -2.5330, -2.6126, -2.3709, -2.3455,\n",
      "        -2.8859, -2.5999, -2.5660, -2.6596, -2.7403, -2.6164, -2.5000, -2.2194,\n",
      "        -2.4003, -2.3383], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6154, -2.6338, -2.6342, -2.5497, -2.5986, -2.6134, -2.6298, -2.5862,\n",
      "        -2.6174, -2.6194, -2.6146, -2.6250, -2.6129, -2.5560, -2.6371, -2.6164,\n",
      "        -2.6156, -2.6372, -2.5738, -2.5719, -2.5760, -2.6237, -2.5741, -2.5789,\n",
      "        -2.6175, -2.6352, -2.5992, -2.6361, -2.6076, -2.6367, -2.5622, -2.5681,\n",
      "        -2.6114, -2.5768, -2.6144, -2.6100, -2.6331, -2.6371, -2.5977, -2.6379,\n",
      "        -2.6342, -2.6344, -2.6251, -2.6087, -2.6269, -2.6289, -2.6329, -2.6216,\n",
      "        -2.6367, -2.6229], device='mps:0')\n",
      "mean: tensor(-2.6113, device='mps:0')\n",
      "iter_dt 1.08s; iter 57: train loss 1.22457 temperature: 7.84999999999999\n",
      "mean_logits tensor([-2.6167, -2.3045, -2.0831, -2.6124, -2.6344, -2.7192, -2.4291, -2.4457,\n",
      "        -2.2489, -2.5323, -2.5111, -2.2036, -2.4905, -2.5043, -2.7643, -2.1541,\n",
      "        -2.1408, -2.5083, -2.6298, -2.6805, -2.8250, -2.4890, -3.1799, -2.6092,\n",
      "        -2.8526, -2.1402, -2.5358, -2.5054, -2.5814, -2.4469, -2.8021, -2.3604,\n",
      "        -2.3600, -2.3655, -2.5067, -2.3861, -2.4173, -2.6822, -2.6264, -2.8784,\n",
      "        -2.7431, -2.5238, -2.4465, -2.6423, -2.8321, -2.5911, -2.2888, -2.5437,\n",
      "        -2.8368, -2.4889], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5857, -2.6392, -2.6356, -2.6335, -2.6164, -2.6372, -2.5628, -2.5549,\n",
      "        -2.6368, -2.6371, -2.6360, -2.6365, -2.6320, -2.6350, -2.6348, -2.6247,\n",
      "        -2.6370, -2.6310, -2.6360, -2.5396, -2.6280, -2.5900, -2.6377, -2.6285,\n",
      "        -2.6355, -2.5760, -2.6349, -2.6379, -2.6280, -2.6214, -2.6190, -2.6352,\n",
      "        -2.6166, -2.5735, -2.6333, -2.6225, -2.6386, -2.6382, -2.6184, -2.6276,\n",
      "        -2.6192, -2.6340, -2.6358, -2.5754, -2.6362, -2.6372, -2.5992, -2.6359,\n",
      "        -2.6380, -2.6374], device='mps:0')\n",
      "mean: tensor(-2.6214, device='mps:0')\n",
      "iter_dt 1.15s; iter 58: train loss 0.83397 temperature: 7.89999999999999\n",
      "mean_logits tensor([-2.4058, -2.3348, -2.2776, -2.3932, -2.3426, -2.4091, -2.5862, -2.6998,\n",
      "        -2.6612, -2.7678, -2.5966, -2.8085, -2.4107, -2.6328, -2.5252, -2.3939,\n",
      "        -2.6047, -2.5380, -2.7748, -2.3257, -2.4738, -2.7798, -2.5423, -2.7534,\n",
      "        -2.4048, -2.3405, -2.9249, -2.7332, -2.8291, -2.6978, -2.7436, -2.2537,\n",
      "        -2.3666, -2.6765, -2.1055, -2.7412, -2.2800, -2.8319, -2.7541, -2.4745,\n",
      "        -2.7484, -2.7144, -2.4732, -2.6108, -2.5338, -2.4243, -2.3559, -2.8621,\n",
      "        -2.5533, -2.5330], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6369, -2.5409, -2.6269, -2.6307, -2.5668, -2.6316, -2.6022, -2.5912,\n",
      "        -2.6421, -2.5578, -2.5760, -2.6362, -2.6301, -2.6371, -2.6273, -2.6179,\n",
      "        -2.5997, -2.6061, -2.6085, -2.6037, -2.5319, -2.5818, -2.6172, -2.6374,\n",
      "        -2.6247, -2.6265, -2.6365, -2.6372, -2.6399, -2.6370, -2.6320, -2.6354,\n",
      "        -2.5544, -2.6375, -2.6337, -2.6350, -2.6024, -2.6378, -2.6375, -2.6064,\n",
      "        -2.6171, -2.6355, -2.6189, -2.6361, -2.6369, -2.6370, -2.6225, -2.6159,\n",
      "        -2.6397, -2.6193], device='mps:0')\n",
      "mean: tensor(-2.6166, device='mps:0')\n",
      "iter_dt 1.12s; iter 59: train loss 0.62887 temperature: 7.9499999999999895\n",
      "mean_logits tensor([-2.6524, -2.5682, -2.5529, -2.7057, -2.4930, -2.4238, -2.4124, -2.4837,\n",
      "        -2.5690, -2.6253, -2.4335, -2.4212, -2.5878, -2.5427, -2.2737, -2.7662,\n",
      "        -2.5927, -2.9205, -2.5974, -2.5321, -2.6590, -2.1965, -2.7295, -2.5503,\n",
      "        -2.5094, -2.5198, -2.5443, -2.5818, -2.6931, -2.5490, -2.7338, -2.3181,\n",
      "        -2.5970, -2.4482, -2.7926, -2.2815, -2.2251, -2.8839, -2.4712, -2.5300,\n",
      "        -2.4580, -2.4878, -2.4432, -2.4649, -2.4189, -2.7560, -2.3951, -2.5307,\n",
      "        -2.4011, -2.6854], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6347, -2.6080, -2.5933, -2.5703, -2.6166, -2.6288, -2.6373, -2.6361,\n",
      "        -2.6350, -2.5733, -2.6118, -2.4753, -2.6229, -2.6192, -2.6245, -2.5607,\n",
      "        -2.6372, -2.6172, -2.6384, -2.6347, -2.6378, -2.5860, -2.5572, -2.6373,\n",
      "        -2.6334, -2.5658, -2.6384, -2.5856, -2.6206, -2.6133, -2.6343, -2.6210,\n",
      "        -2.6079, -2.5726, -2.6277, -2.5825, -2.6301, -2.6363, -2.5700, -2.6183,\n",
      "        -2.5936, -2.6068, -2.6259, -2.6326, -2.6378, -2.6340, -2.6380, -2.6320,\n",
      "        -2.5505, -2.6216], device='mps:0')\n",
      "mean: tensor(-2.6105, device='mps:0')\n",
      "iter_dt 1.12s; iter 60: train loss 0.76557 temperature: 7.999999999999989\n",
      "mean_logits tensor([-2.5672, -2.7278, -2.6490, -2.3672, -2.6131, -2.6180, -2.2115, -2.5262,\n",
      "        -2.6367, -2.5725, -2.3674, -2.5171, -2.5604, -2.3849, -2.6030, -2.8722,\n",
      "        -2.4077, -2.4222, -2.5855, -2.8222, -2.5931, -2.3723, -2.5962, -2.4609,\n",
      "        -2.8132, -2.6246, -2.5738, -2.8813, -2.5913, -2.1643, -2.1223, -2.7176,\n",
      "        -2.6722, -2.5158, -2.3220, -2.5480, -2.5347, -2.4556, -2.3996, -2.6535,\n",
      "        -2.4048, -2.5630, -2.7323, -2.5552, -2.7075, -2.1434, -2.5666, -2.6974,\n",
      "        -2.4260, -2.4237], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6361, -2.6376, -2.6350, -2.6378, -2.5669, -2.6206, -2.6062, -2.6380,\n",
      "        -2.5625, -2.6363, -2.6374, -2.6376, -2.5958, -2.6196, -2.6256, -2.6363,\n",
      "        -2.6256, -2.6201, -2.6280, -2.6374, -2.6258, -2.6272, -2.6089, -2.5856,\n",
      "        -2.6214, -2.6372, -2.5665, -2.6200, -2.6365, -2.6292, -2.6336, -2.6349,\n",
      "        -2.6236, -2.6183, -2.6365, -2.6396, -2.6342, -2.5653, -2.6370, -2.6321,\n",
      "        -2.6124, -2.6182, -2.5704, -2.6172, -2.6144, -2.6378, -2.5646, -2.5259,\n",
      "        -2.6213, -2.5937], device='mps:0')\n",
      "mean: tensor(-2.6166, device='mps:0')\n",
      "iter_dt 1.11s; iter 61: train loss 0.63604 temperature: 8.04999999999999\n",
      "mean_logits tensor([-2.6863, -2.4947, -2.4223, -2.5506, -2.5158, -2.4358, -2.6719, -2.4871,\n",
      "        -2.9244, -2.7425, -2.3616, -2.5551, -2.8313, -2.6885, -2.7506, -2.4520,\n",
      "        -2.7413, -2.5159, -2.3697, -2.5698, -2.7136, -2.7817, -2.6573, -2.2827,\n",
      "        -2.5781, -2.5771, -2.7487, -2.7628, -2.3688, -2.5830, -2.5532, -2.4839,\n",
      "        -2.6769, -2.8800, -2.1945, -2.8472, -2.6452, -2.6154, -2.6861, -2.5999,\n",
      "        -2.4322, -2.5630, -2.5785, -2.2555, -2.6891, -2.8184, -2.6846, -2.7294,\n",
      "        -2.6049, -2.5090], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5681, -2.6298, -2.6183, -2.6346, -2.6375, -2.6315, -2.6372, -2.6362,\n",
      "        -2.6295, -2.6360, -2.6339, -2.6374, -2.6103, -2.6344, -2.6339, -2.6233,\n",
      "        -2.6346, -2.6348, -2.6269, -2.5880, -2.6163, -2.6186, -2.6196, -2.6320,\n",
      "        -2.5731, -2.6371, -2.6315, -2.6178, -2.6315, -2.5746, -2.6302, -2.6379,\n",
      "        -2.5916, -2.5792, -2.5330, -2.6340, -2.6373, -2.6286, -2.6279, -2.5535,\n",
      "        -2.6362, -2.6271, -2.6346, -2.6342, -2.6277, -2.6375, -2.6218, -2.6219,\n",
      "        -2.6366, -2.6188], device='mps:0')\n",
      "mean: tensor(-2.6204, device='mps:0')\n",
      "iter_dt 1.11s; iter 62: train loss 1.05202 temperature: 8.09999999999999\n",
      "mean_logits tensor([-2.2994, -2.4218, -2.6340, -2.3935, -2.5661, -2.3233, -2.2842, -2.3912,\n",
      "        -2.5596, -2.1840, -2.7692, -2.5805, -2.5323, -2.3873, -2.4212, -2.3746,\n",
      "        -2.7170, -2.6809, -2.7590, -2.4266, -2.9410, -2.5756, -2.6117, -2.1131,\n",
      "        -2.5559, -2.5671, -2.7200, -2.3624, -2.3398, -2.6335, -2.3062, -2.6826,\n",
      "        -2.3745, -2.6575, -2.6571, -2.6608, -2.0070, -2.3577, -2.5858, -2.4778,\n",
      "        -2.4597, -2.7756, -2.6776, -2.1876, -2.8028, -2.4707, -2.5700, -2.5833,\n",
      "        -2.4494, -3.0548], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6373, -2.6267, -2.6343, -2.5519, -2.5741, -2.5877, -2.6370, -2.6125,\n",
      "        -2.6360, -2.5844, -2.6176, -2.6345, -2.6363, -2.5661, -2.6332, -2.5664,\n",
      "        -2.5812, -2.6375, -2.6381, -2.6044, -2.6369, -2.6269, -2.5786, -2.6320,\n",
      "        -2.6374, -2.6270, -2.6333, -2.6161, -2.5698, -2.6374, -2.6376, -2.5616,\n",
      "        -2.6295, -2.6362, -2.6212, -2.6301, -2.6385, -2.6372, -2.6234, -2.6375,\n",
      "        -2.6225, -2.6224, -2.6366, -2.6168, -2.6371, -2.6304, -2.5576, -2.6368,\n",
      "        -2.5855, -2.5980], device='mps:0')\n",
      "mean: tensor(-2.6158, device='mps:0')\n",
      "iter_dt 1.12s; iter 63: train loss 0.82493 temperature: 8.149999999999991\n",
      "mean_logits tensor([-2.3166, -2.4052, -2.3712, -2.7168, -2.6792, -2.4155, -2.5677, -2.5469,\n",
      "        -2.6640, -2.6124, -2.6425, -2.4245, -2.8792, -2.5950, -2.2176, -2.9279,\n",
      "        -2.7990, -2.5115, -2.6310, -2.8280, -2.7931, -2.6458, -2.3325, -2.2720,\n",
      "        -2.7810, -2.8228, -2.7254, -2.8049, -2.8258, -2.3569, -2.9369, -2.7067,\n",
      "        -2.5268, -2.4769, -2.6686, -2.6463, -2.4824, -2.6163, -2.5360, -2.1711,\n",
      "        -2.5680, -2.6129, -2.3439, -2.7105, -2.6066, -2.2445, -2.5626, -2.2657,\n",
      "        -2.7491, -2.7121], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6156, -2.6181, -2.5610, -2.6376, -2.6372, -2.6353, -2.6372, -2.6365,\n",
      "        -2.6203, -2.6331, -2.6201, -2.6370, -2.6335, -2.6384, -2.5740, -2.6308,\n",
      "        -2.6321, -2.5723, -2.6373, -2.6190, -2.6353, -2.6278, -2.6222, -2.6349,\n",
      "        -2.6314, -2.6379, -2.6364, -2.6272, -2.5832, -2.6196, -2.6322, -2.6380,\n",
      "        -2.6174, -2.5671, -2.6374, -2.5745, -2.5962, -2.6374, -2.5580, -2.6319,\n",
      "        -2.6172, -2.6375, -2.6342, -2.6370, -2.5941, -2.5671, -2.6352, -2.6345,\n",
      "        -2.6279, -2.6278], device='mps:0')\n",
      "mean: tensor(-2.6197, device='mps:0')\n",
      "iter_dt 1.09s; iter 64: train loss 0.79462 temperature: 8.199999999999992\n",
      "mean_logits tensor([-2.5567, -2.4110, -2.3314, -2.7380, -2.4380, -2.7531, -2.7328, -2.5834,\n",
      "        -2.6004, -2.4214, -2.4452, -2.4097, -2.5875, -2.6981, -2.7575, -2.3763,\n",
      "        -2.5397, -2.4778, -2.8820, -2.5810, -2.2654, -2.5625, -2.4911, -2.5892,\n",
      "        -2.3427, -2.8356, -2.6319, -2.3200, -2.5879, -2.6353, -2.4584, -2.3607,\n",
      "        -2.8673, -2.5280, -2.5791, -2.4877, -2.7679, -2.4265, -2.5909, -2.6441,\n",
      "        -2.6670, -2.6233, -2.0348, -2.6690, -2.6205, -3.0845, -2.4091, -2.5815,\n",
      "        -2.6168, -2.5925], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5514, -2.6375, -2.5555, -2.6173, -2.6371, -2.6346, -2.6092, -2.6273,\n",
      "        -2.6233, -2.5914, -2.6353, -2.6389, -2.6276, -2.5738, -2.6273, -2.6365,\n",
      "        -2.6373, -2.6372, -2.6347, -2.6360, -2.6265, -2.6365, -2.6395, -2.6332,\n",
      "        -2.5690, -2.6089, -2.6361, -2.5796, -2.6344, -2.6376, -2.6201, -2.6137,\n",
      "        -2.6367, -2.6370, -2.5785, -2.6207, -2.6346, -2.5919, -2.6311, -2.6113,\n",
      "        -2.6378, -2.5875, -2.6377, -2.6363, -2.6220, -2.6278, -2.6380, -2.6315,\n",
      "        -2.6263, -2.6371], device='mps:0')\n",
      "mean: tensor(-2.6206, device='mps:0')\n",
      "iter_dt 1.09s; iter 65: train loss 0.97664 temperature: 8.249999999999993\n",
      "mean_logits tensor([-2.5490, -2.0118, -2.4601, -2.0958, -2.5623, -2.6033, -2.5870, -2.6049,\n",
      "        -2.4436, -2.6032, -2.3923, -2.6691, -2.3994, -2.5073, -2.6173, -2.2728,\n",
      "        -2.4271, -2.4665, -2.5403, -2.7266, -2.4950, -2.3949, -2.8166, -2.4062,\n",
      "        -2.8510, -2.7113, -2.7914, -2.5482, -2.5385, -2.3717, -2.6999, -2.7455,\n",
      "        -2.3883, -2.6230, -2.8984, -2.6650, -2.4115, -2.6342, -2.5946, -2.7963,\n",
      "        -2.6559, -2.7481, -2.6495, -2.7959, -2.4479, -3.0828, -2.8772, -2.3565,\n",
      "        -2.7946, -2.3462], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6331, -2.5848, -2.6291, -2.6271, -2.6361, -2.6363, -2.6204, -2.6201,\n",
      "        -2.6277, -2.6183, -2.6210, -2.6362, -2.6341, -2.6320, -2.6044, -2.6275,\n",
      "        -2.5772, -2.6270, -2.6129, -2.6077, -2.6364, -2.6347, -2.6316, -2.6286,\n",
      "        -2.5771, -2.6355, -2.6363, -2.6351, -2.6374, -2.6351, -2.6381, -2.6192,\n",
      "        -2.6330, -2.6342, -2.5885, -2.5767, -2.6240, -2.6240, -2.6200, -2.6182,\n",
      "        -2.6265, -2.6193, -2.6350, -2.6378, -2.6401, -2.6375, -2.6334, -2.6244,\n",
      "        -2.6280, -2.5858], device='mps:0')\n",
      "mean: tensor(-2.6229, device='mps:0')\n",
      "iter_dt 1.10s; iter 66: train loss 0.72959 temperature: 8.299999999999994\n",
      "mean_logits tensor([-2.3997, -2.6048, -2.7212, -2.4328, -2.6619, -2.6770, -2.7086, -2.6890,\n",
      "        -2.3040, -2.6052, -2.6384, -2.7823, -2.3599, -2.8586, -2.7278, -2.9745,\n",
      "        -2.2451, -2.5299, -2.6895, -2.4141, -2.7104, -2.2670, -2.7983, -2.6995,\n",
      "        -2.4401, -2.2889, -2.3640, -2.6012, -2.6044, -2.6653, -2.2099, -2.3496,\n",
      "        -2.6429, -2.4824, -2.6537, -2.6423, -2.5762, -2.3312, -2.1029, -2.6061,\n",
      "        -2.6311, -2.3655, -2.5181, -2.4928, -2.5323, -2.5017, -2.4997, -2.5569,\n",
      "        -2.4933, -2.4999], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5995, -2.6379, -2.6353, -2.6269, -2.5711, -2.6367, -2.6370, -2.6203,\n",
      "        -2.5816, -2.6302, -2.6117, -2.6002, -2.5889, -2.6342, -2.6351, -2.6173,\n",
      "        -2.6124, -2.6321, -2.6269, -2.5737, -2.6374, -2.5764, -2.6219, -2.6198,\n",
      "        -2.6172, -2.5693, -2.6196, -2.6377, -2.5978, -2.6279, -2.6374, -2.6367,\n",
      "        -2.6353, -2.6373, -2.6225, -2.6159, -2.5859, -2.6327, -2.5788, -2.6373,\n",
      "        -2.6271, -2.6358, -2.5952, -2.6333, -2.5821, -2.6363, -2.6365, -2.5822,\n",
      "        -2.6390, -2.6365], device='mps:0')\n",
      "mean: tensor(-2.6172, device='mps:0')\n",
      "iter_dt 1.08s; iter 67: train loss 0.37047 temperature: 8.349999999999994\n",
      "mean_logits tensor([-2.5851, -2.6587, -2.4620, -2.5258, -2.6443, -2.8675, -2.5892, -2.7660,\n",
      "        -2.5172, -2.5877, -2.6424, -2.4315, -2.3322, -2.5413, -2.5342, -2.5660,\n",
      "        -2.4705, -2.4286, -2.6381, -2.5010, -2.6721, -2.7579, -2.8058, -2.5087,\n",
      "        -2.5033, -2.5055, -2.4195, -2.3999, -2.5860, -2.7777, -2.6071, -2.5073,\n",
      "        -2.5798, -2.6761, -2.5278, -2.3871, -2.6920, -2.7277, -2.5077, -2.5437,\n",
      "        -2.6828, -2.4165, -2.5386, -2.3224, -2.6815, -2.3306, -2.6242, -2.5982,\n",
      "        -2.5325, -2.6869], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6282, -2.6360, -2.6373, -2.6374, -2.6380, -2.6274, -2.6384, -2.6289,\n",
      "        -2.6108, -2.6360, -2.5925, -2.6248, -2.6299, -2.6361, -2.6302, -2.6361,\n",
      "        -2.5815, -2.6347, -2.6370, -2.6323, -2.6225, -2.6373, -2.6169, -2.6323,\n",
      "        -2.5694, -2.6359, -2.6382, -2.5546, -2.6371, -2.6293, -2.6339, -2.6231,\n",
      "        -2.6339, -2.6378, -2.6054, -2.5718, -2.6353, -2.6101, -2.5263, -2.5994,\n",
      "        -2.6342, -2.6363, -2.5826, -2.5810, -2.6272, -2.5545, -2.6319, -2.6023,\n",
      "        -2.5952, -2.6280], device='mps:0')\n",
      "mean: tensor(-2.6176, device='mps:0')\n",
      "iter_dt 1.11s; iter 68: train loss 0.42774 temperature: 8.399999999999995\n",
      "mean_logits tensor([-2.5600, -2.6751, -2.5821, -2.7207, -2.5095, -2.4900, -2.3882, -2.4772,\n",
      "        -2.7371, -2.5460, -2.4561, -2.5775, -2.6095, -2.6704, -2.7273, -2.9187,\n",
      "        -2.6805, -2.5340, -2.3372, -2.5537, -2.6917, -2.4563, -2.5326, -2.5111,\n",
      "        -2.6638, -2.6716, -2.6434, -2.4043, -2.6220, -2.4024, -2.7298, -2.5720,\n",
      "        -2.6592, -2.7309, -2.4434, -2.4687, -2.6435, -2.4850, -2.3536, -2.4715,\n",
      "        -2.7112, -2.4908, -2.6720, -2.8231, -2.6778, -2.6352, -2.8524, -2.4852,\n",
      "        -2.4300, -2.4389], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6226, -2.6242, -2.6030, -2.5709, -2.6375, -2.6229, -2.6220, -2.6251,\n",
      "        -2.6263, -2.6322, -2.6360, -2.6204, -2.6039, -2.6332, -2.6337, -2.6243,\n",
      "        -2.6359, -2.6205, -2.6306, -2.5489, -2.6361, -2.6374, -2.5744, -2.6321,\n",
      "        -2.6366, -2.6366, -2.6325, -2.6142, -2.6198, -2.6343, -2.6191, -2.5808,\n",
      "        -2.6222, -2.6381, -2.5471, -2.6371, -2.6382, -2.6254, -2.5540, -2.6369,\n",
      "        -2.6276, -2.6271, -2.6312, -2.6374, -2.6369, -2.6378, -2.6371, -2.5810,\n",
      "        -2.6203, -2.6364], device='mps:0')\n",
      "mean: tensor(-2.6200, device='mps:0')\n",
      "iter_dt 1.10s; iter 69: train loss 0.42172 temperature: 8.449999999999996\n",
      "mean_logits tensor([-2.4336, -2.4117, -2.4299, -2.5595, -2.4714, -2.4912, -2.5059, -2.6708,\n",
      "        -2.4086, -2.6922, -2.5813, -2.6896, -2.3664, -2.5578, -2.5608, -2.4032,\n",
      "        -2.5304, -2.6436, -2.6740, -2.6377, -2.6920, -2.4836, -2.5555, -2.5516,\n",
      "        -2.7177, -2.6259, -2.6311, -2.5943, -2.3090, -2.6563, -2.3097, -2.5153,\n",
      "        -2.3299, -2.4835, -2.4786, -2.3273, -2.5945, -2.6096, -2.7986, -2.5941,\n",
      "        -2.4598, -2.6167, -2.6603, -2.6785, -2.8684, -2.4841, -2.5988, -2.7911,\n",
      "        -2.6786, -2.6938], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6357, -2.5804, -2.6234, -2.6346, -2.5645, -2.6291, -2.6343, -2.6123,\n",
      "        -2.6357, -2.6262, -2.6331, -2.6198, -2.5813, -2.5975, -2.6193, -2.6349,\n",
      "        -2.5810, -2.5813, -2.6191, -2.6354, -2.6313, -2.6386, -2.5785, -2.6282,\n",
      "        -2.6368, -2.6325, -2.6358, -2.6367, -2.6113, -2.5853, -2.6372, -2.6270,\n",
      "        -2.5922, -2.5644, -2.6367, -2.6202, -2.6367, -2.6382, -2.6319, -2.6210,\n",
      "        -2.6373, -2.6371, -2.6365, -2.6358, -2.6185, -2.5926, -2.6338, -2.6340,\n",
      "        -2.6372, -2.6273], device='mps:0')\n",
      "mean: tensor(-2.6198, device='mps:0')\n",
      "iter_dt 1.09s; iter 70: train loss 0.49729 temperature: 8.499999999999996\n",
      "mean_logits tensor([-2.6596, -2.2747, -2.6222, -2.7645, -2.5696, -2.6090, -2.6783, -2.9614,\n",
      "        -2.4876, -2.6719, -2.5314, -2.4003, -2.4884, -2.6625, -2.5105, -2.5436,\n",
      "        -2.5177, -2.6003, -2.5496, -2.4552, -2.7756, -2.5286, -2.6303, -2.4754,\n",
      "        -2.4642, -2.7354, -2.5288, -2.6258, -2.8899, -2.4789, -2.5787, -2.6313,\n",
      "        -2.7704, -2.8068, -2.6898, -2.4775, -2.5906, -2.6258, -2.4726, -2.3337,\n",
      "        -2.7797, -2.7806, -2.6181, -2.6930, -2.5569, -2.4149, -2.4934, -2.4987,\n",
      "        -2.7191, -2.7371], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6166, -2.6066, -2.6372, -2.6370, -2.6377, -2.6351, -2.6368, -2.6261,\n",
      "        -2.6321, -2.6370, -2.6147, -2.6356, -2.6382, -2.6453, -2.6309, -2.6255,\n",
      "        -2.6376, -2.6215, -2.6209, -2.6371, -2.6313, -2.6083, -2.6365, -2.5765,\n",
      "        -2.5853, -2.5717, -2.6289, -2.5645, -2.6283, -2.6176, -2.6370, -2.6204,\n",
      "        -2.6367, -2.5731, -2.6184, -2.6352, -2.6153, -2.6345, -2.6375, -2.6380,\n",
      "        -2.6403, -2.6362, -2.6365, -2.5797, -2.6328, -2.6159, -2.6369, -2.4999,\n",
      "        -2.6373, -2.6376], device='mps:0')\n",
      "mean: tensor(-2.6212, device='mps:0')\n",
      "iter_dt 1.11s; iter 71: train loss 0.73648 temperature: 8.549999999999997\n",
      "mean_logits tensor([-2.2205, -2.6816, -2.4907, -2.2709, -2.4094, -2.8469, -2.5414, -2.4499,\n",
      "        -2.5299, -2.4815, -2.5194, -2.8353, -2.5371, -2.5220, -2.5182, -2.5109,\n",
      "        -2.6335, -2.4427, -2.5394, -2.3539, -2.4948, -2.6518, -2.6325, -2.9432,\n",
      "        -2.5510, -2.7424, -2.7289, -2.5070, -2.6620, -2.5370, -2.2510, -2.5303,\n",
      "        -2.6963, -2.3968, -2.9944, -2.5759, -2.6040, -2.8890, -2.5838, -2.7477,\n",
      "        -2.4019, -2.6041, -2.6108, -2.6650, -2.5233, -2.7796, -2.6265, -2.3295,\n",
      "        -2.3540, -2.8387], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5772, -2.6331, -2.6297, -2.6204, -2.6199, -2.6318, -2.6259, -2.6195,\n",
      "        -2.6315, -2.5946, -2.6365, -2.6366, -2.6379, -2.6223, -2.6351, -2.6248,\n",
      "        -2.6361, -2.6365, -2.6265, -2.6278, -2.6148, -2.6323, -2.6373, -2.5779,\n",
      "        -2.6351, -2.6106, -2.6345, -2.5433, -2.6355, -2.5710, -2.5926, -2.6314,\n",
      "        -2.6379, -2.6246, -2.6261, -2.6340, -2.6275, -2.6342, -2.6355, -2.6267,\n",
      "        -2.5848, -2.6375, -2.6352, -2.5713, -2.6375, -2.6364, -2.5330, -2.5431,\n",
      "        -2.6193, -2.6188], device='mps:0')\n",
      "mean: tensor(-2.6177, device='mps:0')\n",
      "iter_dt 1.10s; iter 72: train loss 0.41507 temperature: 8.599999999999998\n",
      "mean_logits tensor([-2.4297, -2.3623, -2.5380, -2.4000, -2.4971, -2.6463, -2.6565, -2.8115,\n",
      "        -2.6091, -2.6193, -2.4407, -2.5049, -2.4831, -2.8214, -2.6341, -2.7175,\n",
      "        -2.6287, -2.5282, -2.6620, -2.7413, -2.5843, -2.5900, -2.5899, -2.4356,\n",
      "        -2.6597, -2.7712, -2.6252, -2.5379, -2.6413, -2.6096, -2.6632, -2.5329,\n",
      "        -2.7384, -2.8499, -2.4538, -2.6748, -2.4344, -2.5617, -2.5279, -2.4495,\n",
      "        -2.5523, -2.5109, -2.4588, -2.6036, -2.2862, -2.6896, -2.5571, -2.8543,\n",
      "        -2.5551, -2.5971], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6365, -2.6023, -2.6347, -2.6399, -2.6275, -2.6085, -2.6376, -2.6361,\n",
      "        -2.6190, -2.6236, -2.6281, -2.6354, -2.6084, -2.6339, -2.5764, -2.5576,\n",
      "        -2.6362, -2.6377, -2.6364, -2.6331, -2.6298, -2.5745, -2.6323, -2.6344,\n",
      "        -2.6271, -2.6225, -2.6349, -2.6264, -2.6328, -2.6373, -2.6371, -2.6349,\n",
      "        -2.6275, -2.6377, -2.6016, -2.6210, -2.5710, -2.6205, -2.6366, -2.6286,\n",
      "        -2.5946, -2.6248, -2.6346, -2.6032, -2.6282, -2.5360, -2.6377, -2.6198,\n",
      "        -2.6366, -2.5732], device='mps:0')\n",
      "mean: tensor(-2.6201, device='mps:0')\n",
      "iter_dt 1.10s; iter 73: train loss 0.73500 temperature: 8.649999999999999\n",
      "mean_logits tensor([-2.5444, -2.6036, -2.0896, -2.6026, -2.5706, -2.2744, -2.2437, -2.6732,\n",
      "        -2.6955, -2.7707, -2.5755, -2.7236, -2.5357, -2.8824, -2.5415, -2.5804,\n",
      "        -2.7892, -2.6458, -2.5747, -2.5736, -2.5136, -2.7095, -2.8389, -2.8728,\n",
      "        -2.5944, -2.7519, -2.6327, -2.3600, -2.8490, -2.6686, -2.6125, -2.5583,\n",
      "        -2.3278, -2.8751, -2.8062, -2.5096, -2.2597, -2.8075, -2.5170, -2.3985,\n",
      "        -2.6668, -2.5171, -2.3205, -2.7724, -2.4013, -2.4400, -2.6034, -2.5133,\n",
      "        -2.5880, -2.4725], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6334, -2.6270, -2.5793, -2.6355, -2.6241, -2.6327, -2.6347, -2.6214,\n",
      "        -2.6314, -2.6332, -2.6350, -2.6373, -2.5632, -2.6376, -2.6180, -2.6179,\n",
      "        -2.6271, -2.6247, -2.6379, -2.6219, -2.6307, -2.6270, -2.6344, -2.6287,\n",
      "        -2.6180, -2.6371, -2.6340, -2.6348, -2.6051, -2.6196, -2.6353, -2.6375,\n",
      "        -2.6234, -2.6102, -2.6085, -2.6353, -2.6279, -2.5884, -2.6358, -2.5831,\n",
      "        -2.6297, -2.5969, -2.6206, -2.6375, -2.6330, -2.6377, -2.5996, -2.6369,\n",
      "        -2.6373, -2.5997], device='mps:0')\n",
      "mean: tensor(-2.6231, device='mps:0')\n",
      "iter_dt 1.09s; iter 74: train loss 0.64629 temperature: 8.7\n",
      "mean_logits tensor([-2.8060, -2.3471, -2.5461, -2.3799, -2.7590, -2.6447, -2.5618, -2.6349,\n",
      "        -2.5335, -2.7773, -2.4643, -2.7676, -2.4560, -2.4286, -2.7530, -2.9828,\n",
      "        -2.8641, -2.6689, -2.8841, -2.8382, -2.7149, -2.4368, -2.3826, -2.4914,\n",
      "        -2.7536, -2.5805, -2.4952, -2.7154, -2.4089, -2.7659, -2.6104, -2.5059,\n",
      "        -2.4011, -2.4691, -2.7493, -2.6978, -2.6043, -2.5116, -2.6960, -2.4656,\n",
      "        -2.7169, -2.2424, -2.4672, -2.6858, -2.7181, -2.4429, -2.6227, -2.5887,\n",
      "        -2.4650, -2.5015], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6280, -2.6252, -2.6284, -2.6346, -2.6353, -2.6174, -2.6213, -2.5964,\n",
      "        -2.6016, -2.6328, -2.6309, -2.6294, -2.6179, -2.6369, -2.6275, -2.6369,\n",
      "        -2.6362, -2.6369, -2.6287, -2.6408, -2.5740, -2.6356, -2.6109, -2.6223,\n",
      "        -2.6351, -2.6257, -2.6376, -2.6354, -2.6340, -2.6220, -2.5960, -2.6370,\n",
      "        -2.5786, -2.6210, -2.6371, -2.5636, -2.6345, -2.6191, -2.6347, -2.6276,\n",
      "        -2.6334, -2.6400, -2.6230, -2.6331, -2.6321, -2.5459, -2.6188, -2.6375,\n",
      "        -2.6375, -2.6179], device='mps:0')\n",
      "mean: tensor(-2.6229, device='mps:0')\n",
      "iter_dt 1.12s; iter 75: train loss 0.77273 temperature: 8.75\n",
      "mean_logits tensor([-2.7350, -2.7862, -2.7405, -2.4403, -2.5515, -2.5412, -2.6290, -2.8558,\n",
      "        -2.5662, -2.6447, -2.4611, -2.7107, -2.3143, -2.4796, -2.6569, -2.6729,\n",
      "        -2.6366, -2.6558, -2.4762, -2.6548, -2.6811, -2.5584, -2.3368, -2.9540,\n",
      "        -2.6882, -2.6410, -2.4207, -2.7075, -2.3798, -2.5093, -2.8795, -2.6146,\n",
      "        -2.6174, -2.3337, -2.8595, -2.4234, -2.4944, -2.4963, -2.4503, -2.4391,\n",
      "        -2.5389, -2.8360, -2.5125, -2.8048, -2.8599, -2.4341, -2.2450, -2.4790,\n",
      "        -2.5097, -2.9680], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6327, -2.6349, -2.6276, -2.6364, -2.6379, -2.6367, -2.6105, -2.6354,\n",
      "        -2.6313, -2.6010, -2.5605, -2.5813, -2.6421, -2.6247, -2.6330, -2.6348,\n",
      "        -2.6201, -2.5635, -2.6072, -2.6360, -2.5440, -2.6371, -2.6372, -2.6359,\n",
      "        -2.6237, -2.6377, -2.6130, -2.6066, -2.6347, -2.6315, -2.6263, -2.6364,\n",
      "        -2.6304, -2.6258, -2.6330, -2.6359, -2.6384, -2.6025, -2.6411, -2.6223,\n",
      "        -2.6356, -2.6329, -2.6373, -2.6293, -2.6258, -2.6228, -2.6375, -2.5877,\n",
      "        -2.5844, -2.6343], device='mps:0')\n",
      "mean: tensor(-2.6222, device='mps:0')\n",
      "iter_dt 1.08s; iter 76: train loss 1.22499 temperature: 8.8\n",
      "mean_logits tensor([-2.7235, -2.3821, -2.7814, -2.8792, -2.7588, -2.4481, -2.8508, -2.5330,\n",
      "        -2.6768, -2.6017, -2.7209, -2.4334, -2.8166, -2.7498, -2.3683, -2.5709,\n",
      "        -2.8113, -2.6710, -2.6205, -3.0389, -2.7105, -2.2419, -2.8579, -2.6796,\n",
      "        -2.5211, -2.7539, -2.8007, -2.3983, -2.4118, -2.9786, -2.6189, -2.8458,\n",
      "        -2.7960, -2.6261, -2.6741, -2.6057, -2.1832, -2.6016, -2.5666, -2.6438,\n",
      "        -2.6701, -2.5290, -2.4169, -2.7159, -2.5928, -2.5018, -2.6826, -2.6107,\n",
      "        -3.2739, -2.7661], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6287, -2.6266, -2.5786, -2.6371, -2.6378, -2.6336, -2.5927, -2.6282,\n",
      "        -2.6244, -2.6369, -2.6362, -2.5126, -2.6307, -2.6369, -2.5793, -2.6372,\n",
      "        -2.6352, -2.6334, -2.6360, -2.6155, -2.6276, -2.6291, -2.6380, -2.6233,\n",
      "        -2.6163, -2.6150, -2.6351, -2.6362, -2.6195, -2.6096, -2.6013, -2.6252,\n",
      "        -2.6047, -2.5703, -2.6279, -2.6246, -2.5774, -2.6349, -2.6369, -2.6198,\n",
      "        -2.6265, -2.5942, -2.6330, -2.6213, -2.6229, -2.6202, -2.6152, -2.6309,\n",
      "        -2.6362, -2.6218], device='mps:0')\n",
      "mean: tensor(-2.6194, device='mps:0')\n",
      "iter_dt 1.09s; iter 77: train loss 0.79890 temperature: 8.850000000000001\n",
      "mean_logits tensor([-2.8599, -2.5422, -2.5547, -2.6813, -2.7922, -2.6798, -2.7861, -2.5307,\n",
      "        -2.8729, -2.6710, -2.2442, -2.2901, -2.4565, -2.5425, -2.6381, -2.5372,\n",
      "        -2.8483, -2.8473, -2.8609, -2.8357, -2.7438, -2.6176, -2.6498, -2.4430,\n",
      "        -2.5714, -2.5757, -2.4584, -2.7945, -2.7796, -2.3139, -2.4833, -2.7049,\n",
      "        -2.7806, -2.4422, -2.4307, -2.7927, -2.6594, -2.7492, -2.6281, -2.9261,\n",
      "        -2.5409, -2.8469, -2.2652, -2.8462, -2.8237, -2.5149, -2.7928, -2.6279,\n",
      "        -2.6711, -2.6933], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5608, -2.6341, -2.6360, -2.6167, -2.6368, -2.6379, -2.5970, -2.6312,\n",
      "        -2.6322, -2.6138, -2.6370, -2.6072, -2.6361, -2.6225, -2.6278, -2.6346,\n",
      "        -2.5746, -2.6352, -2.6373, -2.6296, -2.6370, -2.6344, -2.6394, -2.6340,\n",
      "        -2.5787, -2.6260, -2.6110, -2.6189, -2.6268, -2.6220, -2.5733, -2.5878,\n",
      "        -2.6356, -2.5719, -2.6353, -2.6222, -2.6298, -2.5735, -2.6172, -2.6270,\n",
      "        -2.6341, -2.6381, -2.5726, -2.6380, -2.6235, -2.5722, -2.5804, -2.5852,\n",
      "        -2.6070, -2.6373], device='mps:0')\n",
      "mean: tensor(-2.6166, device='mps:0')\n",
      "iter_dt 1.13s; iter 78: train loss 0.53494 temperature: 8.900000000000002\n",
      "mean_logits tensor([-2.7615, -2.7203, -2.8410, -2.6204, -2.7301, -2.5504, -2.5875, -2.4040,\n",
      "        -2.3590, -2.7319, -2.6653, -2.4579, -2.6761, -2.7486, -2.6354, -2.6562,\n",
      "        -2.7167, -2.7260, -2.8727, -2.7686, -2.6347, -2.6741, -2.6348, -2.5644,\n",
      "        -2.6402, -2.2599, -2.5795, -2.4873, -2.7318, -2.8568, -2.6102, -2.8112,\n",
      "        -2.2374, -2.6150, -2.4525, -2.7408, -2.5701, -2.5631, -2.4612, -2.7259,\n",
      "        -2.5752, -2.5895, -2.3418, -2.5480, -2.2733, -2.5760, -2.4580, -2.3840,\n",
      "        -2.7587, -2.4872], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5761, -2.6375, -2.6187, -2.6354, -2.6353, -2.6376, -2.6334, -2.6120,\n",
      "        -2.6231, -2.6271, -2.6144, -2.6365, -2.6371, -2.6113, -2.6261, -2.6269,\n",
      "        -2.6280, -2.6377, -2.6319, -2.6372, -2.6359, -2.6372, -2.6330, -2.6314,\n",
      "        -2.6375, -2.6384, -2.6005, -2.6203, -2.6215, -2.6000, -2.6380, -2.6392,\n",
      "        -2.5641, -2.6297, -2.6110, -2.6258, -2.6315, -2.6267, -2.5816, -2.6374,\n",
      "        -2.6265, -2.6262, -2.5952, -2.6331, -2.6377, -2.5625, -2.6380, -2.5990,\n",
      "        -2.6327, -2.6403], device='mps:0')\n",
      "mean: tensor(-2.6231, device='mps:0')\n",
      "iter_dt 1.09s; iter 79: train loss 0.56263 temperature: 8.950000000000003\n",
      "mean_logits tensor([-2.5875, -2.2213, -2.5947, -2.4591, -2.4521, -2.7527, -2.3822, -2.4241,\n",
      "        -2.5648, -2.5782, -2.6244, -2.8081, -2.7374, -2.5140, -2.5981, -2.7837,\n",
      "        -2.4814, -2.4212, -2.4334, -2.7960, -2.6313, -2.3699, -2.3552, -2.7450,\n",
      "        -2.4589, -2.4737, -2.4899, -2.2380, -2.6950, -2.6543, -2.4506, -2.4640,\n",
      "        -2.7797, -2.4125, -2.5918, -2.6945, -2.8115, -2.5214, -2.6121, -2.7585,\n",
      "        -2.4389, -2.6236, -2.5502, -2.6259, -2.5028, -2.6775, -2.7857, -2.4560,\n",
      "        -2.2843, -2.4853], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6337, -2.6316, -2.6173, -2.5902, -2.5606, -2.6080, -2.6033, -2.6283,\n",
      "        -2.6005, -2.6379, -2.6246, -2.6353, -2.6376, -2.6373, -2.6271, -2.5945,\n",
      "        -2.6358, -2.6357, -2.5867, -2.6370, -2.6379, -2.6204, -2.6277, -2.6274,\n",
      "        -2.6169, -2.6370, -2.5751, -2.5813, -2.6377, -2.6260, -2.6369, -2.5567,\n",
      "        -2.6340, -2.6196, -2.5665, -2.6178, -2.6350, -2.6271, -2.6197, -2.6187,\n",
      "        -2.6346, -2.6235, -2.6218, -2.6308, -2.6364, -2.6251, -2.6351, -2.6245,\n",
      "        -2.6382, -2.6115], device='mps:0')\n",
      "mean: tensor(-2.6193, device='mps:0')\n",
      "iter_dt 1.10s; iter 80: train loss 0.59701 temperature: 9.000000000000004\n",
      "mean_logits tensor([-2.4872, -2.5307, -2.6491, -2.5736, -2.5657, -2.4744, -2.8685, -2.4511,\n",
      "        -2.5792, -2.5393, -2.2979, -2.4827, -2.4558, -2.6330, -2.5207, -2.9057,\n",
      "        -2.6679, -2.4362, -2.5565, -2.7570, -2.5536, -2.2944, -2.5536, -2.4324,\n",
      "        -2.4073, -2.5946, -2.7385, -2.4016, -2.5312, -2.6021, -2.5620, -2.6691,\n",
      "        -2.5429, -2.2258, -2.3209, -2.4911, -2.4814, -2.3422, -2.5700, -2.6263,\n",
      "        -2.4343, -2.4394, -2.7189, -2.4409, -2.2374, -2.4563, -2.4157, -2.5572,\n",
      "        -2.3888, -2.3046], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6276, -2.5710, -2.6344, -2.6258, -2.6371, -2.6110, -2.6362, -2.5760,\n",
      "        -2.5682, -2.5409, -2.6354, -2.6354, -2.6392, -2.6366, -2.5626, -2.6366,\n",
      "        -2.6374, -2.5794, -2.6095, -2.6353, -2.6283, -2.5837, -2.6264, -2.6360,\n",
      "        -2.6329, -2.6248, -2.6374, -2.6374, -2.6208, -2.5987, -2.5763, -2.6377,\n",
      "        -2.6334, -2.5305, -2.6376, -2.6348, -2.6330, -2.6276, -2.6368, -2.6366,\n",
      "        -2.6372, -2.5552, -2.6372, -2.6365, -2.5141, -2.5622, -2.6218, -2.6117,\n",
      "        -2.6363, -2.6358], device='mps:0')\n",
      "mean: tensor(-2.6139, device='mps:0')\n",
      "iter_dt 1.08s; iter 81: train loss 0.69003 temperature: 9.050000000000004\n",
      "mean_logits tensor([-2.4701, -2.8105, -2.3745, -2.8827, -2.5252, -2.8159, -2.5266, -2.6123,\n",
      "        -2.7801, -2.6265, -2.2849, -2.5724, -2.4078, -2.5506, -2.6001, -2.6128,\n",
      "        -2.4467, -2.7876, -2.2524, -2.6400, -2.1881, -2.5498, -2.6447, -2.5770,\n",
      "        -2.6790, -2.6565, -2.3983, -2.8730, -2.5194, -2.7856, -2.3360, -2.2376,\n",
      "        -2.3389, -2.6722, -2.5243, -2.6006, -2.7540, -2.5723, -2.6557, -2.6949,\n",
      "        -2.5529, -2.7386, -2.5680, -2.9369, -2.7524, -2.5300, -2.5803, -2.6090,\n",
      "        -2.4080, -2.7112], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6266, -2.6318, -2.6277, -2.6340, -2.6262, -2.6196, -2.6322, -2.6351,\n",
      "        -2.6247, -2.6379, -2.6271, -2.6361, -2.6034, -2.6278, -2.6386, -2.5829,\n",
      "        -2.6398, -2.6346, -2.5768, -2.6269, -2.6274, -2.6315, -2.6386, -2.6247,\n",
      "        -2.6360, -2.6356, -2.5857, -2.6274, -2.6280, -2.6262, -2.6211, -2.6379,\n",
      "        -2.6265, -2.6376, -2.6348, -2.6335, -2.6348, -2.6372, -2.6277, -2.6381,\n",
      "        -2.6367, -2.5988, -2.6174, -2.6316, -2.6314, -2.6192, -2.6395, -2.6354,\n",
      "        -2.6342, -2.6177], device='mps:0')\n",
      "mean: tensor(-2.6268, device='mps:0')\n",
      "iter_dt 1.08s; iter 82: train loss 0.56221 temperature: 9.100000000000005\n",
      "mean_logits tensor([-2.5479, -2.7306, -2.6372, -2.6325, -2.6146, -2.4550, -2.7530, -2.5973,\n",
      "        -2.3704, -2.8313, -2.3709, -2.7255, -2.4332, -2.6001, -2.6397, -2.5162,\n",
      "        -2.5616, -2.5793, -2.9452, -2.5070, -2.5817, -2.6065, -2.4815, -2.5766,\n",
      "        -2.7719, -2.4324, -2.3613, -2.4538, -2.5221, -2.5665, -2.5742, -2.5631,\n",
      "        -2.4749, -2.5497, -2.8047, -2.4097, -2.7822, -2.6890, -2.3637, -2.8825,\n",
      "        -2.4362, -2.4667, -2.5581, -2.6136, -2.3726, -2.5619, -2.4174, -2.6000,\n",
      "        -2.4784, -2.3655], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6168, -2.6111, -2.6366, -2.6090, -2.6201, -2.6368, -2.6249, -2.5675,\n",
      "        -2.6371, -2.6353, -2.6363, -2.6348, -2.6230, -2.6344, -2.6372, -2.6387,\n",
      "        -2.6277, -2.6361, -2.6076, -2.6078, -2.6374, -2.6366, -2.6335, -2.5641,\n",
      "        -2.6316, -2.6176, -2.6363, -2.6284, -2.6165, -2.6360, -2.6302, -2.6243,\n",
      "        -2.6369, -2.6301, -2.5549, -2.6279, -2.6160, -2.6342, -2.6361, -2.6189,\n",
      "        -2.5628, -2.5927, -2.6367, -2.5882, -2.5727, -2.5658, -2.6035, -2.6204,\n",
      "        -2.5722, -2.5934], device='mps:0')\n",
      "mean: tensor(-2.6167, device='mps:0')\n",
      "iter_dt 1.09s; iter 83: train loss 0.79091 temperature: 9.150000000000006\n",
      "mean_logits tensor([-2.4418, -2.6080, -2.7723, -2.8002, -2.6074, -2.6272, -2.4932, -2.7403,\n",
      "        -2.5890, -2.6833, -2.4073, -2.5736, -2.8388, -2.5100, -2.6347, -2.7680,\n",
      "        -2.8413, -2.5828, -2.3129, -2.9843, -2.2498, -2.9099, -2.7003, -2.5254,\n",
      "        -2.4938, -2.7828, -2.4241, -2.5567, -2.7124, -2.5245, -2.4069, -2.6911,\n",
      "        -2.6895, -2.8765, -2.5245, -2.5513, -2.6038, -2.3503, -2.4343, -2.2767,\n",
      "        -2.7636, -2.4686, -2.4442, -2.5316, -2.4161, -2.8601, -2.5517, -2.7092,\n",
      "        -2.8049, -2.3804], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6171, -2.6374, -2.6369, -2.6237, -2.6365, -2.5942, -2.6373, -2.5980,\n",
      "        -2.6363, -2.5634, -2.5975, -2.6245, -2.6106, -2.6200, -2.6328, -2.6080,\n",
      "        -2.6370, -2.6263, -2.6371, -2.6268, -2.6342, -2.6351, -2.6377, -2.5858,\n",
      "        -2.6346, -2.5962, -2.6251, -2.6229, -2.6296, -2.5720, -2.6247, -2.6305,\n",
      "        -2.6322, -2.6241, -2.6324, -2.6220, -2.6125, -2.6173, -2.6229, -2.6361,\n",
      "        -2.6370, -2.6168, -2.6377, -2.6280, -2.6352, -2.6175, -2.6372, -2.6009,\n",
      "        -2.6312, -2.6358], device='mps:0')\n",
      "mean: tensor(-2.6221, device='mps:0')\n",
      "iter_dt 1.10s; iter 84: train loss 0.61695 temperature: 9.200000000000006\n",
      "mean_logits tensor([-2.6917, -2.6680, -2.8574, -2.5204, -2.6137, -2.4428, -2.7514, -2.4106,\n",
      "        -2.5287, -2.6728, -2.4763, -2.5511, -2.4120, -2.4216, -2.3479, -2.8022,\n",
      "        -2.4702, -2.6891, -2.7717, -2.6122, -2.3312, -2.4886, -2.7502, -2.6425,\n",
      "        -2.7465, -2.4845, -2.7119, -2.7090, -2.6135, -2.8012, -2.4010, -2.3457,\n",
      "        -2.5636, -2.6774, -2.4830, -2.7930, -2.4036, -2.5442, -2.5228, -2.4564,\n",
      "        -2.5637, -2.6469, -2.9368, -2.6684, -2.7184, -2.8635, -2.2969, -2.6605,\n",
      "        -2.4446, -2.6896], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6341, -2.6375, -2.6240, -2.6322, -2.6046, -2.6280, -2.6275, -2.5553,\n",
      "        -2.5885, -2.6343, -2.5705, -2.6200, -2.6362, -2.6316, -2.6257, -2.6260,\n",
      "        -2.6351, -2.6375, -2.6360, -2.6282, -2.6384, -2.5722, -2.6367, -2.5527,\n",
      "        -2.6117, -2.6368, -2.6148, -2.6207, -2.6413, -2.6378, -2.6375, -2.6354,\n",
      "        -2.6342, -2.6327, -2.6364, -2.6269, -2.6377, -2.6381, -2.6363, -2.6349,\n",
      "        -2.6352, -2.5635, -2.6313, -2.6377, -2.5790, -2.6398, -2.6372, -2.5998,\n",
      "        -2.6383, -2.6016], device='mps:0')\n",
      "mean: tensor(-2.6218, device='mps:0')\n",
      "iter_dt 1.13s; iter 85: train loss 0.83306 temperature: 9.250000000000007\n",
      "mean_logits tensor([-2.5017, -2.6824, -2.3811, -2.4625, -2.4890, -2.5410, -2.6575, -2.8826,\n",
      "        -2.8235, -2.6913, -2.5511, -2.6061, -2.8638, -2.8721, -2.7752, -2.6256,\n",
      "        -2.4485, -2.9538, -2.2131, -2.5336, -2.8644, -2.1239, -2.5461, -2.5998,\n",
      "        -2.4058, -2.5348, -2.7015, -2.7803, -2.1850, -2.8056, -2.5523, -2.2544,\n",
      "        -2.3724, -2.6020, -2.3663, -2.5599, -2.7313, -2.7305, -2.6262, -2.4868,\n",
      "        -2.5059, -2.7072, -2.5976, -2.6001, -2.4882, -2.5524, -2.2140, -2.6515,\n",
      "        -2.5559, -2.5167], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6176, -2.5621, -2.6329, -2.6190, -2.6347, -2.5807, -2.6150, -2.6374,\n",
      "        -2.6364, -2.6373, -2.6243, -2.6375, -2.6347, -2.5765, -2.6199, -2.6344,\n",
      "        -2.6324, -2.6211, -2.5989, -2.6238, -2.6394, -2.5848, -2.5814, -2.6301,\n",
      "        -2.6334, -2.6376, -2.6153, -2.6333, -2.5960, -2.6347, -2.6220, -2.6324,\n",
      "        -2.6272, -2.6371, -2.6364, -2.6378, -2.6392, -2.6069, -2.6267, -2.6377,\n",
      "        -2.6396, -2.6343, -2.6357, -2.5802, -2.6195, -2.6258, -2.6319, -2.5750,\n",
      "        -2.6238, -2.6382], device='mps:0')\n",
      "mean: tensor(-2.6214, device='mps:0')\n",
      "iter_dt 1.10s; iter 86: train loss 0.50598 temperature: 9.300000000000008\n",
      "mean_logits tensor([-2.3967, -2.6614, -2.7023, -2.4935, -2.4702, -2.5005, -2.3935, -2.7237,\n",
      "        -2.4636, -2.6421, -2.6815, -2.8481, -2.6586, -2.6654, -2.7831, -2.6497,\n",
      "        -2.6492, -2.7229, -2.7779, -2.4987, -2.4033, -2.5203, -2.6973, -2.6268,\n",
      "        -2.4473, -2.5734, -2.4494, -2.6438, -2.5368, -2.5144, -2.6325, -2.6466,\n",
      "        -2.8668, -2.3391, -2.6507, -2.7623, -2.4475, -2.3608, -2.4186, -2.6421,\n",
      "        -2.5638, -2.4678, -2.7081, -2.8300, -2.6728, -2.3475, -2.5099, -2.6222,\n",
      "        -2.3321, -2.4885], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6353, -2.6176, -2.6352, -2.6378, -2.6366, -2.6354, -2.6358, -2.6339,\n",
      "        -2.5619, -2.5640, -2.6373, -2.5694, -2.5495, -2.5816, -2.6305, -2.6373,\n",
      "        -2.6288, -2.6346, -2.6369, -2.5787, -2.6268, -2.6306, -2.6363, -2.6106,\n",
      "        -2.6275, -2.6284, -2.6130, -2.6161, -2.6088, -2.6372, -2.6372, -2.6267,\n",
      "        -2.6260, -2.6017, -2.6375, -2.6376, -2.6129, -2.6364, -2.6353, -2.6274,\n",
      "        -2.6219, -2.6167, -2.6365, -2.6376, -2.6327, -2.6353, -2.6032, -2.6340,\n",
      "        -2.6206, -2.6371], device='mps:0')\n",
      "mean: tensor(-2.6214, device='mps:0')\n",
      "iter_dt 1.09s; iter 87: train loss 0.69827 temperature: 9.350000000000009\n",
      "mean_logits tensor([-2.4792, -2.7753, -2.7972, -2.5622, -2.4319, -2.7425, -2.4356, -3.0617,\n",
      "        -2.5653, -2.4378, -2.7005, -2.5172, -2.6570, -2.6067, -2.3064, -2.3689,\n",
      "        -2.7794, -2.6740, -2.4578, -2.5807, -2.5019, -2.7230, -2.5830, -2.6939,\n",
      "        -2.4925, -2.7329, -2.7723, -2.3412, -2.3792, -2.6115, -2.7643, -2.7783,\n",
      "        -2.6041, -2.7075, -2.5372, -2.6208, -2.4621, -2.4616, -2.4792, -2.2919,\n",
      "        -2.6881, -2.2020, -2.6184, -2.7877, -2.5962, -2.5193, -2.8854, -2.4553,\n",
      "        -2.4516, -2.6987], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6375, -2.6351, -2.6357, -2.6167, -2.6344, -2.6362, -2.6373, -2.6381,\n",
      "        -2.6350, -2.5966, -2.5745, -2.5646, -2.6102, -2.6363, -2.5842, -2.6375,\n",
      "        -2.6369, -2.6394, -2.6120, -2.6330, -2.6240, -2.6347, -2.5787, -2.5808,\n",
      "        -2.6351, -2.6278, -2.6375, -2.6237, -2.6395, -2.6275, -2.6315, -2.6354,\n",
      "        -2.6369, -2.6201, -2.6262, -2.6145, -2.6211, -2.6351, -2.6172, -2.6194,\n",
      "        -2.6213, -2.6189, -2.6224, -2.6325, -2.6239, -2.6074, -2.6318, -2.6279,\n",
      "        -2.6377, -2.6390], device='mps:0')\n",
      "mean: tensor(-2.6232, device='mps:0')\n",
      "iter_dt 1.09s; iter 88: train loss 0.49307 temperature: 9.40000000000001\n",
      "mean_logits tensor([-2.5007, -2.5403, -2.6419, -2.4229, -2.6409, -2.3936, -2.3857, -2.6270,\n",
      "        -2.4796, -2.6022, -2.5788, -2.8119, -2.4173, -2.4109, -2.4589, -2.5426,\n",
      "        -2.6296, -2.3579, -2.5271, -2.3101, -2.8163, -2.3825, -2.4723, -2.5694,\n",
      "        -2.6671, -2.5251, -2.6898, -2.5602, -2.6649, -2.7075, -2.4195, -2.6050,\n",
      "        -2.5658, -2.5212, -2.5694, -2.7238, -2.6548, -2.5330, -2.7664, -2.5144,\n",
      "        -2.4436, -2.5787, -2.3863, -2.5212, -2.1563, -2.7237, -2.5494, -2.6982,\n",
      "        -2.4098, -2.6507], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6190, -2.6343, -2.6374, -2.6170, -2.6254, -2.6208, -2.6367, -2.6268,\n",
      "        -2.6272, -2.6344, -2.5572, -2.6364, -2.5656, -2.6037, -2.5998, -2.6377,\n",
      "        -2.6374, -2.6377, -2.6251, -2.6275, -2.6118, -2.6363, -2.6228, -2.6350,\n",
      "        -2.6279, -2.5952, -2.6372, -2.6125, -2.5311, -2.6029, -2.5643, -2.6376,\n",
      "        -2.6179, -2.6360, -2.6304, -2.6357, -2.6367, -2.6367, -2.6373, -2.5741,\n",
      "        -2.6375, -2.6207, -2.6139, -2.6270, -2.6283, -2.5932, -2.6347, -2.6373,\n",
      "        -2.6357, -2.6370], device='mps:0')\n",
      "mean: tensor(-2.6198, device='mps:0')\n",
      "iter_dt 1.10s; iter 89: train loss 0.71665 temperature: 9.45000000000001\n",
      "mean_logits tensor([-2.5978, -2.8353, -2.3062, -2.6480, -2.5516, -2.4817, -2.5418, -3.0165,\n",
      "        -2.4226, -2.6180, -2.5344, -2.7979, -2.6331, -2.7284, -2.7139, -2.8068,\n",
      "        -2.5692, -2.2252, -2.9086, -2.6714, -2.4195, -2.4632, -2.7542, -2.4542,\n",
      "        -2.3545, -2.4502, -2.3483, -2.7569, -2.7663, -2.5298, -2.4527, -2.3506,\n",
      "        -2.4073, -2.5351, -2.7171, -2.2965, -2.4828, -2.6764, -2.6158, -2.6269,\n",
      "        -2.5425, -2.4328, -2.6989, -2.5693, -2.6553, -2.5686, -2.7778, -2.3572,\n",
      "        -2.4064, -2.4940], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6373, -2.6398, -2.5817, -2.6372, -2.6190, -2.5860, -2.6257, -2.6372,\n",
      "        -2.6335, -2.6262, -2.6340, -2.6177, -2.6201, -2.6324, -2.5767, -2.5809,\n",
      "        -2.6370, -2.5868, -2.6363, -2.6219, -2.5462, -2.6221, -2.6365, -2.6269,\n",
      "        -2.6263, -2.6363, -2.6253, -2.6375, -2.6168, -2.6190, -2.5680, -2.6083,\n",
      "        -2.6295, -2.6198, -2.6202, -2.6284, -2.6348, -2.6360, -2.6300, -2.6364,\n",
      "        -2.6351, -2.6136, -2.5912, -2.6355, -2.5536, -2.6069, -2.6338, -2.6353,\n",
      "        -2.6329, -2.5742], device='mps:0')\n",
      "mean: tensor(-2.6177, device='mps:0')\n",
      "iter_dt 1.14s; iter 90: train loss 0.54583 temperature: 9.50000000000001\n",
      "mean_logits tensor([-2.5414, -2.5986, -2.3369, -2.8108, -2.8513, -2.4436, -2.6842, -2.6980,\n",
      "        -2.4384, -2.4519, -2.4939, -2.4988, -2.5893, -2.6949, -2.4876, -2.5566,\n",
      "        -2.6205, -2.4646, -2.6464, -2.4822, -2.4806, -2.5668, -2.5892, -2.3995,\n",
      "        -2.9031, -2.5631, -2.4387, -2.5637, -2.4089, -2.4098, -2.9249, -2.4344,\n",
      "        -2.5656, -2.7601, -2.6664, -2.7094, -2.4252, -2.5787, -2.5908, -2.3273,\n",
      "        -2.4421, -2.5136, -2.4469, -2.7296, -2.4810, -2.5090, -2.6747, -2.4639,\n",
      "        -2.7017, -2.6661], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6373, -2.6436, -2.6283, -2.6361, -2.6363, -2.6199, -2.6261, -2.6374,\n",
      "        -2.5812, -2.6414, -2.6317, -2.6369, -2.6258, -2.6346, -2.6371, -2.6178,\n",
      "        -2.6186, -2.5864, -2.6109, -2.6339, -2.6206, -2.6266, -2.5496, -2.6376,\n",
      "        -2.6257, -2.6348, -2.6217, -2.6368, -2.6175, -2.6370, -2.6333, -2.5808,\n",
      "        -2.5768, -2.5657, -2.6375, -2.6023, -2.6278, -2.6342, -2.6372, -2.5715,\n",
      "        -2.6348, -2.6270, -2.6154, -2.6173, -2.6267, -2.6364, -2.5721, -2.6207,\n",
      "        -2.6368, -2.5783], device='mps:0')\n",
      "mean: tensor(-2.6192, device='mps:0')\n",
      "iter_dt 1.10s; iter 91: train loss 0.60493 temperature: 9.550000000000011\n",
      "mean_logits tensor([-2.7566, -2.7187, -2.6771, -2.4841, -2.4929, -2.8693, -2.7214, -2.3857,\n",
      "        -2.4457, -2.5648, -2.6072, -2.7280, -2.4135, -2.6682, -2.5114, -2.2552,\n",
      "        -2.5325, -2.5571, -2.6652, -2.5676, -2.9107, -2.6596, -2.5698, -2.4499,\n",
      "        -2.4753, -2.5401, -2.4033, -2.4160, -2.4594, -2.7159, -2.5270, -2.7984,\n",
      "        -2.7463, -2.3970, -2.3146, -2.5230, -2.5756, -2.4637, -2.4536, -2.4240,\n",
      "        -2.4606, -2.7964, -2.6124, -2.5865, -2.5198, -2.8013, -2.2916, -2.3242,\n",
      "        -2.7180, -2.5908], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6339, -2.6331, -2.6283, -2.6074, -2.6348, -2.6281, -2.6383, -2.6325,\n",
      "        -2.6216, -2.6196, -2.6090, -2.6141, -2.6204, -2.6193, -2.6370, -2.5908,\n",
      "        -2.6351, -2.6322, -2.6346, -2.6230, -2.5979, -2.6038, -2.5251, -2.6334,\n",
      "        -2.6377, -2.6285, -2.6281, -2.6326, -2.6219, -2.6292, -2.6378, -2.5936,\n",
      "        -2.6364, -2.6317, -2.5867, -2.6195, -2.5747, -2.5640, -2.6223, -2.6288,\n",
      "        -2.5890, -2.6230, -2.6373, -2.5771, -2.6367, -2.5651, -2.5995, -2.5805,\n",
      "        -2.6376, -2.6190], device='mps:0')\n",
      "mean: tensor(-2.6158, device='mps:0')\n",
      "iter_dt 1.08s; iter 92: train loss 0.52930 temperature: 9.600000000000012\n",
      "mean_logits tensor([-2.8313, -2.4746, -2.4243, -2.4627, -2.4346, -2.5281, -2.1541, -2.7769,\n",
      "        -2.3272, -2.7069, -2.3876, -2.5096, -2.5283, -2.5681, -2.4987, -2.5254,\n",
      "        -2.5884, -2.4449, -2.6078, -2.6662, -2.5744, -2.3438, -2.7204, -2.7270,\n",
      "        -2.6823, -2.5477, -2.5591, -2.5332, -2.5323, -2.7651, -2.5550, -2.7948,\n",
      "        -2.5868, -2.5602, -2.5325, -2.5048, -2.6107, -2.1050, -2.3397, -2.6384,\n",
      "        -2.5926, -2.6404, -2.4983, -2.7116, -2.3935, -2.6414, -2.6708, -2.8129,\n",
      "        -2.6654, -2.5369], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6374, -2.5640, -2.5403, -2.6391, -2.6363, -2.6041, -2.6386, -2.6124,\n",
      "        -2.5728, -2.6275, -2.6387, -2.6356, -2.6139, -2.6348, -2.5824, -2.6371,\n",
      "        -2.6375, -2.6206, -2.6052, -2.6367, -2.5849, -2.6314, -2.6201, -2.6376,\n",
      "        -2.6213, -2.5824, -2.6369, -2.6361, -2.6373, -2.6353, -2.6225, -2.6280,\n",
      "        -2.6284, -2.6274, -2.5926, -2.6376, -2.6369, -2.6202, -2.5575, -2.6369,\n",
      "        -2.6211, -2.6202, -2.6336, -2.6386, -2.6408, -2.6228, -2.5754, -2.5761,\n",
      "        -2.6277, -2.5918], device='mps:0')\n",
      "mean: tensor(-2.6175, device='mps:0')\n",
      "iter_dt 1.08s; iter 93: train loss 0.53838 temperature: 9.650000000000013\n",
      "mean_logits tensor([-2.4194, -2.6745, -2.5130, -2.3095, -2.5345, -2.6492, -2.6375, -2.7885,\n",
      "        -2.5232, -2.7348, -2.6876, -2.5711, -2.3499, -2.5110, -2.6993, -2.5895,\n",
      "        -2.5535, -2.5722, -2.8254, -2.1452, -2.6220, -2.4861, -2.6468, -2.5268,\n",
      "        -2.6696, -2.7525, -2.8263, -2.7094, -2.7450, -2.4098, -2.4218, -2.8421,\n",
      "        -2.6516, -2.6194, -2.4896, -2.6502, -2.7573, -2.4760, -2.4199, -2.7562,\n",
      "        -2.7389, -2.4676, -2.7757, -2.3095, -2.7064, -2.4130, -2.6417, -2.6172,\n",
      "        -2.5703, -2.3816], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6373, -2.6357, -2.6368, -2.6378, -2.6320, -2.6373, -2.6363, -2.5429,\n",
      "        -2.6350, -2.6355, -2.6268, -2.5884, -2.6334, -2.6195, -2.6138, -2.6359,\n",
      "        -2.6370, -2.6370, -2.6371, -2.6368, -2.6388, -2.6196, -2.6217, -2.6370,\n",
      "        -2.6390, -2.6304, -2.6063, -2.6179, -2.6367, -2.5923, -2.6248, -2.6381,\n",
      "        -2.6237, -2.6369, -2.5796, -2.6218, -2.6349, -2.5821, -2.6242, -2.6347,\n",
      "        -2.6057, -2.5997, -2.6171, -2.6363, -2.6281, -2.5637, -2.6360, -2.6244,\n",
      "        -2.6132, -2.5566], device='mps:0')\n",
      "mean: tensor(-2.6211, device='mps:0')\n",
      "iter_dt 1.10s; iter 94: train loss 0.54961 temperature: 9.700000000000014\n",
      "mean_logits tensor([-2.2548, -2.3949, -2.4853, -2.5156, -2.6070, -2.7574, -2.3314, -2.6566,\n",
      "        -2.6190, -2.4662, -2.4311, -2.6126, -2.3119, -2.4328, -2.6450, -2.4623,\n",
      "        -2.6710, -2.4752, -2.8344, -2.5063, -2.6257, -2.4390, -2.6106, -2.5827,\n",
      "        -2.5435, -2.2439, -2.5234, -2.7472, -2.6624, -2.6884, -2.4992, -2.6403,\n",
      "        -2.5633, -2.7474, -2.5185, -2.3533, -2.4957, -2.6980, -2.4955, -2.5601,\n",
      "        -2.6662, -2.5010, -2.8274, -2.5017, -2.8646, -2.7514, -2.7826, -2.5705,\n",
      "        -2.3341, -2.6184], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6218, -2.6062, -2.6364, -2.5490, -2.6411, -2.6049, -2.5943, -2.6359,\n",
      "        -2.6321, -2.6370, -2.6213, -2.6178, -2.6233, -2.6373, -2.6263, -2.6374,\n",
      "        -2.6277, -2.6207, -2.6198, -2.6335, -2.6291, -2.6298, -2.6371, -2.6329,\n",
      "        -2.6242, -2.6380, -2.5463, -2.6383, -2.6375, -2.6368, -2.6377, -2.6327,\n",
      "        -2.6377, -2.6347, -2.6168, -2.6097, -2.5980, -2.6149, -2.6319, -2.6163,\n",
      "        -2.6260, -2.6341, -2.6366, -2.5887, -2.6178, -2.6373, -2.6302, -2.6230,\n",
      "        -2.6357, -2.6372], device='mps:0')\n",
      "mean: tensor(-2.6234, device='mps:0')\n",
      "iter_dt 1.22s; iter 95: train loss 0.57905 temperature: 9.750000000000014\n",
      "mean_logits tensor([-2.4194, -2.5823, -2.7748, -2.6595, -2.0911, -2.5588, -2.7550, -2.3260,\n",
      "        -2.4720, -2.5312, -2.6652, -2.4818, -2.5252, -2.6722, -2.5703, -2.8465,\n",
      "        -2.4657, -2.5292, -2.4913, -2.4511, -2.6081, -2.6178, -2.7223, -2.9431,\n",
      "        -2.3510, -2.7143, -2.5332, -2.5512, -2.5614, -2.6749, -2.6860, -2.7300,\n",
      "        -2.5275, -2.6631, -2.7197, -2.5660, -2.8864, -2.4733, -2.4942, -2.5690,\n",
      "        -2.6392, -2.6612, -2.6999, -2.3601, -2.5973, -2.6157, -2.5931, -2.7901,\n",
      "        -2.7691, -2.8434], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6274, -2.6371, -2.6355, -2.6375, -2.5657, -2.6011, -2.6363, -2.6195,\n",
      "        -2.6357, -2.5627, -2.6267, -2.6170, -2.6194, -2.6320, -2.6333, -2.5634,\n",
      "        -2.6331, -2.6276, -2.6377, -2.6209, -2.6383, -2.6190, -2.6220, -2.6327,\n",
      "        -2.6324, -2.5819, -2.6378, -2.6241, -2.6127, -2.6078, -2.5965, -2.5830,\n",
      "        -2.6199, -2.6368, -2.6379, -2.6277, -2.6274, -2.5699, -2.6369, -2.6111,\n",
      "        -2.6336, -2.6364, -2.6363, -2.6381, -2.6337, -2.5849, -2.6321, -2.6164,\n",
      "        -2.5657, -2.6189], device='mps:0')\n",
      "mean: tensor(-2.6184, device='mps:0')\n",
      "iter_dt 1.09s; iter 96: train loss 0.60259 temperature: 9.800000000000015\n",
      "mean_logits tensor([-2.6752, -2.3248, -2.9158, -2.5334, -2.7340, -2.7729, -2.5074, -2.2990,\n",
      "        -2.5547, -2.5498, -2.6167, -2.4773, -2.6968, -2.6545, -2.8180, -2.6519,\n",
      "        -2.6199, -2.4427, -2.6119, -2.6297, -2.5035, -2.4586, -2.3664, -2.5234,\n",
      "        -2.7759, -2.6176, -2.5413, -2.4405, -2.2218, -2.8233, -2.5909, -2.4780,\n",
      "        -2.8075, -2.7773, -2.7061, -2.7873, -2.6217, -2.6122, -2.5624, -2.2856,\n",
      "        -2.4544, -2.7641, -2.8053, -2.5041, -2.3932, -2.4504, -2.6102, -2.3959,\n",
      "        -2.5546, -2.6475], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6220, -2.6351, -2.6344, -2.6160, -2.6347, -2.5785, -2.6362, -2.6113,\n",
      "        -2.6348, -2.6017, -2.6354, -2.6188, -2.6379, -2.6342, -2.6377, -2.5505,\n",
      "        -2.6226, -2.6377, -2.6240, -2.6226, -2.6310, -2.6339, -2.6355, -2.6376,\n",
      "        -2.6321, -2.5738, -2.6248, -2.5815, -2.6024, -2.6371, -2.5478, -2.6229,\n",
      "        -2.6376, -2.5775, -2.6373, -2.6371, -2.5756, -2.6362, -2.6181, -2.6372,\n",
      "        -2.5573, -2.6183, -2.6272, -2.6369, -2.6185, -2.6261, -2.6369, -2.6348,\n",
      "        -2.6288, -2.6379], device='mps:0')\n",
      "mean: tensor(-2.6193, device='mps:0')\n",
      "iter_dt 1.07s; iter 97: train loss 0.47181 temperature: 9.850000000000016\n",
      "mean_logits tensor([-2.6045, -2.8166, -2.8340, -2.6449, -2.6347, -2.5393, -2.6354, -2.4722,\n",
      "        -2.3847, -2.7806, -2.6992, -2.5384, -2.5129, -2.6514, -2.6004, -2.4745,\n",
      "        -2.4803, -2.5659, -2.6772, -2.7319, -2.6015, -2.8304, -2.4519, -2.5642,\n",
      "        -2.7599, -2.6402, -2.6222, -2.3902, -2.4624, -2.5421, -2.2376, -2.8274,\n",
      "        -2.5122, -2.6920, -2.5750, -2.5762, -2.5355, -2.4989, -2.5222, -2.6652,\n",
      "        -2.4304, -2.8878, -2.4623, -2.7065, -2.8133, -2.4554, -2.7937, -2.5737,\n",
      "        -2.6833, -2.7218], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5710, -2.6356, -2.6259, -2.6371, -2.6204, -2.6378, -2.5809, -2.6371,\n",
      "        -2.6370, -2.6239, -2.6353, -2.6311, -2.5736, -2.6304, -2.6368, -2.6268,\n",
      "        -2.6348, -2.6358, -2.6370, -2.6285, -2.6326, -2.6214, -2.6340, -2.6377,\n",
      "        -2.6333, -2.6361, -2.5787, -2.6259, -2.6168, -2.6273, -2.6223, -2.6218,\n",
      "        -2.6347, -2.6372, -2.5519, -2.6331, -2.6354, -2.6257, -2.6002, -2.6279,\n",
      "        -2.6376, -2.6368, -2.6099, -2.6273, -2.6178, -2.5791, -2.6369, -2.5822,\n",
      "        -2.6194, -2.6359], device='mps:0')\n",
      "mean: tensor(-2.6219, device='mps:0')\n",
      "iter_dt 1.06s; iter 98: train loss 0.59433 temperature: 9.900000000000016\n",
      "mean_logits tensor([-2.5380, -2.4664, -2.5441, -2.4548, -2.4074, -2.4186, -2.6243, -2.6574,\n",
      "        -2.1482, -2.4651, -2.8407, -2.5609, -2.9540, -2.6132, -2.7510, -2.7083,\n",
      "        -2.7389, -2.5131, -2.7628, -2.6932, -2.5994, -2.4738, -2.7211, -2.4651,\n",
      "        -2.4789, -2.7207, -2.6104, -2.5783, -2.6161, -2.5101, -2.3916, -2.7132,\n",
      "        -2.7356, -2.3732, -2.5480, -2.5734, -2.5787, -2.5735, -2.5304, -2.6267,\n",
      "        -2.7937, -2.3692, -2.3875, -2.8229, -2.8160, -2.5391, -2.9619, -2.6205,\n",
      "        -2.4569, -2.3793], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6319, -2.6214, -2.6375, -2.6318, -2.6364, -2.6016, -2.6380, -2.5753,\n",
      "        -2.5727, -2.5649, -2.6284, -2.6339, -2.6362, -2.6273, -2.6344, -2.6080,\n",
      "        -2.6365, -2.6045, -2.6234, -2.6341, -2.6369, -2.5582, -2.6330, -2.5599,\n",
      "        -2.6337, -2.6376, -2.5670, -2.6336, -2.6366, -2.6232, -2.5788, -2.6081,\n",
      "        -2.6126, -2.5145, -2.6346, -2.5852, -2.6366, -2.6323, -2.6371, -2.6371,\n",
      "        -2.6375, -2.6224, -2.6363, -2.6379, -2.6366, -2.6205, -2.6174, -2.6382,\n",
      "        -2.6371, -2.6251], device='mps:0')\n",
      "mean: tensor(-2.6177, device='mps:0')\n",
      "iter_dt 1.06s; iter 99: train loss 0.69090 temperature: 9.950000000000017\n",
      "mean_logits tensor([-2.8182, -2.3801, -2.6962, -2.6932, -2.4139, -2.5466, -2.7707, -2.4261,\n",
      "        -2.2355, -2.3938, -2.3812, -2.4416, -2.7639, -2.7673, -2.3861, -2.6139,\n",
      "        -2.5768, -2.5856, -2.7649, -2.7015, -2.8285, -2.4190, -2.4523, -2.6330,\n",
      "        -2.5357, -2.3425, -2.5850, -2.6355, -2.2971, -2.8293, -2.4742, -2.8664,\n",
      "        -2.7292, -2.7001, -2.4884, -2.5036, -2.7636, -2.2824, -2.7889, -2.6624,\n",
      "        -2.4782, -2.3447, -2.6183, -2.4857, -2.6346, -2.3287, -2.6179, -2.7113,\n",
      "        -2.6193, -2.5648], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6284, -2.5998, -2.6368, -2.5005, -2.6184, -2.6201, -2.6380, -2.6413,\n",
      "        -2.6213, -2.6348, -2.6378, -2.6111, -2.6351, -2.5498, -2.6217, -2.6078,\n",
      "        -2.6353, -2.6350, -2.6303, -2.6256, -2.6379, -2.6327, -2.6193, -2.6204,\n",
      "        -2.6370, -2.6219, -2.6377, -2.6143, -2.6274, -2.6340, -2.6004, -2.6118,\n",
      "        -2.6109, -2.6374, -2.6316, -2.6331, -2.6343, -2.6286, -2.6219, -2.6339,\n",
      "        -2.5308, -2.6339, -2.6339, -2.5536, -2.6316, -2.6345, -2.5513, -2.6272,\n",
      "        -2.6363, -2.6324], device='mps:0')\n",
      "mean: tensor(-2.6184, device='mps:0')\n",
      "current_prefixes: [7278 4037 5557 4534 4632 6985  380 4805 4101 4404 4883  611  346 1045\n",
      " 2273 6235 5773 2879  256  465 6084 8286  375 5500  264  814   67 8921\n",
      "   67 4136 4385 6604  200 1773 2049 8494   86 3932 2808 2015 1661 1504\n",
      " 4149 1661 3803 8007 1292 4308  319 8336]\n",
      "layer: 11 starts running\n",
      "number of parameters: 91.99M\n",
      "running on device mps\n",
      "iter_dt 0.00s; iter 0: train loss 6.57165 temperature: 5\n",
      "mean_logits tensor([-1.8623, -2.2640, -2.4134, -1.7486, -1.9186, -1.8151, -1.8525, -1.6337,\n",
      "        -1.8068, -1.7972, -1.4643, -1.7055, -1.9791, -1.4361, -1.6004, -2.1072,\n",
      "        -2.1652, -1.7600, -2.3723, -1.9873, -2.1017, -1.7587, -2.0349, -2.0050,\n",
      "        -2.1217, -2.1403, -1.8641, -2.0755, -1.9279, -1.6759, -1.8850, -1.7738,\n",
      "        -1.4130, -2.0699, -1.7800, -1.3133, -1.9424, -1.3569, -1.6660, -1.8269,\n",
      "        -1.9933, -2.1242, -2.2189, -1.8420, -1.7479, -2.3104, -2.0617, -1.9788,\n",
      "        -2.3533, -1.6231], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5964, -2.6426, -2.6453, -2.6442, -2.6407, -2.6458, -2.6326, -2.6073,\n",
      "        -2.6294, -2.6342, -2.5750, -2.5707, -2.6085, -2.5376, -2.5429, -2.6361,\n",
      "        -2.6404, -2.6444, -2.5777, -2.5685, -2.6173, -2.6297, -2.6334, -2.6447,\n",
      "        -2.5778, -2.6451, -2.6098, -2.6447, -2.6404, -2.6442, -2.6372, -2.4550,\n",
      "        -2.6441, -2.5840, -2.5858, -2.6340, -2.6474, -2.6006, -2.5050, -2.6430,\n",
      "        -2.5610, -2.6449, -2.4699, -2.6166, -2.6431, -2.6442, -2.5673, -2.5791,\n",
      "        -2.6432, -2.6407], device='mps:0')\n",
      "mean: tensor(-2.6091, device='mps:0')\n",
      "iter_dt 1695864863.28s; iter 1: train loss 5.03588 temperature: 5.05\n",
      "mean_logits tensor([-1.8929, -1.8016, -1.3867, -1.5181, -1.9248, -1.8623, -2.1665, -2.4097,\n",
      "        -1.9384, -2.0293, -2.5046, -2.2339, -2.3625, -1.9171, -1.9588, -1.8205,\n",
      "        -2.1944, -2.3136, -2.1174, -1.9063, -1.9457, -2.0460, -2.1195, -2.5075,\n",
      "        -1.9301, -2.2464, -2.2104, -2.1467, -1.8545, -1.8307, -2.1167, -2.2966,\n",
      "        -1.9637, -2.3146, -2.1201, -1.7223, -2.4653, -1.8300, -2.5565, -2.1554,\n",
      "        -1.6997, -2.0248, -2.1346, -2.0243, -1.5382, -2.2669, -1.7209, -1.7888,\n",
      "        -2.1531, -2.0027], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6456, -2.6400, -2.6452, -2.5851, -2.5640, -2.6265, -2.6447, -2.6436,\n",
      "        -2.6443, -2.6414, -2.6250, -2.6153, -2.5803, -2.5799, -2.6403, -2.5890,\n",
      "        -2.6454, -2.6278, -2.6457, -2.6336, -2.5887, -2.6313, -2.6433, -2.5978,\n",
      "        -2.6212, -2.6370, -2.5763, -2.5797, -2.6388, -2.6078, -2.6400, -2.6096,\n",
      "        -2.6180, -2.5977, -2.6279, -2.6246, -2.6166, -2.6046, -2.6043, -2.5513,\n",
      "        -2.6385, -2.5596, -2.6176, -2.5857, -2.6408, -2.6371, -2.6427, -2.5941,\n",
      "        -2.5802, -2.5764], device='mps:0')\n",
      "mean: tensor(-2.6150, device='mps:0')\n",
      "iter_dt 1.15s; iter 2: train loss 4.64660 temperature: 5.1\n",
      "mean_logits tensor([-2.0037, -2.0297, -2.2846, -2.1489, -1.9420, -2.6147, -1.5939, -2.2776,\n",
      "        -2.4640, -2.0351, -2.3211, -1.7858, -2.0182, -2.4453, -2.0041, -2.0856,\n",
      "        -1.6374, -2.5886, -1.6847, -2.1037, -2.1068, -1.8337, -1.8912, -2.2376,\n",
      "        -2.0020, -1.9404, -1.9090, -2.0443, -2.1580, -2.1817, -2.1577, -1.7363,\n",
      "        -1.9529, -2.2089, -2.5458, -2.5353, -2.1133, -2.1533, -2.1180, -1.8307,\n",
      "        -2.0980, -2.0586, -1.6321, -1.6258, -1.7558, -2.1115, -1.7250, -2.4622,\n",
      "        -1.8633, -2.4458], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6381, -2.5669, -2.5785, -2.5970, -2.6310, -2.6392, -2.6396, -2.6397,\n",
      "        -2.6000, -2.6267, -2.6227, -2.6375, -2.5840, -2.6429, -2.6199, -2.6437,\n",
      "        -2.5240, -2.6418, -2.6129, -2.6305, -2.6260, -2.6304, -2.5778, -2.6048,\n",
      "        -2.6104, -2.6383, -2.5847, -2.6289, -2.6448, -2.6465, -2.5772, -2.5960,\n",
      "        -2.5925, -2.6432, -2.6148, -2.6452, -2.6369, -2.6414, -2.6109, -2.5160,\n",
      "        -2.5739, -2.5617, -2.6282, -2.6326, -2.5923, -2.6413, -2.6436, -2.6392,\n",
      "        -2.5801, -2.6309], device='mps:0')\n",
      "mean: tensor(-2.6141, device='mps:0')\n",
      "iter_dt 1.09s; iter 3: train loss 3.20431 temperature: 5.1499999999999995\n",
      "mean_logits tensor([-2.8305, -2.2055, -2.3407, -1.3970, -2.4708, -2.6921, -2.0135, -2.5537,\n",
      "        -2.3601, -1.8520, -2.1846, -2.7305, -2.4247, -2.4230, -2.6917, -2.2460,\n",
      "        -2.3038, -2.6656, -1.5697, -1.9087, -1.9694, -1.9739, -2.5592, -2.1474,\n",
      "        -2.6367, -2.2653, -2.1356, -2.8668, -2.5936, -2.4635, -2.5471, -2.0457,\n",
      "        -2.2500, -1.8456, -2.3275, -2.2128, -2.8061, -2.3641, -2.6134, -1.6689,\n",
      "        -2.2584, -2.0144, -2.0168, -2.2716, -2.1316, -1.7882, -2.2812, -2.3596,\n",
      "        -2.2093, -2.2156], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5698, -2.6443, -2.6468, -2.6340, -2.6274, -2.6098, -2.6460, -2.5831,\n",
      "        -2.6423, -2.5836, -2.6433, -2.6353, -2.6410, -2.6041, -2.6270, -2.6530,\n",
      "        -2.6445, -2.5752, -2.6443, -2.6256, -2.5818, -2.6422, -2.6452, -2.6439,\n",
      "        -2.5795, -2.6429, -2.6402, -2.6216, -2.6274, -2.6363, -2.6316, -2.6408,\n",
      "        -2.6453, -2.6463, -2.6229, -2.6410, -2.5690, -2.6333, -2.5605, -2.6473,\n",
      "        -2.6330, -2.5958, -2.6116, -2.6454, -2.6114, -2.5974, -2.6054, -2.6121,\n",
      "        -2.6231, -2.6266], device='mps:0')\n",
      "mean: tensor(-2.6228, device='mps:0')\n",
      "iter_dt 1.09s; iter 4: train loss 2.58924 temperature: 5.199999999999999\n",
      "mean_logits tensor([-2.4302, -2.2366, -1.9222, -1.6865, -2.8304, -2.7965, -2.5593, -2.5547,\n",
      "        -2.4338, -2.2563, -2.4745, -2.4017, -2.2151, -2.5087, -2.4856, -2.3103,\n",
      "        -2.2673, -2.0543, -2.0568, -2.4219, -2.2802, -2.5915, -2.4112, -2.0780,\n",
      "        -2.3295, -2.1665, -2.6745, -2.2935, -2.1792, -2.0228, -1.9160, -2.1307,\n",
      "        -2.2479, -2.4333, -2.0819, -2.4373, -1.9300, -1.8683, -2.0749, -2.4440,\n",
      "        -2.6071, -2.8071, -2.3316, -2.2149, -2.2868, -2.0978, -2.1024, -2.0067,\n",
      "        -2.1815, -2.6769], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6452, -2.6453, -2.6277, -2.6284, -2.6446, -2.6388, -2.5980, -2.5701,\n",
      "        -2.6298, -2.6439, -2.5924, -2.6460, -2.5735, -2.6456, -2.6283, -2.5917,\n",
      "        -2.5829, -2.6300, -2.6441, -2.6434, -2.5863, -2.6339, -2.6022, -2.5996,\n",
      "        -2.6439, -2.6382, -2.6241, -2.6435, -2.6513, -2.6405, -2.5975, -2.6447,\n",
      "        -2.6405, -2.6427, -2.5854, -2.6072, -2.5176, -2.6342, -2.6451, -2.6274,\n",
      "        -2.6453, -2.6335, -2.6454, -2.6281, -2.5550, -2.6165, -2.6207, -2.6311,\n",
      "        -2.6304, -2.6232], device='mps:0')\n",
      "mean: tensor(-2.6217, device='mps:0')\n",
      "iter_dt 1.09s; iter 5: train loss 2.94128 temperature: 5.249999999999999\n",
      "mean_logits tensor([-2.3046, -2.6581, -1.9112, -2.7202, -2.3849, -2.4419, -3.2913, -2.0363,\n",
      "        -2.4835, -2.5262, -2.2928, -2.3923, -2.2990, -2.5390, -2.2960, -1.7905,\n",
      "        -2.2097, -2.5613, -2.1379, -2.3068, -2.6344, -2.3116, -2.5077, -2.3734,\n",
      "        -2.0269, -1.9542, -2.6239, -2.4005, -2.3596, -2.5142, -2.2445, -2.5837,\n",
      "        -2.0911, -2.8307, -2.8176, -2.4659, -2.5507, -1.9269, -1.7234, -2.0582,\n",
      "        -2.5552, -1.9404, -2.1722, -2.5966, -2.2064, -2.6537, -2.0683, -2.2988,\n",
      "        -3.2593, -2.2471], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6411, -2.5993, -2.5666, -2.6410, -2.6351, -2.6107, -2.6165, -2.6330,\n",
      "        -2.6445, -2.6120, -2.5717, -2.6444, -2.5731, -2.6427, -2.6429, -2.5819,\n",
      "        -2.5239, -2.5351, -2.6392, -2.6326, -2.6412, -2.6420, -2.6286, -2.6145,\n",
      "        -2.5733, -2.5013, -2.6119, -2.5967, -2.6344, -2.6108, -2.6426, -2.5807,\n",
      "        -2.6336, -2.6407, -2.6453, -2.6255, -2.6389, -2.6358, -2.6447, -2.6436,\n",
      "        -2.6267, -2.6284, -2.5743, -2.6248, -2.5247, -2.6392, -2.6393, -2.6217,\n",
      "        -2.6313, -2.6457], device='mps:0')\n",
      "mean: tensor(-2.6146, device='mps:0')\n",
      "iter_dt 1.08s; iter 6: train loss 2.52630 temperature: 5.299999999999999\n",
      "mean_logits tensor([-2.5397, -2.2029, -2.4165, -1.9606, -3.1166, -2.6375, -2.8799, -2.2670,\n",
      "        -2.3437, -2.7519, -2.7704, -2.5636, -2.9674, -3.0010, -2.3366, -2.5453,\n",
      "        -2.5149, -3.1266, -2.3425, -2.8443, -2.5128, -2.2812, -2.3934, -2.4057,\n",
      "        -2.4337, -2.4411, -2.5981, -1.9869, -2.5479, -2.1590, -2.8979, -2.1750,\n",
      "        -2.2925, -2.7676, -1.7950, -2.1134, -2.6072, -2.8308, -2.0805, -3.0855,\n",
      "        -2.3360, -2.1557, -2.7300, -2.2845, -2.1290, -2.8281, -2.7281, -1.8356,\n",
      "        -2.5753, -2.6667], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6007, -2.6111, -2.6450, -2.6203, -2.5965, -2.6407, -2.5808, -2.6057,\n",
      "        -2.6108, -2.5575, -2.6263, -2.6025, -2.6118, -2.6456, -2.6394, -2.5931,\n",
      "        -2.6450, -2.6434, -2.6453, -2.6385, -2.6313, -2.6343, -2.5932, -2.6348,\n",
      "        -2.6445, -2.5940, -2.6416, -2.6369, -2.6025, -2.5908, -2.6054, -2.6269,\n",
      "        -2.6403, -2.6404, -2.6426, -2.6424, -2.5736, -2.6411, -2.6356, -2.6113,\n",
      "        -2.6426, -2.6095, -2.6453, -2.6048, -2.5826, -2.6411, -2.6238, -2.6048,\n",
      "        -2.6366, -2.6397], device='mps:0')\n",
      "mean: tensor(-2.6211, device='mps:0')\n",
      "iter_dt 1.07s; iter 7: train loss 2.63953 temperature: 5.349999999999999\n",
      "mean_logits tensor([-2.4857, -3.2905, -2.5340, -2.3705, -2.2101, -1.9226, -2.3611, -2.4572,\n",
      "        -2.6850, -2.6696, -2.2254, -2.7771, -2.5461, -2.2265, -2.7754, -1.8997,\n",
      "        -2.2018, -3.1617, -2.4289, -2.5993, -2.3375, -2.6928, -2.5008, -2.1000,\n",
      "        -2.8390, -2.7154, -2.0747, -2.5205, -2.8285, -2.1318, -2.2619, -2.8496,\n",
      "        -2.6387, -2.6177, -2.4764, -2.4810, -2.9486, -2.5559, -2.5666, -1.7642,\n",
      "        -2.2983, -2.7582, -2.1969, -2.0827, -2.9510, -2.7477, -2.9027, -1.8837,\n",
      "        -2.6712, -3.0970], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6472, -2.6316, -2.6296, -2.6063, -2.5769, -2.6457, -2.6412, -2.6447,\n",
      "        -2.6123, -2.6459, -2.6455, -2.5730, -2.6059, -2.6446, -2.6455, -2.5710,\n",
      "        -2.5950, -2.6458, -2.6452, -2.6335, -2.5818, -2.6446, -2.5681, -2.5868,\n",
      "        -2.5866, -2.6239, -2.6376, -2.6454, -2.6314, -2.5719, -2.5820, -2.5848,\n",
      "        -2.6453, -2.6032, -2.6447, -2.5901, -2.6289, -2.5831, -2.6452, -2.6266,\n",
      "        -2.6250, -2.6395, -2.6456, -2.5297, -2.6124, -2.6089, -2.6250, -2.6360,\n",
      "        -2.6447, -2.6453], device='mps:0')\n",
      "mean: tensor(-2.6182, device='mps:0')\n",
      "iter_dt 1.06s; iter 8: train loss 4.90196 temperature: 5.399999999999999\n",
      "mean_logits tensor([-2.1879, -2.5547, -2.4189, -2.3155, -2.7739, -2.6334, -1.8403, -2.7625,\n",
      "        -2.1653, -2.6319, -2.6779, -2.3876, -3.0043, -2.3943, -2.3367, -2.2066,\n",
      "        -2.7601, -2.2498, -2.9412, -2.4624, -2.8261, -2.0582, -2.2177, -2.8215,\n",
      "        -2.7875, -2.2810, -2.1100, -3.4013, -2.6019, -1.8668, -2.9316, -2.5217,\n",
      "        -2.2675, -3.4552, -2.8057, -2.1779, -2.6980, -2.7358, -2.2021, -1.8658,\n",
      "        -2.4572, -2.6885, -3.2819, -2.6867, -2.8330, -2.8172, -2.3909, -3.5791,\n",
      "        -2.6958, -2.4536], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6451, -2.6449, -2.6347, -2.5722, -2.6261, -2.6382, -2.5580, -2.6454,\n",
      "        -2.5910, -2.5548, -2.6453, -2.5598, -2.6316, -2.5928, -2.6407, -2.6207,\n",
      "        -2.6455, -2.6275, -2.6412, -2.6249, -2.6273, -2.6441, -2.6061, -2.6454,\n",
      "        -2.6058, -2.6442, -2.4851, -2.5961, -2.6416, -2.5562, -2.6317, -2.6453,\n",
      "        -2.6075, -2.6457, -2.6444, -2.6440, -2.6447, -2.6432, -2.6306, -2.5734,\n",
      "        -2.6285, -2.6447, -2.6413, -2.6413, -2.6269, -2.6237, -2.6455, -2.6417,\n",
      "        -2.6179, -2.5904], device='mps:0')\n",
      "mean: tensor(-2.6201, device='mps:0')\n",
      "iter_dt 1.10s; iter 9: train loss 1.46777 temperature: 5.449999999999998\n",
      "mean_logits tensor([-2.6408, -2.4625, -2.5951, -2.9631, -2.6679, -2.4679, -3.0901, -2.6571,\n",
      "        -2.5659, -2.6676, -2.1897, -2.1693, -2.2482, -2.5902, -2.1712, -2.5322,\n",
      "        -2.7502, -2.7546, -2.5031, -2.7632, -2.2863, -2.8535, -3.0199, -2.5895,\n",
      "        -2.5313, -3.0423, -2.6667, -2.7543, -2.6748, -2.6392, -2.9074, -2.6269,\n",
      "        -2.6610, -2.7613, -2.3815, -2.4383, -2.4952, -2.4095, -2.1255, -1.9167,\n",
      "        -2.6895, -2.5674, -2.7470, -3.0545, -2.5683, -2.4130, -2.7525, -2.3948,\n",
      "        -2.8540, -2.6477], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6386, -2.6316, -2.5921, -2.6455, -2.6449, -2.5964, -2.6341, -2.6401,\n",
      "        -2.6453, -2.6415, -2.5793, -2.5694, -2.5722, -2.6416, -2.6408, -2.6287,\n",
      "        -2.6457, -2.6306, -2.6336, -2.6449, -2.6396, -2.6452, -2.6164, -2.6000,\n",
      "        -2.6407, -2.5723, -2.5950, -2.6382, -2.6427, -2.5855, -2.5978, -2.6416,\n",
      "        -2.6163, -2.6436, -2.5835, -2.5869, -2.6410, -2.5593, -2.5736, -2.6202,\n",
      "        -2.6454, -2.6412, -2.6182, -2.6236, -2.6305, -2.6362, -2.6411, -2.6370,\n",
      "        -2.6285, -2.6168], device='mps:0')\n",
      "mean: tensor(-2.6211, device='mps:0')\n",
      "iter_dt 1.08s; iter 10: train loss 1.73822 temperature: 5.499999999999998\n",
      "mean_logits tensor([-2.2626, -2.1179, -2.3055, -2.8166, -2.6030, -2.0899, -2.7523, -2.1301,\n",
      "        -2.2847, -2.4909, -2.2396, -2.3116, -2.4366, -2.1833, -2.5765, -2.4694,\n",
      "        -1.7719, -2.6377, -2.6851, -2.4060, -2.6899, -2.8603, -2.5400, -2.9355,\n",
      "        -2.4778, -2.8418, -2.4282, -2.5488, -1.9533, -2.7636, -2.6194, -2.7973,\n",
      "        -2.6039, -2.6162, -2.8006, -2.5110, -2.7249, -1.8304, -2.2364, -2.8066,\n",
      "        -2.9727, -2.5320, -2.4672, -2.4108, -2.3657, -2.7330, -1.4920, -2.3063,\n",
      "        -2.7756, -2.5359], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5507, -2.6203, -2.5929, -2.6457, -2.6270, -2.5660, -2.6412, -2.6253,\n",
      "        -2.6413, -2.6316, -2.6429, -2.6179, -2.6312, -2.6197, -2.6320, -2.5477,\n",
      "        -2.6036, -2.6412, -2.6453, -2.5972, -2.6357, -2.6413, -2.6454, -2.6457,\n",
      "        -2.6451, -2.6071, -2.5437, -2.6454, -2.6440, -2.6236, -2.5817, -2.5387,\n",
      "        -2.5816, -2.6457, -2.6379, -2.6448, -2.5679, -2.5767, -2.6453, -2.6455,\n",
      "        -2.6432, -2.5724, -2.6419, -2.5356, -2.5906, -2.6455, -2.6336, -2.6443,\n",
      "        -2.6014, -2.6297], device='mps:0')\n",
      "mean: tensor(-2.6160, device='mps:0')\n",
      "iter_dt 1.08s; iter 11: train loss 1.87518 temperature: 5.549999999999998\n",
      "mean_logits tensor([-1.8870, -2.3895, -2.7056, -2.9057, -2.2339, -2.7074, -2.5767, -2.3382,\n",
      "        -2.1330, -2.0440, -2.3259, -1.9332, -2.1005, -2.4657, -2.2633, -2.2353,\n",
      "        -2.2827, -2.3479, -2.5516, -2.4929, -2.8008, -2.9081, -2.5646, -2.1330,\n",
      "        -2.7625, -2.6081, -2.5419, -2.3232, -2.5465, -2.6299, -2.6209, -2.3982,\n",
      "        -2.1646, -2.5221, -2.2206, -2.4232, -2.6307, -2.4104, -2.8930, -2.3797,\n",
      "        -2.1944, -2.6502, -2.6255, -2.8168, -2.9111, -2.2144, -2.0623, -2.3384,\n",
      "        -2.5762, -2.1287], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6379, -2.6449, -2.6142, -2.5995, -2.6397, -2.6400, -2.6451, -2.6330,\n",
      "        -2.5924, -2.6390, -2.6312, -2.6354, -2.5539, -2.6446, -2.6094, -2.6412,\n",
      "        -2.6447, -2.6471, -2.6456, -2.6407, -2.5381, -2.6121, -2.6414, -2.5785,\n",
      "        -2.6418, -2.5912, -2.6453, -2.6441, -2.6440, -2.5900, -2.6074, -2.6229,\n",
      "        -2.6443, -2.6447, -2.6453, -2.6077, -2.6458, -2.5382, -2.5729, -2.6455,\n",
      "        -2.5815, -2.5842, -2.6457, -2.6033, -2.5372, -2.5708, -2.5827, -2.6260,\n",
      "        -2.6412, -2.6414], device='mps:0')\n",
      "mean: tensor(-2.6179, device='mps:0')\n",
      "iter_dt 1.07s; iter 12: train loss 2.14981 temperature: 5.599999999999998\n",
      "mean_logits tensor([-2.5282, -2.3174, -2.4653, -2.1534, -2.2399, -2.3424, -2.1179, -2.2464,\n",
      "        -1.9736, -2.0992, -2.1044, -2.3358, -2.2912, -2.6045, -2.5101, -2.7509,\n",
      "        -2.5495, -2.4399, -1.8222, -2.1961, -2.7261, -2.2163, -2.4900, -2.7549,\n",
      "        -2.5674, -1.7412, -2.7380, -2.2415, -2.4914, -2.4932, -2.4449, -2.3362,\n",
      "        -2.3178, -2.0297, -2.5081, -2.2205, -2.0281, -2.5609, -2.6557, -2.1328,\n",
      "        -2.2837, -2.2430, -1.9845, -2.8470, -1.9093, -2.7274, -2.5475, -2.6825,\n",
      "        -2.6001, -1.8938], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5948, -2.6445, -2.6317, -2.6450, -2.5898, -2.6222, -2.6451, -2.5791,\n",
      "        -2.5928, -2.5833, -2.6380, -2.6253, -2.5552, -2.6228, -2.6309, -2.6363,\n",
      "        -2.6042, -2.5841, -2.5677, -2.6438, -2.6453, -2.5886, -2.5978, -2.6166,\n",
      "        -2.6346, -2.5560, -2.6110, -2.6105, -2.6058, -2.6319, -2.6296, -2.6446,\n",
      "        -2.6413, -2.6436, -2.6268, -2.6346, -2.6045, -2.5301, -2.6364, -2.6442,\n",
      "        -2.6457, -2.6434, -2.5889, -2.6453, -2.6336, -2.5859, -2.5947, -2.6456,\n",
      "        -2.6453, -2.6455], device='mps:0')\n",
      "mean: tensor(-2.6169, device='mps:0')\n",
      "iter_dt 1.12s; iter 13: train loss 1.89954 temperature: 5.649999999999998\n",
      "mean_logits tensor([-2.4801, -2.2014, -2.3521, -2.5478, -1.8370, -2.2579, -2.7146, -2.2819,\n",
      "        -2.3230, -2.7711, -2.7730, -2.4643, -2.5208, -2.3540, -2.4293, -2.5923,\n",
      "        -2.3614, -2.0299, -2.7754, -2.1897, -2.0217, -2.7583, -2.1602, -2.3695,\n",
      "        -2.7597, -2.5386, -2.2964, -2.0555, -1.8952, -2.1670, -2.1507, -2.3120,\n",
      "        -2.3601, -2.5647, -2.8491, -2.2021, -2.4438, -2.2151, -2.1749, -2.7894,\n",
      "        -2.8465, -2.3229, -2.5757, -2.5578, -2.7538, -2.3797, -2.8253, -2.0464,\n",
      "        -2.4129, -2.2601], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6048, -2.6302, -2.6027, -2.6455, -2.6318, -2.6164, -2.6450, -2.6449,\n",
      "        -2.6383, -2.6129, -2.5986, -2.6333, -2.5789, -2.6445, -2.5746, -2.6071,\n",
      "        -2.5820, -2.6411, -2.6231, -2.6256, -2.6411, -2.6315, -2.6429, -2.6358,\n",
      "        -2.6453, -2.6404, -2.5941, -2.6262, -2.6067, -2.5678, -2.6128, -2.6452,\n",
      "        -2.5831, -2.5993, -2.6451, -2.6441, -2.6411, -2.6255, -2.6009, -2.6169,\n",
      "        -2.6272, -2.6358, -2.6378, -2.6430, -2.6457, -2.6371, -2.6071, -2.5895,\n",
      "        -2.6416, -2.5607], device='mps:0')\n",
      "mean: tensor(-2.6210, device='mps:0')\n",
      "iter_dt 1.07s; iter 14: train loss 2.03138 temperature: 5.6999999999999975\n",
      "mean_logits tensor([-2.5399, -2.3239, -2.3473, -2.1643, -2.9410, -2.3898, -2.5521, -2.4862,\n",
      "        -2.7638, -2.2271, -2.3891, -2.6953, -2.8084, -2.6758, -2.5604, -2.5695,\n",
      "        -2.2259, -2.0664, -2.3670, -1.9741, -2.0928, -2.3260, -2.1477, -2.1667,\n",
      "        -2.8748, -2.4562, -2.1200, -1.8780, -2.3907, -2.5591, -2.8091, -2.5232,\n",
      "        -2.3521, -2.9318, -2.5049, -2.6359, -2.1177, -2.6661, -2.2896, -2.2398,\n",
      "        -2.1010, -2.1059, -2.5705, -2.2640, -2.0650, -1.5317, -2.6359, -2.4749,\n",
      "        -2.7742, -2.9195], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6003, -2.6477, -2.6323, -2.6036, -2.6449, -2.5792, -2.6196, -2.6437,\n",
      "        -2.5962, -2.6453, -2.6429, -2.6128, -2.6458, -2.5628, -2.6459, -2.5658,\n",
      "        -2.6063, -2.6440, -2.6060, -2.6318, -2.5626, -2.5943, -2.6046, -2.5957,\n",
      "        -2.6197, -2.6449, -2.6262, -2.6370, -2.5962, -2.5883, -2.6362, -2.6235,\n",
      "        -2.5234, -2.6269, -2.6182, -2.6310, -2.6370, -2.6457, -2.5987, -2.6352,\n",
      "        -2.6330, -2.5747, -2.6317, -2.6008, -2.6017, -2.5777, -2.6130, -2.6316,\n",
      "        -2.6162, -2.6349], device='mps:0')\n",
      "mean: tensor(-2.6148, device='mps:0')\n",
      "iter_dt 1.08s; iter 15: train loss 1.90668 temperature: 5.749999999999997\n",
      "mean_logits tensor([-2.3147, -2.3054, -2.3460, -2.5771, -2.4336, -2.0503, -2.7448, -2.4784,\n",
      "        -1.9867, -2.3456, -2.0046, -2.2340, -2.3778, -2.2231, -2.6312, -2.4652,\n",
      "        -2.3656, -2.4139, -1.9621, -2.0592, -2.5763, -2.4191, -2.3350, -2.1731,\n",
      "        -2.4829, -2.7488, -2.2238, -2.5039, -2.5515, -2.3551, -2.3450, -2.5620,\n",
      "        -2.7359, -2.4566, -2.1678, -2.6049, -2.4544, -2.2558, -2.0109, -2.2671,\n",
      "        -2.2105, -2.2629, -2.6983, -2.5084, -2.0749, -2.0571, -2.4518, -2.2592,\n",
      "        -2.4124, -2.3229], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6441, -2.6023, -2.4931, -2.6399, -2.6259, -2.5839, -2.6437, -2.5705,\n",
      "        -2.6265, -2.6356, -2.6446, -2.6452, -2.6290, -2.6425, -2.6351, -2.6381,\n",
      "        -2.6449, -2.6449, -2.6269, -2.5416, -2.6186, -2.6436, -2.6367, -2.5508,\n",
      "        -2.5761, -2.5609, -2.6438, -2.6421, -2.6444, -2.6371, -2.6321, -2.6277,\n",
      "        -2.6452, -2.6233, -2.6449, -2.6446, -2.6021, -2.6305, -2.6408, -2.6445,\n",
      "        -2.6449, -2.6417, -2.5720, -2.6114, -2.6407, -2.6008, -2.6399, -2.6371,\n",
      "        -2.6460, -2.6453], device='mps:0')\n",
      "mean: tensor(-2.6226, device='mps:0')\n",
      "iter_dt 1.07s; iter 16: train loss 1.74885 temperature: 5.799999999999997\n",
      "mean_logits tensor([-2.8764, -2.3596, -2.1900, -2.6127, -2.4739, -2.1598, -2.1588, -2.6946,\n",
      "        -2.3608, -2.6413, -2.0409, -2.6341, -2.4285, -2.5744, -2.5211, -2.5232,\n",
      "        -2.7495, -1.9571, -2.2811, -2.5093, -2.0685, -2.6960, -2.2000, -2.1393,\n",
      "        -2.6159, -2.2457, -2.4804, -2.2804, -2.6247, -2.3833, -2.3470, -2.6400,\n",
      "        -2.3526, -2.2178, -2.2621, -2.6076, -2.8630, -2.8585, -2.3468, -2.1729,\n",
      "        -2.2604, -2.1698, -2.2198, -2.3285, -2.0899, -1.9439, -2.4842, -2.5737,\n",
      "        -2.3509, -2.5106], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6406, -2.6382, -2.6458, -2.6410, -2.6406, -2.6205, -2.6064, -2.6330,\n",
      "        -2.6043, -2.5783, -2.6015, -2.6453, -2.6457, -2.6453, -2.6323, -2.6162,\n",
      "        -2.6328, -2.6420, -2.5701, -2.4116, -2.5949, -2.5893, -2.5785, -2.6371,\n",
      "        -2.6349, -2.6096, -2.5626, -2.6443, -2.6226, -2.6446, -2.6386, -2.6275,\n",
      "        -2.6273, -2.6323, -2.6349, -2.6070, -2.6450, -2.5809, -2.6438, -2.6406,\n",
      "        -2.5338, -2.6210, -2.6448, -2.5941, -2.6222, -2.5969, -2.5838, -2.6349,\n",
      "        -2.6402, -2.6404], device='mps:0')\n",
      "mean: tensor(-2.6160, device='mps:0')\n",
      "iter_dt 1.06s; iter 17: train loss 2.49232 temperature: 5.849999999999997\n",
      "mean_logits tensor([-2.1679, -2.7365, -2.6887, -2.3496, -2.2261, -1.6752, -2.4724, -2.1181,\n",
      "        -2.2125, -2.3251, -2.1211, -2.6484, -2.2986, -2.4129, -1.9042, -2.3275,\n",
      "        -2.3911, -2.0023, -1.8450, -2.0285, -2.3373, -2.4490, -2.4395, -2.5251,\n",
      "        -1.9693, -1.6161, -2.4461, -2.2210, -2.1558, -1.7613, -1.8725, -2.5794,\n",
      "        -2.0010, -2.0753, -2.4601, -2.2860, -2.3553, -2.6910, -2.9284, -2.5869,\n",
      "        -2.3936, -2.3233, -2.6405, -2.6856, -2.1198, -2.3363, -2.6287, -2.3752,\n",
      "        -2.5842, -2.5778], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6442, -2.6410, -2.6242, -2.5572, -2.6283, -2.6265, -2.6420, -2.5734,\n",
      "        -2.6100, -2.5826, -2.6251, -2.6053, -2.5065, -2.6439, -2.6081, -2.5680,\n",
      "        -2.5794, -2.6451, -2.5829, -2.5995, -2.6231, -2.6225, -2.5761, -2.5838,\n",
      "        -2.5896, -2.6021, -2.6453, -2.6430, -2.6263, -2.5856, -2.6291, -2.6435,\n",
      "        -2.6279, -2.6412, -2.5894, -2.6311, -2.6457, -2.6128, -2.6277, -2.5683,\n",
      "        -2.5686, -2.5474, -2.6457, -2.5594, -2.6421, -2.6454, -2.6292, -2.6449,\n",
      "        -2.5467, -2.5872], device='mps:0')\n",
      "mean: tensor(-2.6085, device='mps:0')\n",
      "iter_dt 1.06s; iter 18: train loss 2.05264 temperature: 5.899999999999997\n",
      "mean_logits tensor([-2.5074, -2.6544, -2.5560, -1.8328, -2.0944, -2.5115, -2.4628, -2.4275,\n",
      "        -2.5692, -2.0556, -2.6212, -2.1191, -2.3981, -2.1661, -2.1677, -2.3740,\n",
      "        -2.3471, -2.0900, -2.2558, -2.1243, -2.5448, -2.7286, -2.7722, -2.7538,\n",
      "        -2.2457, -2.4423, -2.5542, -2.1893, -2.4284, -1.7824, -2.6615, -2.4821,\n",
      "        -2.1783, -1.9217, -1.8447, -2.2666, -2.3460, -2.7320, -2.6190, -2.9376,\n",
      "        -2.6806, -2.3268, -2.3121, -2.2316, -2.6181, -2.5017, -2.1963, -2.2060,\n",
      "        -2.4215, -2.4678], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6452, -2.6057, -2.6423, -2.6341, -2.6446, -2.6440, -2.6345, -2.6024,\n",
      "        -2.6453, -2.6272, -2.6333, -2.6461, -2.5756, -2.6431, -2.6412, -2.5868,\n",
      "        -2.6447, -2.6189, -2.6456, -2.6470, -2.6407, -2.6170, -2.6458, -2.6414,\n",
      "        -2.5144, -2.6409, -2.6408, -2.6454, -2.6327, -2.6307, -2.6244, -2.5490,\n",
      "        -2.6457, -2.5604, -2.6415, -2.6409, -2.5725, -2.6417, -2.6213, -2.6436,\n",
      "        -2.6176, -2.6444, -2.6299, -2.6266, -2.5857, -2.6406, -2.6432, -2.5993,\n",
      "        -2.6205, -2.6454], device='mps:0')\n",
      "mean: tensor(-2.6250, device='mps:0')\n",
      "iter_dt 1.07s; iter 19: train loss 1.78514 temperature: 5.949999999999997\n",
      "mean_logits tensor([-2.3629, -2.6030, -2.7106, -2.5738, -2.5092, -2.2837, -2.5839, -2.6292,\n",
      "        -2.5544, -2.6165, -2.4076, -2.5151, -2.0530, -2.5281, -2.3121, -2.5717,\n",
      "        -2.4895, -2.7071, -2.6444, -2.6686, -3.2279, -2.6109, -2.7990, -2.1320,\n",
      "        -2.2655, -2.1055, -2.5980, -2.6910, -2.8464, -2.5359, -1.9232, -2.0787,\n",
      "        -2.0596, -1.7372, -2.6333, -2.1006, -2.6775, -2.6850, -2.2781, -2.3896,\n",
      "        -2.1881, -2.7789, -2.5282, -1.9419, -2.3262, -2.4967, -2.2726, -2.7983,\n",
      "        -2.6750, -2.5586], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6224, -2.6346, -2.6458, -2.6031, -2.6199, -2.6198, -2.6392, -2.6406,\n",
      "        -2.6297, -2.6314, -2.6025, -2.5907, -2.5441, -2.6422, -2.6318, -2.6419,\n",
      "        -2.6347, -2.6350, -2.6125, -2.6271, -2.6456, -2.6244, -2.6101, -2.6449,\n",
      "        -2.6290, -2.6387, -2.5957, -2.6324, -2.6267, -2.6407, -2.6453, -2.5927,\n",
      "        -2.6445, -2.6250, -2.6475, -2.6444, -2.6470, -2.6273, -2.6443, -2.4925,\n",
      "        -2.5348, -2.6455, -2.5689, -2.6330, -2.6450, -2.6417, -2.5815, -2.6454,\n",
      "        -2.6377, -2.6458], device='mps:0')\n",
      "mean: tensor(-2.6225, device='mps:0')\n",
      "iter_dt 1.09s; iter 20: train loss 1.75854 temperature: 5.9999999999999964\n",
      "mean_logits tensor([-2.5543, -2.1327, -2.1820, -2.4354, -2.1638, -2.0572, -2.5895, -2.8083,\n",
      "        -2.6797, -2.6330, -2.1800, -2.8560, -2.5162, -2.6408, -2.1257, -2.5033,\n",
      "        -2.6352, -2.2975, -2.5681, -2.1128, -2.5521, -1.8041, -2.1124, -2.1653,\n",
      "        -2.6529, -2.4411, -2.0648, -2.6163, -2.7791, -2.1676, -2.5980, -2.5632,\n",
      "        -2.0569, -2.4708, -2.7610, -2.4028, -2.9211, -2.4918, -2.8812, -2.1943,\n",
      "        -2.2672, -2.7692, -2.5204, -2.4525, -2.4990, -2.4808, -2.9585, -2.6234,\n",
      "        -2.5349, -2.3755], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6433, -2.6321, -2.6227, -2.6453, -2.6453, -2.6396, -2.6355, -2.5884,\n",
      "        -2.6458, -2.6413, -2.6237, -2.6455, -2.6410, -2.6000, -2.6291, -2.6425,\n",
      "        -2.6260, -2.6044, -2.6347, -2.6432, -2.5693, -2.6439, -2.5804, -2.6457,\n",
      "        -2.5650, -2.6274, -2.6453, -2.6458, -2.6296, -2.6454, -2.6399, -2.6067,\n",
      "        -2.5872, -2.6452, -2.6477, -2.6247, -2.6014, -2.6409, -2.6465, -2.6249,\n",
      "        -2.6456, -2.5637, -2.6439, -2.6129, -2.6399, -2.6409, -2.6454, -2.6419,\n",
      "        -2.6211, -2.6262], device='mps:0')\n",
      "mean: tensor(-2.6275, device='mps:0')\n",
      "iter_dt 1.08s; iter 21: train loss 1.84542 temperature: 6.049999999999996\n",
      "mean_logits tensor([-2.3294, -2.4593, -2.3670, -2.5101, -2.9731, -1.8352, -2.4089, -1.7941,\n",
      "        -2.6014, -3.1764, -2.2720, -2.5286, -2.5264, -2.8163, -2.7098, -2.9713,\n",
      "        -2.4620, -2.1105, -2.4865, -2.6578, -2.4247, -2.4876, -2.9255, -2.1676,\n",
      "        -2.8722, -2.6522, -2.0266, -2.6196, -2.3992, -2.5801, -2.6059, -2.6639,\n",
      "        -2.5647, -2.7678, -2.8935, -2.7267, -2.3481, -2.5245, -2.1901, -2.6135,\n",
      "        -2.6705, -1.9084, -2.5146, -2.4134, -2.6396, -2.8331, -2.0766, -2.5035,\n",
      "        -2.4085, -2.8296], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6455, -2.6455, -2.6454, -2.6383, -2.6320, -2.6423, -2.5927, -2.5924,\n",
      "        -2.6449, -2.6429, -2.5989, -2.6357, -2.6355, -2.6414, -2.6456, -2.6361,\n",
      "        -2.6455, -2.6357, -2.6000, -2.6449, -2.6271, -2.6228, -2.6389, -2.6303,\n",
      "        -2.5687, -2.6059, -2.5816, -2.6456, -2.6271, -2.6447, -2.6433, -2.5771,\n",
      "        -2.5979, -2.6453, -2.6313, -2.6454, -2.6280, -2.6432, -2.5842, -2.6360,\n",
      "        -2.6457, -2.6390, -2.6365, -2.6316, -2.6303, -2.6330, -2.6036, -2.6445,\n",
      "        -2.6438, -2.6455], device='mps:0')\n",
      "mean: tensor(-2.6284, device='mps:0')\n",
      "iter_dt 1.10s; iter 22: train loss 0.88277 temperature: 6.099999999999996\n",
      "mean_logits tensor([-2.6468, -2.5561, -2.6551, -2.6273, -2.9322, -2.4958, -2.5426, -2.5741,\n",
      "        -2.5101, -2.9032, -2.6984, -2.7890, -2.4685, -2.7293, -2.6783, -2.3161,\n",
      "        -2.7439, -2.5577, -2.3412, -2.6143, -2.5246, -2.5490, -2.9529, -2.6907,\n",
      "        -2.5011, -2.4150, -2.6211, -2.8864, -2.5638, -2.6309, -2.4936, -2.4143,\n",
      "        -2.3067, -2.7017, -2.7109, -2.6256, -2.6797, -2.5996, -2.7200, -2.3679,\n",
      "        -2.8559, -2.1949, -2.8477, -2.7959, -2.9247, -2.4512, -2.6101, -2.2795,\n",
      "        -2.2817, -2.7304], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5750, -2.6454, -2.5556, -2.6407, -2.6257, -2.6453, -2.6454, -2.6174,\n",
      "        -2.6272, -2.6446, -2.6452, -2.6423, -2.5775, -2.6287, -2.5447, -2.6402,\n",
      "        -2.6375, -2.6320, -2.6460, -2.6311, -2.5829, -2.6115, -2.6395, -2.6041,\n",
      "        -2.6250, -2.6451, -2.6408, -2.6028, -2.6446, -2.6413, -2.6448, -2.6458,\n",
      "        -2.6253, -2.6408, -2.6359, -2.6451, -2.6453, -2.5780, -2.6411, -2.6413,\n",
      "        -2.5592, -2.6444, -2.6322, -2.6185, -2.6365, -2.6438, -2.6147, -2.5413,\n",
      "        -2.6417, -2.5677], device='mps:0')\n",
      "mean: tensor(-2.6226, device='mps:0')\n",
      "iter_dt 1.11s; iter 23: train loss 1.66406 temperature: 6.149999999999996\n",
      "mean_logits tensor([-2.4483, -2.6205, -2.1515, -2.7604, -2.4104, -2.6175, -2.6302, -2.3291,\n",
      "        -2.5292, -2.1482, -2.3231, -2.7438, -2.8183, -2.5933, -2.4365, -2.6954,\n",
      "        -2.3254, -2.3728, -2.4704, -2.4346, -2.7928, -2.3630, -2.8125, -2.5630,\n",
      "        -2.8332, -2.1309, -1.7004, -2.6026, -2.1534, -2.6814, -2.1434, -2.3226,\n",
      "        -2.8897, -2.2093, -2.6589, -3.0042, -2.7673, -2.8864, -2.7810, -2.4817,\n",
      "        -2.5565, -2.0041, -2.6994, -2.5743, -1.7357, -1.9156, -2.6472, -2.5263,\n",
      "        -2.6861, -2.6723], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6413, -2.6452, -2.5535, -2.6457, -2.6449, -2.6454, -2.6015, -2.6441,\n",
      "        -2.5960, -2.6443, -2.6430, -2.6346, -2.6260, -2.6409, -2.6460, -2.6358,\n",
      "        -2.5937, -2.5784, -2.6413, -2.6425, -2.6365, -2.6333, -2.6415, -2.5695,\n",
      "        -2.6049, -2.6451, -2.6181, -2.6339, -2.6051, -2.5768, -2.5790, -2.6482,\n",
      "        -2.6404, -2.6561, -2.6408, -2.6207, -2.6414, -2.6457, -2.6397, -2.6385,\n",
      "        -2.6355, -2.5896, -2.5742, -2.6307, -2.6270, -2.6463, -2.6416, -2.6305,\n",
      "        -2.6457, -2.6453], device='mps:0')\n",
      "mean: tensor(-2.6265, device='mps:0')\n",
      "iter_dt 1.11s; iter 24: train loss 1.54828 temperature: 6.199999999999996\n",
      "mean_logits tensor([-2.5558, -2.0382, -2.8174, -2.4111, -2.5242, -2.5016, -2.8034, -3.1275,\n",
      "        -2.8952, -3.1363, -2.1175, -2.4601, -2.7491, -2.6193, -2.4838, -2.6313,\n",
      "        -2.6781, -2.5492, -2.6449, -2.5894, -2.5024, -2.3801, -2.4611, -2.4645,\n",
      "        -2.8656, -3.0223, -2.5088, -2.5580, -2.1847, -2.3345, -2.5953, -2.6089,\n",
      "        -2.7672, -2.4209, -2.4537, -2.2220, -2.5232, -2.6138, -2.4047, -2.1410,\n",
      "        -2.5965, -2.1234, -2.9208, -2.5406, -2.5438, -2.5153, -2.2942, -2.8936,\n",
      "        -2.2862, -2.6929], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6258, -2.5177, -2.6458, -2.6366, -2.5808, -2.6522, -2.6265, -2.6451,\n",
      "        -2.6455, -2.6248, -2.6434, -2.6305, -2.6438, -2.6445, -2.5674, -2.5923,\n",
      "        -2.6446, -2.6377, -2.6445, -2.6341, -2.6445, -2.6350, -2.6427, -2.6415,\n",
      "        -2.6385, -2.5690, -2.6456, -2.5626, -2.6459, -2.6442, -2.6404, -2.6437,\n",
      "        -2.6275, -2.5841, -2.6453, -2.5512, -2.5438, -2.6448, -2.5995, -2.6451,\n",
      "        -2.5415, -2.5608, -2.6348, -2.5827, -2.6424, -2.6258, -2.6449, -2.6451,\n",
      "        -2.6375, -2.5903], device='mps:0')\n",
      "mean: tensor(-2.6197, device='mps:0')\n",
      "iter_dt 1.10s; iter 25: train loss 1.18617 temperature: 6.249999999999996\n",
      "mean_logits tensor([-2.9527, -2.2208, -2.7774, -2.2826, -2.3085, -2.4056, -2.5396, -2.4963,\n",
      "        -2.7286, -2.7972, -2.5866, -2.6031, -2.1997, -2.4324, -2.5058, -2.6988,\n",
      "        -2.7342, -2.4825, -2.5295, -2.7936, -2.4566, -2.3014, -2.6026, -2.9008,\n",
      "        -2.7626, -2.7114, -2.7847, -2.5294, -2.8504, -2.4377, -2.8908, -2.2757,\n",
      "        -2.9695, -2.8864, -2.7887, -2.4085, -2.5867, -2.5559, -2.8740, -2.7559,\n",
      "        -2.2328, -2.7063, -2.2808, -2.4519, -2.4755, -2.5956, -2.3373, -2.3690,\n",
      "        -2.4638, -2.4183], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6458, -2.5714, -2.6438, -2.6494, -2.6321, -2.6449, -2.6460, -2.6260,\n",
      "        -2.5438, -2.6437, -2.6358, -2.6458, -2.6337, -2.6452, -2.6244, -2.5967,\n",
      "        -2.6430, -2.6321, -2.6446, -2.6462, -2.6011, -2.6396, -2.6377, -2.6413,\n",
      "        -2.6115, -2.6443, -2.6217, -2.6457, -2.5813, -2.6404, -2.6165, -2.5956,\n",
      "        -2.6384, -2.5557, -2.5936, -2.6292, -2.6441, -2.6405, -2.6458, -2.5995,\n",
      "        -2.6273, -2.5809, -2.6413, -2.6299, -2.6403, -2.6296, -2.6407, -2.6387,\n",
      "        -2.6041, -2.6351], device='mps:0')\n",
      "mean: tensor(-2.6257, device='mps:0')\n",
      "iter_dt 1.07s; iter 26: train loss 1.46946 temperature: 6.299999999999995\n",
      "mean_logits tensor([-2.6316, -2.6011, -1.9620, -2.3054, -2.3303, -2.4586, -2.7642, -2.5485,\n",
      "        -2.0161, -2.2967, -2.5510, -2.5168, -2.8248, -2.4652, -2.8770, -2.4711,\n",
      "        -2.3755, -2.4004, -2.6446, -2.2070, -2.4075, -2.4842, -2.4845, -2.5791,\n",
      "        -2.9421, -2.8988, -2.9218, -2.3361, -2.7743, -2.4138, -2.5871, -2.4038,\n",
      "        -2.1848, -2.1838, -2.6415, -2.6652, -2.5446, -2.2778, -2.7023, -2.3555,\n",
      "        -2.4900, -2.3054, -2.6295, -2.2125, -2.3715, -2.4900, -3.0527, -2.6865,\n",
      "        -2.6688, -2.7238], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6148, -2.6404, -2.6447, -2.6434, -2.6444, -2.6381, -2.6448, -2.6354,\n",
      "        -2.5976, -2.6447, -2.6390, -2.6163, -2.6442, -2.6099, -2.6035, -2.6154,\n",
      "        -2.6431, -2.6330, -2.6410, -2.6391, -2.6434, -2.6360, -2.6417, -2.6410,\n",
      "        -2.6441, -2.5295, -2.6317, -2.6454, -2.6452, -2.6446, -2.6373, -2.6452,\n",
      "        -2.6447, -2.5963, -2.6446, -2.6253, -2.6302, -2.6361, -2.6208, -2.6458,\n",
      "        -2.6439, -2.6325, -2.6318, -2.6272, -2.6048, -2.6426, -2.6170, -2.6356,\n",
      "        -2.6431, -2.6385], device='mps:0')\n",
      "mean: tensor(-2.6316, device='mps:0')\n",
      "iter_dt 1.07s; iter 27: train loss 1.38107 temperature: 6.349999999999995\n",
      "mean_logits tensor([-2.7106, -2.7438, -2.5453, -2.7583, -2.6004, -2.8357, -2.5804, -2.3424,\n",
      "        -2.7649, -2.4609, -2.3956, -2.1445, -2.3231, -2.7565, -2.5879, -2.5147,\n",
      "        -2.5280, -2.7302, -2.9951, -2.6864, -2.4627, -2.2501, -2.5319, -2.0005,\n",
      "        -1.8936, -2.4477, -2.4649, -2.1535, -2.8192, -2.3133, -2.7280, -2.3708,\n",
      "        -2.5950, -2.4485, -2.4189, -2.6507, -2.7176, -2.1312, -2.6249, -2.3683,\n",
      "        -2.5315, -2.3642, -2.0523, -2.7797, -2.6058, -2.8039, -1.9737, -2.7567,\n",
      "        -2.3636, -2.2249], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6253, -2.6008, -2.5997, -2.6358, -2.6459, -2.6456, -2.6431, -2.6183,\n",
      "        -2.6340, -2.6427, -2.6349, -2.6437, -2.5715, -2.6351, -2.6444, -2.6435,\n",
      "        -2.6409, -2.5974, -2.6277, -2.6429, -2.5376, -2.6390, -2.6460, -2.6049,\n",
      "        -2.5998, -2.6283, -2.6427, -2.6240, -2.6455, -2.6388, -2.5920, -2.6437,\n",
      "        -2.6328, -2.5720, -2.6453, -2.5888, -2.6454, -2.6237, -2.6443, -2.6113,\n",
      "        -2.6323, -2.6012, -2.6444, -2.6438, -2.6322, -2.6442, -2.6444, -2.6419,\n",
      "        -2.5824, -2.6445], device='mps:0')\n",
      "mean: tensor(-2.6258, device='mps:0')\n",
      "iter_dt 1.08s; iter 28: train loss 1.24905 temperature: 6.399999999999995\n",
      "mean_logits tensor([-2.6807, -2.6251, -2.4712, -2.3111, -2.0913, -2.1766, -2.7811, -2.4523,\n",
      "        -2.3260, -2.4862, -2.7067, -2.4976, -2.5349, -2.5538, -2.3904, -2.4703,\n",
      "        -2.1144, -2.4774, -2.7167, -2.4834, -2.9290, -2.3992, -2.7665, -1.7752,\n",
      "        -2.2073, -2.7561, -2.2404, -2.5244, -2.3349, -2.5609, -2.5550, -2.5199,\n",
      "        -2.5233, -2.3615, -2.4522, -2.4079, -2.8178, -2.4274, -2.2547, -2.7899,\n",
      "        -2.6030, -2.6818, -2.5785, -2.4660, -2.9553, -2.2931, -2.2464, -2.9058,\n",
      "        -2.4537, -2.6281], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6400, -2.6458, -2.6123, -2.6456, -2.6446, -2.6096, -2.6434, -2.5706,\n",
      "        -2.6434, -2.6453, -2.6410, -2.5376, -2.6009, -2.6081, -2.6410, -2.6434,\n",
      "        -2.6415, -2.6442, -2.6356, -2.5565, -2.6457, -2.6391, -2.6378, -2.5637,\n",
      "        -2.6459, -2.6247, -2.6355, -2.6445, -2.5868, -2.6029, -2.6406, -2.6453,\n",
      "        -2.6224, -2.5903, -2.6052, -2.6303, -2.6457, -2.6419, -2.6450, -2.6429,\n",
      "        -2.6294, -2.6399, -2.6453, -2.6449, -2.6199, -2.6043, -2.6217, -2.6420,\n",
      "        -2.6261, -2.6354], device='mps:0')\n",
      "mean: tensor(-2.6259, device='mps:0')\n",
      "iter_dt 1.07s; iter 29: train loss 1.95510 temperature: 6.449999999999995\n",
      "mean_logits tensor([-2.0362, -2.1775, -2.2430, -2.5610, -2.6919, -2.2421, -2.4883, -2.5857,\n",
      "        -2.7443, -2.9998, -2.6520, -2.5371, -2.4743, -2.6909, -2.2394, -2.8183,\n",
      "        -2.4497, -2.6535, -2.8385, -2.5248, -2.2814, -2.4977, -2.6662, -2.4103,\n",
      "        -2.5379, -2.6993, -2.7160, -3.1727, -2.8130, -2.1654, -2.4928, -2.8481,\n",
      "        -2.8011, -2.4213, -2.4844, -2.9082, -1.9698, -1.9931, -2.8523, -2.1196,\n",
      "        -2.1521, -2.5956, -2.4714, -2.2974, -2.6657, -2.4127, -2.3078, -2.1782,\n",
      "        -2.2293, -1.6839], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6416, -2.6035, -2.6460, -2.5792, -2.6381, -2.6458, -2.6455, -2.6414,\n",
      "        -2.6400, -2.6457, -2.6459, -2.6334, -2.6455, -2.6412, -2.6433, -2.6438,\n",
      "        -2.6442, -2.6259, -2.6302, -2.6071, -2.6218, -2.6274, -2.6444, -2.6441,\n",
      "        -2.6354, -2.6027, -2.6433, -2.6457, -2.6354, -2.6242, -2.6445, -2.5646,\n",
      "        -2.6235, -2.6455, -2.6448, -2.6418, -2.6289, -2.6319, -2.6453, -2.6451,\n",
      "        -2.6445, -2.5840, -2.6434, -2.6114, -2.5709, -2.6411, -2.6377, -2.6450,\n",
      "        -2.5988, -2.5088], device='mps:0')\n",
      "mean: tensor(-2.6283, device='mps:0')\n",
      "iter_dt 1.31s; iter 30: train loss 1.22356 temperature: 6.499999999999995\n",
      "mean_logits tensor([-2.2056, -2.2091, -2.5349, -3.1233, -2.4787, -2.2144, -2.5319, -2.8033,\n",
      "        -2.2146, -2.4185, -2.5707, -2.4042, -2.0947, -2.3859, -2.4179, -2.7046,\n",
      "        -2.4897, -2.2515, -2.7399, -2.3581, -2.4845, -2.5108, -2.6956, -2.9269,\n",
      "        -2.3934, -2.3436, -2.3845, -2.1563, -2.8301, -2.4143, -2.5284, -2.6348,\n",
      "        -2.2920, -2.6290, -2.7577, -2.4561, -2.3052, -2.5811, -2.4813, -2.7299,\n",
      "        -2.5012, -2.3738, -2.7167, -2.5986, -2.4748, -2.6882, -2.3944, -2.4139,\n",
      "        -2.4166, -2.4929], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5043, -2.6455, -2.5965, -2.6334, -2.6442, -2.5875, -2.6374, -2.6061,\n",
      "        -2.6428, -2.6140, -2.6326, -2.6396, -2.6445, -2.6399, -2.5527, -2.6256,\n",
      "        -2.6297, -2.6192, -2.5771, -2.6400, -2.6087, -2.6033, -2.6330, -2.6444,\n",
      "        -2.5651, -2.6428, -2.5712, -2.6146, -2.6347, -2.6446, -2.6038, -2.6006,\n",
      "        -2.6455, -2.6043, -2.6407, -2.5977, -2.6423, -2.6355, -2.5958, -2.6412,\n",
      "        -2.6374, -2.6444, -2.6227, -2.6320, -2.6248, -2.6439, -2.6241, -2.6424,\n",
      "        -2.5846, -2.6176], device='mps:0')\n",
      "mean: tensor(-2.6191, device='mps:0')\n",
      "iter_dt 1.10s; iter 31: train loss 1.01640 temperature: 6.5499999999999945\n",
      "mean_logits tensor([-2.4212, -2.2496, -2.6851, -2.4152, -2.4347, -2.4701, -2.4233, -2.6420,\n",
      "        -2.2917, -2.1439, -2.3397, -2.6757, -2.0665, -2.4664, -2.4560, -2.5447,\n",
      "        -2.4424, -2.6192, -2.7603, -2.2861, -2.3938, -2.9003, -2.6311, -2.7313,\n",
      "        -2.3444, -2.3733, -2.0425, -2.3752, -2.2914, -2.1916, -2.6633, -2.3821,\n",
      "        -2.6175, -2.3312, -2.3476, -2.6343, -2.5336, -2.6278, -2.5293, -2.7652,\n",
      "        -2.6579, -2.6670, -2.5959, -2.5881, -2.4923, -2.4195, -2.5972, -2.5572,\n",
      "        -2.2019, -2.6240], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5942, -2.6012, -2.5915, -2.6328, -2.5499, -2.6209, -2.6323, -2.6049,\n",
      "        -2.6228, -2.6051, -2.6333, -2.6309, -2.5654, -2.6392, -2.6348, -2.5615,\n",
      "        -2.6388, -2.5534, -2.6433, -2.6389, -2.6437, -2.6386, -2.6393, -2.6364,\n",
      "        -2.5981, -2.6404, -2.6452, -2.5815, -2.6443, -2.6453, -2.6461, -2.6175,\n",
      "        -2.6329, -2.5657, -2.6465, -2.6229, -2.6288, -2.6424, -2.6454, -2.5976,\n",
      "        -2.6357, -2.5710, -2.5669, -2.6452, -2.6106, -2.6365, -2.6314, -2.6436,\n",
      "        -2.6333, -2.6389], device='mps:0')\n",
      "mean: tensor(-2.6193, device='mps:0')\n",
      "iter_dt 1.15s; iter 32: train loss 1.22762 temperature: 6.599999999999994\n",
      "mean_logits tensor([-2.0021, -2.3262, -2.3518, -2.4840, -2.3393, -2.5678, -2.3415, -2.6794,\n",
      "        -2.7048, -2.7350, -2.4895, -2.4828, -2.2811, -2.2188, -2.5611, -2.5413,\n",
      "        -2.0912, -2.4687, -2.6114, -2.6813, -2.4806, -2.5412, -2.5860, -2.4699,\n",
      "        -2.0216, -2.2472, -2.7838, -2.5297, -2.4981, -2.6223, -2.4371, -2.4618,\n",
      "        -2.2630, -2.4390, -2.1855, -2.5810, -2.3245, -2.2801, -2.4882, -2.4965,\n",
      "        -2.1010, -2.3519, -2.2995, -2.6142, -2.5854, -2.2915, -2.2183, -2.3397,\n",
      "        -2.4289, -2.3373], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5702, -2.5898, -2.6454, -2.6452, -2.6455, -2.6413, -2.6350, -2.5905,\n",
      "        -2.6456, -2.6304, -2.6457, -2.6454, -2.5608, -2.6430, -2.6457, -2.6455,\n",
      "        -2.6073, -2.5857, -2.6417, -2.6455, -2.6457, -2.6238, -2.6411, -2.6442,\n",
      "        -2.6318, -2.6450, -2.6380, -2.6360, -2.6395, -2.6402, -2.5561, -2.6449,\n",
      "        -2.6415, -2.6241, -2.6449, -2.6107, -2.6447, -2.5778, -2.6019, -2.6258,\n",
      "        -2.6199, -2.6426, -2.5804, -2.6434, -2.5998, -2.6345, -2.5034, -2.6147,\n",
      "        -2.6235, -2.6455], device='mps:0')\n",
      "mean: tensor(-2.6234, device='mps:0')\n",
      "iter_dt 1.10s; iter 33: train loss 0.97661 temperature: 6.649999999999994\n",
      "mean_logits tensor([-2.5745, -2.6189, -2.6538, -2.9786, -2.2531, -2.7891, -2.3203, -2.6896,\n",
      "        -2.5399, -2.4240, -2.0133, -2.5635, -2.4539, -2.5020, -2.5337, -2.6938,\n",
      "        -2.7784, -2.4156, -2.5108, -2.2931, -2.7713, -2.5488, -2.4595, -2.3487,\n",
      "        -2.5402, -2.4344, -2.8899, -2.5733, -2.5475, -2.5768, -2.7667, -2.2122,\n",
      "        -2.5512, -2.5655, -2.2444, -2.3359, -2.3445, -2.6419, -2.4074, -2.1415,\n",
      "        -2.1984, -2.6880, -2.5332, -2.6550, -2.5031, -2.4670, -2.5086, -2.5723,\n",
      "        -2.4755, -2.3788], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6151, -2.6455, -2.6357, -2.6442, -2.5841, -2.6436, -2.6432, -2.6449,\n",
      "        -2.6301, -2.6282, -2.6435, -2.6241, -2.5904, -2.5904, -2.5886, -2.6177,\n",
      "        -2.6086, -2.6414, -2.6433, -2.5805, -2.6240, -2.6204, -2.6455, -2.6353,\n",
      "        -2.6349, -2.6451, -2.6453, -2.6303, -2.6153, -2.6408, -2.5405, -2.5825,\n",
      "        -2.6326, -2.6374, -2.6446, -2.6285, -2.6542, -2.6452, -2.6259, -2.6298,\n",
      "        -2.6049, -2.6455, -2.6454, -2.6444, -2.6449, -2.5714, -2.6303, -2.6092,\n",
      "        -2.6404, -2.6377], device='mps:0')\n",
      "mean: tensor(-2.6255, device='mps:0')\n",
      "iter_dt 1.07s; iter 34: train loss 1.43126 temperature: 6.699999999999994\n",
      "mean_logits tensor([-2.6958, -2.1664, -2.1831, -2.6348, -2.3536, -2.7449, -2.8592, -2.5740,\n",
      "        -2.3428, -2.5275, -2.0845, -2.5144, -2.5235, -2.7866, -2.2229, -2.5292,\n",
      "        -1.8817, -2.4705, -2.5740, -2.3918, -2.4591, -2.3568, -2.3991, -2.2998,\n",
      "        -2.8564, -2.4572, -2.6154, -2.7777, -2.7317, -2.9222, -2.7450, -1.9995,\n",
      "        -2.4189, -2.2567, -2.1747, -2.4636, -2.7552, -2.5583, -2.0805, -2.4211,\n",
      "        -2.7306, -2.2694, -2.4370, -2.4479, -2.3303, -2.3929, -2.8463, -2.5742,\n",
      "        -2.6139, -2.9408], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6179, -2.6261, -2.5824, -2.5855, -2.5548, -2.6441, -2.6457, -2.6150,\n",
      "        -2.6444, -2.6121, -2.5334, -2.6303, -2.6356, -2.6109, -2.6055, -2.6384,\n",
      "        -2.6448, -2.6279, -2.6421, -2.6358, -2.6313, -2.6466, -2.6442, -2.5740,\n",
      "        -2.6252, -2.6456, -2.5879, -2.6457, -2.6444, -2.6423, -2.6448, -2.6458,\n",
      "        -2.6234, -2.6429, -2.6414, -2.6438, -2.5970, -2.5609, -2.6440, -2.6452,\n",
      "        -2.6453, -2.6344, -2.6442, -2.6285, -2.6201, -2.6224, -2.6454, -2.5806,\n",
      "        -2.6375, -2.6362], device='mps:0')\n",
      "mean: tensor(-2.6241, device='mps:0')\n",
      "iter_dt 1.06s; iter 35: train loss 0.91965 temperature: 6.749999999999994\n",
      "mean_logits tensor([-2.2804, -2.4424, -2.6046, -2.5978, -2.2619, -2.7120, -2.3524, -3.0059,\n",
      "        -2.6439, -2.3921, -2.4255, -2.2960, -2.4996, -2.6417, -2.9214, -2.8777,\n",
      "        -2.3970, -2.3866, -2.5966, -2.5732, -2.6009, -2.4660, -2.2845, -2.6600,\n",
      "        -2.6054, -2.5112, -2.2700, -2.3833, -2.3026, -2.6907, -2.3441, -2.5795,\n",
      "        -2.6271, -2.4839, -2.7820, -2.6566, -2.6114, -2.7033, -2.6096, -2.4942,\n",
      "        -2.2891, -2.8250, -2.4579, -2.4165, -2.3689, -2.5963, -2.7686, -2.6511,\n",
      "        -2.3608, -2.5183], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6436, -2.6421, -2.6454, -2.6230, -2.5818, -2.6391, -2.6405, -2.6389,\n",
      "        -2.6448, -2.6051, -2.6242, -2.6285, -2.6395, -2.6275, -2.6449, -2.6346,\n",
      "        -2.6437, -2.6456, -2.6417, -2.3899, -2.6428, -2.6349, -2.6439, -2.6049,\n",
      "        -2.6445, -2.6395, -2.6432, -2.6349, -2.6282, -2.6341, -2.6454, -2.6153,\n",
      "        -2.6330, -2.6044, -2.6197, -2.6374, -2.6448, -2.5993, -2.6018, -2.6249,\n",
      "        -2.5774, -2.5996, -2.6318, -2.6456, -2.6446, -2.6099, -2.6381, -2.6361,\n",
      "        -2.5720, -2.6365], device='mps:0')\n",
      "mean: tensor(-2.6239, device='mps:0')\n",
      "iter_dt 1.09s; iter 36: train loss 1.23257 temperature: 6.799999999999994\n",
      "mean_logits tensor([-2.2867, -2.7561, -2.3974, -2.4013, -2.4864, -2.3830, -2.6745, -2.5541,\n",
      "        -2.4735, -2.5865, -2.7350, -2.4695, -2.4443, -2.3908, -2.5914, -2.5645,\n",
      "        -2.1022, -2.5574, -2.8447, -2.4115, -2.2335, -2.1400, -2.4233, -2.4353,\n",
      "        -2.0841, -2.3375, -2.7446, -2.3661, -2.0819, -2.9939, -2.5245, -2.5592,\n",
      "        -2.4995, -2.3623, -2.5101, -2.3878, -2.3396, -2.8488, -2.8120, -2.1963,\n",
      "        -2.9730, -2.5371, -2.6691, -2.3042, -2.4987, -2.5641, -2.7004, -2.6593,\n",
      "        -2.7295, -2.4625], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6267, -2.6102, -2.6418, -2.6464, -2.6332, -2.6457, -2.6440, -2.6255,\n",
      "        -2.6283, -2.6087, -2.6443, -2.6346, -2.5542, -2.6457, -2.5922, -2.6453,\n",
      "        -2.5920, -2.5723, -2.5978, -2.6204, -2.6418, -2.6261, -2.6353, -2.6416,\n",
      "        -2.6096, -2.6432, -2.6235, -2.6446, -2.6418, -2.6452, -2.6314, -2.5272,\n",
      "        -2.6461, -2.6130, -2.6092, -2.6451, -2.5822, -2.6443, -2.6455, -2.6433,\n",
      "        -2.6440, -2.6317, -2.6384, -2.6399, -2.6368, -2.6455, -2.6409, -2.6358,\n",
      "        -2.6414, -2.6038], device='mps:0')\n",
      "mean: tensor(-2.6262, device='mps:0')\n",
      "iter_dt 1.08s; iter 37: train loss 1.04608 temperature: 6.849999999999993\n",
      "mean_logits tensor([-2.6687, -2.5523, -2.3635, -2.3621, -2.3419, -2.6852, -2.6490, -2.5749,\n",
      "        -2.0139, -2.6961, -2.6981, -2.4489, -2.2925, -2.4810, -2.6796, -2.8145,\n",
      "        -2.8531, -2.7582, -2.5084, -2.4769, -2.4998, -2.7199, -2.4302, -2.4124,\n",
      "        -1.9355, -2.5910, -2.7063, -2.8105, -2.5597, -2.4301, -2.5458, -2.6652,\n",
      "        -2.6703, -2.5133, -2.1441, -2.3871, -2.6465, -2.4057, -2.3458, -2.5483,\n",
      "        -2.2210, -2.3007, -2.2231, -2.3016, -2.4282, -2.4177, -2.7925, -2.7682,\n",
      "        -2.1819, -2.3728], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6455, -2.6440, -2.5862, -2.6449, -2.6270, -2.6225, -2.6441, -2.6083,\n",
      "        -2.6423, -2.6384, -2.6328, -2.6455, -2.6442, -2.6313, -2.6418, -2.6408,\n",
      "        -2.6396, -2.6447, -2.6438, -2.6363, -2.5947, -2.6441, -2.5920, -2.5687,\n",
      "        -2.6426, -2.6426, -2.5986, -2.6451, -2.6155, -2.5778, -2.6448, -2.6454,\n",
      "        -2.5908, -2.6444, -2.6257, -2.6433, -2.5824, -2.6420, -2.5677, -2.5989,\n",
      "        -2.6458, -2.5780, -2.6338, -2.5920, -2.6305, -2.5810, -2.5980, -2.6459,\n",
      "        -2.6056, -2.5816], device='mps:0')\n",
      "mean: tensor(-2.6221, device='mps:0')\n",
      "iter_dt 1.08s; iter 38: train loss 0.90637 temperature: 6.899999999999993\n",
      "mean_logits tensor([-2.4149, -2.5140, -2.1147, -2.4246, -2.8692, -2.3947, -2.5465, -2.2792,\n",
      "        -2.9242, -2.5782, -2.4779, -2.5890, -2.3280, -2.7960, -2.3363, -2.5507,\n",
      "        -2.5951, -2.5974, -2.6891, -2.7193, -2.6983, -2.4943, -2.2590, -2.5400,\n",
      "        -2.4482, -2.5211, -2.8511, -2.4021, -2.8493, -2.3992, -2.7777, -2.4455,\n",
      "        -2.3809, -2.5169, -2.3710, -2.5829, -2.6671, -2.3807, -2.0925, -2.5617,\n",
      "        -2.5288, -2.5374, -2.6773, -2.4104, -2.8144, -2.5694, -2.7013, -2.3020,\n",
      "        -2.3016, -2.4244], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6282, -2.5647, -2.6222, -2.5786, -2.6309, -2.6448, -2.6452, -2.6417,\n",
      "        -2.6554, -2.6418, -2.5763, -2.5998, -2.6449, -2.6451, -2.6030, -2.6281,\n",
      "        -2.6432, -2.6402, -2.6354, -2.6447, -2.6456, -2.6431, -2.5901, -2.6441,\n",
      "        -2.6408, -2.6273, -2.6457, -2.5768, -2.6271, -2.6185, -2.6286, -2.6362,\n",
      "        -2.6449, -2.5553, -2.5799, -2.6413, -2.6447, -2.6312, -2.6354, -2.6317,\n",
      "        -2.6455, -2.5955, -2.6432, -2.6265, -2.6384, -2.6456, -2.6335, -2.6453,\n",
      "        -2.6445, -2.6279], device='mps:0')\n",
      "mean: tensor(-2.6270, device='mps:0')\n",
      "iter_dt 1.07s; iter 39: train loss 0.98352 temperature: 6.949999999999993\n",
      "mean_logits tensor([-2.8133, -2.5981, -2.5060, -2.4450, -2.5662, -2.3941, -2.9556, -2.6105,\n",
      "        -2.0972, -2.6377, -2.7758, -2.6479, -2.8237, -2.7986, -2.6079, -2.7397,\n",
      "        -2.7476, -2.7700, -2.3336, -2.4912, -2.6238, -2.2997, -2.6713, -2.1468,\n",
      "        -2.4581, -2.9201, -2.2060, -2.5774, -2.6313, -2.3132, -2.8353, -2.6005,\n",
      "        -2.6710, -3.0263, -2.5020, -2.3746, -2.7004, -2.3559, -2.7399, -2.5907,\n",
      "        -2.4983, -2.5372, -2.6349, -2.5692, -2.5567, -2.3740, -2.3958, -2.6742,\n",
      "        -2.3768, -2.6673], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6430, -2.6326, -2.6217, -2.6379, -2.6367, -2.5765, -2.6023, -2.6402,\n",
      "        -2.6441, -2.6447, -2.6443, -2.6261, -2.6267, -2.6439, -2.6453, -2.6371,\n",
      "        -2.6471, -2.6224, -2.6410, -2.5831, -2.6292, -2.6451, -2.6228, -2.5973,\n",
      "        -2.6350, -2.6401, -2.6454, -2.6377, -2.5833, -2.6430, -2.6433, -2.5592,\n",
      "        -2.6251, -2.6445, -2.6485, -2.6356, -2.6442, -2.6458, -2.6328, -2.6211,\n",
      "        -2.6443, -2.6446, -2.5807, -2.5884, -2.6437, -2.6454, -2.6373, -2.6433,\n",
      "        -2.6450, -2.5879], device='mps:0')\n",
      "mean: tensor(-2.6287, device='mps:0')\n",
      "iter_dt 1.10s; iter 40: train loss 0.74867 temperature: 6.999999999999993\n",
      "mean_logits tensor([-2.3418, -2.7491, -2.2899, -2.4258, -2.6186, -2.4850, -2.2242, -2.4721,\n",
      "        -2.4198, -2.4779, -2.6892, -2.7069, -2.1575, -2.7693, -2.6084, -2.6689,\n",
      "        -2.5518, -2.4463, -2.5828, -2.4041, -2.7391, -2.6988, -2.6185, -2.2333,\n",
      "        -2.3298, -2.4492, -2.5016, -2.1914, -2.6596, -2.5398, -2.7331, -2.2894,\n",
      "        -2.3423, -2.7189, -2.6460, -2.5206, -2.4507, -2.6870, -2.7030, -2.7946,\n",
      "        -2.7737, -2.6822, -2.3463, -2.3626, -2.6394, -2.6995, -2.5709, -2.7586,\n",
      "        -2.6458, -2.6343], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6231, -2.6193, -2.6410, -2.6424, -2.6115, -2.6448, -2.6251, -2.5861,\n",
      "        -2.6273, -2.6364, -2.5674, -2.6360, -2.5594, -2.6021, -2.6440, -2.6452,\n",
      "        -2.6284, -2.6074, -2.6424, -2.6338, -2.6021, -2.6458, -2.6453, -2.6395,\n",
      "        -2.6125, -2.6410, -2.6456, -2.6440, -2.4438, -2.5504, -2.5944, -2.5534,\n",
      "        -2.6440, -2.6440, -2.6444, -2.5631, -2.6410, -2.6219, -2.6413, -2.6437,\n",
      "        -2.6431, -2.6412, -2.6413, -2.6427, -2.6446, -2.6023, -2.6186, -2.6391,\n",
      "        -2.6307, -2.6349], device='mps:0')\n",
      "mean: tensor(-2.6205, device='mps:0')\n",
      "iter_dt 1.10s; iter 41: train loss 0.92496 temperature: 7.049999999999993\n",
      "mean_logits tensor([-2.6726, -2.2803, -2.4925, -2.7643, -2.3579, -2.3496, -2.6109, -2.5080,\n",
      "        -2.7336, -2.6727, -2.6261, -2.4387, -2.8217, -2.5548, -2.2899, -2.3862,\n",
      "        -2.3216, -2.5707, -2.6235, -2.5202, -2.3862, -2.3392, -2.3596, -2.5567,\n",
      "        -2.4833, -2.8542, -2.5115, -2.6640, -2.6592, -2.6850, -2.2522, -2.4489,\n",
      "        -2.6048, -2.6327, -2.4256, -2.5505, -2.6515, -2.5550, -2.4578, -2.7249,\n",
      "        -2.4170, -2.0288, -2.7885, -2.6017, -2.8819, -2.2245, -2.4712, -2.6068,\n",
      "        -2.3548, -2.1377], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5769, -2.6275, -2.5640, -2.6289, -2.6422, -2.6283, -2.6441, -2.6440,\n",
      "        -2.6302, -2.6455, -2.5644, -2.6444, -2.6422, -2.5794, -2.6412, -2.6420,\n",
      "        -2.6452, -2.6450, -2.6045, -2.6381, -2.6449, -2.6022, -2.6441, -2.5764,\n",
      "        -2.6139, -2.6462, -2.6451, -2.6412, -2.6352, -2.6024, -2.6297, -2.6449,\n",
      "        -2.5817, -2.6443, -2.6456, -2.6455, -2.6448, -2.6438, -2.5874, -2.6453,\n",
      "        -2.6456, -2.6398, -2.6235, -2.6453, -2.6438, -2.6451, -2.5130, -2.6417,\n",
      "        -2.6438, -2.6434], device='mps:0')\n",
      "mean: tensor(-2.6266, device='mps:0')\n",
      "iter_dt 1.08s; iter 42: train loss 1.27582 temperature: 7.0999999999999925\n",
      "mean_logits tensor([-2.7644, -2.0657, -2.7932, -2.2443, -2.5396, -2.4891, -2.6672, -2.8614,\n",
      "        -2.6492, -2.5187, -2.2654, -2.0162, -2.9482, -2.3888, -2.3850, -2.3527,\n",
      "        -2.4297, -2.3519, -2.6034, -2.2286, -2.7819, -2.4400, -2.2762, -3.0802,\n",
      "        -2.9413, -2.8484, -2.6799, -2.6184, -2.6687, -2.7694, -2.6715, -2.4689,\n",
      "        -2.3635, -2.6449, -2.8504, -2.4681, -2.5106, -2.5595, -2.7364, -2.4275,\n",
      "        -2.6429, -2.7753, -2.6408, -2.5658, -2.3732, -2.5764, -2.7096, -2.8553,\n",
      "        -2.3579, -2.3478], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6444, -2.6144, -2.6355, -2.6250, -2.6401, -2.6076, -2.5835, -2.6387,\n",
      "        -2.6445, -2.5826, -2.6438, -2.6130, -2.6021, -2.6457, -2.6337, -2.6442,\n",
      "        -2.6264, -2.6353, -2.6445, -2.5569, -2.6277, -2.6174, -2.6437, -2.6032,\n",
      "        -2.6442, -2.5918, -2.6277, -2.6370, -2.5637, -2.6357, -2.6056, -2.6292,\n",
      "        -2.6379, -2.6080, -2.6443, -2.6193, -2.6290, -2.6452, -2.6077, -2.6451,\n",
      "        -2.6418, -2.6298, -2.6454, -2.6408, -2.6279, -2.6396, -2.6343, -2.6285,\n",
      "        -2.6048, -2.6447], device='mps:0')\n",
      "mean: tensor(-2.6253, device='mps:0')\n",
      "iter_dt 1.09s; iter 43: train loss 0.99311 temperature: 7.149999999999992\n",
      "mean_logits tensor([-2.4524, -2.5750, -2.4355, -2.2422, -2.8537, -2.6588, -2.7836, -2.9544,\n",
      "        -2.4965, -2.6436, -2.5617, -2.0511, -2.4098, -2.5446, -2.5076, -2.4814,\n",
      "        -2.5431, -2.5076, -2.4826, -2.3919, -2.4570, -2.5452, -2.5359, -2.6470,\n",
      "        -2.3957, -2.5649, -2.2771, -2.4066, -2.3762, -2.5535, -2.5485, -2.8233,\n",
      "        -2.2502, -2.6888, -2.6911, -2.2549, -2.5707, -2.2930, -2.7824, -2.8177,\n",
      "        -2.4646, -2.6538, -2.6653, -2.3760, -2.0511, -2.5629, -2.7930, -2.4534,\n",
      "        -2.3401, -2.7884], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6259, -2.6436, -2.6451, -2.6036, -2.6398, -2.6455, -2.5918, -2.6195,\n",
      "        -2.5730, -2.6236, -2.5844, -2.6298, -2.6453, -2.5730, -2.6357, -2.6428,\n",
      "        -2.6456, -2.6405, -2.5878, -2.5839, -2.6268, -2.6431, -2.6393, -2.6418,\n",
      "        -2.6062, -2.6459, -2.6350, -2.6257, -2.6453, -2.6096, -2.5863, -2.6448,\n",
      "        -2.6356, -2.6457, -2.6450, -2.6267, -2.6427, -2.6382, -2.6289, -2.6146,\n",
      "        -2.5812, -2.5873, -2.6327, -2.6030, -2.6395, -2.6457, -2.5843, -2.6359,\n",
      "        -2.6456, -2.5655], device='mps:0')\n",
      "mean: tensor(-2.6226, device='mps:0')\n",
      "iter_dt 1.09s; iter 44: train loss 0.96030 temperature: 7.199999999999992\n",
      "mean_logits tensor([-2.4521, -2.8281, -2.7992, -2.6345, -2.1970, -2.7078, -2.2955, -2.5659,\n",
      "        -2.4850, -2.6286, -2.8808, -2.7211, -2.8712, -2.3983, -2.5810, -2.6146,\n",
      "        -2.8227, -2.5937, -2.4052, -2.8836, -2.5467, -2.4927, -2.8263, -2.5390,\n",
      "        -2.6715, -2.5732, -2.8802, -2.8998, -2.4619, -2.6081, -2.2576, -2.8942,\n",
      "        -2.8656, -2.6222, -2.5683, -2.5988, -2.3012, -2.2579, -2.2980, -2.4901,\n",
      "        -2.3170, -2.6875, -2.2706, -2.6673, -2.4719, -2.3489, -2.7413, -2.5987,\n",
      "        -2.3283, -2.4119], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6432, -2.6320, -2.6446, -2.6391, -2.6025, -2.6233, -2.6440, -2.6444,\n",
      "        -2.6240, -2.6459, -2.6414, -2.6051, -2.6445, -2.6287, -2.6400, -2.6412,\n",
      "        -2.6238, -2.6449, -2.5962, -2.6046, -2.6230, -2.6500, -2.6387, -2.6417,\n",
      "        -2.5838, -2.6091, -2.6454, -2.6354, -2.6447, -2.5789, -2.5603, -2.6422,\n",
      "        -2.6454, -2.6125, -2.6454, -2.6456, -2.6409, -2.6278, -2.5979, -2.5925,\n",
      "        -2.6453, -2.5824, -2.6438, -2.6048, -2.6444, -2.6350, -2.6451, -2.6443,\n",
      "        -2.5729, -2.6443], device='mps:0')\n",
      "mean: tensor(-2.6267, device='mps:0')\n",
      "iter_dt 1.08s; iter 45: train loss 1.06589 temperature: 7.249999999999992\n",
      "mean_logits tensor([-2.8368, -2.7829, -2.5875, -2.8098, -2.6001, -2.6128, -2.7541, -2.4498,\n",
      "        -2.4212, -2.6583, -2.6433, -2.9980, -2.6181, -2.6686, -2.6832, -2.6989,\n",
      "        -2.6396, -2.6818, -2.3326, -2.2457, -2.4400, -2.3827, -2.8082, -2.6426,\n",
      "        -2.7252, -2.5952, -2.5708, -2.6550, -2.4214, -2.6494, -2.9775, -2.8211,\n",
      "        -2.1167, -2.7721, -2.5081, -2.5204, -2.3198, -2.7073, -2.4519, -2.5153,\n",
      "        -2.8286, -2.3534, -2.7613, -2.5413, -2.5688, -2.6316, -2.4386, -2.7343,\n",
      "        -3.1219, -2.8861], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6395, -2.6415, -2.6008, -2.5916, -2.6405, -2.6442, -2.6243, -2.6348,\n",
      "        -2.6441, -2.6424, -2.6237, -2.6453, -2.6443, -2.6419, -2.6455, -2.6054,\n",
      "        -2.5867, -2.6363, -2.6422, -2.6452, -2.6379, -2.6420, -2.6395, -2.5821,\n",
      "        -2.6391, -2.5844, -2.6267, -2.6429, -2.6434, -2.6249, -2.6307, -2.6456,\n",
      "        -2.6423, -2.6437, -2.6033, -2.6000, -2.6262, -2.6400, -2.6446, -2.6305,\n",
      "        -2.5456, -2.6430, -2.6453, -2.6403, -2.6284, -2.6449, -2.6271, -2.6436,\n",
      "        -2.6306, -2.5937], device='mps:0')\n",
      "mean: tensor(-2.6286, device='mps:0')\n",
      "iter_dt 1.11s; iter 46: train loss 1.03367 temperature: 7.299999999999992\n",
      "mean_logits tensor([-2.2846, -2.7402, -2.7030, -2.7490, -2.7038, -2.7231, -2.7846, -2.5929,\n",
      "        -2.4682, -2.2683, -2.3169, -2.6225, -2.5366, -2.7132, -2.1786, -2.6109,\n",
      "        -2.8395, -2.5968, -2.9077, -2.3051, -2.4878, -2.6862, -2.2975, -2.4430,\n",
      "        -2.7441, -2.4709, -2.8818, -2.4120, -2.7637, -2.8772, -2.4664, -2.8659,\n",
      "        -2.8741, -2.3911, -2.6076, -2.5493, -2.1926, -2.5482, -2.5880, -2.9501,\n",
      "        -2.7616, -2.6651, -2.7232, -2.8137, -2.8475, -2.6199, -2.6107, -2.2914,\n",
      "        -2.8653, -2.2105], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6363, -2.6446, -2.6124, -2.5863, -2.5981, -2.6047, -2.6405, -2.5751,\n",
      "        -2.6048, -2.6429, -2.6436, -2.6298, -2.6441, -2.6429, -2.5834, -2.5829,\n",
      "        -2.5712, -2.6337, -2.6278, -2.5960, -2.6324, -2.6059, -2.6342, -2.6351,\n",
      "        -2.6284, -2.6453, -2.6453, -2.6475, -2.6015, -2.6438, -2.5980, -2.6431,\n",
      "        -2.6354, -2.6261, -2.6152, -2.6399, -2.5800, -2.6342, -2.6428, -2.6289,\n",
      "        -2.6436, -2.6383, -2.6205, -2.6457, -2.6457, -2.6441, -2.6453, -2.6370,\n",
      "        -2.6412, -2.6312], device='mps:0')\n",
      "mean: tensor(-2.6251, device='mps:0')\n",
      "iter_dt 1.09s; iter 47: train loss 0.75230 temperature: 7.349999999999992\n",
      "mean_logits tensor([-2.4781, -2.7507, -2.5317, -2.6538, -2.5040, -2.9473, -2.8176, -2.5991,\n",
      "        -2.3986, -2.6719, -2.7188, -2.5123, -2.7026, -2.7127, -2.6075, -2.4160,\n",
      "        -2.4490, -2.5720, -2.5264, -2.2139, -2.5931, -2.7779, -2.7746, -2.7310,\n",
      "        -2.8432, -3.0397, -2.6179, -2.5189, -2.8698, -2.6652, -2.8990, -2.7419,\n",
      "        -2.7402, -2.7330, -2.7272, -2.8028, -2.5982, -2.6587, -2.7369, -2.5769,\n",
      "        -2.6414, -2.6019, -2.6315, -2.6560, -2.8214, -2.4585, -2.4344, -2.8259,\n",
      "        -2.5559, -2.5079], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6454, -2.6450, -2.6451, -2.6413, -2.6341, -2.5579, -2.6452, -2.6445,\n",
      "        -2.6452, -2.6378, -2.6138, -2.6348, -2.6432, -2.5038, -2.5890, -2.6407,\n",
      "        -2.6431, -2.6448, -2.6272, -2.6456, -2.6268, -2.6456, -2.6116, -2.6358,\n",
      "        -2.6445, -2.6351, -2.6397, -2.6065, -2.6434, -2.6449, -2.6409, -2.5850,\n",
      "        -2.6448, -2.5892, -2.6449, -2.6432, -2.6452, -2.6290, -2.5486, -2.6339,\n",
      "        -2.6456, -2.6452, -2.6457, -2.6425, -2.6358, -2.6433, -2.5231, -2.6444,\n",
      "        -2.6411, -2.6433], device='mps:0')\n",
      "mean: tensor(-2.6275, device='mps:0')\n",
      "iter_dt 1.10s; iter 48: train loss 0.79271 temperature: 7.3999999999999915\n",
      "mean_logits tensor([-2.5232, -2.2999, -2.5328, -2.3938, -2.8194, -2.2311, -2.8169, -2.7538,\n",
      "        -2.5110, -2.4884, -2.7214, -2.5246, -2.4453, -2.7362, -2.6328, -2.7560,\n",
      "        -2.7211, -2.4243, -2.5061, -2.8599, -2.4231, -2.4399, -2.9279, -2.5414,\n",
      "        -2.3734, -2.6098, -2.6935, -2.7571, -3.0540, -2.7004, -2.4836, -2.6448,\n",
      "        -2.5829, -2.3704, -2.5650, -2.6660, -2.5274, -2.8295, -2.5425, -2.7674,\n",
      "        -2.7473, -2.5192, -2.6728, -2.5471, -2.1420, -2.5517, -2.5337, -2.7758,\n",
      "        -2.6314, -2.5474], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6222, -2.5905, -2.6360, -2.6175, -2.6267, -2.6384, -2.6173, -2.6472,\n",
      "        -2.6446, -2.5991, -2.6446, -2.6189, -2.6451, -2.6454, -2.6454, -2.6449,\n",
      "        -2.6413, -2.6430, -2.6026, -2.5997, -2.5837, -2.6449, -2.6438, -2.6359,\n",
      "        -2.6409, -2.6458, -2.6432, -2.5916, -2.6448, -2.4922, -2.6231, -2.6450,\n",
      "        -2.6413, -2.5799, -2.6437, -2.6215, -2.6269, -2.6450, -2.6443, -2.6448,\n",
      "        -2.6267, -2.6453, -2.6407, -2.6264, -2.6437, -2.6294, -2.6420, -2.6458,\n",
      "        -2.6347, -2.6416], device='mps:0')\n",
      "mean: tensor(-2.6286, device='mps:0')\n",
      "iter_dt 1.08s; iter 49: train loss 1.00444 temperature: 7.449999999999991\n",
      "mean_logits tensor([-2.5511, -2.5825, -2.7904, -2.5042, -2.3753, -2.6404, -2.8835, -2.6162,\n",
      "        -2.5856, -2.6526, -2.9421, -2.4759, -2.3299, -2.6599, -2.5263, -2.5095,\n",
      "        -2.3369, -2.7470, -2.3519, -3.0082, -2.7063, -2.4789, -2.7755, -2.7043,\n",
      "        -2.0830, -2.9947, -2.6030, -2.6383, -2.4709, -2.5982, -2.5003, -2.5263,\n",
      "        -2.6523, -2.5084, -2.1301, -2.5102, -2.3791, -2.4680, -2.4056, -2.7448,\n",
      "        -2.1630, -2.8129, -2.7885, -2.5095, -2.7114, -2.5149, -2.3952, -2.1909,\n",
      "        -2.5539, -2.6657], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6455, -2.6223, -2.6282, -2.6454, -2.6058, -2.6262, -2.6456, -2.6424,\n",
      "        -2.6031, -2.6444, -2.6112, -2.6349, -2.6420, -2.6418, -2.6443, -2.6412,\n",
      "        -2.5744, -2.6443, -2.6054, -2.6457, -2.6450, -2.6448, -2.6453, -2.5761,\n",
      "        -2.6445, -2.6453, -2.6448, -2.6412, -2.6424, -2.6076, -2.5388, -2.6407,\n",
      "        -2.6425, -2.6356, -2.6240, -2.6356, -2.5681, -2.6229, -2.6340, -2.6009,\n",
      "        -2.6464, -2.6457, -2.6454, -2.6205, -2.6434, -2.6414, -2.6249, -2.6317,\n",
      "        -2.6431, -2.6301], device='mps:0')\n",
      "mean: tensor(-2.6289, device='mps:0')\n",
      "iter_dt 1.17s; iter 50: train loss 0.74225 temperature: 7.499999999999991\n",
      "mean_logits tensor([-2.4915, -2.6187, -2.4932, -2.7752, -2.7408, -2.8674, -2.8139, -2.3448,\n",
      "        -2.5447, -2.5745, -2.2506, -2.9094, -2.5576, -2.9175, -2.7204, -2.7880,\n",
      "        -2.6480, -2.5082, -2.7426, -2.4990, -2.4481, -2.6501, -2.5989, -2.5431,\n",
      "        -2.8315, -2.5874, -2.4542, -2.5526, -2.2612, -2.3708, -2.5505, -2.3021,\n",
      "        -2.7098, -2.7047, -2.9403, -2.7118, -2.6731, -2.7223, -2.6405, -2.7762,\n",
      "        -2.6182, -2.5527, -2.7237, -2.6754, -2.8934, -2.6733, -2.3089, -2.5254,\n",
      "        -2.5402, -2.8656], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6063, -2.6395, -2.6010, -2.6457, -2.6452, -2.6454, -2.5974, -2.6266,\n",
      "        -2.6454, -2.6417, -2.6447, -2.6064, -2.6422, -2.6282, -2.6454, -2.6449,\n",
      "        -2.6456, -2.6233, -2.6424, -2.6301, -2.6022, -2.6350, -2.6416, -2.6413,\n",
      "        -2.6373, -2.6336, -2.6358, -2.6421, -2.6178, -2.5596, -2.6357, -2.6406,\n",
      "        -2.6444, -2.6267, -2.6243, -2.6420, -2.6321, -2.6431, -2.6441, -2.6442,\n",
      "        -2.6363, -2.6137, -2.6267, -2.6456, -2.6356, -2.6372, -2.6434, -2.6449,\n",
      "        -2.5601, -2.6448], device='mps:0')\n",
      "mean: tensor(-2.6312, device='mps:0')\n",
      "iter_dt 1.10s; iter 51: train loss 0.82176 temperature: 7.549999999999991\n",
      "mean_logits tensor([-2.6779, -2.5772, -2.4697, -2.5296, -2.1606, -2.7751, -2.6212, -2.4540,\n",
      "        -2.3270, -2.7093, -2.5842, -2.7715, -2.6295, -2.5952, -2.7281, -2.5254,\n",
      "        -2.5403, -2.4400, -2.4546, -2.6097, -2.3759, -2.4343, -2.3076, -2.7398,\n",
      "        -2.7284, -2.2973, -2.3652, -2.9410, -2.7159, -2.8198, -2.5361, -2.8792,\n",
      "        -2.5732, -2.5235, -2.5912, -2.5286, -2.7568, -2.6558, -2.5100, -2.6465,\n",
      "        -2.5262, -2.5200, -2.6574, -2.2450, -2.6153, -2.8546, -2.1079, -2.7385,\n",
      "        -2.8924, -2.4223], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5979, -2.6012, -2.6466, -2.5838, -2.5988, -2.6158, -2.6445, -2.6416,\n",
      "        -2.6455, -2.6275, -2.6350, -2.6265, -2.6155, -2.6444, -2.6303, -2.6439,\n",
      "        -2.6450, -2.6446, -2.6404, -2.6420, -2.6344, -2.6328, -2.6355, -2.6432,\n",
      "        -2.6040, -2.6424, -2.6455, -2.6454, -2.6417, -2.6037, -2.6094, -2.6447,\n",
      "        -2.6452, -2.6304, -2.6262, -2.6452, -2.6441, -2.6457, -2.6275, -2.6426,\n",
      "        -2.6434, -2.5983, -2.6411, -2.6411, -2.5434, -2.6457, -2.6439, -2.6358,\n",
      "        -2.6346, -2.6160], device='mps:0')\n",
      "mean: tensor(-2.6301, device='mps:0')\n",
      "iter_dt 1.07s; iter 52: train loss 0.62431 temperature: 7.599999999999991\n",
      "mean_logits tensor([-2.7684, -2.6162, -2.5794, -2.3940, -2.3660, -2.6336, -2.6128, -2.5830,\n",
      "        -2.3877, -2.4049, -2.6553, -2.4741, -2.5140, -2.5719, -2.3715, -2.5314,\n",
      "        -2.5725, -2.5618, -2.7806, -2.6413, -2.6962, -2.5870, -2.6301, -2.5348,\n",
      "        -2.2146, -2.4216, -2.5375, -2.6557, -2.5560, -2.8231, -2.5412, -2.0884,\n",
      "        -2.5660, -2.7314, -2.5897, -2.5066, -2.0929, -2.5072, -2.8630, -2.6514,\n",
      "        -2.6728, -2.5577, -2.6501, -2.7394, -2.7219, -2.4530, -2.5920, -2.4668,\n",
      "        -2.4383, -2.5008], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6356, -2.6357, -2.5723, -2.6406, -2.6446, -2.6266, -2.6325, -2.6263,\n",
      "        -2.6439, -2.6450, -2.6278, -2.6453, -2.6422, -2.6429, -2.6451, -2.6317,\n",
      "        -2.6057, -2.6452, -2.6316, -2.6416, -2.6446, -2.6455, -2.6266, -2.5884,\n",
      "        -2.5718, -2.6448, -2.6401, -2.6441, -2.5905, -2.6453, -2.6447, -2.6431,\n",
      "        -2.6453, -2.6414, -2.6421, -2.6446, -2.6339, -2.5668, -2.5689, -2.6448,\n",
      "        -2.6372, -2.6363, -2.6444, -2.6446, -2.6452, -2.6452, -2.6328, -2.6168,\n",
      "        -2.6375, -2.6354], device='mps:0')\n",
      "mean: tensor(-2.6311, device='mps:0')\n",
      "iter_dt 1.09s; iter 53: train loss 0.62398 temperature: 7.649999999999991\n",
      "mean_logits tensor([-2.6139, -2.4518, -2.7898, -2.2856, -2.5841, -2.7475, -2.7268, -2.2846,\n",
      "        -2.5449, -2.5409, -2.6947, -2.7680, -2.5547, -2.2129, -2.7891, -2.3299,\n",
      "        -2.5203, -2.3700, -2.7115, -2.6280, -2.6182, -2.4525, -2.7343, -2.4335,\n",
      "        -2.6011, -2.2324, -2.6218, -2.5363, -2.6005, -2.6475, -2.4547, -2.7029,\n",
      "        -2.5058, -2.5821, -2.5807, -2.4563, -2.6664, -2.3823, -2.5647, -2.9047,\n",
      "        -2.4262, -2.7664, -2.4362, -2.3810, -2.5810, -2.6805, -2.5527, -2.7768,\n",
      "        -2.7044, -2.8863], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6447, -2.6407, -2.6414, -2.5675, -2.6303, -2.6309, -2.6442, -2.6333,\n",
      "        -2.6430, -2.6462, -2.5580, -2.6282, -2.5539, -2.6435, -2.6309, -2.5525,\n",
      "        -2.5366, -2.6381, -2.6460, -2.6245, -2.6339, -2.6162, -2.6434, -2.6448,\n",
      "        -2.6270, -2.6001, -2.6347, -2.6421, -2.6453, -2.6108, -2.5696, -2.6350,\n",
      "        -2.6298, -2.6423, -2.6397, -2.5672, -2.6457, -2.6453, -2.6047, -2.5996,\n",
      "        -2.6445, -2.6435, -2.6436, -2.6458, -2.6440, -2.6353, -2.5962, -2.6223,\n",
      "        -2.6250, -2.6428], device='mps:0')\n",
      "mean: tensor(-2.6231, device='mps:0')\n",
      "iter_dt 1.07s; iter 54: train loss 1.09413 temperature: 7.69999999999999\n",
      "mean_logits tensor([-2.0460, -2.4301, -2.2897, -2.5306, -2.9307, -2.3843, -2.7736, -2.6242,\n",
      "        -2.6810, -2.7452, -2.4747, -2.3821, -2.2423, -2.5320, -2.8304, -2.7065,\n",
      "        -2.4994, -2.4145, -2.7069, -2.5672, -2.3925, -2.1206, -2.8497, -2.7855,\n",
      "        -2.1978, -2.5426, -2.5034, -2.3760, -2.2271, -2.5254, -2.3239, -2.4172,\n",
      "        -2.3865, -2.4977, -2.6919, -2.7987, -2.3095, -2.6563, -2.8017, -2.1597,\n",
      "        -2.6768, -2.3242, -2.6423, -2.5980, -2.4010, -2.8165, -2.4192, -2.7356,\n",
      "        -2.7435, -2.7315], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6420, -2.5917, -2.6452, -2.6304, -2.6120, -2.6412, -2.6446, -2.6423,\n",
      "        -2.6321, -2.6234, -2.5914, -2.6382, -2.6175, -2.4978, -2.6385, -2.6250,\n",
      "        -2.6450, -2.6409, -2.6430, -2.5589, -2.6447, -2.6280, -2.5896, -2.6449,\n",
      "        -2.6442, -2.6266, -2.6182, -2.6447, -2.6073, -2.5801, -2.6311, -2.6456,\n",
      "        -2.5910, -2.6433, -2.6044, -2.6420, -2.6447, -2.6451, -2.6356, -2.5860,\n",
      "        -2.6256, -2.6452, -2.6190, -2.6395, -2.6228, -2.6434, -2.5975, -2.6438,\n",
      "        -2.6279, -2.6351], device='mps:0')\n",
      "mean: tensor(-2.6240, device='mps:0')\n",
      "iter_dt 1.08s; iter 55: train loss 1.08002 temperature: 7.74999999999999\n",
      "mean_logits tensor([-2.7157, -2.5000, -2.8804, -2.4004, -2.5732, -2.4926, -2.8992, -2.6661,\n",
      "        -2.8079, -2.5148, -2.5506, -2.0651, -2.7214, -2.8230, -2.6461, -2.4504,\n",
      "        -2.4220, -2.7345, -2.0849, -2.4395, -2.6845, -2.3205, -2.6998, -2.2016,\n",
      "        -2.1764, -2.3673, -2.8787, -2.8238, -2.2984, -2.8691, -2.5636, -2.4776,\n",
      "        -2.5553, -2.8657, -2.5321, -2.5800, -2.7380, -2.4996, -2.3455, -2.7582,\n",
      "        -2.6764, -2.1101, -2.3687, -2.3480, -2.6917, -2.7302, -2.5896, -2.7936,\n",
      "        -2.2413, -2.3959], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6447, -2.6206, -2.6321, -2.6448, -2.5956, -2.5583, -2.6457, -2.6400,\n",
      "        -2.6447, -2.6246, -2.6438, -2.6421, -2.6434, -2.6416, -2.6434, -2.6095,\n",
      "        -2.6442, -2.6452, -2.6054, -2.6453, -2.6451, -2.6333, -2.6447, -2.5839,\n",
      "        -2.6370, -2.5825, -2.6450, -2.6425, -2.6220, -2.6365, -2.6433, -2.6038,\n",
      "        -2.6002, -2.6454, -2.5595, -2.6188, -2.6369, -2.6455, -2.5914, -2.5967,\n",
      "        -2.5699, -2.6401, -2.6447, -2.6427, -2.6451, -2.6443, -2.6413, -2.6456,\n",
      "        -2.6433, -2.5860], device='mps:0')\n",
      "mean: tensor(-2.6266, device='mps:0')\n",
      "iter_dt 1.07s; iter 56: train loss 1.00937 temperature: 7.79999999999999\n",
      "mean_logits tensor([-2.6997, -2.5983, -2.7807, -2.5729, -2.3360, -2.3386, -2.4043, -2.6092,\n",
      "        -2.7194, -2.3820, -2.6197, -2.4779, -2.7115, -2.2747, -2.5925, -2.6421,\n",
      "        -2.3817, -2.5779, -2.3958, -2.8500, -2.4374, -2.8955, -2.7630, -2.5824,\n",
      "        -2.3459, -2.6263, -2.7036, -2.2244, -2.3191, -2.7981, -2.7676, -2.4739,\n",
      "        -2.3394, -2.6180, -2.5869, -3.0090, -2.7147, -2.6105, -2.5180, -2.3820,\n",
      "        -2.3614, -2.9222, -2.5498, -2.5695, -2.3043, -2.9164, -2.7059, -2.3234,\n",
      "        -2.9348, -2.4716], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5832, -2.6452, -2.6448, -2.6106, -2.6440, -2.6424, -2.5647, -2.6449,\n",
      "        -2.6373, -2.6188, -2.6435, -2.6449, -2.6439, -2.6046, -2.6302, -2.6049,\n",
      "        -2.6288, -2.6450, -2.6280, -2.6449, -2.6436, -2.6448, -2.6108, -2.6280,\n",
      "        -2.6447, -2.6454, -2.5917, -2.6088, -2.6348, -2.6199, -2.6055, -2.6445,\n",
      "        -2.6265, -2.6007, -2.6248, -2.6445, -2.5730, -2.6437, -2.6452, -2.6408,\n",
      "        -2.6448, -2.6420, -2.6355, -2.6297, -2.5988, -2.6281, -2.6005, -2.6290,\n",
      "        -2.6351, -2.6446], device='mps:0')\n",
      "mean: tensor(-2.6273, device='mps:0')\n",
      "iter_dt 1.06s; iter 57: train loss 0.76598 temperature: 7.84999999999999\n",
      "mean_logits tensor([-2.5915, -2.7426, -2.6398, -2.6351, -2.8025, -2.2287, -2.7378, -2.6500,\n",
      "        -2.4027, -2.6914, -2.4436, -2.4400, -2.1745, -2.4970, -2.1367, -2.7599,\n",
      "        -2.1508, -2.4358, -2.4966, -2.6505, -2.4212, -2.7435, -2.6943, -2.4179,\n",
      "        -2.7358, -2.4854, -2.4238, -2.7797, -2.3422, -2.5923, -2.6965, -2.2878,\n",
      "        -2.7243, -2.5151, -2.6578, -2.6308, -2.5191, -2.6037, -2.4689, -2.8618,\n",
      "        -2.5248, -2.4551, -2.5351, -2.7895, -2.5720, -2.6629, -2.3762, -2.3644,\n",
      "        -2.4556, -2.7709], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6255, -2.6449, -2.6444, -2.6289, -2.5496, -2.6315, -2.6342, -2.6266,\n",
      "        -2.6430, -2.6357, -2.6352, -2.6453, -2.6300, -2.5744, -2.6096, -2.6340,\n",
      "        -2.6352, -2.6262, -2.5600, -2.6004, -2.6368, -2.6410, -2.6449, -2.5965,\n",
      "        -2.6049, -2.6096, -2.6432, -2.6453, -2.6052, -2.6438, -2.6436, -2.6441,\n",
      "        -2.5636, -2.5764, -2.6451, -2.6055, -2.6414, -2.6398, -2.6263, -2.6449,\n",
      "        -2.6444, -2.6245, -2.6436, -2.6360, -2.5810, -2.6449, -2.6411, -2.6448,\n",
      "        -2.5743, -2.6405], device='mps:0')\n",
      "mean: tensor(-2.6238, device='mps:0')\n",
      "iter_dt 1.06s; iter 58: train loss 0.83352 temperature: 7.89999999999999\n",
      "mean_logits tensor([-2.6040, -2.2255, -2.7939, -2.5265, -2.7337, -2.3259, -2.4768, -2.1982,\n",
      "        -2.6832, -2.5252, -2.4757, -2.5993, -2.6683, -2.5004, -2.6255, -2.6768,\n",
      "        -2.6094, -2.4899, -2.6756, -2.6498, -2.2482, -2.6580, -2.6683, -2.6257,\n",
      "        -2.7732, -2.6949, -2.3331, -2.4892, -2.5402, -2.6181, -2.2733, -2.6431,\n",
      "        -2.6343, -2.4900, -2.5380, -2.5490, -2.5234, -2.0613, -2.2342, -2.4839,\n",
      "        -2.8244, -2.7439, -2.0174, -2.8206, -2.6964, -2.3355, -2.6033, -2.5469,\n",
      "        -2.2339, -2.4540], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6374, -2.6448, -2.6450, -2.6406, -2.6447, -2.6347, -2.6438, -2.6118,\n",
      "        -2.6394, -2.6334, -2.6362, -2.6320, -2.6439, -2.6404, -2.6158, -2.6012,\n",
      "        -2.6453, -2.6335, -2.6454, -2.5829, -2.6450, -2.6334, -2.6449, -2.6445,\n",
      "        -2.6259, -2.6427, -2.6427, -2.6350, -2.6279, -2.6353, -2.6453, -2.6458,\n",
      "        -2.6213, -2.6105, -2.6222, -2.6259, -2.6371, -2.6429, -2.5860, -2.6349,\n",
      "        -2.6447, -2.6329, -2.5546, -2.6286, -2.6316, -2.6221, -2.6356, -2.6268,\n",
      "        -2.6415, -2.6461], device='mps:0')\n",
      "mean: tensor(-2.6313, device='mps:0')\n",
      "iter_dt 1.07s; iter 59: train loss 0.73874 temperature: 7.9499999999999895\n",
      "mean_logits tensor([-2.5839, -2.7873, -2.5009, -2.8530, -2.6198, -2.6092, -2.6957, -2.6602,\n",
      "        -2.2802, -2.8375, -2.8908, -2.6119, -2.6122, -2.4636, -2.4660, -2.4474,\n",
      "        -2.3245, -2.5881, -2.7296, -2.8461, -2.4686, -2.4213, -2.5623, -2.3972,\n",
      "        -2.6639, -2.4498, -2.7959, -2.7158, -2.7845, -2.6156, -2.5302, -2.4768,\n",
      "        -2.5744, -2.8725, -2.1436, -2.8619, -2.5729, -2.5940, -2.5779, -2.3664,\n",
      "        -2.4407, -2.6856, -2.4023, -2.6106, -2.6214, -2.3854, -2.0521, -2.5291,\n",
      "        -2.5512, -2.6193], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6413, -2.6430, -2.6229, -2.6454, -2.6337, -2.6421, -2.6344, -2.6517,\n",
      "        -2.6245, -2.6339, -2.6451, -2.6291, -2.6352, -2.6350, -2.6402, -2.6423,\n",
      "        -2.6367, -2.6013, -2.6419, -2.6324, -2.6446, -2.5991, -2.6043, -2.5918,\n",
      "        -2.6424, -2.6445, -2.6453, -2.6456, -2.6442, -2.6303, -2.6309, -2.6254,\n",
      "        -2.6317, -2.6342, -2.6364, -2.6455, -2.5916, -2.6444, -2.6451, -2.5661,\n",
      "        -2.6456, -2.6240, -2.6424, -2.6393, -2.6384, -2.6331, -2.6417, -2.6158,\n",
      "        -2.6420, -2.6411], device='mps:0')\n",
      "mean: tensor(-2.6324, device='mps:0')\n",
      "iter_dt 1.08s; iter 60: train loss 0.91161 temperature: 7.999999999999989\n",
      "mean_logits tensor([-2.5226, -2.3736, -2.4980, -2.4493, -2.5139, -2.6324, -2.3673, -2.6214,\n",
      "        -2.7064, -2.3154, -2.7453, -2.5388, -2.8622, -2.5767, -2.3665, -2.5925,\n",
      "        -2.8037, -2.4210, -2.7005, -2.9261, -2.3623, -2.7350, -2.6367, -2.5263,\n",
      "        -2.7440, -2.6388, -2.5606, -2.4502, -2.9668, -2.6212, -2.8692, -2.8583,\n",
      "        -2.5520, -2.6231, -2.8539, -2.1405, -2.4509, -2.5342, -2.6950, -2.3829,\n",
      "        -2.4493, -2.7096, -2.5966, -2.3300, -2.7231, -2.2319, -2.7516, -2.9105,\n",
      "        -2.6214, -2.9252], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6454, -2.6212, -2.6439, -2.6452, -2.6440, -2.6438, -2.6174, -2.5784,\n",
      "        -2.5778, -2.6443, -2.6207, -2.6437, -2.6362, -2.6352, -2.6366, -2.6326,\n",
      "        -2.6449, -2.6416, -2.6412, -2.6357, -2.6261, -2.6445, -2.6443, -2.6440,\n",
      "        -2.6452, -2.6454, -2.6451, -2.6450, -2.6408, -2.6441, -2.6359, -2.6446,\n",
      "        -2.6446, -2.5963, -2.6382, -2.5868, -2.5965, -2.6408, -2.6408, -2.6312,\n",
      "        -2.6407, -2.6446, -2.5971, -2.6345, -2.6271, -2.6415, -2.6291, -2.6331,\n",
      "        -2.6450, -2.6447], device='mps:0')\n",
      "mean: tensor(-2.6329, device='mps:0')\n",
      "iter_dt 1.07s; iter 61: train loss 0.55831 temperature: 8.04999999999999\n",
      "mean_logits tensor([-2.4839, -2.3781, -2.5519, -2.6310, -2.6257, -2.5719, -2.4263, -2.4058,\n",
      "        -2.4713, -2.6892, -2.5086, -2.5189, -2.3879, -2.8981, -2.7138, -2.6812,\n",
      "        -3.0034, -2.5912, -2.3853, -2.5707, -2.5408, -2.5989, -2.4763, -2.4209,\n",
      "        -2.6672, -2.6070, -2.6788, -2.8753, -2.5513, -2.5187, -2.6344, -2.6451,\n",
      "        -2.5903, -2.7198, -2.6657, -2.7467, -2.6393, -2.4111, -2.6135, -2.6948,\n",
      "        -2.7050, -2.3985, -2.7636, -2.5223, -2.8556, -2.4556, -2.4168, -2.5121,\n",
      "        -2.4977, -2.6446], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6448, -2.6457, -2.6348, -2.6354, -2.6357, -2.6383, -2.6414, -2.6405,\n",
      "        -2.6408, -2.6452, -2.6448, -2.6295, -2.6154, -2.6450, -2.6390, -2.6413,\n",
      "        -2.6443, -2.6444, -2.6420, -2.6362, -2.6328, -2.5789, -2.5996, -2.5890,\n",
      "        -2.6254, -2.6319, -2.6446, -2.6454, -2.6447, -2.6413, -2.6033, -2.6451,\n",
      "        -2.6436, -2.6376, -2.5809, -2.6399, -2.6090, -2.6227, -2.6077, -2.6435,\n",
      "        -2.6292, -2.6438, -2.5794, -2.6340, -2.6441, -2.6450, -2.6348, -2.6454,\n",
      "        -2.5681, -2.6138], device='mps:0')\n",
      "mean: tensor(-2.6298, device='mps:0')\n",
      "iter_dt 1.07s; iter 62: train loss 0.77128 temperature: 8.09999999999999\n",
      "mean_logits tensor([-2.6621, -2.6063, -2.7031, -2.3933, -2.7432, -2.4492, -2.6478, -2.4282,\n",
      "        -2.7813, -2.6963, -2.5339, -2.4396, -2.7944, -2.7030, -2.3995, -2.2164,\n",
      "        -2.3307, -2.4302, -2.8053, -2.8161, -2.6103, -2.7216, -2.6087, -2.4455,\n",
      "        -2.8328, -2.6616, -2.8480, -2.7426, -2.4891, -2.5700, -2.4088, -2.2928,\n",
      "        -2.4966, -2.8305, -2.2688, -2.7085, -2.6614, -2.6113, -2.5019, -2.3545,\n",
      "        -2.8847, -2.4349, -2.6458, -2.8876, -2.5657, -2.3947, -2.4591, -2.3057,\n",
      "        -2.4159, -2.7737], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6445, -2.5780, -2.5904, -2.6345, -2.6268, -2.6283, -2.6453, -2.6336,\n",
      "        -2.6278, -2.6456, -2.6447, -2.6178, -2.6411, -2.6472, -2.6455, -2.6447,\n",
      "        -2.6446, -2.6054, -2.6444, -2.6446, -2.6150, -2.6446, -2.5867, -2.6374,\n",
      "        -2.6434, -2.6452, -2.6430, -2.6416, -2.6016, -2.6454, -2.6374, -2.5893,\n",
      "        -2.6453, -2.6331, -2.5793, -2.6399, -2.5711, -2.6449, -2.6181, -2.6451,\n",
      "        -2.6445, -2.6421, -2.5830, -2.6354, -2.5886, -2.6403, -2.6412, -2.6346,\n",
      "        -2.6300, -2.6409], device='mps:0')\n",
      "mean: tensor(-2.6285, device='mps:0')\n",
      "iter_dt 1.10s; iter 63: train loss 0.96111 temperature: 8.149999999999991\n",
      "mean_logits tensor([-2.3968, -2.6960, -2.3866, -2.0857, -2.7260, -2.5429, -2.5257, -2.6696,\n",
      "        -2.3697, -2.2960, -2.6667, -2.2269, -2.7669, -2.2791, -2.3846, -2.3946,\n",
      "        -2.3183, -2.5452, -2.1606, -2.5954, -2.5007, -2.5488, -2.9788, -2.5226,\n",
      "        -2.4022, -2.5894, -2.6065, -2.6811, -2.5252, -2.6360, -2.5329, -2.5658,\n",
      "        -2.7437, -2.5266, -2.5767, -2.9238, -2.3734, -2.6825, -2.2738, -2.5943,\n",
      "        -2.7664, -2.5451, -2.3915, -2.7236, -2.3902, -2.7679, -2.3374, -2.7437,\n",
      "        -2.7789, -2.7471], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6128, -2.6431, -2.5480, -2.6453, -2.6410, -2.6447, -2.6451, -2.6425,\n",
      "        -2.6405, -2.6362, -2.6398, -2.6000, -2.6305, -2.5918, -2.6375, -2.6423,\n",
      "        -2.6453, -2.6338, -2.6442, -2.6422, -2.6432, -2.5844, -2.5748, -2.5772,\n",
      "        -2.6390, -2.6452, -2.6189, -2.6111, -2.6425, -2.6436, -2.6429, -2.6147,\n",
      "        -2.6454, -2.6324, -2.6265, -2.6296, -2.5568, -2.6349, -2.6247, -2.6413,\n",
      "        -2.6404, -2.6398, -2.6449, -2.6452, -2.6406, -2.6447, -2.6454, -2.6339,\n",
      "        -2.5755, -2.5535], device='mps:0')\n",
      "mean: tensor(-2.6260, device='mps:0')\n",
      "iter_dt 1.10s; iter 64: train loss 0.75187 temperature: 8.199999999999992\n",
      "mean_logits tensor([-2.3276, -2.2657, -2.5175, -2.4855, -2.7154, -2.1537, -2.5218, -2.7028,\n",
      "        -2.8882, -2.5307, -2.7756, -2.6583, -2.3118, -2.3315, -2.5181, -2.3022,\n",
      "        -2.4839, -2.4499, -2.6548, -2.4873, -2.4010, -2.6210, -2.7715, -2.8354,\n",
      "        -2.6268, -2.3555, -2.6504, -2.3353, -2.5762, -2.7169, -2.5070, -2.5842,\n",
      "        -2.6285, -2.6358, -2.4294, -2.5700, -2.6442, -2.5693, -2.4140, -2.6909,\n",
      "        -2.8322, -2.6578, -2.8044, -2.7633, -2.5285, -2.8441, -2.7287, -2.7446,\n",
      "        -2.1942, -2.3561], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6201, -2.6464, -2.6199, -2.6450, -2.5988, -2.6390, -2.6225, -2.6316,\n",
      "        -2.6414, -2.6396, -2.6257, -2.6396, -2.6052, -2.6452, -2.6447, -2.5785,\n",
      "        -2.6405, -2.6411, -2.5748, -2.5273, -2.6460, -2.6437, -2.6334, -2.6111,\n",
      "        -2.6019, -2.6353, -2.6445, -2.6250, -2.6453, -2.6420, -2.5877, -2.6382,\n",
      "        -2.6341, -2.6347, -2.6161, -2.5881, -2.6360, -2.6345, -2.6451, -2.5588,\n",
      "        -2.5838, -2.6424, -2.6264, -2.6447, -2.6452, -2.6452, -2.6553, -2.6429,\n",
      "        -2.5555, -2.5607], device='mps:0')\n",
      "mean: tensor(-2.6226, device='mps:0')\n",
      "iter_dt 1.09s; iter 65: train loss 0.72988 temperature: 8.249999999999993\n",
      "mean_logits tensor([-2.7715, -2.5701, -2.4971, -2.4873, -2.7131, -2.6720, -2.4505, -2.2036,\n",
      "        -2.4607, -2.5753, -2.4062, -2.5354, -2.5106, -2.4651, -2.2131, -2.6577,\n",
      "        -2.0607, -2.4700, -2.8905, -2.6765, -2.4948, -2.6645, -2.4938, -2.8716,\n",
      "        -2.6969, -2.4829, -2.6871, -2.7036, -2.4065, -2.5636, -2.2898, -2.5571,\n",
      "        -2.5693, -2.5646, -2.4295, -2.4817, -2.2713, -2.4371, -2.5159, -2.4129,\n",
      "        -2.5112, -2.4948, -2.5366, -2.5162, -2.4074, -2.6071, -2.5430, -2.6295,\n",
      "        -2.6721, -2.3612], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6444, -2.6161, -2.6286, -2.6448, -2.6436, -2.6358, -2.6204, -2.6269,\n",
      "        -2.6371, -2.6320, -2.5963, -2.6453, -2.6050, -2.6552, -2.6438, -2.6425,\n",
      "        -2.6283, -2.5760, -2.6450, -2.6256, -2.6406, -2.6422, -2.6426, -2.6442,\n",
      "        -2.5598, -2.6456, -2.6445, -2.6440, -2.6332, -2.6048, -2.6434, -2.6411,\n",
      "        -2.6449, -2.6458, -2.6276, -2.6446, -2.6416, -2.6350, -2.5595, -2.6223,\n",
      "        -2.6460, -2.6343, -2.6123, -2.5828, -2.6320, -2.6290, -2.6450, -2.6405,\n",
      "        -2.6358, -2.6349], device='mps:0')\n",
      "mean: tensor(-2.6298, device='mps:0')\n",
      "iter_dt 1.15s; iter 66: train loss 0.63243 temperature: 8.299999999999994\n",
      "mean_logits tensor([-2.6379, -2.4409, -2.7660, -2.3360, -2.4634, -2.3065, -2.3983, -2.5382,\n",
      "        -2.6133, -2.3452, -2.6249, -2.5248, -2.2797, -2.4428, -2.8263, -2.6216,\n",
      "        -2.2721, -2.5816, -2.7411, -2.6063, -2.5015, -2.7228, -2.4252, -2.5781,\n",
      "        -2.7007, -2.5523, -2.5223, -2.8047, -2.6576, -2.2899, -2.6122, -2.5324,\n",
      "        -2.4813, -2.7122, -2.7733, -2.7847, -2.7658, -2.7079, -2.5008, -2.4569,\n",
      "        -2.6572, -2.3237, -2.3401, -2.6793, -2.6271, -2.4389, -2.3933, -2.6443,\n",
      "        -2.5886, -2.4578], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6445, -2.6443, -2.6443, -2.5840, -2.6100, -2.6022, -2.6458, -2.6435,\n",
      "        -2.6268, -2.6452, -2.6198, -2.6422, -2.6448, -2.6311, -2.6425, -2.6224,\n",
      "        -2.6465, -2.6452, -2.6164, -2.6433, -2.6164, -2.6413, -2.5803, -2.6446,\n",
      "        -2.6452, -2.6382, -2.5823, -2.6448, -2.6437, -2.6443, -2.6358, -2.6428,\n",
      "        -2.6448, -2.6245, -2.6445, -2.6344, -2.5599, -2.6437, -2.6429, -2.6329,\n",
      "        -2.5849, -2.6447, -2.6454, -2.6021, -2.6041, -2.6294, -2.5667, -2.6449,\n",
      "        -2.6021, -2.6452], device='mps:0')\n",
      "mean: tensor(-2.6280, device='mps:0')\n",
      "iter_dt 1.07s; iter 67: train loss 0.48385 temperature: 8.349999999999994\n",
      "mean_logits tensor([-2.5386, -2.7410, -2.6331, -2.5381, -2.6570, -2.6189, -2.5066, -2.7396,\n",
      "        -2.5229, -2.7224, -2.3920, -2.6880, -2.7869, -2.7373, -2.7602, -2.2929,\n",
      "        -2.1516, -2.6172, -2.6162, -2.5550, -2.5001, -2.3968, -2.4267, -2.3654,\n",
      "        -2.3344, -2.5612, -2.4744, -2.6165, -2.4921, -2.5324, -2.4522, -2.4984,\n",
      "        -2.7046, -2.5827, -2.6399, -2.6691, -2.8032, -2.5424, -2.5607, -2.6874,\n",
      "        -2.5206, -2.5951, -2.4012, -2.8264, -2.4747, -2.5953, -2.4225, -2.3529,\n",
      "        -2.5567, -2.2616], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6047, -2.6370, -2.6388, -2.6234, -2.6427, -2.6454, -2.6447, -2.6429,\n",
      "        -2.6403, -2.6415, -2.6267, -2.5845, -2.6279, -2.6202, -2.6428, -2.6499,\n",
      "        -2.6074, -2.5838, -2.6455, -2.6053, -2.6379, -2.5457, -2.6440, -2.6042,\n",
      "        -2.6189, -2.6388, -2.6415, -2.6393, -2.6453, -2.6449, -2.5758, -2.6450,\n",
      "        -2.6400, -2.6150, -2.6454, -2.6297, -2.6474, -2.5948, -2.6139, -2.6445,\n",
      "        -2.6453, -2.6312, -2.5822, -2.6347, -2.6235, -2.5604, -2.5842, -2.5396,\n",
      "        -2.5915, -2.5480], device='mps:0')\n",
      "mean: tensor(-2.6202, device='mps:0')\n",
      "iter_dt 1.09s; iter 68: train loss 0.80778 temperature: 8.399999999999995\n",
      "mean_logits tensor([-2.5412, -2.5627, -2.6470, -2.1457, -2.7184, -2.1705, -2.4363, -2.8369,\n",
      "        -2.4733, -2.1492, -2.4201, -2.8021, -2.6032, -2.4266, -2.4974, -2.7076,\n",
      "        -2.5168, -2.3988, -2.6226, -2.7832, -2.5792, -2.6606, -2.4742, -2.3277,\n",
      "        -2.4627, -2.6286, -2.2125, -2.9046, -2.2711, -2.7340, -2.6185, -2.6378,\n",
      "        -2.6438, -2.6702, -2.1913, -2.7180, -2.5187, -2.4084, -2.5998, -2.5076,\n",
      "        -2.3186, -2.7603, -2.5136, -2.3393, -2.6075, -2.6326, -2.4171, -2.6403,\n",
      "        -2.7124, -2.7445], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6433, -2.6105, -2.6441, -2.6443, -2.6321, -2.6105, -2.6456, -2.6450,\n",
      "        -2.6440, -2.5835, -2.5575, -2.6413, -2.6414, -2.6449, -2.6441, -2.6452,\n",
      "        -2.6413, -2.6433, -2.5838, -2.6330, -2.6442, -2.6429, -2.5688, -2.6453,\n",
      "        -2.5973, -2.6441, -2.6380, -2.6445, -2.6451, -2.6424, -2.6271, -2.6142,\n",
      "        -2.5748, -2.6455, -2.6122, -2.6329, -2.6321, -2.5258, -2.6430, -2.6454,\n",
      "        -2.6110, -2.6428, -2.6438, -2.6449, -2.6268, -2.6416, -2.6455, -2.6113,\n",
      "        -2.5978, -2.6406], device='mps:0')\n",
      "mean: tensor(-2.6270, device='mps:0')\n",
      "iter_dt 1.07s; iter 69: train loss 0.59234 temperature: 8.449999999999996\n",
      "mean_logits tensor([-2.4990, -2.8313, -2.6026, -2.4128, -2.4296, -2.5722, -2.3155, -2.6789,\n",
      "        -2.6294, -2.5424, -2.5661, -2.3501, -2.6221, -2.5217, -2.5033, -2.7210,\n",
      "        -2.3353, -2.6732, -2.5236, -2.3676, -2.5749, -2.4759, -2.6224, -2.6621,\n",
      "        -2.3124, -2.2738, -2.7713, -2.3803, -2.6176, -2.5808, -2.5419, -2.6625,\n",
      "        -2.6093, -2.4228, -2.4938, -2.5906, -2.7285, -2.7838, -2.4672, -2.6816,\n",
      "        -2.6893, -2.7723, -2.3249, -2.5489, -2.8462, -2.5696, -2.3272, -2.6638,\n",
      "        -2.5875, -2.4652], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6413, -2.6292, -2.6446, -2.6454, -2.6054, -2.6432, -2.6441, -2.6411,\n",
      "        -2.6555, -2.5736, -2.6427, -2.6426, -2.5775, -2.6428, -2.6438, -2.5949,\n",
      "        -2.6031, -2.6453, -2.6436, -2.6431, -2.6438, -2.6425, -2.6234, -2.6427,\n",
      "        -2.6454, -2.6452, -2.6452, -2.6406, -2.5546, -2.6212, -2.6455, -2.6313,\n",
      "        -2.5795, -2.6408, -2.6429, -2.6354, -2.6452, -2.6436, -2.6383, -2.6356,\n",
      "        -2.6445, -2.6255, -2.6375, -2.6449, -2.6414, -2.6173, -2.5931, -2.6455,\n",
      "        -2.6066, -2.6441], device='mps:0')\n",
      "mean: tensor(-2.6309, device='mps:0')\n",
      "iter_dt 1.06s; iter 70: train loss 0.77663 temperature: 8.499999999999996\n",
      "mean_logits tensor([-2.3362, -2.9981, -2.7973, -2.7632, -2.5524, -2.4839, -2.6455, -2.6936,\n",
      "        -2.8241, -2.6328, -2.7996, -2.4765, -2.5483, -2.5810, -2.2657, -2.6986,\n",
      "        -2.7755, -2.7309, -2.7609, -2.1567, -2.2777, -2.6414, -2.7078, -2.3320,\n",
      "        -2.5980, -2.3022, -2.5989, -2.4777, -2.7163, -2.6065, -2.7897, -2.6716,\n",
      "        -2.6867, -2.5920, -2.6821, -2.6996, -2.3933, -2.3967, -2.9156, -2.4093,\n",
      "        -2.4260, -2.5014, -2.5120, -2.6313, -2.6266, -2.4296, -2.4820, -2.3696,\n",
      "        -2.4075, -2.6754], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6447, -2.6454, -2.6456, -2.5956, -2.6452, -2.6418, -2.6445, -2.6260,\n",
      "        -2.5919, -2.6447, -2.6387, -2.6314, -2.6416, -2.5958, -2.5692, -2.5689,\n",
      "        -2.6155, -2.6414, -2.6421, -2.5838, -2.6406, -2.6340, -2.6442, -2.6366,\n",
      "        -2.6418, -2.6363, -2.6260, -2.5733, -2.6153, -2.5899, -2.6442, -2.6400,\n",
      "        -2.6399, -2.6458, -2.6250, -2.6430, -2.6107, -2.6447, -2.6055, -2.5869,\n",
      "        -2.6185, -2.6327, -2.6456, -2.6388, -2.6372, -2.6390, -2.6418, -2.6395,\n",
      "        -2.6467, -2.6160], device='mps:0')\n",
      "mean: tensor(-2.6267, device='mps:0')\n",
      "iter_dt 1.09s; iter 71: train loss 0.61976 temperature: 8.549999999999997\n",
      "mean_logits tensor([-2.5981, -2.6091, -2.9521, -2.6007, -2.3841, -2.3580, -2.3892, -2.3889,\n",
      "        -2.5658, -2.4915, -2.4310, -2.4801, -2.6159, -2.6168, -2.6455, -2.4575,\n",
      "        -2.6030, -2.4700, -2.6116, -2.4354, -2.3952, -2.3985, -2.8074, -2.0506,\n",
      "        -2.5444, -2.6752, -2.6971, -2.3705, -2.6345, -2.7380, -2.6247, -2.5814,\n",
      "        -2.3737, -2.6927, -2.6940, -2.5006, -2.6811, -2.3093, -2.6238, -2.6044,\n",
      "        -2.6793, -2.6538, -2.8391, -2.4625, -2.6686, -2.5132, -2.7955, -2.3026,\n",
      "        -2.6285, -2.7008], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6348, -2.6267, -2.6453, -2.5593, -2.6441, -2.6336, -2.6391, -2.6426,\n",
      "        -2.5765, -2.6449, -2.6419, -2.5906, -2.5928, -2.6447, -2.5538, -2.6455,\n",
      "        -2.6448, -2.6416, -2.6206, -2.5872, -2.6443, -2.6395, -2.6415, -2.5403,\n",
      "        -2.6277, -2.6447, -2.6374, -2.6441, -2.6156, -2.6446, -2.5487, -2.5722,\n",
      "        -2.6431, -2.6271, -2.6444, -2.6055, -2.5541, -2.6454, -2.6452, -2.6445,\n",
      "        -2.6443, -2.6451, -2.6344, -2.6457, -2.6446, -2.6284, -2.6434, -2.5573,\n",
      "        -2.6472, -2.6453], device='mps:0')\n",
      "mean: tensor(-2.6231, device='mps:0')\n",
      "iter_dt 1.08s; iter 72: train loss 0.77520 temperature: 8.599999999999998\n",
      "mean_logits tensor([-2.5849, -2.4799, -2.6179, -2.4715, -2.6058, -2.8089, -2.6140, -2.8032,\n",
      "        -2.8322, -2.5958, -2.4113, -2.8345, -2.7130, -2.7054, -2.5205, -2.6770,\n",
      "        -2.1854, -2.4851, -2.3929, -2.9347, -2.5134, -2.5968, -2.5870, -2.6285,\n",
      "        -2.4273, -2.5832, -2.6722, -2.8037, -2.2444, -2.7810, -2.4944, -2.3758,\n",
      "        -2.7597, -2.6662, -2.7937, -2.3372, -2.2886, -2.7946, -2.7525, -2.4664,\n",
      "        -2.6966, -2.2243, -2.8990, -2.4736, -2.4726, -2.4672, -2.5430, -2.6178,\n",
      "        -2.7574, -2.5709], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5752, -2.6435, -2.6445, -2.6408, -2.6338, -2.6006, -2.6425, -2.6305,\n",
      "        -2.6457, -2.6406, -2.6453, -2.6325, -2.6451, -2.6187, -2.5472, -2.6314,\n",
      "        -2.6443, -2.6418, -2.6430, -2.6252, -2.6041, -2.6256, -2.6432, -2.6258,\n",
      "        -2.6413, -2.6427, -2.6446, -2.6452, -2.6458, -2.6435, -2.6451, -2.6286,\n",
      "        -2.6457, -2.6416, -2.6445, -2.6423, -2.6341, -2.6294, -2.6452, -2.6399,\n",
      "        -2.6041, -2.6254, -2.6442, -2.6292, -2.6333, -2.6295, -2.6451, -2.6317,\n",
      "        -2.6434, -2.5722], device='mps:0')\n",
      "mean: tensor(-2.6318, device='mps:0')\n",
      "iter_dt 1.09s; iter 73: train loss 0.64086 temperature: 8.649999999999999\n",
      "mean_logits tensor([-2.5344, -2.6179, -2.3357, -2.7721, -2.7643, -3.0045, -2.7762, -2.7474,\n",
      "        -2.8728, -2.5443, -2.5728, -2.5003, -2.5989, -2.4906, -2.7571, -2.4471,\n",
      "        -2.5201, -2.5616, -2.5164, -2.4454, -2.5793, -2.7178, -2.4440, -2.5375,\n",
      "        -2.6982, -2.5201, -2.3235, -2.7122, -2.1804, -2.5237, -2.6263, -2.7575,\n",
      "        -2.6961, -2.7747, -2.5204, -2.7037, -2.7061, -2.5352, -2.7516, -2.4168,\n",
      "        -2.5075, -2.6033, -2.6369, -2.8807, -2.6281, -2.6660, -2.4913, -2.6763,\n",
      "        -2.7930, -2.3986], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6357, -2.6352, -2.6333, -2.6444, -2.6166, -2.6168, -2.6454, -2.6376,\n",
      "        -2.6418, -2.6425, -2.5843, -2.6304, -2.6336, -2.6447, -2.6381, -2.6394,\n",
      "        -2.6267, -2.6034, -2.6451, -2.6330, -2.5380, -2.6441, -2.6282, -2.6417,\n",
      "        -2.6344, -2.6440, -2.6453, -2.6330, -2.6433, -2.6442, -2.6452, -2.6403,\n",
      "        -2.6408, -2.6404, -2.6359, -2.6383, -2.5843, -2.6108, -2.6443, -2.6045,\n",
      "        -2.6314, -2.6007, -2.6436, -2.6176, -2.6331, -2.6455, -2.6308, -2.6374,\n",
      "        -2.5354, -2.5785], device='mps:0')\n",
      "mean: tensor(-2.6273, device='mps:0')\n",
      "iter_dt 1.09s; iter 74: train loss 0.80384 temperature: 8.7\n",
      "mean_logits tensor([-2.4573, -2.8282, -2.8141, -2.8324, -2.5857, -2.6116, -2.5365, -2.7975,\n",
      "        -2.9858, -2.6488, -2.6842, -2.2267, -2.6144, -2.4886, -2.6314, -2.4215,\n",
      "        -2.1512, -3.0021, -2.6404, -2.8306, -2.3564, -2.8910, -2.5922, -2.6816,\n",
      "        -2.6319, -2.7492, -2.9305, -2.6859, -2.4941, -2.6692, -2.4242, -2.8275,\n",
      "        -2.6898, -2.6672, -2.7395, -2.4874, -2.6536, -2.8234, -2.6502, -2.5696,\n",
      "        -2.6286, -2.4995, -2.5466, -2.3954, -2.6676, -2.5799, -2.6586, -2.4308,\n",
      "        -2.4950, -2.4884], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6455, -2.6315, -2.6429, -2.6414, -2.6452, -2.6418, -2.6427, -2.6446,\n",
      "        -2.6442, -2.6140, -2.6442, -2.5777, -2.6447, -2.6448, -2.6444, -2.6452,\n",
      "        -2.6451, -2.6256, -2.6427, -2.6325, -2.6345, -2.6450, -2.6214, -2.5809,\n",
      "        -2.6403, -2.6456, -2.6449, -2.6259, -2.6333, -2.6447, -2.6444, -2.6437,\n",
      "        -2.6335, -2.6428, -2.6354, -2.6408, -2.6320, -2.6438, -2.6440, -2.6284,\n",
      "        -2.6411, -2.6354, -2.6384, -2.6414, -2.6308, -2.6040, -2.6156, -2.6403,\n",
      "        -2.6448, -2.6391], device='mps:0')\n",
      "mean: tensor(-2.6355, device='mps:0')\n",
      "iter_dt 1.07s; iter 75: train loss 0.88140 temperature: 8.75\n",
      "mean_logits tensor([-2.7320, -2.8713, -2.7055, -2.6390, -2.7810, -2.7758, -2.4891, -2.6313,\n",
      "        -2.2288, -2.5999, -2.8329, -2.8390, -2.5434, -2.6277, -2.5608, -2.4756,\n",
      "        -2.6704, -2.5685, -2.4772, -2.7213, -2.3876, -2.7099, -2.7248, -2.4963,\n",
      "        -2.6202, -2.6129, -2.3416, -2.8532, -2.4850, -2.9035, -2.8225, -2.6165,\n",
      "        -2.9949, -2.5456, -2.2442, -2.4276, -2.8790, -2.6881, -2.7525, -2.4446,\n",
      "        -2.3224, -2.7766, -2.7862, -2.7903, -2.9161, -2.7969, -2.7471, -2.9359,\n",
      "        -2.5750, -2.4434], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6429, -2.6376, -2.6445, -2.6433, -2.6363, -2.6342, -2.6452, -2.6261,\n",
      "        -2.6335, -2.6442, -2.6452, -2.6411, -2.6110, -2.6253, -2.6323, -2.6263,\n",
      "        -2.5710, -2.6355, -2.6163, -2.5995, -2.6235, -2.6384, -2.6448, -2.5775,\n",
      "        -2.6281, -2.6440, -2.6452, -2.6409, -2.6452, -2.6417, -2.6393, -2.5877,\n",
      "        -2.6328, -2.6402, -2.6412, -2.6455, -2.6425, -2.6442, -2.6453, -2.6020,\n",
      "        -2.6289, -2.6350, -2.6446, -2.6332, -2.6414, -2.6421, -2.6448, -2.6310,\n",
      "        -2.6348, -2.6444], device='mps:0')\n",
      "mean: tensor(-2.6324, device='mps:0')\n",
      "iter_dt 1.10s; iter 76: train loss 0.78817 temperature: 8.8\n",
      "mean_logits tensor([-2.6040, -2.6240, -2.4769, -2.4834, -2.4410, -2.7056, -2.5134, -2.3102,\n",
      "        -2.5925, -2.3877, -2.3475, -2.6728, -2.6229, -3.0445, -2.9642, -2.6910,\n",
      "        -2.5936, -2.5419, -2.6847, -2.5876, -2.4484, -2.5701, -2.3859, -2.1238,\n",
      "        -2.5762, -2.7497, -2.3554, -2.6470, -2.7307, -2.5615, -2.6491, -2.4682,\n",
      "        -2.6657, -2.6257, -2.4171, -2.3899, -2.5873, -2.4182, -2.5977, -2.6381,\n",
      "        -2.6530, -2.7744, -2.2765, -2.5978, -2.6815, -2.6628, -2.7935, -2.7601,\n",
      "        -2.3432, -2.4785], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6316, -2.6270, -2.6451, -2.6435, -2.6302, -2.6153, -2.6387, -2.6446,\n",
      "        -2.6450, -2.6374, -2.6446, -2.6454, -2.6326, -2.5842, -2.6451, -2.6348,\n",
      "        -2.6455, -2.6443, -2.6412, -2.6447, -2.6359, -2.6452, -2.6452, -2.6437,\n",
      "        -2.6437, -2.6048, -2.6304, -2.6040, -2.6324, -2.6190, -2.6441, -2.6395,\n",
      "        -2.6451, -2.6399, -2.5048, -2.6270, -2.6445, -2.6332, -2.6321, -2.6440,\n",
      "        -2.5740, -2.6261, -2.6354, -2.6228, -2.6447, -2.6255, -2.6447, -2.6449,\n",
      "        -2.6364, -2.6282], device='mps:0')\n",
      "mean: tensor(-2.6312, device='mps:0')\n",
      "iter_dt 1.10s; iter 77: train loss 0.83227 temperature: 8.850000000000001\n",
      "mean_logits tensor([-2.6073, -2.9111, -2.5532, -2.9123, -2.4048, -2.4999, -2.5793, -2.6394,\n",
      "        -2.6871, -2.6281, -2.3503, -2.7135, -2.3016, -2.4157, -2.5919, -2.6378,\n",
      "        -2.4737, -2.4626, -2.6578, -2.5053, -2.4709, -2.4125, -2.1702, -2.8434,\n",
      "        -2.7723, -2.6507, -2.5754, -2.7258, -2.4475, -2.4898, -2.8037, -2.5266,\n",
      "        -2.8878, -2.5352, -2.5376, -2.4666, -2.2687, -2.3972, -2.7535, -2.9419,\n",
      "        -2.4490, -2.6012, -2.4459, -2.7789, -2.4514, -2.9715, -2.7115, -2.5474,\n",
      "        -2.6305, -2.4159], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5798, -2.5839, -2.6443, -2.6441, -2.6137, -2.6365, -2.6442, -2.6407,\n",
      "        -2.6415, -2.6067, -2.5832, -2.6267, -2.6443, -2.6449, -2.6441, -2.6049,\n",
      "        -2.6388, -2.6423, -2.6446, -2.6244, -2.6331, -2.6171, -2.6233, -2.6349,\n",
      "        -2.6332, -2.6109, -2.6175, -2.6010, -2.5840, -2.6242, -2.6345, -2.6309,\n",
      "        -2.6274, -2.6369, -2.6024, -2.6420, -2.6285, -2.6457, -2.6439, -2.6457,\n",
      "        -2.6430, -2.6368, -2.6101, -2.6451, -2.6422, -2.6440, -2.6446, -2.5823,\n",
      "        -2.6411, -2.5819], device='mps:0')\n",
      "mean: tensor(-2.6264, device='mps:0')\n",
      "iter_dt 1.09s; iter 78: train loss 0.54989 temperature: 8.900000000000002\n",
      "mean_logits tensor([-2.8040, -2.5756, -2.7791, -2.5997, -2.6409, -2.6718, -2.3847, -2.6781,\n",
      "        -2.7254, -2.3002, -2.6657, -2.6664, -2.6221, -2.7233, -2.9490, -2.8155,\n",
      "        -2.4498, -2.6209, -2.7247, -2.5369, -2.4504, -2.6497, -2.3202, -2.5164,\n",
      "        -2.5138, -2.7012, -2.6389, -2.6097, -2.3833, -2.8359, -2.4205, -2.4559,\n",
      "        -2.6184, -2.6435, -2.5642, -2.7652, -2.7850, -2.5866, -2.7907, -2.5773,\n",
      "        -2.7380, -2.5348, -2.8064, -2.5477, -2.4348, -2.2453, -2.4959, -2.5674,\n",
      "        -2.7814, -2.7803], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6359, -2.6313, -2.6336, -2.6335, -2.5969, -2.6453, -2.6443, -2.6457,\n",
      "        -2.6423, -2.6428, -2.6251, -2.6239, -2.6416, -2.6441, -2.6425, -2.6446,\n",
      "        -2.5979, -2.6455, -2.6258, -2.6292, -2.6413, -2.6428, -2.6149, -2.6444,\n",
      "        -2.6435, -2.6452, -2.6365, -2.6329, -2.6360, -2.6422, -2.6027, -2.6449,\n",
      "        -2.6398, -2.5793, -2.6400, -2.6457, -2.6434, -2.6446, -2.6439, -2.6454,\n",
      "        -2.6458, -2.6458, -2.6426, -2.6432, -2.6211, -2.6348, -2.6286, -2.5834,\n",
      "        -2.6346, -2.6392], device='mps:0')\n",
      "mean: tensor(-2.6340, device='mps:0')\n",
      "iter_dt 1.09s; iter 79: train loss 0.40510 temperature: 8.950000000000003\n",
      "mean_logits tensor([-2.4333, -2.7499, -2.5231, -2.6278, -2.7587, -2.6534, -2.5294, -2.5215,\n",
      "        -2.6599, -2.6385, -2.4674, -2.6613, -2.4307, -2.6410, -2.5864, -2.2559,\n",
      "        -2.8242, -2.4990, -2.5093, -2.5062, -2.4790, -2.3140, -2.5901, -2.7518,\n",
      "        -2.6444, -2.5972, -2.4467, -2.5394, -2.5620, -2.7228, -2.5885, -2.6896,\n",
      "        -2.6455, -2.7255, -2.4994, -2.4325, -2.6268, -2.4722, -2.7641, -2.7781,\n",
      "        -2.3929, -2.7216, -2.5844, -2.4449, -2.6577, -2.6165, -2.4974, -2.6081,\n",
      "        -2.6658, -2.5034], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6378, -2.6414, -2.6216, -2.6159, -2.6445, -2.5961, -2.6143, -2.6443,\n",
      "        -2.6425, -2.6005, -2.6454, -2.5159, -2.6443, -2.6453, -2.6316, -2.6389,\n",
      "        -2.6347, -2.6417, -2.6444, -2.6448, -2.6233, -2.6332, -2.6351, -2.6430,\n",
      "        -2.6446, -2.5721, -2.6441, -2.6403, -2.6442, -2.6426, -2.6450, -2.6444,\n",
      "        -2.6426, -2.6282, -2.6453, -2.6267, -2.6444, -2.6416, -2.6452, -2.6451,\n",
      "        -2.6443, -2.6449, -2.6451, -2.5935, -2.6360, -2.6201, -2.5798, -2.6353,\n",
      "        -2.6450, -2.6352], device='mps:0')\n",
      "mean: tensor(-2.6311, device='mps:0')\n",
      "iter_dt 1.05s; iter 80: train loss 0.77079 temperature: 9.000000000000004\n",
      "mean_logits tensor([-2.6104, -2.6317, -2.8439, -2.7720, -2.4686, -2.8300, -2.6225, -2.7625,\n",
      "        -2.7470, -2.6239, -2.8782, -2.8092, -2.6263, -2.6667, -2.3843, -2.6835,\n",
      "        -2.6786, -2.8031, -2.6092, -2.6499, -2.7733, -2.7231, -2.5878, -3.0064,\n",
      "        -2.6237, -2.8170, -2.7246, -2.8815, -2.6521, -2.4455, -2.6963, -2.6833,\n",
      "        -2.7694, -2.6315, -2.4951, -2.9209, -2.6845, -2.6467, -2.4687, -2.3422,\n",
      "        -2.9228, -2.7057, -2.5873, -2.6553, -2.5152, -2.1410, -2.6844, -2.3560,\n",
      "        -2.5073, -2.7792], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6291, -2.6031, -2.6266, -2.5807, -2.6453, -2.6413, -2.6349, -2.6451,\n",
      "        -2.6338, -2.6440, -2.6444, -2.6449, -2.6430, -2.6458, -2.6357, -2.6455,\n",
      "        -2.6441, -2.6435, -2.6418, -2.6449, -2.6454, -2.6364, -2.6378, -2.6103,\n",
      "        -2.6445, -2.6411, -2.6442, -2.6152, -2.6316, -2.6283, -2.6312, -2.6420,\n",
      "        -2.6364, -2.6023, -2.6480, -2.6410, -2.6553, -2.6453, -2.6422, -2.6386,\n",
      "        -2.6025, -2.6433, -2.6398, -2.6432, -2.6184, -2.6455, -2.6355, -2.6436,\n",
      "        -2.6417, -2.6444], device='mps:0')\n",
      "mean: tensor(-2.6359, device='mps:0')\n",
      "iter_dt 1.04s; iter 81: train loss 0.73554 temperature: 9.050000000000004\n",
      "mean_logits tensor([-2.3184, -2.4851, -2.7821, -2.4393, -2.5973, -2.5166, -2.4916, -2.4951,\n",
      "        -2.7334, -2.5638, -2.7840, -2.6065, -2.5508, -2.5651, -2.7548, -2.5314,\n",
      "        -2.3457, -2.6124, -2.4957, -2.7420, -2.5675, -2.5723, -2.5517, -2.6566,\n",
      "        -2.6505, -2.4760, -2.6485, -2.7707, -2.7578, -2.8318, -2.8001, -2.6592,\n",
      "        -2.6668, -2.3669, -2.9662, -2.7686, -2.7206, -2.6393, -2.7395, -2.6644,\n",
      "        -2.5656, -2.8682, -2.5304, -2.6119, -2.7460, -3.0236, -2.4350, -2.2008,\n",
      "        -2.3600, -2.3672], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6453, -2.6453, -2.6123, -2.6558, -2.5842, -2.6356, -2.6448, -2.6430,\n",
      "        -2.5815, -2.6422, -2.5876, -2.6350, -2.6390, -2.6394, -2.6440, -2.6242,\n",
      "        -2.6097, -2.6420, -2.6415, -2.6344, -2.6255, -2.6448, -2.6452, -2.6452,\n",
      "        -2.6375, -2.6151, -2.5604, -2.5969, -2.6237, -2.6454, -2.6323, -2.6450,\n",
      "        -2.6392, -2.5943, -2.6428, -2.6367, -2.6316, -2.6334, -2.6447, -2.6453,\n",
      "        -2.5599, -2.6445, -2.6339, -2.6019, -2.6338, -2.6416, -2.6405, -2.6414,\n",
      "        -2.6284, -2.6427], device='mps:0')\n",
      "mean: tensor(-2.6288, device='mps:0')\n",
      "iter_dt 1.21s; iter 82: train loss 0.42440 temperature: 9.100000000000005\n",
      "mean_logits tensor([-2.4086, -2.2645, -2.7102, -2.5766, -2.5860, -2.4916, -2.6949, -2.7253,\n",
      "        -2.6429, -2.5098, -2.6147, -2.3884, -2.6778, -2.3917, -2.8092, -2.5598,\n",
      "        -2.6435, -2.6537, -2.8151, -2.6846, -2.8599, -2.5775, -2.6879, -2.4864,\n",
      "        -2.5010, -2.5632, -2.4775, -2.8354, -2.6974, -2.5441, -2.3956, -2.7485,\n",
      "        -2.5632, -2.5427, -2.5482, -2.6663, -2.6705, -2.6395, -2.7699, -2.6549,\n",
      "        -2.5406, -2.7259, -2.6907, -2.4619, -2.3474, -2.4358, -2.6814, -2.5465,\n",
      "        -2.6148, -2.6511], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6432, -2.6436, -2.6421, -2.6446, -2.6089, -2.6453, -2.6045, -2.6452,\n",
      "        -2.6455, -2.5775, -2.6092, -2.6401, -2.6431, -2.6401, -2.6450, -2.5813,\n",
      "        -2.6436, -2.6454, -2.6441, -2.6332, -2.6453, -2.6400, -2.6435, -2.6429,\n",
      "        -2.6418, -2.6351, -2.6454, -2.6253, -2.6240, -2.6404, -2.5906, -2.6355,\n",
      "        -2.6265, -2.6309, -2.6331, -2.6447, -2.5846, -2.6450, -2.6454, -2.6176,\n",
      "        -2.6231, -2.5838, -2.6408, -2.5784, -2.6451, -2.6301, -2.6352, -2.6453,\n",
      "        -2.5822, -2.6311], device='mps:0')\n",
      "mean: tensor(-2.6292, device='mps:0')\n",
      "iter_dt 1.03s; iter 83: train loss 0.62808 temperature: 9.150000000000006\n",
      "mean_logits tensor([-2.4309, -2.7100, -2.4924, -2.4566, -2.7807, -2.4155, -2.2448, -2.6912,\n",
      "        -2.8057, -2.3524, -2.7273, -2.7298, -2.6848, -2.3330, -2.5983, -2.4568,\n",
      "        -2.5187, -2.5109, -2.4543, -2.7770, -2.6800, -2.6606, -2.5715, -2.5819,\n",
      "        -2.8085, -2.6208, -2.6594, -2.5094, -2.6069, -2.5854, -2.9601, -2.5236,\n",
      "        -2.6301, -2.8026, -2.4084, -2.5791, -2.7382, -2.9357, -2.4470, -2.6248,\n",
      "        -2.4600, -2.3835, -2.5843, -2.8676, -2.5747, -2.5683, -2.4894, -2.4116,\n",
      "        -2.3668, -2.4687], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6415, -2.6449, -2.6370, -2.6286, -2.6447, -2.6448, -2.6359, -2.6423,\n",
      "        -2.6453, -2.6448, -2.6451, -2.6249, -2.6449, -2.5321, -2.6452, -2.6446,\n",
      "        -2.6356, -2.5485, -2.5717, -2.6359, -2.6416, -2.6342, -2.5725, -2.6188,\n",
      "        -2.6411, -2.6410, -2.6270, -2.6217, -2.6227, -2.6386, -2.6381, -2.6455,\n",
      "        -2.6222, -2.6440, -2.6323, -2.6451, -2.6439, -2.6438, -2.6358, -2.6355,\n",
      "        -2.6454, -2.5961, -2.6422, -2.6232, -2.6428, -2.6453, -2.6243, -2.6272,\n",
      "        -2.6050, -2.6423], device='mps:0')\n",
      "mean: tensor(-2.6296, device='mps:0')\n",
      "iter_dt 1.00s; iter 84: train loss 0.63061 temperature: 9.200000000000006\n",
      "mean_logits tensor([-2.6520, -2.6327, -2.7430, -2.6293, -2.6580, -2.6015, -2.4389, -2.4027,\n",
      "        -2.3962, -2.5835, -2.6765, -2.6258, -2.7631, -2.6113, -2.7808, -1.9932,\n",
      "        -2.5544, -2.5226, -2.6810, -2.4802, -2.3068, -2.8036, -2.4519, -2.2511,\n",
      "        -2.7096, -2.5142, -2.6543, -2.5731, -2.6501, -2.7761, -2.7324, -2.5528,\n",
      "        -2.5981, -2.2216, -2.7823, -2.4760, -2.6581, -2.5403, -2.6418, -2.6742,\n",
      "        -2.6209, -2.2988, -2.7497, -2.6698, -2.6002, -2.7056, -2.9062, -2.5851,\n",
      "        -2.8458, -2.5092], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6425, -2.6442, -2.6454, -2.6313, -2.6447, -2.6432, -2.6364, -2.6335,\n",
      "        -2.6447, -2.6451, -2.6449, -2.6456, -2.6414, -2.6449, -2.6452, -2.6111,\n",
      "        -2.6446, -2.6444, -2.6382, -2.6371, -2.6453, -2.6448, -2.6456, -2.6452,\n",
      "        -2.6276, -2.6328, -2.6242, -2.6431, -2.6454, -2.6114, -2.6286, -2.6002,\n",
      "        -2.6420, -2.6452, -2.6320, -2.6434, -2.6401, -2.6056, -2.6439, -2.6451,\n",
      "        -2.6284, -2.6448, -2.6454, -2.6451, -2.6356, -2.6435, -2.6410, -2.6331,\n",
      "        -2.6456, -2.6435], device='mps:0')\n",
      "mean: tensor(-2.6381, device='mps:0')\n",
      "iter_dt 1.00s; iter 85: train loss 0.58071 temperature: 9.250000000000007\n",
      "mean_logits tensor([-2.5308, -2.4428, -2.4903, -2.6313, -2.4705, -2.6119, -2.8895, -2.4656,\n",
      "        -2.4332, -2.3444, -2.5251, -2.9154, -2.5679, -2.5086, -2.7522, -2.5358,\n",
      "        -2.4501, -2.6554, -2.6194, -2.3677, -2.6209, -2.4306, -2.5710, -2.7776,\n",
      "        -2.5212, -2.6496, -2.6980, -2.6312, -2.5040, -2.7515, -2.4916, -2.7992,\n",
      "        -2.4568, -2.3321, -2.4162, -2.5188, -2.6961, -2.6150, -2.7142, -2.4940,\n",
      "        -2.6714, -2.2473, -2.5360, -2.6902, -2.8298, -2.5175, -2.4072, -2.7872,\n",
      "        -2.6683, -2.7114], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6469, -2.6421, -2.6412, -2.6448, -2.6300, -2.6342, -2.6443, -2.6450,\n",
      "        -2.6314, -2.6152, -2.6451, -2.6452, -2.6411, -2.6423, -2.6060, -2.6349,\n",
      "        -2.6451, -2.6323, -2.6280, -2.5860, -2.6348, -2.6437, -2.6421, -2.6320,\n",
      "        -2.6456, -2.6465, -2.6374, -2.6293, -2.6317, -2.6414, -2.6333, -2.6364,\n",
      "        -2.5937, -2.6428, -2.6405, -2.6444, -2.6234, -2.6310, -2.6173, -2.5788,\n",
      "        -2.6439, -2.6441, -2.6309, -2.5732, -2.6414, -2.6213, -2.6496, -2.6412,\n",
      "        -2.6340, -2.6284], device='mps:0')\n",
      "mean: tensor(-2.6323, device='mps:0')\n",
      "iter_dt 1.10s; iter 86: train loss 0.66174 temperature: 9.300000000000008\n",
      "mean_logits tensor([-2.9321, -2.5493, -2.5087, -2.4817, -2.8492, -2.9532, -2.5835, -2.5553,\n",
      "        -2.4777, -2.7532, -2.6283, -2.7907, -2.5263, -2.3611, -2.4971, -2.8249,\n",
      "        -2.5510, -2.7125, -2.6079, -2.3857, -2.4645, -2.4919, -2.5360, -2.6027,\n",
      "        -2.4606, -2.7178, -2.5063, -2.4787, -2.3224, -2.5866, -2.7847, -2.3132,\n",
      "        -2.7172, -2.5166, -2.6237, -2.8677, -2.5023, -2.5740, -2.5217, -2.7281,\n",
      "        -2.4861, -2.6639, -2.5658, -2.1571, -2.7153, -2.5111, -2.6179, -2.6448,\n",
      "        -2.6399, -2.6506], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6456, -2.6411, -2.6440, -2.6395, -2.6428, -2.6428, -2.6420, -2.5741,\n",
      "        -2.6451, -2.6448, -2.6458, -2.6455, -2.6403, -2.6194, -2.6454, -2.5998,\n",
      "        -2.6354, -2.6428, -2.6421, -2.6299, -2.5944, -2.6285, -2.6359, -2.6432,\n",
      "        -2.6308, -2.6340, -2.6523, -2.6395, -2.6424, -2.6452, -2.6446, -2.5921,\n",
      "        -2.6043, -2.6453, -2.6419, -2.5731, -2.6427, -2.6295, -2.6424, -2.5741,\n",
      "        -2.6069, -2.5957, -2.6364, -2.6452, -2.6439, -2.5778, -2.6326, -2.6453,\n",
      "        -2.6418, -2.6244], device='mps:0')\n",
      "mean: tensor(-2.6299, device='mps:0')\n",
      "iter_dt 1.07s; iter 87: train loss 0.68042 temperature: 9.350000000000009\n",
      "mean_logits tensor([-2.5731, -2.5837, -2.5222, -2.4139, -2.4089, -2.5930, -2.7229, -2.7014,\n",
      "        -2.4489, -3.0070, -2.7426, -2.2721, -2.4045, -2.1968, -2.3885, -2.4588,\n",
      "        -2.6539, -2.3933, -2.5643, -2.6353, -2.6233, -2.7001, -2.6521, -2.5829,\n",
      "        -2.6246, -2.6282, -2.4872, -2.4508, -2.7686, -2.5572, -2.5361, -2.5897,\n",
      "        -2.4477, -2.7393, -2.4583, -2.3814, -2.7854, -2.7117, -2.4879, -2.6305,\n",
      "        -2.4434, -2.5125, -2.8690, -2.6630, -2.8620, -2.5499, -2.1832, -2.6063,\n",
      "        -2.6668, -2.4763], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6336, -2.5711, -2.6360, -2.5776, -2.6441, -2.6451, -2.6445, -2.6378,\n",
      "        -2.6418, -2.6451, -2.6453, -2.6383, -2.6448, -2.6425, -2.6418, -2.5896,\n",
      "        -2.6452, -2.6311, -2.6434, -2.6430, -2.6404, -2.6448, -2.6457, -2.6457,\n",
      "        -2.6244, -2.6364, -2.6452, -2.6077, -2.6352, -2.6240, -2.6205, -2.5847,\n",
      "        -2.5379, -2.6251, -2.6552, -2.6116, -2.6453, -2.6331, -2.6439, -2.6453,\n",
      "        -2.6455, -2.6306, -2.6360, -2.6119, -2.6318, -2.6454, -2.6378, -2.6447,\n",
      "        -2.6344, -2.6311], device='mps:0')\n",
      "mean: tensor(-2.6309, device='mps:0')\n",
      "iter_dt 1.06s; iter 88: train loss 0.81705 temperature: 9.40000000000001\n",
      "mean_logits tensor([-2.7679, -2.4376, -2.6712, -2.6221, -2.2813, -2.5859, -2.6959, -2.3339,\n",
      "        -2.6450, -2.7820, -2.6395, -2.8618, -2.6503, -2.6655, -2.9903, -2.4737,\n",
      "        -2.6236, -2.7145, -2.4941, -2.5282, -2.6363, -2.6806, -2.6531, -2.7638,\n",
      "        -2.1581, -2.3870, -2.7370, -2.9741, -2.5443, -2.7465, -2.1650, -2.4657,\n",
      "        -2.8018, -2.5248, -2.1760, -2.7526, -2.5287, -2.7582, -2.8523, -2.6033,\n",
      "        -2.3768, -2.6144, -2.7354, -2.6997, -2.7149, -2.5492, -2.4299, -2.6428,\n",
      "        -2.6635, -2.6476], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6326, -2.6207, -2.6448, -2.6440, -2.6437, -2.6302, -2.6351, -2.6447,\n",
      "        -2.6453, -2.6446, -2.6425, -2.5914, -2.6451, -2.6451, -2.6443, -2.6466,\n",
      "        -2.6364, -2.6409, -2.6205, -2.6437, -2.6442, -2.6109, -2.5824, -2.6454,\n",
      "        -2.6434, -2.6265, -2.6445, -2.6430, -2.6412, -2.6368, -2.6416, -2.6403,\n",
      "        -2.6066, -2.6354, -2.6236, -2.6407, -2.6449, -2.5867, -2.6435, -2.6452,\n",
      "        -2.6080, -2.6366, -2.6449, -2.6453, -2.6175, -2.6444, -2.6415, -2.6271,\n",
      "        -2.6272, -2.6335], device='mps:0')\n",
      "mean: tensor(-2.6339, device='mps:0')\n",
      "iter_dt 1.03s; iter 89: train loss 0.53152 temperature: 9.45000000000001\n",
      "mean_logits tensor([-2.5951, -2.7824, -2.5070, -2.4726, -2.7132, -2.6513, -2.5667, -2.4284,\n",
      "        -2.4420, -2.6981, -2.5691, -2.5454, -2.7784, -2.5828, -2.6594, -2.7231,\n",
      "        -2.6988, -2.6697, -2.7433, -2.5137, -2.7115, -2.8074, -2.7615, -2.7906,\n",
      "        -2.6222, -2.7643, -2.5758, -2.7741, -2.5741, -2.7860, -2.5735, -2.6817,\n",
      "        -3.0054, -2.4377, -2.6208, -2.4719, -2.5631, -2.7586, -2.5899, -2.6700,\n",
      "        -2.6315, -2.9224, -2.3340, -2.6119, -2.5640, -2.5489, -2.5493, -2.6779,\n",
      "        -2.6441, -2.9375], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6451, -2.5814, -2.6426, -2.6304, -2.6450, -2.6355, -2.6420, -2.6356,\n",
      "        -2.6419, -2.5352, -2.6453, -2.5594, -2.6344, -2.6175, -2.6043, -2.6420,\n",
      "        -2.6265, -2.6436, -2.6198, -2.6314, -2.6439, -2.6418, -2.6424, -2.6419,\n",
      "        -2.6018, -2.6293, -2.6442, -2.6220, -2.6213, -2.6431, -2.6353, -2.6115,\n",
      "        -2.6419, -2.5794, -2.6442, -2.6370, -2.6447, -2.6057, -2.6440, -2.6355,\n",
      "        -2.6345, -2.6449, -2.6480, -2.6267, -2.6182, -2.5906, -2.6280, -2.6428,\n",
      "        -2.6364, -2.6451], device='mps:0')\n",
      "mean: tensor(-2.6277, device='mps:0')\n",
      "iter_dt 1.02s; iter 90: train loss 0.79565 temperature: 9.50000000000001\n",
      "mean_logits tensor([-2.6102, -2.5091, -2.5865, -2.7542, -3.0444, -2.6707, -2.8567, -2.3132,\n",
      "        -2.2856, -2.3810, -2.5535, -2.3387, -2.4771, -2.5585, -2.6665, -2.7351,\n",
      "        -2.3203, -2.5031, -2.6508, -2.5914, -2.4583, -2.6998, -2.4035, -2.4461,\n",
      "        -2.7614, -2.5187, -2.4322, -2.7180, -2.6696, -2.7643, -2.7165, -2.5723,\n",
      "        -2.8817, -2.5758, -2.6846, -2.2691, -2.6887, -2.6172, -2.8437, -2.8033,\n",
      "        -2.6967, -2.6126, -2.7744, -2.9275, -2.4784, -2.7844, -2.5210, -2.6189,\n",
      "        -2.4226, -2.4692], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6448, -2.6433, -2.6272, -2.6353, -2.5885, -2.6452, -2.6318, -2.5763,\n",
      "        -2.6299, -2.6445, -2.6443, -2.6453, -2.5923, -2.6451, -2.6406, -2.6115,\n",
      "        -2.6293, -2.6230, -2.6454, -2.6450, -2.5809, -2.6335, -2.6444, -2.6446,\n",
      "        -2.6355, -2.6059, -2.6355, -2.5943, -2.4965, -2.6364, -2.6446, -2.6449,\n",
      "        -2.6453, -2.6455, -2.6376, -2.6362, -2.6334, -2.6451, -2.6469, -2.6453,\n",
      "        -2.6363, -2.6359, -2.6220, -2.6448, -2.6418, -2.6423, -2.6102, -2.6442,\n",
      "        -2.5846, -2.6447], device='mps:0')\n",
      "mean: tensor(-2.6286, device='mps:0')\n",
      "iter_dt 1.02s; iter 91: train loss 0.53081 temperature: 9.550000000000011\n",
      "mean_logits tensor([-2.6326, -2.5209, -2.4721, -2.3810, -2.4432, -2.5926, -2.3447, -2.9324,\n",
      "        -2.5168, -2.5901, -2.7897, -2.8311, -2.5489, -2.6365, -2.4661, -2.7824,\n",
      "        -2.5627, -2.7167, -2.7776, -2.5937, -2.7222, -2.6173, -2.7622, -2.4588,\n",
      "        -2.5506, -2.6766, -2.5120, -2.6176, -2.6396, -2.5428, -2.5905, -2.6370,\n",
      "        -2.6032, -2.5050, -2.5194, -2.6043, -2.7671, -2.6116, -2.7051, -2.5813,\n",
      "        -2.6217, -2.6533, -2.6144, -2.5847, -2.4656, -2.2643, -2.5248, -2.0249,\n",
      "        -2.6751, -2.3764], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6444, -2.5871, -2.6351, -2.6373, -2.6268, -2.6446, -2.6110, -2.6433,\n",
      "        -2.6117, -2.6269, -2.6452, -2.6448, -2.6423, -2.6354, -2.6320, -2.6337,\n",
      "        -2.6448, -2.6005, -2.6434, -2.6450, -2.6358, -2.6368, -2.6319, -2.6252,\n",
      "        -2.6416, -2.6416, -2.6043, -2.6446, -2.6288, -2.6279, -2.6444, -2.6337,\n",
      "        -2.6360, -2.6325, -2.5605, -2.6443, -2.6141, -2.5848, -2.6441, -2.6413,\n",
      "        -2.6453, -2.6355, -2.6452, -2.6432, -2.6455, -2.6447, -2.6457, -2.6453,\n",
      "        -2.5833, -2.6356], device='mps:0')\n",
      "mean: tensor(-2.6312, device='mps:0')\n",
      "iter_dt 1.02s; iter 92: train loss 0.49499 temperature: 9.600000000000012\n",
      "mean_logits tensor([-2.6212, -2.4043, -2.6511, -2.7660, -2.5811, -2.5595, -2.8602, -2.4872,\n",
      "        -2.6763, -2.5494, -2.6751, -2.4785, -2.5062, -2.7051, -2.4349, -2.7073,\n",
      "        -2.6153, -2.5710, -2.6386, -2.6089, -2.5831, -2.4990, -2.4520, -2.6652,\n",
      "        -2.6119, -2.3414, -2.4493, -2.5708, -2.5227, -2.5753, -2.5200, -2.4698,\n",
      "        -2.5617, -2.1937, -2.4405, -2.6787, -2.6224, -2.7827, -2.6607, -2.3578,\n",
      "        -2.3199, -2.5924, -2.3233, -2.2824, -2.5798, -2.5635, -2.6043, -2.4895,\n",
      "        -2.5942, -2.5737], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6252, -2.6269, -2.6351, -2.6268, -2.6369, -2.6434, -2.6446, -2.6449,\n",
      "        -2.6444, -2.6453, -2.6226, -2.6427, -2.5657, -2.6429, -2.6453, -2.6176,\n",
      "        -2.6350, -2.5489, -2.6367, -2.6387, -2.6443, -2.6422, -2.6364, -2.6324,\n",
      "        -2.6447, -2.6438, -2.5769, -2.6361, -2.6448, -2.6321, -2.6293, -2.6555,\n",
      "        -2.5857, -2.6443, -2.6454, -2.6362, -2.6444, -2.6430, -2.6451, -2.6437,\n",
      "        -2.5838, -2.6198, -2.6190, -2.6436, -2.6447, -2.6346, -2.6407, -2.6488,\n",
      "        -2.6450, -2.6452], device='mps:0')\n",
      "mean: tensor(-2.6320, device='mps:0')\n",
      "iter_dt 1.05s; iter 93: train loss 0.51657 temperature: 9.650000000000013\n",
      "mean_logits tensor([-2.4749, -2.8539, -2.7993, -2.4563, -2.5524, -2.3262, -2.5707, -2.5750,\n",
      "        -2.5020, -2.7523, -2.5039, -2.6048, -2.6716, -2.6919, -2.6071, -2.5652,\n",
      "        -2.5711, -2.5774, -2.6848, -2.6740, -2.5839, -2.4268, -2.6320, -2.4779,\n",
      "        -2.8397, -2.4248, -2.3018, -2.5709, -2.5718, -2.5444, -2.2744, -2.7660,\n",
      "        -2.3766, -2.4725, -2.4119, -2.7314, -2.7979, -2.6567, -2.6471, -2.4666,\n",
      "        -2.6968, -2.7403, -2.5806, -2.7229, -2.5141, -2.8372, -2.6730, -2.8407,\n",
      "        -2.6070, -2.7566], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6256, -2.6456, -2.6266, -2.6445, -2.6458, -2.6300, -2.6457, -2.6431,\n",
      "        -2.6275, -2.6452, -2.6439, -2.6260, -2.6433, -2.6272, -2.6442, -2.5882,\n",
      "        -2.6440, -2.6434, -2.6431, -2.6341, -2.6281, -2.6264, -2.6354, -2.6390,\n",
      "        -2.6451, -2.6248, -2.6269, -2.6439, -2.6353, -2.6466, -2.6447, -2.5974,\n",
      "        -2.6437, -2.6436, -2.6351, -2.6445, -2.6148, -2.5723, -2.6444, -2.6104,\n",
      "        -2.6415, -2.6437, -2.6444, -2.6428, -2.5568, -2.6433, -2.6285, -2.6400,\n",
      "        -2.6030, -2.6344], device='mps:0')\n",
      "mean: tensor(-2.6320, device='mps:0')\n",
      "iter_dt 1.01s; iter 94: train loss 0.50025 temperature: 9.700000000000014\n",
      "mean_logits tensor([-2.5496, -2.6306, -2.4511, -2.6980, -2.5636, -2.6434, -2.7231, -2.5701,\n",
      "        -2.4066, -2.5000, -2.9263, -2.6939, -2.7607, -2.6334, -2.6878, -2.6146,\n",
      "        -2.5459, -2.5305, -2.4078, -2.8245, -2.4840, -2.5091, -2.5302, -2.6561,\n",
      "        -2.2385, -2.5398, -2.6235, -2.5345, -2.4907, -2.7772, -2.4524, -2.6751,\n",
      "        -2.6671, -2.6125, -2.7409, -2.3765, -2.2537, -2.3534, -2.5062, -2.4527,\n",
      "        -2.4792, -2.6207, -2.6926, -2.7415, -2.7006, -2.7119, -2.6758, -2.7241,\n",
      "        -2.4645, -2.5280], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6450, -2.6446, -2.6358, -2.6346, -2.6444, -2.6453, -2.6359, -2.6454,\n",
      "        -2.5796, -2.6053, -2.6456, -2.6322, -2.6242, -2.6452, -2.6447, -2.6356,\n",
      "        -2.6117, -2.6415, -2.6448, -2.5721, -2.6302, -2.6225, -2.5754, -2.6437,\n",
      "        -2.6058, -2.6427, -2.6447, -2.6433, -2.6316, -2.5783, -2.6043, -2.6233,\n",
      "        -2.6430, -2.6058, -2.6450, -2.6392, -2.6400, -2.6234, -2.6195, -2.6270,\n",
      "        -2.6391, -2.6106, -2.5817, -2.6355, -2.6443, -2.6291, -2.6448, -2.6443,\n",
      "        -2.6467, -2.6443], device='mps:0')\n",
      "mean: tensor(-2.6285, device='mps:0')\n",
      "iter_dt 1.02s; iter 95: train loss 0.66262 temperature: 9.750000000000014\n",
      "mean_logits tensor([-2.6994, -2.6047, -2.9416, -2.4571, -2.6390, -2.6469, -2.5306, -2.5770,\n",
      "        -2.4928, -2.7983, -2.6957, -2.4614, -2.2961, -2.5862, -2.6490, -2.6226,\n",
      "        -2.4287, -2.5102, -2.3954, -2.4483, -2.8181, -2.4737, -2.5973, -2.5360,\n",
      "        -2.4391, -2.3338, -2.6470, -2.6329, -2.7225, -2.5885, -2.4988, -2.3302,\n",
      "        -2.6854, -2.4667, -2.6960, -2.8895, -2.7708, -2.6472, -2.4006, -2.8606,\n",
      "        -2.6310, -2.5820, -2.6552, -2.4794, -2.2930, -2.9093, -2.6945, -2.3841,\n",
      "        -2.4997, -2.5991], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6434, -2.6319, -2.6450, -2.6450, -2.6439, -2.6427, -2.6032, -2.6438,\n",
      "        -2.6455, -2.6443, -2.6431, -2.6342, -2.6445, -2.6449, -2.6447, -2.5841,\n",
      "        -2.6293, -2.6419, -2.6294, -2.6396, -2.6449, -2.6381, -2.6418, -2.6450,\n",
      "        -2.6444, -2.6369, -2.6456, -2.6449, -2.6452, -2.6362, -2.6341, -2.6443,\n",
      "        -2.6218, -2.6450, -2.5824, -2.6363, -2.6349, -2.6455, -2.6421, -2.6437,\n",
      "        -2.6286, -2.6454, -2.6449, -2.6345, -2.6237, -2.6453, -2.6363, -2.6442,\n",
      "        -2.6447, -2.6434], device='mps:0')\n",
      "mean: tensor(-2.6374, device='mps:0')\n",
      "iter_dt 1.01s; iter 96: train loss 0.39766 temperature: 9.800000000000015\n",
      "mean_logits tensor([-2.5316, -2.6239, -2.7208, -2.7799, -2.6458, -2.7572, -2.5507, -2.5954,\n",
      "        -2.6720, -2.6963, -2.7149, -2.5431, -2.4765, -2.5488, -2.6167, -2.6142,\n",
      "        -2.4279, -2.6047, -2.5715, -2.4942, -2.6602, -2.7647, -2.4418, -2.4635,\n",
      "        -2.6672, -2.6111, -2.5162, -2.6801, -2.5210, -2.6700, -2.6127, -2.5699,\n",
      "        -2.7598, -2.2458, -2.4788, -2.8149, -2.6158, -2.4845, -2.6572, -2.6121,\n",
      "        -2.1439, -2.4917, -2.6513, -2.5772, -2.6786, -2.3937, -2.3779, -2.6893,\n",
      "        -2.6478, -2.6564], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6435, -2.6335, -2.6437, -2.6336, -2.6446, -2.6445, -2.6455, -2.5747,\n",
      "        -2.6413, -2.6451, -2.6076, -2.6047, -2.6048, -2.6448, -2.6414, -2.6439,\n",
      "        -2.6372, -2.6424, -2.5916, -2.6448, -2.6433, -2.6021, -2.6306, -2.6453,\n",
      "        -2.6290, -2.6395, -2.6289, -2.6412, -2.5889, -2.6448, -2.6350, -2.6255,\n",
      "        -2.6293, -2.6305, -2.6413, -2.6385, -2.6452, -2.6448, -2.6429, -2.6233,\n",
      "        -2.6294, -2.6256, -2.6259, -2.6449, -2.6364, -2.6409, -2.6417, -2.6383,\n",
      "        -2.6362, -2.6355], device='mps:0')\n",
      "mean: tensor(-2.6324, device='mps:0')\n",
      "iter_dt 1.02s; iter 97: train loss 0.61158 temperature: 9.850000000000016\n",
      "mean_logits tensor([-2.4925, -2.6546, -2.4464, -2.4644, -2.6125, -2.4005, -2.1580, -2.8293,\n",
      "        -2.7221, -2.5384, -2.2763, -2.4891, -2.9260, -2.7020, -2.7420, -2.8576,\n",
      "        -2.3503, -2.5738, -2.4870, -2.5816, -2.6365, -2.7245, -2.6015, -2.6942,\n",
      "        -2.5955, -2.3836, -2.5742, -2.5398, -2.5290, -2.5775, -2.7002, -2.7484,\n",
      "        -2.8202, -2.7295, -2.7816, -2.5343, -2.5615, -2.6357, -2.8591, -2.5406,\n",
      "        -2.5746, -2.5199, -2.7069, -2.6014, -2.5729, -2.3680, -2.6778, -2.5352,\n",
      "        -2.6176, -2.8201], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6287, -2.6555, -2.5649, -2.6425, -2.6439, -2.6032, -2.6431, -2.6454,\n",
      "        -2.6411, -2.6298, -2.6455, -2.6137, -2.6415, -2.6447, -2.6418, -2.6036,\n",
      "        -2.6421, -2.6439, -2.6342, -2.6369, -2.6184, -2.5785, -2.6406, -2.6452,\n",
      "        -2.6054, -2.6450, -2.6456, -2.6446, -2.6334, -2.6430, -2.6405, -2.5733,\n",
      "        -2.6302, -2.6453, -2.6407, -2.6450, -2.6271, -2.6045, -2.5750, -2.6029,\n",
      "        -2.6451, -2.6405, -2.6456, -2.6310, -2.6418, -2.6451, -2.6363, -2.5967,\n",
      "        -2.6271, -2.6459], device='mps:0')\n",
      "mean: tensor(-2.6297, device='mps:0')\n",
      "iter_dt 1.03s; iter 98: train loss 0.56392 temperature: 9.900000000000016\n",
      "mean_logits tensor([-2.4936, -2.4277, -2.3477, -2.6471, -2.5827, -2.4061, -2.6555, -2.6778,\n",
      "        -2.4956, -2.3933, -2.4412, -2.6227, -2.3839, -2.5725, -2.6201, -2.4381,\n",
      "        -2.8147, -2.5353, -2.4914, -2.5387, -2.2270, -2.5108, -2.5671, -2.7102,\n",
      "        -2.4799, -2.6376, -2.3835, -2.5091, -2.7010, -2.4960, -2.7597, -2.7680,\n",
      "        -2.2739, -2.7010, -2.4777, -2.4666, -2.7052, -2.5670, -2.7475, -2.6551,\n",
      "        -2.5988, -2.4005, -2.7039, -2.6989, -2.5952, -2.3690, -2.8480, -2.3075,\n",
      "        -2.4515, -2.6549], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5489, -2.6323, -2.6237, -2.6467, -2.6405, -2.6416, -2.6409, -2.6361,\n",
      "        -2.6366, -2.6349, -2.6411, -2.6453, -2.6173, -2.6291, -2.6453, -2.6344,\n",
      "        -2.6444, -2.5835, -2.6436, -2.6147, -2.6245, -2.6434, -2.6431, -2.6115,\n",
      "        -2.6232, -2.6441, -2.6442, -2.5461, -2.6411, -2.5861, -2.6441, -2.6449,\n",
      "        -2.6455, -2.6438, -2.6423, -2.6411, -2.6362, -2.6446, -2.6429, -2.6419,\n",
      "        -2.6395, -2.6452, -2.6452, -2.6265, -2.6451, -2.6162, -2.6447, -2.6365,\n",
      "        -2.6295, -2.6403], device='mps:0')\n",
      "mean: tensor(-2.6317, device='mps:0')\n",
      "iter_dt 1.02s; iter 99: train loss 0.64695 temperature: 9.950000000000017\n",
      "mean_logits tensor([-2.5806, -2.5266, -2.6574, -2.4984, -2.9044, -2.1968, -2.7500, -2.7086,\n",
      "        -2.5503, -2.6188, -2.8150, -2.5411, -2.5283, -2.3886, -2.5783, -2.6091,\n",
      "        -2.5550, -2.4956, -2.7381, -2.3671, -2.7357, -2.5496, -2.3580, -2.7537,\n",
      "        -2.5175, -2.6541, -2.6227, -2.8477, -2.3362, -2.4390, -2.6116, -2.7691,\n",
      "        -2.6019, -2.9957, -2.8107, -2.7845, -2.8059, -2.7155, -2.6636, -2.5543,\n",
      "        -2.7003, -2.6706, -2.4747, -2.5649, -2.5909, -2.8561, -2.3931, -2.5126,\n",
      "        -2.5374, -2.4689], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6296, -2.6282, -2.5891, -2.6426, -2.6442, -2.6450, -2.6447, -2.6335,\n",
      "        -2.6454, -2.6042, -2.6259, -2.6411, -2.5616, -2.6438, -2.6445, -2.6453,\n",
      "        -2.6351, -2.6420, -2.6446, -2.6361, -2.6341, -2.6447, -2.6297, -2.6441,\n",
      "        -2.6456, -2.6438, -2.6316, -2.6461, -2.6209, -2.5736, -2.6445, -2.6331,\n",
      "        -2.6322, -2.6446, -2.6373, -2.6178, -2.6447, -2.6446, -2.6410, -2.6449,\n",
      "        -2.5735, -2.6328, -2.6439, -2.6447, -2.6290, -2.6420, -2.6351, -2.6441,\n",
      "        -2.6286, -2.6330], device='mps:0')\n",
      "mean: tensor(-2.6326, device='mps:0')\n",
      "current_prefixes: [7278 4037 5557 4534 4632 6985  380 4805 4101 4404 4883  611  346 1045\n",
      " 2273 6235 5773 2879  256  465 6084 8286  375 5500  264  814   67 8921\n",
      "   67 4136 4385 6604  200 1773 2049 8494   86 3932 2808 2015 1661 1504\n",
      " 4149 1661 3803 8007 1292 4308  319 8336 4047 3188 2061  885 3979]\n",
      "layer: 12 starts running\n",
      "number of parameters: 91.99M\n",
      "running on device mps\n",
      "iter_dt 0.00s; iter 0: train loss 6.28537 temperature: 5\n",
      "mean_logits tensor([-1.7190, -1.9306, -2.1296, -1.9423, -1.7474, -2.0682, -1.9188, -2.1099,\n",
      "        -1.9104, -1.9127, -1.7472, -1.6945, -1.8924, -1.7892, -2.0215, -1.4584,\n",
      "        -1.7518, -2.2797, -1.7385, -1.9973, -1.8902, -1.6919, -1.8591, -2.1277,\n",
      "        -1.8523, -1.9876, -1.6955, -2.1645, -1.8346, -2.2735, -2.4732, -1.9021,\n",
      "        -1.9878, -2.0583, -2.0355, -1.6758, -1.6862, -1.6638, -1.8373, -2.1919,\n",
      "        -1.7612, -2.4361, -1.9884, -1.5677, -1.9416, -2.1310, -2.0165, -1.8728,\n",
      "        -2.1219, -1.9210], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5702, -2.6495, -2.6517, -2.6456, -2.6119, -2.6549, -2.6429, -2.5711,\n",
      "        -2.6546, -2.6555, -2.5404, -2.6386, -2.6434, -2.5830, -2.5987, -2.6478,\n",
      "        -2.6539, -2.3232, -2.6146, -2.6081, -2.6411, -2.5859, -2.6517, -2.5988,\n",
      "        -2.6085, -2.6398, -2.5875, -2.6358, -2.5527, -2.5977, -2.6558, -2.6535,\n",
      "        -2.6288, -2.5699, -2.5597, -2.5843, -2.5845, -2.5904, -2.6053, -2.6424,\n",
      "        -2.5361, -2.5709, -2.6408, -2.6441, -2.6552, -2.6537, -2.5916, -2.5873,\n",
      "        -2.6551, -2.6420], device='mps:0')\n",
      "mean: tensor(-2.6102, device='mps:0')\n",
      "iter_dt 1695864973.82s; iter 1: train loss 6.25791 temperature: 5.05\n",
      "mean_logits tensor([-1.7375, -2.0442, -2.3124, -1.6322, -2.4221, -1.7677, -1.7283, -1.8982,\n",
      "        -1.6340, -1.8537, -1.8490, -2.0416, -1.5764, -1.8335, -1.8817, -1.9674,\n",
      "        -1.8745, -1.9897, -1.7443, -1.9820, -2.2385, -1.9391, -1.7096, -2.1288,\n",
      "        -2.1486, -1.6412, -1.6324, -1.9879, -2.1157, -1.6719, -2.2155, -1.8592,\n",
      "        -2.1810, -2.2011, -1.8057, -2.2606, -1.9578, -2.2065, -1.8915, -1.8758,\n",
      "        -1.4522, -2.0495, -2.1153, -1.9750, -2.0853, -1.9638, -2.1556, -1.6643,\n",
      "        -2.0182, -2.0656], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5240, -2.6362, -2.6081, -2.6006, -2.6488, -2.5638, -2.6447, -2.6520,\n",
      "        -2.6539, -2.6041, -2.5849, -2.6238, -2.6526, -2.6554, -2.5755, -2.6101,\n",
      "        -2.6511, -2.5672, -2.5642, -2.6373, -2.6266, -2.6423, -2.6569, -2.5891,\n",
      "        -2.5742, -2.6027, -2.5814, -2.6538, -2.5935, -2.6548, -2.6502, -2.6483,\n",
      "        -2.6177, -2.6497, -2.5915, -2.6620, -2.6559, -2.5714, -2.6471, -2.6538,\n",
      "        -2.6545, -2.6150, -2.5735, -2.5623, -2.6254, -2.5995, -2.6363, -2.6202,\n",
      "        -2.6427, -2.6468], device='mps:0')\n",
      "mean: tensor(-2.6191, device='mps:0')\n",
      "iter_dt 1.09s; iter 2: train loss 6.29216 temperature: 5.1\n",
      "mean_logits tensor([-1.5857, -1.7233, -2.0881, -1.8234, -1.8285, -2.0769, -1.8393, -2.5193,\n",
      "        -1.7552, -2.1333, -1.8107, -1.5342, -1.7979, -1.7339, -1.8498, -2.3654,\n",
      "        -2.2728, -1.8802, -2.2708, -1.9441, -2.2908, -2.1520, -2.1781, -1.6069,\n",
      "        -2.3541, -1.7860, -1.6417, -1.7253, -1.8313, -1.7851, -1.9608, -1.6301,\n",
      "        -1.5440, -2.2170, -2.0135, -2.2449, -1.7024, -1.9495, -1.8372, -2.1233,\n",
      "        -1.8201, -1.9691, -2.0184, -1.9551, -1.9047, -2.0170, -1.7867, -1.8681,\n",
      "        -2.0767, -2.6998], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5890, -2.6014, -2.6295, -2.6266, -2.6391, -2.6111, -2.6251, -2.5821,\n",
      "        -2.6304, -2.5708, -2.6560, -2.5830, -2.6426, -2.6414, -2.6441, -2.6394,\n",
      "        -2.6347, -2.6476, -2.6381, -2.4935, -2.6436, -2.6555, -2.6522, -2.5989,\n",
      "        -2.5546, -2.6362, -2.6520, -2.5285, -2.6521, -2.5807, -2.5908, -2.6456,\n",
      "        -2.6408, -2.6326, -2.6553, -2.6518, -2.6385, -2.6487, -2.6150, -2.5577,\n",
      "        -2.6457, -2.6480, -2.5786, -2.6384, -2.6280, -2.6252, -2.6535, -2.6141,\n",
      "        -2.6497, -2.6489], device='mps:0')\n",
      "mean: tensor(-2.6217, device='mps:0')\n",
      "iter_dt 1.09s; iter 3: train loss 4.82487 temperature: 5.1499999999999995\n",
      "mean_logits tensor([-2.1937, -2.1417, -2.1217, -2.1478, -2.4358, -1.6508, -2.6099, -2.5849,\n",
      "        -1.9501, -1.8916, -1.9598, -1.8919, -1.8221, -2.3590, -1.7100, -1.9474,\n",
      "        -2.1867, -2.0009, -1.9721, -1.3605, -2.2201, -2.0389, -2.2547, -2.3865,\n",
      "        -1.8893, -2.4198, -2.1115, -2.4425, -1.6096, -2.0772, -1.9639, -2.0759,\n",
      "        -2.4052, -1.6484, -1.9844, -1.8495, -2.3110, -2.3229, -2.1599, -2.3712,\n",
      "        -1.5991, -2.3274, -1.8950, -2.3031, -2.0991, -2.1666, -2.2465, -1.9911,\n",
      "        -1.8728, -2.2414], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6560, -2.6542, -2.6394, -2.6444, -2.6545, -2.6167, -2.6099, -2.6436,\n",
      "        -2.6372, -2.6373, -2.6550, -2.6230, -2.6518, -2.6409, -2.6469, -2.6560,\n",
      "        -2.6198, -2.6397, -2.6496, -2.6208, -2.6442, -2.5924, -2.6207, -2.6367,\n",
      "        -2.6091, -2.6506, -2.5891, -2.6393, -2.6572, -2.6241, -2.6358, -2.6023,\n",
      "        -2.6392, -2.6501, -2.5711, -2.6536, -2.6480, -2.6557, -2.6207, -2.5646,\n",
      "        -2.6385, -2.6111, -2.6430, -2.6422, -2.6202, -2.6531, -2.5628, -2.6463,\n",
      "        -2.5810, -2.6007], device='mps:0')\n",
      "mean: tensor(-2.6300, device='mps:0')\n",
      "iter_dt 1.08s; iter 4: train loss 4.50320 temperature: 5.199999999999999\n",
      "mean_logits tensor([-2.2834, -1.8421, -2.3285, -2.0827, -2.2937, -2.1861, -1.8770, -2.5055,\n",
      "        -1.8787, -2.1070, -2.4376, -2.3525, -2.1061, -2.2096, -2.1890, -2.1795,\n",
      "        -1.8556, -1.8516, -2.4407, -1.9426, -2.2024, -2.0079, -2.0159, -2.1470,\n",
      "        -1.8308, -2.0530, -1.7955, -1.6706, -1.7510, -2.0262, -1.9737, -1.6068,\n",
      "        -2.2254, -1.9134, -1.6430, -2.1844, -2.0358, -1.9268, -2.1196, -2.4510,\n",
      "        -1.9677, -2.2993, -2.2821, -1.8955, -2.1017, -2.1641, -2.4807, -2.0540,\n",
      "        -1.9769, -2.4148], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6380, -2.6221, -2.6258, -2.6015, -2.6462, -2.6557, -2.5812, -2.6438,\n",
      "        -2.6428, -2.6349, -2.6597, -2.5861, -2.5757, -2.6000, -2.6415, -2.6513,\n",
      "        -2.6300, -2.5848, -2.6614, -2.5604, -2.6400, -2.6458, -2.6382, -2.6560,\n",
      "        -2.6463, -2.5728, -2.5954, -2.5995, -2.6085, -2.6381, -2.6335, -2.6104,\n",
      "        -2.6274, -2.5952, -2.6530, -2.5611, -2.6079, -2.6126, -2.6416, -2.6109,\n",
      "        -2.5715, -2.6442, -2.6427, -2.5406, -2.6428, -2.5576, -2.6560, -2.6463,\n",
      "        -2.5836, -2.6563], device='mps:0')\n",
      "mean: tensor(-2.6196, device='mps:0')\n",
      "iter_dt 1.09s; iter 5: train loss 4.55505 temperature: 5.249999999999999\n",
      "mean_logits tensor([-2.2146, -1.7024, -1.5221, -1.9884, -2.2132, -1.8252, -2.1328, -2.0937,\n",
      "        -2.2899, -2.0347, -2.3542, -2.1401, -2.3542, -2.5448, -1.9896, -2.1502,\n",
      "        -2.2472, -1.8767, -2.2734, -2.0512, -1.8385, -2.0330, -2.5801, -2.2337,\n",
      "        -2.1276, -1.8445, -1.6854, -2.1918, -2.0685, -2.1299, -2.2090, -2.5139,\n",
      "        -1.7699, -2.0178, -2.3410, -1.9057, -1.7311, -2.2183, -1.7568, -2.1364,\n",
      "        -2.1460, -2.0095, -2.7652, -2.2549, -2.0522, -1.9569, -1.9275, -2.4151,\n",
      "        -1.7057, -2.2583], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5519, -2.6194, -2.5932, -2.6475, -2.6449, -2.5947, -2.6519, -2.6267,\n",
      "        -2.6440, -2.6411, -2.6331, -2.5800, -2.6546, -2.6449, -2.5803, -2.6555,\n",
      "        -2.6471, -2.5614, -2.6507, -2.6534, -2.5937, -2.6566, -2.6419, -2.6175,\n",
      "        -2.6385, -2.6551, -2.5489, -2.6430, -2.6580, -2.6382, -2.5949, -2.6544,\n",
      "        -2.6555, -2.6559, -2.6513, -2.6392, -2.5993, -2.6078, -2.6556, -2.6128,\n",
      "        -2.6483, -2.6331, -2.6532, -2.5085, -2.6365, -2.6335, -2.5814, -2.6559,\n",
      "        -2.6295, -2.5264], device='mps:0')\n",
      "mean: tensor(-2.6240, device='mps:0')\n",
      "iter_dt 1.09s; iter 6: train loss 3.36218 temperature: 5.299999999999999\n",
      "mean_logits tensor([-1.7160, -2.4110, -2.5611, -2.3080, -2.1703, -2.0683, -2.4054, -1.8105,\n",
      "        -2.7712, -2.3409, -1.8840, -2.2650, -2.3385, -1.9169, -2.6733, -2.4120,\n",
      "        -2.0746, -2.4664, -2.0745, -1.6196, -2.8341, -2.0678, -2.1536, -2.3005,\n",
      "        -2.2855, -2.1572, -2.1994, -1.5980, -2.1715, -2.0837, -1.6020, -2.6845,\n",
      "        -2.0649, -2.3719, -1.9615, -2.1228, -2.7705, -2.6808, -1.9095, -2.8061,\n",
      "        -2.7786, -2.1426, -2.0771, -2.2432, -2.3889, -2.5190, -2.5233, -1.9068,\n",
      "        -2.3481, -2.0991], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5921, -2.6576, -2.6523, -2.6534, -2.5890, -2.6131, -2.6550, -2.6347,\n",
      "        -2.6426, -2.6409, -2.5928, -2.6502, -2.5461, -2.5752, -2.6461, -2.6157,\n",
      "        -2.6554, -2.5090, -2.6527, -2.6517, -2.6181, -2.6416, -2.6342, -2.6475,\n",
      "        -2.6307, -2.6218, -2.6518, -2.6556, -2.6252, -2.5888, -2.5752, -2.6443,\n",
      "        -2.5917, -2.6552, -2.6471, -2.6398, -2.6505, -2.5815, -2.5326, -2.6534,\n",
      "        -2.6502, -2.6278, -2.5902, -2.6080, -2.6564, -2.6439, -2.6465, -2.6194,\n",
      "        -2.6541, -2.6476], device='mps:0')\n",
      "mean: tensor(-2.6251, device='mps:0')\n",
      "iter_dt 1.09s; iter 7: train loss 3.40469 temperature: 5.349999999999999\n",
      "mean_logits tensor([-2.5468, -1.9221, -1.5132, -1.8466, -2.2223, -3.1615, -2.6607, -2.1140,\n",
      "        -2.1403, -2.2486, -2.2262, -1.7823, -2.5155, -1.8881, -2.3600, -2.5559,\n",
      "        -2.6295, -2.3025, -2.3526, -2.5950, -2.7256, -2.4184, -2.5635, -2.1343,\n",
      "        -2.6494, -2.1286, -1.9280, -1.9461, -3.0261, -2.3700, -1.9474, -2.5871,\n",
      "        -2.5367, -2.2509, -2.2270, -2.4978, -1.7567, -1.9169, -2.0903, -2.5521,\n",
      "        -2.8398, -2.1576, -2.4115, -2.0309, -1.8937, -2.7662, -2.6002, -2.1103,\n",
      "        -2.3472, -2.4523], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6159, -2.6324, -2.6346, -2.6528, -2.6424, -2.6392, -2.6558, -2.6531,\n",
      "        -2.6504, -2.6550, -2.6417, -2.6422, -2.6539, -2.6511, -2.6335, -2.5246,\n",
      "        -2.6431, -2.6563, -2.6554, -2.6120, -2.6551, -2.6455, -2.6419, -2.6252,\n",
      "        -2.6533, -2.6537, -2.5747, -2.6526, -2.5911, -2.5912, -2.6524, -2.6107,\n",
      "        -2.6384, -2.6563, -2.6284, -2.6562, -2.5896, -2.6516, -2.5758, -2.6561,\n",
      "        -2.5667, -2.6331, -2.5449, -2.6403, -2.6454, -2.6561, -2.6148, -2.6513,\n",
      "        -2.6498, -2.5541], device='mps:0')\n",
      "mean: tensor(-2.6300, device='mps:0')\n",
      "iter_dt 1.08s; iter 8: train loss 2.62388 temperature: 5.399999999999999\n",
      "mean_logits tensor([-2.6216, -2.5225, -2.9041, -2.5339, -2.3305, -3.0412, -2.7254, -2.0534,\n",
      "        -2.4018, -2.0781, -3.2226, -2.8897, -2.7325, -2.8899, -2.4228, -2.5683,\n",
      "        -2.0038, -2.9773, -2.8583, -2.5123, -1.9889, -2.3081, -2.3782, -2.5445,\n",
      "        -2.1256, -2.3444, -2.8386, -2.6952, -1.9108, -2.5940, -2.4516, -2.7980,\n",
      "        -2.7472, -2.5280, -2.3736, -2.5797, -2.2593, -2.0673, -2.5195, -2.9388,\n",
      "        -2.1645, -2.8155, -3.1257, -2.0536, -2.0557, -2.8643, -2.4294, -2.0083,\n",
      "        -2.7185, -3.1650], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6048, -2.6499, -2.6509, -2.6416, -2.6510, -2.6520, -2.6556, -2.6293,\n",
      "        -2.5592, -2.6079, -2.6481, -2.6508, -2.6388, -2.6173, -2.6453, -2.6554,\n",
      "        -2.6283, -2.6558, -2.6490, -2.6277, -2.6073, -2.6460, -2.6555, -2.6497,\n",
      "        -2.6269, -2.6553, -2.6558, -2.5845, -2.6544, -2.5659, -2.6073, -2.6536,\n",
      "        -2.6291, -2.6567, -2.4552, -2.6334, -2.5798, -2.6066, -2.6456, -2.6413,\n",
      "        -2.6401, -2.6456, -2.6561, -2.5850, -2.3843, -2.6490, -2.6410, -2.6046,\n",
      "        -2.5224, -2.6560], device='mps:0')\n",
      "mean: tensor(-2.6223, device='mps:0')\n",
      "iter_dt 1.10s; iter 9: train loss 3.40544 temperature: 5.449999999999998\n",
      "mean_logits tensor([-3.1125, -2.6040, -1.7451, -2.7422, -1.9279, -2.5506, -2.8177, -2.6091,\n",
      "        -2.5370, -2.3809, -2.2297, -2.9980, -2.6299, -2.0682, -2.4879, -2.7568,\n",
      "        -2.4697, -2.4967, -2.1505, -2.6172, -2.8275, -3.2129, -1.9039, -2.8217,\n",
      "        -2.6797, -2.2954, -2.1652, -2.1740, -2.1723, -2.3718, -2.8352, -2.8076,\n",
      "        -2.1606, -2.3965, -2.4593, -3.5115, -3.0072, -2.4439, -2.3231, -2.2073,\n",
      "        -2.6564, -2.2516, -3.0146, -2.3324, -2.0385, -2.5166, -2.6891, -2.5094,\n",
      "        -2.5815, -2.6896], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6463, -2.6560, -2.6348, -2.6534, -2.6355, -2.5968, -2.6551, -2.6560,\n",
      "        -2.6511, -2.6541, -2.5995, -2.6564, -2.5617, -2.6535, -2.6279, -2.6434,\n",
      "        -2.6349, -2.6236, -2.6452, -2.6515, -2.6390, -2.6560, -2.6482, -2.6560,\n",
      "        -2.6558, -2.5933, -2.6539, -2.6487, -2.5700, -2.6314, -2.6591, -2.6505,\n",
      "        -2.6344, -2.6391, -2.6087, -2.6559, -2.6163, -2.6066, -2.5215, -2.6527,\n",
      "        -2.6057, -2.6526, -2.6398, -2.6424, -2.6566, -2.6459, -2.6560, -2.6560,\n",
      "        -2.5783, -2.6418], device='mps:0')\n",
      "mean: tensor(-2.6342, device='mps:0')\n",
      "iter_dt 1.07s; iter 10: train loss 3.20001 temperature: 5.499999999999998\n",
      "mean_logits tensor([-1.9469, -1.9436, -2.9430, -2.4772, -2.4010, -2.1174, -2.2796, -2.2466,\n",
      "        -2.2672, -2.0539, -2.7404, -2.0926, -2.2784, -2.3372, -2.1573, -2.2802,\n",
      "        -2.6040, -2.5237, -2.3903, -2.3463, -2.7103, -2.8040, -2.8513, -2.8666,\n",
      "        -2.2357, -2.3876, -1.9737, -2.1078, -3.1206, -1.8565, -2.2936, -2.9326,\n",
      "        -2.9903, -2.7623, -2.1271, -2.1715, -2.8405, -3.1431, -2.8704, -2.2233,\n",
      "        -2.7819, -2.7461, -2.2559, -2.4416, -2.3965, -1.5698, -2.0158, -2.5004,\n",
      "        -3.1904, -2.6048], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6228, -2.6563, -2.6560, -2.6545, -2.6483, -2.6347, -2.6559, -2.5660,\n",
      "        -2.6314, -2.6529, -2.6455, -2.6527, -2.6561, -2.6548, -2.6435, -2.6314,\n",
      "        -2.6186, -2.6557, -2.5754, -2.6464, -2.5796, -2.6461, -2.6493, -2.6540,\n",
      "        -2.6508, -2.6572, -2.6046, -2.5918, -2.6551, -2.5875, -2.6394, -2.6506,\n",
      "        -2.6561, -2.6589, -2.6504, -2.6536, -2.5789, -2.6533, -2.6536, -2.5815,\n",
      "        -2.6517, -2.6535, -2.6070, -2.6430, -2.6541, -2.6034, -2.6494, -2.6110,\n",
      "        -2.6212, -2.6559], device='mps:0')\n",
      "mean: tensor(-2.6352, device='mps:0')\n",
      "iter_dt 1.08s; iter 11: train loss 3.13331 temperature: 5.549999999999998\n",
      "mean_logits tensor([-2.5700, -2.4407, -2.1174, -3.3550, -2.2944, -2.5751, -3.0603, -2.5004,\n",
      "        -2.3773, -2.3708, -2.4435, -1.9145, -2.0026, -2.4508, -2.1412, -2.6874,\n",
      "        -2.6728, -2.7057, -2.8091, -1.9988, -2.3933, -3.0133, -2.8920, -2.3166,\n",
      "        -2.1745, -2.6041, -2.0749, -2.0473, -2.6549, -2.3399, -2.6877, -2.4150,\n",
      "        -2.1497, -2.2521, -2.4404, -1.7553, -2.4035, -1.9343, -2.7206, -2.0146,\n",
      "        -2.7772, -1.9585, -2.0919, -2.1871, -3.1386, -2.5360, -2.5235, -2.7890,\n",
      "        -2.2642, -2.7838], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6434, -2.6504, -2.6254, -2.6559, -2.6464, -2.6452, -2.6542, -2.5874,\n",
      "        -2.5790, -2.5764, -2.6510, -2.6456, -2.6120, -2.5787, -2.6480, -2.6390,\n",
      "        -2.6452, -2.6560, -2.6533, -2.6362, -2.5062, -2.6482, -2.6565, -2.6097,\n",
      "        -2.6511, -2.6224, -2.6116, -2.6542, -2.6171, -2.6545, -2.5935, -2.6409,\n",
      "        -2.5896, -2.6492, -2.5713, -2.6560, -2.5776, -2.6498, -2.6555, -2.6418,\n",
      "        -2.6152, -2.5896, -2.6383, -2.6394, -2.5797, -2.5948, -2.6461, -2.6507,\n",
      "        -2.6388, -2.6564], device='mps:0')\n",
      "mean: tensor(-2.6267, device='mps:0')\n",
      "iter_dt 1.10s; iter 12: train loss 2.12124 temperature: 5.599999999999998\n",
      "mean_logits tensor([-2.3215, -2.5570, -2.4241, -3.0411, -2.5943, -2.5589, -2.5142, -2.5320,\n",
      "        -2.7904, -2.3110, -2.2087, -1.6290, -2.4899, -2.8727, -2.2483, -2.5010,\n",
      "        -1.7649, -2.6528, -2.6805, -2.6209, -2.3848, -2.8594, -2.5782, -3.1060,\n",
      "        -2.6609, -2.6986, -2.5984, -2.4941, -2.4507, -2.2569, -2.4728, -2.9043,\n",
      "        -2.7879, -2.3021, -2.3576, -2.4538, -2.3562, -3.0829, -1.8892, -2.1364,\n",
      "        -2.2042, -2.7447, -2.7406, -2.7334, -1.9245, -2.4843, -2.5540, -2.3302,\n",
      "        -2.6035, -1.9126], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6615, -2.5782, -2.6431, -2.6391, -2.6545, -2.6271, -2.5861, -2.6423,\n",
      "        -2.6527, -2.6118, -2.5920, -2.6399, -2.6356, -2.6509, -2.6386, -2.6545,\n",
      "        -2.6069, -2.5890, -2.6504, -2.6011, -2.6025, -2.5488, -2.6564, -2.6527,\n",
      "        -2.6074, -2.6551, -2.5621, -2.6388, -2.6543, -2.6359, -2.5594, -2.6561,\n",
      "        -2.5793, -2.6446, -2.6452, -2.6554, -2.6510, -2.6561, -2.6018, -2.6401,\n",
      "        -2.6536, -2.6422, -2.6174, -2.5838, -2.6562, -2.6496, -2.6448, -2.6500,\n",
      "        -2.6333, -2.5749], device='mps:0')\n",
      "mean: tensor(-2.6273, device='mps:0')\n",
      "iter_dt 1.09s; iter 13: train loss 2.12489 temperature: 5.649999999999998\n",
      "mean_logits tensor([-2.1435, -2.2993, -2.8635, -2.5556, -2.1523, -2.0224, -2.6877, -2.6210,\n",
      "        -2.0246, -2.5001, -3.0177, -2.0387, -2.6544, -2.3208, -2.7131, -1.9921,\n",
      "        -2.0373, -2.4224, -2.3021, -2.4539, -2.1608, -2.4019, -2.6461, -2.1918,\n",
      "        -2.0774, -2.6499, -2.6561, -2.4795, -2.3530, -1.5666, -2.4157, -2.4166,\n",
      "        -2.6647, -2.3621, -2.1126, -2.0340, -2.4381, -2.1682, -2.3531, -2.4162,\n",
      "        -2.7100, -2.4320, -2.6510, -2.8672, -2.7742, -2.3765, -2.1790, -2.8755,\n",
      "        -2.1383, -2.5440], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5988, -2.6109, -2.6411, -2.5880, -2.6562, -2.5231, -2.6530, -2.6003,\n",
      "        -2.6248, -2.6506, -2.5845, -2.6541, -2.6533, -2.6410, -2.6154, -2.6430,\n",
      "        -2.6101, -2.6211, -2.5236, -2.6515, -2.6504, -2.6401, -2.5523, -2.6516,\n",
      "        -2.6536, -2.5794, -2.6541, -2.6548, -2.5950, -2.6061, -2.6351, -2.6454,\n",
      "        -2.6325, -2.5601, -2.6469, -2.5838, -2.5311, -2.6270, -2.6500, -2.5634,\n",
      "        -2.5998, -2.6068, -2.6559, -2.6227, -2.6561, -2.6313, -2.6505, -2.6561,\n",
      "        -2.5772, -2.6147], device='mps:0')\n",
      "mean: tensor(-2.6186, device='mps:0')\n",
      "iter_dt 1.10s; iter 14: train loss 2.47865 temperature: 5.6999999999999975\n",
      "mean_logits tensor([-2.4615, -2.3707, -2.0520, -2.0123, -2.5403, -1.8140, -2.1559, -2.3665,\n",
      "        -2.3201, -2.3445, -2.4804, -2.1634, -2.7180, -2.4034, -2.1108, -2.0182,\n",
      "        -2.1091, -2.2064, -2.4164, -2.0378, -2.3435, -2.7568, -2.1698, -2.2405,\n",
      "        -1.9300, -2.1782, -2.1480, -2.5133, -2.4624, -2.3460, -2.6449, -2.0711,\n",
      "        -1.8313, -2.8007, -2.0798, -2.4082, -2.2806, -2.2671, -2.5393, -2.4210,\n",
      "        -1.8965, -2.0390, -2.6567, -2.6211, -2.3080, -2.7748, -2.7235, -2.3101,\n",
      "        -2.5160, -2.7610], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5499, -2.4307, -2.6555, -2.6419, -2.6500, -2.6489, -2.5693, -2.6413,\n",
      "        -2.6536, -2.5806, -2.6482, -2.6411, -2.6099, -2.6229, -2.6401, -2.6280,\n",
      "        -2.6486, -2.6425, -2.6496, -2.6491, -2.6066, -2.6463, -2.6546, -2.6326,\n",
      "        -2.5837, -2.6550, -2.6477, -2.6518, -2.6570, -2.6556, -2.6531, -2.6379,\n",
      "        -2.5853, -2.6512, -2.5193, -2.5990, -2.6529, -2.6277, -2.6334, -2.4397,\n",
      "        -2.6478, -2.6555, -2.5775, -2.5879, -2.6451, -2.6533, -2.6513, -2.6506,\n",
      "        -2.5673, -2.6508], device='mps:0')\n",
      "mean: tensor(-2.6216, device='mps:0')\n",
      "iter_dt 1.11s; iter 15: train loss 1.89520 temperature: 5.749999999999997\n",
      "mean_logits tensor([-2.6110, -2.3956, -2.6394, -2.4674, -2.6396, -2.7389, -2.3090, -2.4405,\n",
      "        -2.5179, -2.4757, -2.2899, -2.3687, -2.4332, -2.3396, -2.3906, -2.3472,\n",
      "        -2.4511, -2.2415, -2.3343, -2.1177, -2.0734, -2.1062, -2.5274, -2.2782,\n",
      "        -2.7118, -2.5010, -2.1906, -2.6554, -2.5485, -2.0670, -2.3591, -2.3898,\n",
      "        -2.3622, -3.1762, -2.5682, -2.0175, -2.2321, -2.1530, -2.4028, -2.1920,\n",
      "        -2.5959, -2.3822, -2.7068, -2.5657, -2.1516, -1.9685, -1.8476, -2.6991,\n",
      "        -2.6444, -2.4802], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6516, -2.6426, -2.6233, -2.6503, -2.6485, -2.6327, -2.5602, -2.5854,\n",
      "        -2.6458, -2.5762, -2.5881, -2.6264, -2.6553, -2.6212, -2.6365, -2.4906,\n",
      "        -2.6422, -2.6557, -2.5331, -2.6547, -2.6109, -2.5923, -2.6559, -2.6105,\n",
      "        -2.5226, -2.6455, -2.5979, -2.6526, -2.6561, -2.6421, -2.6558, -2.5289,\n",
      "        -2.6562, -2.5816, -2.6457, -2.5332, -2.6520, -2.6542, -2.6536, -2.5993,\n",
      "        -2.6417, -2.5792, -2.6101, -2.6463, -2.5836, -2.6423, -2.6377, -2.6516,\n",
      "        -2.6208, -2.6361], device='mps:0')\n",
      "mean: tensor(-2.6183, device='mps:0')\n",
      "iter_dt 1.11s; iter 16: train loss 2.53811 temperature: 5.799999999999997\n",
      "mean_logits tensor([-2.7778, -2.2902, -2.4488, -2.6024, -1.9073, -2.3538, -2.3889, -2.3538,\n",
      "        -2.1451, -2.4318, -2.4900, -2.4470, -1.8174, -2.6834, -2.1173, -2.6134,\n",
      "        -1.6330, -2.0090, -2.3937, -2.2991, -2.4075, -2.6224, -2.4807, -2.8624,\n",
      "        -2.4706, -2.0149, -2.3873, -2.2628, -2.1567, -2.0035, -2.3609, -2.1744,\n",
      "        -2.0036, -2.6342, -2.1732, -2.5855, -2.2891, -2.4299, -2.5338, -2.7896,\n",
      "        -1.9037, -2.4835, -2.0384, -2.7902, -2.6419, -2.4248, -2.2725, -2.0959,\n",
      "        -1.8728, -1.6767], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6512, -2.6380, -2.6431, -2.6522, -2.6072, -2.6019, -2.5952, -2.6121,\n",
      "        -2.5895, -2.6264, -2.5848, -2.6549, -2.5874, -2.6398, -2.6488, -2.6551,\n",
      "        -2.6526, -2.6108, -2.6448, -2.6457, -2.5982, -2.6538, -2.6372, -2.6438,\n",
      "        -2.5306, -2.6407, -2.6416, -2.5879, -2.6408, -2.6344, -2.6065, -2.6427,\n",
      "        -2.5886, -2.6147, -2.6356, -2.6509, -2.6517, -2.6461, -2.6220, -2.6357,\n",
      "        -2.5945, -2.6371, -2.6543, -2.6383, -2.6378, -2.5999, -2.6343, -2.6509,\n",
      "        -2.6533, -2.5884], device='mps:0')\n",
      "mean: tensor(-2.6267, device='mps:0')\n",
      "iter_dt 1.11s; iter 17: train loss 2.54253 temperature: 5.849999999999997\n",
      "mean_logits tensor([-2.4555, -2.7022, -2.6700, -2.1311, -2.6730, -2.1347, -2.5572, -2.1361,\n",
      "        -2.1774, -2.3845, -2.0492, -2.7202, -2.0153, -2.0641, -2.1929, -2.4605,\n",
      "        -2.5926, -2.6996, -2.2987, -2.1499, -2.4803, -2.3263, -1.8041, -2.2071,\n",
      "        -2.0926, -2.0415, -2.5163, -2.0199, -2.4976, -2.5005, -2.2027, -1.7457,\n",
      "        -2.3219, -2.3797, -2.0895, -2.4914, -2.1500, -2.3329, -2.4366, -2.2070,\n",
      "        -2.6608, -2.1848, -2.3687, -1.9163, -2.3008, -2.2291, -1.9153, -2.8322,\n",
      "        -1.9947, -2.1255], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5687, -2.6341, -2.6527, -2.6134, -2.6477, -2.6094, -2.5815, -2.5799,\n",
      "        -2.5565, -2.5938, -2.6037, -2.6358, -2.5467, -2.6387, -2.5851, -2.6260,\n",
      "        -2.6182, -2.6550, -2.5799, -2.5865, -2.6419, -2.6489, -2.6458, -2.6557,\n",
      "        -2.5966, -2.6542, -2.6480, -2.6321, -2.6132, -2.6307, -2.6507, -2.6149,\n",
      "        -2.6515, -2.6415, -2.5294, -2.6398, -2.6108, -2.5690, -2.6500, -2.6359,\n",
      "        -2.6525, -2.6396, -2.5846, -2.6482, -2.6517, -2.5742, -2.6276, -2.6296,\n",
      "        -2.6446, -2.5958], device='mps:0')\n",
      "mean: tensor(-2.6184, device='mps:0')\n",
      "iter_dt 1.12s; iter 18: train loss 2.70392 temperature: 5.899999999999997\n",
      "mean_logits tensor([-2.0246, -2.0679, -2.6374, -2.4068, -2.0112, -2.3705, -2.1703, -2.5100,\n",
      "        -2.7632, -1.8972, -2.4103, -2.2082, -2.5576, -2.5394, -2.0105, -2.6489,\n",
      "        -2.6280, -2.0062, -2.6065, -2.7911, -2.2845, -1.9482, -2.0828, -2.5326,\n",
      "        -2.0401, -2.2338, -2.4629, -2.4858, -2.0342, -2.3717, -2.4048, -2.7037,\n",
      "        -2.6097, -1.7561, -1.8874, -1.7093, -2.1038, -2.2137, -2.2936, -1.9420,\n",
      "        -2.5003, -2.2287, -1.9935, -2.1522, -2.3309, -2.4737, -2.3494, -2.2793,\n",
      "        -2.7013, -2.2505], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6470, -2.6528, -2.6385, -2.6493, -2.5997, -2.6505, -2.5780, -2.6468,\n",
      "        -2.6462, -2.6485, -2.5730, -2.6497, -2.6500, -2.6518, -2.6143, -2.6117,\n",
      "        -2.6393, -2.5334, -2.6413, -2.6364, -2.6266, -2.5550, -2.6358, -2.6536,\n",
      "        -2.6535, -2.6066, -2.6417, -2.6444, -2.5941, -2.5565, -2.6130, -2.6409,\n",
      "        -2.6232, -2.5895, -2.6337, -2.6095, -2.6441, -2.6405, -2.6339, -2.6555,\n",
      "        -2.6504, -2.6510, -2.6507, -2.6413, -2.6557, -2.6237, -2.6454, -2.6523,\n",
      "        -2.6313, -2.5612], device='mps:0')\n",
      "mean: tensor(-2.6275, device='mps:0')\n",
      "iter_dt 1.15s; iter 19: train loss 1.65612 temperature: 5.949999999999997\n",
      "mean_logits tensor([-2.0732, -2.3211, -2.8119, -2.5894, -2.4966, -2.6511, -2.6691, -1.8836,\n",
      "        -2.3941, -2.2124, -2.3742, -2.3753, -1.6830, -2.1023, -2.5550, -2.1823,\n",
      "        -2.4689, -2.2311, -2.3501, -2.4737, -2.1761, -2.6328, -2.2474, -2.6150,\n",
      "        -2.7253, -3.0517, -2.6066, -2.4228, -2.8030, -2.7855, -2.4611, -2.5126,\n",
      "        -2.9013, -2.8107, -2.4539, -2.6891, -2.5864, -2.5676, -2.5748, -2.4297,\n",
      "        -2.4750, -2.7109, -2.2984, -2.2621, -2.6479, -2.4576, -2.7488, -2.0896,\n",
      "        -2.6523, -2.2523], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6312, -2.5988, -2.6315, -2.6474, -2.6511, -2.6452, -2.6516, -2.6482,\n",
      "        -2.6315, -2.6557, -2.6455, -2.6402, -2.6324, -2.6451, -2.6536, -2.6421,\n",
      "        -2.6418, -2.6371, -2.6319, -2.6320, -2.6493, -2.5817, -2.6306, -2.6421,\n",
      "        -2.6420, -2.6462, -2.6508, -2.6410, -2.6550, -2.6499, -2.5650, -2.6395,\n",
      "        -2.6377, -2.6558, -2.5994, -2.5970, -2.6262, -2.6504, -2.6468, -2.6457,\n",
      "        -2.6506, -2.6516, -2.6434, -2.6438, -2.6508, -2.6483, -2.5517, -2.5955,\n",
      "        -2.6295, -2.6090], device='mps:0')\n",
      "mean: tensor(-2.6344, device='mps:0')\n",
      "iter_dt 1.09s; iter 20: train loss 1.91843 temperature: 5.9999999999999964\n",
      "mean_logits tensor([-2.4079, -2.5600, -1.9427, -2.5772, -2.0587, -2.4141, -2.6636, -2.1366,\n",
      "        -2.3614, -2.0642, -2.5388, -2.6580, -1.8924, -2.4305, -2.7158, -2.5388,\n",
      "        -2.4677, -2.1784, -2.8098, -2.9040, -2.7179, -2.6594, -2.4470, -2.7948,\n",
      "        -2.1345, -2.8434, -2.4609, -2.2636, -2.5704, -2.2371, -2.0636, -2.8287,\n",
      "        -2.2477, -2.0100, -2.4635, -2.3506, -2.9232, -2.5870, -2.1890, -2.0640,\n",
      "        -2.0637, -2.9388, -2.4392, -2.3005, -2.2648, -2.6940, -2.7181, -2.4284,\n",
      "        -2.6421, -2.5103], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6217, -2.6377, -2.6317, -2.6400, -2.6446, -2.6561, -2.6423, -2.6225,\n",
      "        -2.5796, -2.6528, -2.6340, -2.5866, -2.6255, -2.6367, -2.6407, -2.6068,\n",
      "        -2.6403, -2.6385, -2.6412, -2.6553, -2.6469, -2.6390, -2.4942, -2.6537,\n",
      "        -2.6224, -2.6394, -2.6468, -2.6213, -2.5799, -2.6553, -2.6589, -2.6069,\n",
      "        -2.6263, -2.6492, -2.6496, -2.6317, -2.6329, -2.6358, -2.5140, -2.6484,\n",
      "        -2.6543, -2.6286, -2.6117, -2.6434, -2.6137, -2.5970, -2.6465, -2.6453,\n",
      "        -2.6557, -2.5742], device='mps:0')\n",
      "mean: tensor(-2.6272, device='mps:0')\n",
      "iter_dt 1.12s; iter 21: train loss 2.00504 temperature: 6.049999999999996\n",
      "mean_logits tensor([-2.3550, -2.4050, -1.8953, -2.0538, -2.2675, -2.6990, -2.4148, -2.5900,\n",
      "        -3.2666, -2.2385, -2.6773, -2.2777, -2.3959, -2.4841, -2.5938, -2.5760,\n",
      "        -2.4522, -2.5820, -2.1367, -2.8367, -2.7127, -2.4276, -2.5332, -3.0671,\n",
      "        -2.4190, -2.0026, -2.5609, -1.9265, -2.4187, -2.2218, -2.4826, -2.6214,\n",
      "        -2.1820, -2.7520, -2.1505, -2.0877, -2.3819, -2.5931, -2.7496, -2.4410,\n",
      "        -2.2911, -2.0903, -2.6202, -2.8023, -2.6998, -2.5328, -2.3865, -2.5080,\n",
      "        -2.2424, -2.5450], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6558, -2.5871, -2.6373, -2.6103, -2.6347, -2.5807, -2.5900, -2.6484,\n",
      "        -2.6257, -2.6403, -2.5729, -2.5718, -2.6532, -2.5988, -2.6454, -2.6033,\n",
      "        -2.6371, -2.6378, -2.6440, -2.6482, -2.6286, -2.5706, -2.6443, -2.6381,\n",
      "        -2.6486, -2.6245, -2.6167, -2.5730, -2.5970, -2.6387, -2.6389, -2.6557,\n",
      "        -2.5846, -2.6263, -2.6512, -2.6199, -2.6330, -2.6269, -2.6291, -2.6340,\n",
      "        -2.5961, -2.5813, -2.6553, -2.6442, -2.5857, -2.6392, -2.5379, -2.6152,\n",
      "        -2.5986, -2.6428], device='mps:0')\n",
      "mean: tensor(-2.6200, device='mps:0')\n",
      "iter_dt 1.09s; iter 22: train loss 1.26212 temperature: 6.099999999999996\n",
      "mean_logits tensor([-2.2614, -2.5519, -1.9573, -2.6842, -2.5318, -2.5143, -2.5153, -2.7279,\n",
      "        -2.6742, -2.6776, -2.4077, -2.4468, -3.0512, -2.3163, -2.6015, -2.8514,\n",
      "        -2.3750, -2.7212, -2.4342, -2.7118, -2.1276, -2.0265, -2.6243, -2.3689,\n",
      "        -2.6871, -2.5889, -2.0484, -2.6741, -2.6992, -2.4889, -2.3361, -2.5233,\n",
      "        -2.7586, -2.2108, -2.6417, -2.5593, -2.4035, -2.7651, -2.7776, -2.4326,\n",
      "        -2.2552, -2.5733, -2.2689, -2.6682, -2.2370, -2.4287, -2.7004, -2.3131,\n",
      "        -2.7885, -2.8679], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5620, -2.6302, -2.6557, -2.5730, -2.6422, -2.6408, -2.6350, -2.6410,\n",
      "        -2.6479, -2.6511, -2.6495, -2.6414, -2.6305, -2.6294, -2.6244, -2.6443,\n",
      "        -2.6310, -2.6473, -2.6334, -2.5972, -2.6075, -2.6168, -2.5982, -2.6313,\n",
      "        -2.6414, -2.6487, -2.6523, -2.6041, -2.6394, -2.6377, -2.5945, -2.6554,\n",
      "        -2.6508, -2.6350, -2.6364, -2.5975, -2.6390, -2.5794, -2.5206, -2.6343,\n",
      "        -2.5837, -2.6276, -2.5835, -2.5840, -2.5845, -2.6258, -2.6438, -2.6207,\n",
      "        -2.6355, -2.6377], device='mps:0')\n",
      "mean: tensor(-2.6231, device='mps:0')\n",
      "iter_dt 1.12s; iter 23: train loss 1.49545 temperature: 6.149999999999996\n",
      "mean_logits tensor([-2.7846, -2.1083, -2.7506, -2.2615, -2.2590, -2.5125, -2.2947, -2.5301,\n",
      "        -2.3466, -2.2991, -2.7672, -2.3114, -2.0068, -2.4626, -2.6029, -2.2306,\n",
      "        -2.4224, -1.8916, -2.2918, -2.6046, -2.8142, -2.9388, -2.3595, -2.1971,\n",
      "        -2.6630, -2.4112, -2.6182, -2.1986, -2.2428, -2.5185, -2.5017, -2.5465,\n",
      "        -2.0633, -2.3470, -2.3636, -2.3813, -2.8150, -2.4223, -2.3387, -2.6948,\n",
      "        -2.6008, -2.5291, -2.4323, -2.6533, -2.6058, -2.1568, -2.6102, -2.2271,\n",
      "        -2.7276, -2.4202], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6410, -2.6412, -2.6320, -2.6498, -2.5808, -2.6466, -2.6052, -2.6455,\n",
      "        -2.6510, -2.5774, -2.6469, -2.6344, -2.6526, -2.5832, -2.6240, -2.6426,\n",
      "        -2.6602, -2.6207, -2.6494, -2.6377, -2.5675, -2.6483, -2.6083, -2.6035,\n",
      "        -2.6424, -2.5818, -2.5363, -2.6456, -2.5949, -2.6447, -2.6258, -2.6092,\n",
      "        -2.6472, -2.6502, -2.6333, -2.5991, -2.6434, -2.6283, -2.6294, -2.6417,\n",
      "        -2.6507, -2.5587, -2.6264, -2.6512, -2.5396, -2.5758, -2.6433, -2.5588,\n",
      "        -2.5739, -2.6299], device='mps:0')\n",
      "mean: tensor(-2.6202, device='mps:0')\n",
      "iter_dt 1.15s; iter 24: train loss 1.18551 temperature: 6.199999999999996\n",
      "mean_logits tensor([-2.8706, -2.4011, -2.8795, -2.1935, -2.7129, -2.4263, -2.4069, -2.5940,\n",
      "        -2.2544, -2.2395, -2.3052, -2.5407, -2.3141, -2.4362, -2.0521, -2.2887,\n",
      "        -2.8722, -2.6056, -2.5150, -2.6148, -2.7327, -2.4912, -2.7053, -2.5373,\n",
      "        -2.7120, -2.6324, -2.8837, -2.6608, -2.1623, -2.5965, -2.7701, -2.2744,\n",
      "        -2.7076, -2.6238, -2.8408, -2.5161, -2.6252, -2.8351, -2.9186, -2.4792,\n",
      "        -2.8159, -2.4959, -2.8010, -2.2310, -2.4563, -2.6419, -2.4164, -2.9626,\n",
      "        -2.3902, -2.7152], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6509, -2.6509, -2.6497, -2.5837, -2.6347, -2.6469, -2.6073, -2.5931,\n",
      "        -2.6145, -2.5888, -2.5890, -2.5975, -2.5941, -2.6458, -2.6493, -2.6547,\n",
      "        -2.6508, -2.6426, -2.5892, -2.5451, -2.6456, -2.6444, -2.5798, -2.6446,\n",
      "        -2.6352, -2.6365, -2.6501, -2.6509, -2.6427, -2.6488, -2.5814, -2.6269,\n",
      "        -2.6353, -2.6366, -2.6335, -2.6352, -2.6023, -2.6334, -2.5708, -2.6444,\n",
      "        -2.6378, -2.6549, -2.6302, -2.6537, -2.6018, -2.6467, -2.6509, -2.6218,\n",
      "        -2.6383, -2.6412], device='mps:0')\n",
      "mean: tensor(-2.6267, device='mps:0')\n",
      "iter_dt 1.13s; iter 25: train loss 1.45587 temperature: 6.249999999999996\n",
      "mean_logits tensor([-2.6694, -2.8344, -2.5548, -2.5327, -2.6476, -2.5247, -2.3101, -2.3787,\n",
      "        -2.3836, -2.5371, -2.8124, -2.3270, -2.6781, -2.4298, -2.6403, -2.9775,\n",
      "        -2.6389, -2.6668, -2.8699, -2.8130, -2.6250, -2.2565, -3.2433, -3.0581,\n",
      "        -2.7065, -2.4961, -2.6216, -2.5472, -2.5557, -2.6883, -2.3911, -2.4499,\n",
      "        -2.8712, -2.2935, -2.7553, -2.5342, -2.5629, -2.2314, -2.6555, -2.1519,\n",
      "        -2.7059, -2.4503, -2.8887, -2.7520, -2.9021, -2.4542, -2.5134, -2.9276,\n",
      "        -2.3950, -2.3234], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5941, -2.6420, -2.6347, -2.6276, -2.6331, -2.5778, -2.5177, -2.6089,\n",
      "        -2.6162, -2.6511, -2.6382, -2.6266, -2.6383, -2.6287, -2.6341, -2.6160,\n",
      "        -2.6191, -2.6464, -2.5734, -2.6476, -2.6143, -2.6384, -2.6245, -2.6501,\n",
      "        -2.6331, -2.5203, -2.6412, -2.6302, -2.5913, -2.6539, -2.6487, -2.6397,\n",
      "        -2.6391, -2.6412, -2.6505, -2.6383, -2.6291, -2.6475, -2.6371, -2.6033,\n",
      "        -2.5779, -2.6419, -2.6443, -2.6273, -2.6244, -2.6479, -2.6452, -2.6322,\n",
      "        -2.6045, -2.6352], device='mps:0')\n",
      "mean: tensor(-2.6245, device='mps:0')\n",
      "iter_dt 1.13s; iter 26: train loss 1.47172 temperature: 6.299999999999995\n",
      "mean_logits tensor([-2.2845, -2.6453, -2.2198, -2.6047, -1.8479, -2.4317, -2.9792, -2.4721,\n",
      "        -2.4639, -2.8973, -2.6392, -2.5839, -2.2386, -2.4870, -2.3914, -2.5455,\n",
      "        -2.6695, -2.5674, -2.9246, -2.2375, -2.3926, -2.5371, -2.6623, -2.6388,\n",
      "        -2.7040, -2.6957, -2.8013, -2.4115, -2.4598, -2.3767, -2.4956, -2.2266,\n",
      "        -2.8241, -2.5713, -3.0644, -2.4946, -2.2453, -2.0833, -2.1711, -2.4971,\n",
      "        -2.9756, -2.6742, -2.7568, -2.5877, -2.5440, -2.4978, -2.3747, -2.6654,\n",
      "        -2.3492, -2.4995], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5920, -2.5799, -2.6441, -2.6488, -2.5792, -2.5807, -2.6387, -2.6324,\n",
      "        -2.6409, -2.5815, -2.6479, -2.6394, -2.6385, -2.6368, -2.6129, -2.6503,\n",
      "        -2.6373, -2.5791, -2.6419, -2.6369, -2.5943, -2.6061, -2.5691, -2.6121,\n",
      "        -2.3525, -2.6389, -2.6333, -2.6508, -2.5740, -2.6564, -2.6511, -2.6356,\n",
      "        -2.6351, -2.6322, -2.6286, -2.6291, -2.6564, -2.6431, -2.6358, -2.6239,\n",
      "        -2.5859, -2.6340, -2.5627, -2.5915, -2.6240, -2.6360, -2.5563, -2.6466,\n",
      "        -2.6107, -2.6385], device='mps:0')\n",
      "mean: tensor(-2.6157, device='mps:0')\n",
      "iter_dt 1.12s; iter 27: train loss 1.56337 temperature: 6.349999999999995\n",
      "mean_logits tensor([-2.7662, -2.4767, -2.5361, -2.4365, -2.6352, -2.6539, -2.7031, -3.1142,\n",
      "        -3.0320, -2.6070, -2.5772, -2.8133, -2.3377, -2.2362, -2.1105, -2.4965,\n",
      "        -2.7231, -2.4723, -2.5742, -2.1805, -2.3487, -2.7748, -2.6242, -2.2951,\n",
      "        -2.3990, -2.4264, -2.3546, -2.7866, -2.3520, -2.3747, -2.2882, -2.6756,\n",
      "        -2.3388, -2.5880, -2.3696, -2.1231, -2.5433, -2.0806, -2.8214, -2.3318,\n",
      "        -2.6263, -2.0817, -2.6110, -2.6416, -2.4828, -2.7371, -2.7512, -2.2887,\n",
      "        -2.8710, -2.5135], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6345, -2.5251, -2.5762, -2.5618, -2.6494, -2.5889, -2.5762, -2.4707,\n",
      "        -2.6508, -2.6469, -2.6392, -2.6343, -2.6376, -2.6107, -2.6508, -2.5896,\n",
      "        -2.6476, -2.6418, -2.6554, -2.6004, -2.6375, -2.6069, -2.6383, -2.5874,\n",
      "        -2.6379, -2.6403, -2.6062, -2.6308, -2.6496, -2.6494, -2.6327, -2.6368,\n",
      "        -2.6372, -2.6300, -2.6461, -2.6556, -2.6419, -2.6564, -2.5578, -2.6489,\n",
      "        -2.6454, -2.6071, -2.6362, -2.6527, -2.6477, -2.6287, -2.5715, -2.5889,\n",
      "        -2.6363, -2.6344], device='mps:0')\n",
      "mean: tensor(-2.6213, device='mps:0')\n",
      "iter_dt 1.11s; iter 28: train loss 1.38050 temperature: 6.399999999999995\n",
      "mean_logits tensor([-2.7234, -2.6758, -2.6054, -2.7125, -2.3133, -2.8929, -2.5672, -2.4838,\n",
      "        -2.4853, -2.6890, -2.4511, -2.7148, -2.8468, -2.9277, -2.6948, -1.9981,\n",
      "        -2.9048, -2.4348, -2.5645, -2.6369, -2.7349, -2.8801, -2.4648, -2.8387,\n",
      "        -2.5117, -2.5104, -2.6812, -2.9944, -2.5097, -3.1034, -2.6068, -2.6260,\n",
      "        -2.7939, -2.2636, -2.7781, -2.4585, -2.2218, -2.4755, -2.8306, -2.3306,\n",
      "        -2.3655, -2.7816, -1.6312, -2.7231, -2.6928, -2.4796, -2.3789, -2.5352,\n",
      "        -2.5583, -2.6580], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6507, -2.5859, -2.5785, -2.5852, -2.6366, -2.6418, -2.6484, -2.6145,\n",
      "        -2.6467, -2.6408, -2.6463, -2.6324, -2.6312, -2.6246, -2.6500, -2.6514,\n",
      "        -2.6318, -2.6558, -2.6516, -2.6146, -2.6247, -2.5884, -2.5715, -2.6421,\n",
      "        -2.6312, -2.6343, -2.6466, -2.5581, -2.6291, -2.6461, -2.5683, -2.6038,\n",
      "        -2.6335, -2.6344, -2.6123, -2.6561, -2.6466, -2.6304, -2.6353, -2.5947,\n",
      "        -2.6258, -2.6481, -2.6070, -2.5800, -2.6052, -2.6282, -2.5816, -2.6347,\n",
      "        -2.6461, -2.6409], device='mps:0')\n",
      "mean: tensor(-2.6241, device='mps:0')\n",
      "iter_dt 1.10s; iter 29: train loss 1.10158 temperature: 6.449999999999995\n",
      "mean_logits tensor([-2.6890, -2.7485, -2.5158, -2.0996, -2.5780, -2.5914, -2.4674, -2.4819,\n",
      "        -2.6706, -2.6924, -2.8345, -2.3578, -2.7273, -2.5230, -2.6969, -2.7302,\n",
      "        -2.0725, -2.5666, -2.4203, -2.9464, -2.6066, -2.5789, -2.5713, -2.8480,\n",
      "        -2.5320, -2.4508, -2.3681, -2.7215, -2.6134, -2.8801, -2.5671, -2.5737,\n",
      "        -2.3649, -2.8032, -2.3742, -2.6405, -2.8240, -2.1337, -2.5616, -2.3644,\n",
      "        -2.8219, -2.2024, -2.4757, -2.6551, -2.1945, -2.3935, -2.3575, -1.9331,\n",
      "        -2.1578, -2.6105], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6393, -2.6484, -2.5285, -2.6134, -2.6422, -2.6374, -2.4941, -2.6285,\n",
      "        -2.6508, -2.6383, -2.6357, -2.6483, -2.6511, -2.6303, -2.6199, -2.6497,\n",
      "        -2.5971, -2.6470, -2.5844, -2.6120, -2.6060, -2.6391, -2.5798, -2.6369,\n",
      "        -2.6436, -2.5486, -2.6395, -2.6055, -2.6384, -2.6246, -2.6532, -2.5896,\n",
      "        -2.5995, -2.6311, -2.6257, -2.5654, -2.6304, -2.6347, -2.6531, -2.5777,\n",
      "        -2.6317, -2.5948, -2.6000, -2.6330, -2.6523, -2.6504, -2.5869, -2.6477,\n",
      "        -2.6501, -2.5652], device='mps:0')\n",
      "mean: tensor(-2.6186, device='mps:0')\n",
      "iter_dt 1.12s; iter 30: train loss 1.09855 temperature: 6.499999999999995\n",
      "mean_logits tensor([-2.4737, -2.2815, -2.3100, -2.6256, -2.3492, -2.4392, -2.6166, -2.7119,\n",
      "        -2.3831, -2.5630, -2.0370, -2.6331, -2.6288, -2.2510, -2.6684, -2.3160,\n",
      "        -2.6994, -2.6717, -2.4446, -2.5971, -2.8340, -2.6497, -2.4183, -2.5218,\n",
      "        -2.7188, -2.9111, -2.6488, -2.4281, -2.2805, -2.6042, -2.6147, -2.5519,\n",
      "        -2.4548, -2.8096, -2.3942, -2.6665, -2.4261, -2.1147, -2.4079, -2.8234,\n",
      "        -2.2980, -2.4294, -2.8210, -2.0646, -2.8987, -2.4684, -2.8712, -2.6772,\n",
      "        -2.3922, -2.6072], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5283, -2.6360, -2.6515, -2.6335, -2.6352, -2.6260, -2.5992, -2.6471,\n",
      "        -2.5889, -2.5537, -2.6449, -2.6317, -2.6290, -2.6369, -2.6370, -2.6523,\n",
      "        -2.6290, -2.6469, -2.6335, -2.5804, -2.6258, -2.6385, -2.6444, -2.6540,\n",
      "        -2.6110, -2.5836, -2.5919, -2.5781, -2.6039, -2.6507, -2.6356, -2.6512,\n",
      "        -2.6280, -2.6031, -2.6468, -2.6331, -2.5700, -2.5841, -2.5646, -2.5857,\n",
      "        -2.6557, -2.6493, -2.5741, -2.6558, -2.6442, -2.5973, -2.6481, -2.6310,\n",
      "        -2.6522, -2.5756], device='mps:0')\n",
      "mean: tensor(-2.6198, device='mps:0')\n",
      "iter_dt 1.12s; iter 31: train loss 0.92906 temperature: 6.5499999999999945\n",
      "mean_logits tensor([-2.6679, -2.4869, -2.9063, -2.9328, -2.5350, -2.8872, -2.5050, -2.6218,\n",
      "        -2.2593, -2.2803, -2.5351, -2.7949, -2.7406, -2.2809, -2.9175, -2.7146,\n",
      "        -2.9407, -2.3489, -2.3127, -2.5178, -2.4235, -2.5602, -2.5732, -2.5188,\n",
      "        -2.3923, -2.5061, -2.1532, -2.5662, -2.5520, -2.6610, -2.2339, -2.7244,\n",
      "        -2.7007, -2.4242, -2.5627, -2.7204, -2.6809, -2.6511, -2.6546, -2.5760,\n",
      "        -2.2781, -2.4495, -2.6690, -2.6349, -2.5964, -2.6910, -2.4402, -2.4801,\n",
      "        -2.4486, -2.4819], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6490, -2.6379, -2.6379, -2.6433, -2.6317, -2.5795, -2.6531, -2.5967,\n",
      "        -2.6485, -2.6383, -2.5955, -2.6475, -2.6338, -2.5313, -2.6374, -2.6286,\n",
      "        -2.6104, -2.6380, -2.6443, -2.6501, -2.6494, -2.6340, -2.6238, -2.6505,\n",
      "        -2.5739, -2.6457, -2.6369, -2.6510, -2.6464, -2.6462, -2.6542, -2.6491,\n",
      "        -2.6476, -2.6508, -2.6350, -2.6074, -2.6027, -2.6456, -2.5585, -2.6516,\n",
      "        -2.6397, -2.6106, -2.6481, -2.6500, -2.5788, -2.6508, -2.6448, -2.6502,\n",
      "        -2.5696, -2.6367], device='mps:0')\n",
      "mean: tensor(-2.6294, device='mps:0')\n",
      "iter_dt 1.09s; iter 32: train loss 1.20952 temperature: 6.599999999999994\n",
      "mean_logits tensor([-2.4341, -2.5014, -2.5733, -2.4228, -2.5322, -1.9891, -2.7576, -2.9454,\n",
      "        -2.3850, -2.7881, -2.6700, -2.4725, -2.3536, -2.3074, -2.7620, -2.5986,\n",
      "        -2.8586, -2.3281, -2.7304, -2.3549, -2.6391, -2.7699, -2.0335, -2.5124,\n",
      "        -2.6015, -2.2130, -2.7907, -2.7213, -2.9305, -2.7175, -2.6679, -2.4855,\n",
      "        -2.3740, -2.3767, -2.4423, -2.9470, -2.6841, -2.3045, -2.6350, -2.6761,\n",
      "        -2.2147, -2.6064, -2.6710, -2.5922, -2.5351, -2.3929, -2.1354, -2.6685,\n",
      "        -2.5134, -1.8315], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6281, -2.6373, -2.5708, -2.6442, -2.5820, -2.4920, -2.6372, -2.6325,\n",
      "        -2.5698, -2.6524, -2.6287, -2.6576, -2.6106, -2.6384, -2.6029, -2.6315,\n",
      "        -2.6271, -2.6298, -2.5444, -2.6563, -2.5685, -2.6336, -2.3834, -2.5463,\n",
      "        -2.6500, -2.6218, -2.6237, -2.6245, -2.5248, -2.6439, -2.6515, -2.6411,\n",
      "        -2.6283, -2.6451, -2.6446, -2.5841, -2.5661, -2.5740, -2.5257, -2.5745,\n",
      "        -2.6558, -2.5990, -2.6379, -2.6085, -2.6492, -2.6248, -2.6322, -2.6390,\n",
      "        -2.5698, -2.5939], device='mps:0')\n",
      "mean: tensor(-2.6068, device='mps:0')\n",
      "iter_dt 1.12s; iter 33: train loss 1.43604 temperature: 6.649999999999994\n",
      "mean_logits tensor([-3.0291, -2.7194, -3.1100, -2.2714, -2.2913, -2.6309, -2.1297, -2.3881,\n",
      "        -2.2560, -2.0380, -2.6093, -2.1736, -2.6476, -2.4012, -2.5648, -2.4366,\n",
      "        -2.5295, -2.6284, -2.6611, -2.4181, -2.5021, -2.5346, -2.3096, -2.6110,\n",
      "        -2.4170, -2.3364, -2.5791, -2.6661, -2.8769, -2.6285, -2.0466, -2.2637,\n",
      "        -2.4237, -2.3001, -2.7523, -2.6081, -2.3341, -2.6018, -2.5058, -2.3426,\n",
      "        -2.4966, -2.2272, -2.3834, -2.5663, -2.6620, -2.5254, -2.5779, -2.3368,\n",
      "        -2.7168, -2.4389], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6194, -2.6456, -2.6393, -2.6489, -2.6533, -2.6417, -2.6559, -2.5854,\n",
      "        -2.6369, -2.6440, -2.6469, -2.6465, -2.6487, -2.6508, -2.6449, -2.6110,\n",
      "        -2.6401, -2.5117, -2.6492, -2.6340, -2.6433, -2.5837, -2.6383, -2.6246,\n",
      "        -2.6567, -2.5887, -2.6460, -2.5817, -2.6445, -2.5707, -2.6354, -2.6028,\n",
      "        -2.5572, -2.6508, -2.6480, -2.6287, -2.6382, -2.6499, -2.5024, -2.6287,\n",
      "        -2.6483, -2.6384, -2.6368, -2.6436, -2.6429, -2.6427, -2.6561, -2.5876,\n",
      "        -2.5663, -2.6355], device='mps:0')\n",
      "mean: tensor(-2.6255, device='mps:0')\n",
      "iter_dt 1.14s; iter 34: train loss 1.37331 temperature: 6.699999999999994\n",
      "mean_logits tensor([-2.7807, -2.5896, -2.4908, -2.5263, -2.5673, -2.2756, -2.2221, -2.9858,\n",
      "        -2.6379, -2.4659, -2.5480, -2.3168, -2.1776, -2.6391, -2.3535, -2.3343,\n",
      "        -1.9173, -2.1837, -2.6053, -2.6198, -2.6983, -2.4690, -2.6610, -2.8634,\n",
      "        -2.3238, -2.6283, -2.3299, -2.2354, -2.4818, -2.3794, -2.2379, -2.7013,\n",
      "        -2.6053, -2.5424, -2.7336, -2.3991, -2.4792, -2.4109, -2.5664, -2.4794,\n",
      "        -2.0300, -2.4579, -2.0281, -2.3155, -2.4047, -2.8763, -2.6204, -2.3418,\n",
      "        -2.3440, -2.6230], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6443, -2.6440, -2.6513, -2.6378, -2.6509, -2.6530, -2.6099, -2.6387,\n",
      "        -2.5975, -2.5930, -2.6368, -2.6021, -2.6082, -2.5832, -2.6491, -2.5965,\n",
      "        -2.6540, -2.6558, -2.6443, -2.6482, -2.6464, -2.6544, -2.6521, -2.6361,\n",
      "        -2.6233, -2.5728, -2.6112, -2.5976, -2.6442, -2.6503, -2.6028, -2.6492,\n",
      "        -2.6396, -2.6444, -2.5035, -2.6065, -2.6421, -2.5990, -2.6504, -2.6308,\n",
      "        -2.6391, -2.6299, -2.6451, -2.6512, -2.6442, -2.6507, -2.6507, -2.6203,\n",
      "        -2.6375, -2.6274], device='mps:0')\n",
      "mean: tensor(-2.6290, device='mps:0')\n",
      "iter_dt 1.11s; iter 35: train loss 1.38074 temperature: 6.749999999999994\n",
      "mean_logits tensor([-2.8110, -2.2624, -2.4489, -2.6191, -2.2436, -2.6925, -2.7878, -2.7720,\n",
      "        -2.5477, -2.1963, -2.6409, -2.4320, -2.7792, -2.3041, -2.7016, -2.6076,\n",
      "        -2.2792, -2.3488, -2.7772, -2.6401, -2.7384, -1.8452, -2.4824, -2.3628,\n",
      "        -2.2548, -2.0242, -2.8719, -2.5723, -2.7930, -2.8369, -2.3393, -2.6089,\n",
      "        -2.3706, -2.5524, -2.4358, -2.4287, -2.3202, -3.0017, -2.1867, -2.6374,\n",
      "        -2.3894, -2.2789, -2.2757, -2.4682, -2.2138, -2.5918, -2.6922, -2.3359,\n",
      "        -2.2901, -2.7686], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6293, -2.5948, -2.6415, -2.6550, -2.6365, -2.5771, -2.6484, -2.6568,\n",
      "        -2.6505, -2.5992, -2.6254, -2.5694, -2.6211, -2.6137, -2.5881, -2.6397,\n",
      "        -2.6254, -2.6354, -2.6280, -2.6494, -2.6410, -2.5858, -2.6443, -2.6439,\n",
      "        -2.6358, -2.5806, -2.6372, -2.6441, -2.6379, -2.6384, -2.6389, -2.6203,\n",
      "        -2.6275, -2.5676, -2.6552, -2.6354, -2.6018, -2.5627, -2.6322, -2.6381,\n",
      "        -2.6363, -2.5279, -2.6395, -2.6349, -2.6284, -2.6436, -2.6477, -2.6515,\n",
      "        -2.6453, -2.6315], device='mps:0')\n",
      "mean: tensor(-2.6248, device='mps:0')\n",
      "iter_dt 1.13s; iter 36: train loss 1.03964 temperature: 6.799999999999994\n",
      "mean_logits tensor([-2.5300, -2.5183, -2.2319, -2.2357, -2.4744, -2.4944, -2.3945, -2.5019,\n",
      "        -2.4614, -2.3864, -2.3485, -2.2905, -2.5566, -2.5773, -2.5114, -2.3753,\n",
      "        -2.4015, -2.5335, -1.9276, -2.8771, -2.8714, -2.5051, -2.4699, -2.6566,\n",
      "        -2.5573, -2.3516, -2.1278, -2.6582, -2.4772, -2.7703, -2.3697, -2.5305,\n",
      "        -2.2410, -2.7359, -2.7193, -2.5892, -2.5213, -2.4299, -2.3119, -2.5732,\n",
      "        -2.4060, -2.7581, -2.4591, -2.4899, -2.5271, -2.2865, -2.4816, -2.3858,\n",
      "        -2.4255, -2.6455], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6478, -2.6352, -2.6466, -2.6310, -2.6539, -2.6395, -2.6345, -2.6435,\n",
      "        -2.5629, -2.6330, -2.6002, -2.6332, -2.6489, -2.6421, -2.6373, -2.6463,\n",
      "        -2.6356, -2.5913, -2.6528, -2.6465, -2.5853, -2.6396, -2.6294, -2.6354,\n",
      "        -2.6520, -2.5751, -2.6362, -2.6485, -2.5971, -2.6485, -2.6535, -2.6500,\n",
      "        -2.6145, -2.6488, -2.6352, -2.5486, -2.6368, -2.5879, -2.6511, -2.6480,\n",
      "        -2.6486, -2.6434, -2.6374, -2.5744, -2.6483, -2.6149, -2.5702, -2.6486,\n",
      "        -2.6260, -2.6259], device='mps:0')\n",
      "mean: tensor(-2.6284, device='mps:0')\n",
      "iter_dt 1.11s; iter 37: train loss 1.17602 temperature: 6.849999999999993\n",
      "mean_logits tensor([-2.8653, -2.5834, -2.1787, -2.8521, -2.7357, -2.2453, -2.3337, -2.2878,\n",
      "        -2.5603, -2.3494, -2.2880, -2.5148, -2.8328, -2.5148, -2.6976, -2.9516,\n",
      "        -2.3395, -2.3159, -2.3461, -2.2864, -2.5964, -2.2040, -2.4292, -2.6693,\n",
      "        -2.6180, -2.8764, -2.2160, -2.4037, -2.4943, -2.7515, -2.8179, -2.6185,\n",
      "        -2.2681, -2.7036, -2.4083, -2.7982, -2.4171, -2.5738, -2.4431, -2.3362,\n",
      "        -2.5148, -2.4744, -2.6392, -2.3740, -2.3515, -2.2534, -2.5079, -2.6765,\n",
      "        -2.4140, -2.8738], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6046, -2.6494, -2.5729, -2.6011, -2.6475, -2.6560, -2.3849, -2.6263,\n",
      "        -2.6417, -2.6539, -2.4940, -2.6406, -2.6510, -2.5704, -2.6169, -2.6050,\n",
      "        -2.6562, -2.6115, -2.6345, -2.5912, -2.6359, -2.6464, -2.6515, -2.6508,\n",
      "        -2.6361, -2.6471, -2.5703, -2.5492, -2.6407, -2.6289, -2.3867, -2.6365,\n",
      "        -2.5646, -2.6394, -2.6371, -2.6430, -2.6278, -2.6468, -2.6468, -2.6333,\n",
      "        -2.6456, -2.6268, -2.6390, -2.6494, -2.6508, -2.5571, -2.6380, -2.6331,\n",
      "        -2.6435, -2.6433], device='mps:0')\n",
      "mean: tensor(-2.6151, device='mps:0')\n",
      "iter_dt 1.09s; iter 38: train loss 0.88671 temperature: 6.899999999999993\n",
      "mean_logits tensor([-2.9269, -2.6294, -2.6096, -2.2401, -2.3552, -2.6743, -2.5105, -2.7265,\n",
      "        -2.9745, -2.6536, -2.2939, -2.4538, -2.7985, -2.6014, -2.6653, -2.5386,\n",
      "        -2.6362, -2.5935, -2.5108, -2.4763, -2.0275, -2.5083, -2.6001, -2.7678,\n",
      "        -2.3336, -2.5218, -2.2828, -2.7919, -2.5541, -2.3989, -2.5561, -2.7360,\n",
      "        -2.5764, -2.3630, -2.2688, -2.5966, -2.7176, -2.4613, -2.4832, -2.7142,\n",
      "        -2.4632, -2.4229, -2.2502, -2.6141, -2.6734, -2.6822, -2.2792, -2.1227,\n",
      "        -2.5504, -2.3840], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6398, -2.6417, -2.6363, -2.6192, -2.5493, -2.6284, -2.6321, -2.6108,\n",
      "        -2.6542, -2.6535, -2.5957, -2.6533, -2.6476, -2.6277, -2.6494, -2.5197,\n",
      "        -2.5527, -2.6065, -2.6189, -2.5009, -2.6509, -2.5589, -2.6469, -2.6364,\n",
      "        -2.6564, -2.6379, -2.5639, -2.6520, -2.6485, -2.5514, -2.6590, -2.6473,\n",
      "        -2.6537, -2.6468, -2.6471, -2.6453, -2.6382, -2.6564, -2.6060, -2.6485,\n",
      "        -2.6562, -2.6489, -2.6314, -2.6387, -2.6452, -2.6544, -2.6372, -2.6511,\n",
      "        -2.5982, -2.3773], device='mps:0')\n",
      "mean: tensor(-2.6206, device='mps:0')\n",
      "iter_dt 1.08s; iter 39: train loss 1.40249 temperature: 6.949999999999993\n",
      "mean_logits tensor([-2.2400, -2.7600, -2.5920, -2.5432, -2.5525, -2.5142, -2.1469, -2.6037,\n",
      "        -2.5417, -3.0437, -2.2539, -2.2885, -2.4824, -2.1592, -2.4855, -2.4014,\n",
      "        -2.4110, -2.7631, -2.3861, -2.5247, -2.0879, -2.4746, -2.4330, -2.2862,\n",
      "        -2.8330, -2.5417, -2.2979, -2.5250, -2.4525, -2.4422, -2.7683, -2.7047,\n",
      "        -2.2265, -2.5626, -2.7438, -1.9544, -2.4484, -2.2923, -2.3223, -2.4040,\n",
      "        -2.3598, -2.5898, -2.0014, -2.5452, -2.1684, -2.5546, -2.1211, -2.5310,\n",
      "        -2.6452, -2.6481], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6508, -2.5861, -2.6326, -2.6484, -2.5985, -2.5690, -2.6108, -2.6504,\n",
      "        -2.5671, -2.6552, -2.6440, -2.6317, -2.6531, -2.6296, -2.6265, -2.5040,\n",
      "        -2.6535, -2.6509, -2.6460, -2.6196, -2.6527, -2.6419, -2.5821, -2.5535,\n",
      "        -2.6557, -2.6091, -2.6375, -2.6483, -2.5477, -2.5363, -2.6300, -2.5892,\n",
      "        -2.6414, -2.6479, -2.6561, -2.6186, -2.6478, -2.6366, -2.6157, -2.6079,\n",
      "        -2.6440, -2.6476, -2.6475, -2.6212, -2.5892, -2.5936, -2.6392, -2.6022,\n",
      "        -2.6485, -2.6030], device='mps:0')\n",
      "mean: tensor(-2.6204, device='mps:0')\n",
      "iter_dt 1.10s; iter 40: train loss 1.32757 temperature: 6.999999999999993\n",
      "mean_logits tensor([-2.3747, -2.7306, -2.4576, -2.4766, -2.3161, -2.6386, -2.1702, -2.3460,\n",
      "        -2.5825, -2.4306, -2.5615, -2.9630, -2.3228, -2.4351, -2.1304, -2.3186,\n",
      "        -2.2936, -2.0323, -2.1566, -2.4767, -2.7050, -2.4328, -2.4448, -2.7802,\n",
      "        -2.2736, -2.3585, -2.8344, -2.5218, -2.1439, -2.5088, -2.2678, -2.6215,\n",
      "        -2.2297, -2.3071, -2.6270, -2.5347, -2.5888, -2.7753, -1.9846, -2.6558,\n",
      "        -2.1661, -2.4539, -2.6081, -2.6230, -2.1377, -2.4283, -2.5822, -2.6265,\n",
      "        -2.5028, -2.6037], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6477, -2.6472, -2.6366, -2.5481, -2.6532, -2.6505, -2.5776, -2.6436,\n",
      "        -2.6370, -2.6382, -2.5211, -2.6366, -2.6390, -2.6310, -2.5733, -2.6378,\n",
      "        -2.6412, -2.5744, -2.6446, -2.6398, -2.6303, -2.6151, -2.6400, -2.6516,\n",
      "        -2.6015, -2.5760, -2.6456, -2.6588, -2.6234, -2.6235, -2.5742, -2.6357,\n",
      "        -2.6442, -2.6295, -2.6393, -2.6034, -2.6475, -2.6476, -2.6334, -2.6454,\n",
      "        -2.6528, -2.5811, -2.6389, -2.6258, -2.6507, -2.5497, -2.6286, -2.6381,\n",
      "        -2.6155, -2.6460], device='mps:0')\n",
      "mean: tensor(-2.6242, device='mps:0')\n",
      "iter_dt 1.07s; iter 41: train loss 1.04246 temperature: 7.049999999999993\n",
      "mean_logits tensor([-2.7009, -1.9738, -2.5563, -2.1531, -2.5571, -2.7616, -2.7291, -2.0570,\n",
      "        -2.5503, -2.6004, -2.5079, -2.4793, -2.4492, -2.5723, -2.2350, -2.6132,\n",
      "        -2.2827, -2.5049, -2.7002, -2.5495, -2.4906, -2.5723, -2.4858, -2.6205,\n",
      "        -2.5019, -2.3032, -2.5435, -2.2388, -2.3718, -2.3728, -2.8799, -2.6135,\n",
      "        -2.4897, -2.4633, -2.7960, -2.5550, -2.3537, -2.3846, -2.6650, -2.4747,\n",
      "        -2.4484, -2.5957, -2.6869, -2.5894, -2.7867, -2.3385, -2.8214, -2.9059,\n",
      "        -2.2386, -2.3550], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6284, -2.6212, -2.6447, -2.6430, -2.6426, -2.5877, -2.5723, -2.6565,\n",
      "        -2.6399, -2.6122, -2.6435, -2.5678, -2.6164, -2.6501, -2.6566, -2.5644,\n",
      "        -2.6134, -2.6501, -2.5839, -2.5656, -2.6307, -2.5877, -2.6367, -2.5762,\n",
      "        -2.6525, -2.6509, -2.5636, -2.6559, -2.6302, -2.5831, -2.6343, -2.6475,\n",
      "        -2.6391, -2.5706, -2.6478, -2.6000, -2.6375, -2.6464, -2.6330, -2.6487,\n",
      "        -2.6381, -2.5983, -2.6484, -2.5813, -2.6342, -2.5478, -2.6386, -2.6401,\n",
      "        -2.6260, -2.6529], device='mps:0')\n",
      "mean: tensor(-2.6208, device='mps:0')\n",
      "iter_dt 1.07s; iter 42: train loss 1.38841 temperature: 7.0999999999999925\n",
      "mean_logits tensor([-2.4267, -2.3730, -2.7685, -2.3023, -2.8163, -2.7001, -2.8600, -2.3466,\n",
      "        -2.7677, -2.7152, -2.6737, -2.3589, -2.5460, -2.6919, -2.1563, -2.6329,\n",
      "        -2.5372, -2.8234, -2.4571, -2.8967, -2.3813, -2.6985, -2.3565, -2.2237,\n",
      "        -2.6830, -2.6936, -2.3706, -2.4036, -2.7602, -2.2403, -2.7232, -2.6191,\n",
      "        -2.7789, -2.4156, -2.6260, -2.3254, -1.9770, -2.0937, -2.8712, -2.1628,\n",
      "        -2.3331, -2.1195, -2.1514, -2.8824, -2.4310, -2.6330, -2.6084, -2.6309,\n",
      "        -2.6615, -2.5396], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6413, -2.6363, -2.6081, -2.6486, -2.6344, -2.5964, -2.5987, -2.6327,\n",
      "        -2.6475, -2.6398, -2.6075, -2.6562, -2.5817, -2.6421, -2.6257, -2.6516,\n",
      "        -2.6490, -2.5945, -2.6562, -2.6403, -2.6508, -2.6251, -2.6506, -2.6232,\n",
      "        -2.6405, -2.6095, -2.6489, -2.6250, -2.6361, -2.6316, -2.6483, -2.5946,\n",
      "        -2.6323, -2.6339, -2.6204, -2.6419, -2.6533, -2.6530, -2.5785, -2.5742,\n",
      "        -2.6503, -2.6423, -2.6415, -2.5958, -2.6425, -2.6198, -2.6519, -2.6340,\n",
      "        -2.6549, -2.6463], device='mps:0')\n",
      "mean: tensor(-2.6308, device='mps:0')\n",
      "iter_dt 1.18s; iter 43: train loss 1.32406 temperature: 7.149999999999992\n",
      "mean_logits tensor([-2.4401, -2.9425, -2.2378, -2.5781, -2.3340, -2.2385, -2.9052, -2.6612,\n",
      "        -2.4977, -2.9145, -2.4324, -2.5153, -2.6559, -3.0122, -2.6135, -2.1441,\n",
      "        -2.4904, -2.4580, -2.6711, -2.1845, -2.3055, -2.3013, -2.5139, -2.8767,\n",
      "        -2.7586, -2.1157, -2.3741, -2.6821, -2.2497, -2.2316, -2.5371, -2.3834,\n",
      "        -2.3447, -2.2286, -2.5673, -2.5423, -2.5232, -2.3783, -2.7619, -2.5359,\n",
      "        -2.3071, -2.7166, -2.4101, -2.8271, -2.4893, -2.7475, -2.7002, -2.7482,\n",
      "        -2.1881, -2.6952], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6397, -2.6524, -2.6556, -2.6178, -2.6517, -2.6527, -2.6566, -2.6257,\n",
      "        -2.6369, -2.5932, -2.6403, -2.5793, -2.6219, -2.5806, -2.6281, -2.6070,\n",
      "        -2.5759, -2.6560, -2.6066, -2.5915, -2.5979, -2.6291, -2.6460, -2.6552,\n",
      "        -2.6511, -2.5903, -2.5625, -2.5703, -2.6543, -2.6074, -2.6261, -2.6550,\n",
      "        -2.5784, -2.5856, -2.6452, -2.6485, -2.6328, -2.6531, -2.6460, -2.5880,\n",
      "        -2.5584, -2.6459, -2.6549, -2.6471, -2.6413, -2.6411, -2.6343, -2.6484,\n",
      "        -2.6432, -2.5638], device='mps:0')\n",
      "mean: tensor(-2.6234, device='mps:0')\n",
      "iter_dt 1.12s; iter 44: train loss 0.63510 temperature: 7.199999999999992\n",
      "mean_logits tensor([-2.4813, -2.5425, -2.6861, -2.4280, -2.7854, -2.3136, -2.7853, -2.8151,\n",
      "        -2.4487, -2.5228, -2.6677, -2.5117, -2.6226, -2.3583, -2.6001, -2.3051,\n",
      "        -2.5257, -2.6223, -2.5571, -2.8439, -2.5970, -2.5833, -2.6721, -2.5246,\n",
      "        -2.5843, -2.5612, -2.7753, -2.7175, -2.6464, -2.5785, -2.5422, -2.5899,\n",
      "        -2.5404, -2.0009, -2.6062, -2.5194, -2.6127, -2.4288, -2.7022, -2.5134,\n",
      "        -2.5958, -2.6496, -2.6643, -2.9626, -2.3760, -2.4033, -2.4435, -2.4060,\n",
      "        -2.5684, -2.3554], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6507, -2.6358, -2.6362, -2.6439, -2.6386, -2.6445, -2.6584, -2.6093,\n",
      "        -2.6551, -2.6258, -2.6344, -2.6260, -2.6217, -2.6391, -2.6504, -2.5226,\n",
      "        -2.6407, -2.6331, -2.6506, -2.6052, -2.6525, -2.6559, -2.6548, -2.5579,\n",
      "        -2.5807, -2.6229, -2.6366, -2.6484, -2.6553, -2.6011, -2.6363, -2.5986,\n",
      "        -2.6536, -2.6309, -2.6391, -2.6358, -2.6236, -2.6417, -2.6390, -2.6482,\n",
      "        -2.6474, -2.6092, -2.5656, -2.6513, -2.5678, -2.6522, -2.6139, -2.6558,\n",
      "        -2.6345, -2.6402], device='mps:0')\n",
      "mean: tensor(-2.6295, device='mps:0')\n",
      "iter_dt 1.14s; iter 45: train loss 1.24286 temperature: 7.249999999999992\n",
      "mean_logits tensor([-2.5037, -2.5997, -2.3589, -2.3386, -2.7196, -2.9650, -2.2975, -2.5711,\n",
      "        -2.8046, -2.4026, -2.0943, -2.7470, -2.3161, -2.6177, -2.7641, -2.2639,\n",
      "        -2.5424, -2.8754, -2.6550, -2.3946, -2.1574, -2.7635, -2.6802, -3.0803,\n",
      "        -2.6376, -2.9471, -2.5205, -2.1443, -2.4543, -2.5425, -2.6569, -2.4863,\n",
      "        -2.7368, -2.5034, -2.6972, -2.3086, -2.2566, -2.8240, -2.7008, -2.4833,\n",
      "        -2.4799, -2.7805, -2.5854, -2.7400, -2.9187, -2.5210, -2.8115, -2.2978,\n",
      "        -2.6152, -2.3431], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6356, -2.6086, -2.6094, -2.6551, -2.6334, -2.6512, -2.6452, -2.6174,\n",
      "        -2.6401, -2.6381, -2.6534, -2.6210, -2.5766, -2.6405, -2.6317, -2.6274,\n",
      "        -2.5761, -2.5984, -2.5550, -2.6508, -2.6256, -2.6482, -2.5953, -2.6290,\n",
      "        -2.6504, -2.6331, -2.5524, -2.6388, -2.6388, -2.6531, -2.6413, -2.6055,\n",
      "        -2.6217, -2.5863, -2.6270, -2.5973, -2.6483, -2.6418, -2.6493, -2.5899,\n",
      "        -2.6518, -2.6564, -2.6422, -2.6465, -2.6515, -2.6563, -2.6534, -2.5671,\n",
      "        -2.6145, -2.6398], device='mps:0')\n",
      "mean: tensor(-2.6264, device='mps:0')\n",
      "iter_dt 1.17s; iter 46: train loss 0.74816 temperature: 7.299999999999992\n",
      "mean_logits tensor([-2.6524, -2.5174, -2.0199, -2.3366, -2.5474, -2.6945, -2.6156, -2.3254,\n",
      "        -2.6595, -2.4095, -2.6385, -2.3728, -2.4343, -2.5241, -2.6531, -2.5097,\n",
      "        -2.5158, -2.6058, -2.6495, -2.7436, -2.8057, -2.6325, -2.5324, -2.3678,\n",
      "        -2.5168, -2.4709, -2.4776, -2.6538, -2.5049, -2.6896, -2.5745, -2.3944,\n",
      "        -2.3471, -2.8205, -2.5380, -2.4431, -2.4511, -2.3198, -2.0976, -2.4634,\n",
      "        -2.3896, -2.5814, -2.2095, -2.4713, -2.6420, -2.4822, -2.5997, -2.6980,\n",
      "        -2.2496, -2.5284], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6339, -2.6107, -2.4639, -2.6288, -2.6496, -2.6442, -2.6158, -2.6481,\n",
      "        -2.5784, -2.6446, -2.6388, -2.6432, -2.6378, -2.6432, -2.6511, -2.6294,\n",
      "        -2.6460, -2.5848, -2.6200, -2.6198, -2.6214, -2.6164, -2.6138, -2.6134,\n",
      "        -2.6296, -2.6258, -2.6319, -2.6414, -2.5760, -2.6398, -2.5811, -2.6397,\n",
      "        -2.5800, -2.5799, -2.6473, -2.6093, -2.6427, -2.6335, -2.6428, -2.6446,\n",
      "        -2.5818, -2.6276, -2.6511, -2.6435, -2.6547, -2.6131, -2.6476, -2.5876,\n",
      "        -2.6330, -2.5968], device='mps:0')\n",
      "mean: tensor(-2.6216, device='mps:0')\n",
      "iter_dt 1.13s; iter 47: train loss 0.73389 temperature: 7.349999999999992\n",
      "mean_logits tensor([-2.5416, -2.5797, -2.4521, -2.8717, -2.4794, -2.4906, -2.0574, -2.3556,\n",
      "        -2.4576, -2.6391, -2.5338, -2.7790, -2.5940, -2.3589, -2.2901, -2.6059,\n",
      "        -2.8823, -2.5597, -2.4045, -2.5197, -2.5235, -2.6522, -2.6793, -2.9255,\n",
      "        -2.7781, -2.3997, -2.3657, -2.6692, -2.6099, -2.6480, -2.5872, -2.7123,\n",
      "        -2.5341, -2.6611, -2.8347, -2.7419, -2.9335, -2.8385, -2.6563, -2.4856,\n",
      "        -2.6717, -2.8042, -2.6586, -2.6965, -2.6586, -2.7934, -2.6201, -2.7380,\n",
      "        -2.3582, -2.4414], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6469, -2.5680, -2.6560, -2.6517, -2.6466, -2.6429, -2.5391, -2.6513,\n",
      "        -2.6348, -2.6583, -2.6038, -2.6426, -2.6227, -2.6061, -2.5353, -2.6245,\n",
      "        -2.6313, -2.6010, -2.6171, -2.6113, -2.6510, -2.6488, -2.6271, -2.6340,\n",
      "        -2.6441, -2.5629, -2.6562, -2.6293, -2.6440, -2.5791, -2.6404, -2.6123,\n",
      "        -2.5768, -2.6535, -2.5559, -2.5890, -2.6275, -2.6124, -2.5875, -2.6353,\n",
      "        -2.6269, -2.6404, -2.5560, -2.5638, -2.6331, -2.5993, -2.6260, -2.6488,\n",
      "        -2.6347, -2.6383], device='mps:0')\n",
      "mean: tensor(-2.6185, device='mps:0')\n",
      "iter_dt 1.10s; iter 48: train loss 0.53934 temperature: 7.3999999999999915\n",
      "mean_logits tensor([-2.7867, -2.5925, -2.5385, -2.5769, -2.5103, -2.4512, -2.5034, -2.5145,\n",
      "        -2.8014, -2.5584, -2.6769, -2.5340, -2.8273, -2.7210, -2.3749, -2.5820,\n",
      "        -2.5802, -2.6646, -2.3836, -2.1024, -2.5330, -2.7735, -2.5841, -2.5077,\n",
      "        -2.5202, -2.3261, -2.5999, -2.6366, -2.4916, -2.3215, -2.5846, -2.6061,\n",
      "        -2.3481, -2.5791, -2.3802, -2.5032, -2.6955, -2.5877, -2.6850, -2.4750,\n",
      "        -2.6136, -2.4643, -2.6471, -2.4298, -2.4220, -2.8260, -2.7408, -2.4409,\n",
      "        -2.6627, -2.5361], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6223, -2.6512, -2.6364, -2.6401, -2.5825, -2.6203, -2.6566, -2.5991,\n",
      "        -2.6231, -2.6417, -2.5860, -2.6362, -2.6355, -2.6488, -2.6622, -2.6508,\n",
      "        -2.6478, -2.6373, -2.6055, -2.6523, -2.6357, -2.6506, -2.6465, -2.6541,\n",
      "        -2.6154, -2.6359, -2.6505, -2.6209, -2.6258, -2.5137, -2.6484, -2.6527,\n",
      "        -2.6467, -2.6504, -2.6179, -2.6383, -2.5986, -2.6252, -2.5837, -2.6463,\n",
      "        -2.6408, -2.6478, -2.6535, -2.5859, -2.5798, -2.6053, -2.6242, -2.5382,\n",
      "        -2.6403, -2.6342], device='mps:0')\n",
      "mean: tensor(-2.6269, device='mps:0')\n",
      "iter_dt 1.14s; iter 49: train loss 1.02978 temperature: 7.449999999999991\n",
      "mean_logits tensor([-2.2612, -2.2356, -2.5314, -2.5350, -2.3993, -2.9620, -2.6319, -2.7845,\n",
      "        -2.5796, -2.5076, -2.6310, -2.6593, -2.4307, -2.4954, -2.4297, -2.4710,\n",
      "        -2.7968, -2.5812, -2.7681, -2.5659, -2.5508, -2.4452, -2.7805, -2.8294,\n",
      "        -2.7930, -2.3947, -2.3144, -2.8229, -2.8490, -2.4801, -2.5633, -2.5181,\n",
      "        -2.3483, -2.7713, -2.4937, -2.4133, -2.3938, -2.8355, -2.7203, -2.4448,\n",
      "        -2.5927, -2.6841, -2.9890, -2.2921, -2.3939, -2.3081, -2.6327, -3.0258,\n",
      "        -2.4624, -2.5379], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6565, -2.6506, -2.6379, -2.6295, -2.6114, -2.6486, -2.6206, -2.6493,\n",
      "        -2.6434, -2.6521, -2.6502, -2.6514, -2.6202, -2.6003, -2.6065, -2.6402,\n",
      "        -2.6270, -2.6106, -2.6616, -2.6541, -2.6463, -2.6459, -2.6384, -2.6499,\n",
      "        -2.6359, -2.6347, -2.6291, -2.6372, -2.5977, -2.6504, -2.6279, -2.5207,\n",
      "        -2.6276, -2.6369, -2.6117, -2.6535, -2.6505, -2.6442, -2.6523, -2.5988,\n",
      "        -2.6335, -2.6444, -2.6390, -2.6501, -2.6363, -2.5788, -2.6304, -2.5818,\n",
      "        -2.6428, -2.6345], device='mps:0')\n",
      "mean: tensor(-2.6317, device='mps:0')\n",
      "iter_dt 1.11s; iter 50: train loss 1.06513 temperature: 7.499999999999991\n",
      "mean_logits tensor([-2.5945, -2.6762, -2.6797, -2.4697, -2.6527, -2.7711, -2.4619, -2.5551,\n",
      "        -2.3820, -2.7519, -2.7583, -2.7929, -2.5962, -2.1202, -2.7825, -2.4857,\n",
      "        -2.5669, -2.6984, -2.9750, -2.8769, -2.7402, -2.4160, -2.6138, -2.4702,\n",
      "        -2.6060, -2.4145, -2.9769, -2.1212, -2.6068, -2.8369, -2.4407, -2.5785,\n",
      "        -2.4112, -2.4361, -2.6167, -2.5451, -2.3756, -2.5645, -2.5254, -2.5634,\n",
      "        -2.6111, -2.6111, -2.7244, -2.0426, -2.9549, -2.2384, -2.3404, -2.7068,\n",
      "        -2.7022, -2.8625], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6207, -2.6391, -2.6421, -2.5419, -2.6535, -2.5889, -2.6460, -2.5848,\n",
      "        -2.6407, -2.5938, -2.6384, -2.6510, -2.6320, -2.6350, -2.6454, -2.6304,\n",
      "        -2.6054, -2.6434, -2.5777, -2.6410, -2.6507, -2.5856, -2.6059, -2.5744,\n",
      "        -2.6261, -2.6367, -2.6229, -2.6377, -2.5982, -2.5655, -2.6389, -2.6522,\n",
      "        -2.6376, -2.6418, -2.6504, -2.6486, -2.6429, -2.6462, -2.6349, -2.6403,\n",
      "        -2.6312, -2.6403, -2.6128, -2.5711, -2.5645, -2.6557, -2.6544, -2.6300,\n",
      "        -2.6531, -2.6373], device='mps:0')\n",
      "mean: tensor(-2.6248, device='mps:0')\n",
      "iter_dt 1.10s; iter 51: train loss 0.92870 temperature: 7.549999999999991\n",
      "mean_logits tensor([-2.9640, -2.6806, -2.4876, -2.5917, -2.6145, -2.2536, -2.3613, -2.7095,\n",
      "        -2.5143, -2.7865, -2.3802, -2.7435, -2.3896, -2.1207, -2.7082, -2.8566,\n",
      "        -2.4016, -2.4019, -2.7576, -2.4193, -2.4879, -2.4916, -2.6726, -2.7305,\n",
      "        -2.7208, -2.5144, -2.8113, -2.3412, -2.5846, -2.5584, -2.4567, -2.3218,\n",
      "        -2.7119, -2.8970, -2.6076, -3.0220, -2.6927, -2.4626, -2.6625, -2.4387,\n",
      "        -2.5507, -2.1513, -2.7488, -2.8954, -2.7436, -2.6263, -2.5289, -2.4484,\n",
      "        -2.6213, -2.7562], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6381, -2.5883, -2.6131, -2.6560, -2.6307, -2.5733, -2.6459, -2.6500,\n",
      "        -2.6066, -2.6364, -2.5845, -2.6407, -2.6534, -2.5997, -2.6411, -2.6268,\n",
      "        -2.5986, -2.6302, -2.5950, -2.6462, -2.6557, -2.6565, -2.5806, -2.6094,\n",
      "        -2.5782, -2.6287, -2.6237, -2.6506, -2.6347, -2.5657, -2.6434, -2.5866,\n",
      "        -2.6623, -2.6322, -2.6134, -2.6309, -2.6290, -2.6249, -2.6487, -2.6398,\n",
      "        -2.6538, -2.5928, -2.6456, -2.6389, -2.6513, -2.6361, -2.6263, -2.6529,\n",
      "        -2.6533, -2.6432], device='mps:0')\n",
      "mean: tensor(-2.6269, device='mps:0')\n",
      "iter_dt 1.08s; iter 52: train loss 1.09524 temperature: 7.599999999999991\n",
      "mean_logits tensor([-2.4103, -2.4837, -2.1777, -2.4295, -2.7453, -2.4904, -2.9270, -2.8583,\n",
      "        -2.6973, -2.5148, -2.5709, -2.6481, -2.6128, -2.6725, -2.1845, -2.8919,\n",
      "        -2.1181, -2.5123, -2.5039, -2.6628, -2.1929, -3.0164, -2.7882, -2.8376,\n",
      "        -2.9459, -2.5741, -2.3716, -2.6251, -2.3394, -2.4205, -2.3617, -2.6408,\n",
      "        -2.5678, -2.6381, -2.7864, -2.8891, -2.2655, -2.6422, -2.6677, -2.4099,\n",
      "        -2.6466, -2.4926, -2.4143, -2.5822, -2.6921, -2.5866, -2.6865, -2.5615,\n",
      "        -2.9409, -2.7085], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5994, -2.6433, -2.6525, -2.6459, -2.6388, -2.6104, -2.6422, -2.6367,\n",
      "        -2.6432, -2.6561, -2.6370, -2.6485, -2.6558, -2.6382, -2.6271, -2.5686,\n",
      "        -2.6231, -2.6043, -2.6536, -2.6271, -2.6504, -2.6458, -2.5915, -2.6509,\n",
      "        -2.6489, -2.6356, -2.6096, -2.6429, -2.6373, -2.6495, -2.5891, -2.5543,\n",
      "        -2.6230, -2.6029, -2.6439, -2.6506, -2.6304, -2.5947, -2.6263, -2.5930,\n",
      "        -2.5782, -2.6157, -2.5836, -2.6390, -2.6444, -2.6466, -2.6372, -2.6324,\n",
      "        -2.6126, -2.6509], device='mps:0')\n",
      "mean: tensor(-2.6273, device='mps:0')\n",
      "iter_dt 1.11s; iter 53: train loss 0.72560 temperature: 7.649999999999991\n",
      "mean_logits tensor([-2.8653, -2.4355, -2.7119, -2.8314, -2.5898, -2.7894, -2.7318, -2.3954,\n",
      "        -2.5519, -2.4994, -2.9229, -2.8535, -2.5790, -2.4488, -2.5483, -2.5877,\n",
      "        -2.6714, -2.3325, -2.3854, -2.8469, -2.1028, -2.7603, -2.5759, -2.7714,\n",
      "        -2.6244, -2.8273, -2.7631, -2.3325, -2.6225, -2.5827, -2.6872, -2.6347,\n",
      "        -2.6244, -2.6145, -2.7336, -2.3880, -2.5750, -2.6019, -2.2613, -2.7064,\n",
      "        -2.5473, -2.5336, -2.4527, -2.7182, -2.7600, -2.5773, -2.6899, -2.3659,\n",
      "        -2.3532, -2.5088], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6443, -2.6395, -2.6411, -2.6411, -2.6352, -2.6469, -2.5813, -2.5815,\n",
      "        -2.6503, -2.6347, -2.6297, -2.6513, -2.6484, -2.6546, -2.6458, -2.6473,\n",
      "        -2.6452, -2.6133, -2.6513, -2.5927, -2.6027, -2.6420, -2.6457, -2.6427,\n",
      "        -2.6364, -2.6482, -2.5642, -2.6442, -2.5865, -2.6564, -2.5677, -2.5451,\n",
      "        -2.6442, -2.6415, -2.6486, -2.6050, -2.6439, -2.6502, -2.6272, -2.6371,\n",
      "        -2.6487, -2.6433, -2.6427, -2.6397, -2.6539, -2.6482, -2.6501, -2.6392,\n",
      "        -2.6484, -2.5542], device='mps:0')\n",
      "mean: tensor(-2.6305, device='mps:0')\n",
      "iter_dt 1.11s; iter 54: train loss 0.89744 temperature: 7.69999999999999\n",
      "mean_logits tensor([-2.5275, -2.7472, -2.7856, -2.8204, -2.6075, -2.5437, -2.3674, -2.1140,\n",
      "        -2.5994, -2.4759, -2.5154, -2.7029, -2.4823, -2.7271, -2.7173, -2.7007,\n",
      "        -2.5061, -2.6903, -2.2645, -2.5327, -2.3767, -2.5068, -2.5592, -2.3089,\n",
      "        -2.7627, -2.6366, -2.6255, -2.6187, -2.8850, -2.7147, -2.1319, -2.6387,\n",
      "        -2.3602, -2.6660, -2.2245, -2.4332, -2.5492, -2.5547, -2.7324, -2.6026,\n",
      "        -2.6050, -2.3678, -2.8715, -2.2615, -2.6902, -2.3150, -2.6401, -2.9714,\n",
      "        -2.2936, -2.7729], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6528, -2.5752, -2.6468, -2.6207, -2.6111, -2.6356, -2.5835, -2.6518,\n",
      "        -2.6345, -2.6456, -2.6507, -2.6521, -2.6515, -2.6350, -2.5952, -2.6332,\n",
      "        -2.6459, -2.6466, -2.6375, -2.6086, -2.6424, -2.5845, -2.6433, -2.6415,\n",
      "        -2.5643, -2.6396, -2.5711, -2.6421, -2.6560, -2.6401, -2.6359, -2.5997,\n",
      "        -2.5815, -2.6545, -2.5818, -2.6409, -2.5944, -2.6416, -2.6396, -2.6508,\n",
      "        -2.6385, -2.6459, -2.6304, -2.6540, -2.6440, -2.6393, -2.6559, -2.6435,\n",
      "        -2.5612, -2.6347], device='mps:0')\n",
      "mean: tensor(-2.6281, device='mps:0')\n",
      "iter_dt 1.12s; iter 55: train loss 0.77552 temperature: 7.74999999999999\n",
      "mean_logits tensor([-2.4455, -2.8104, -2.7181, -2.4245, -2.4989, -2.3513, -2.9980, -2.7040,\n",
      "        -2.5387, -2.4360, -2.5635, -2.3991, -2.6398, -2.5699, -2.6470, -2.8184,\n",
      "        -2.3368, -2.4901, -2.9308, -2.6156, -2.4757, -2.3873, -2.5542, -2.7188,\n",
      "        -2.4130, -2.4522, -2.3162, -2.3903, -2.6218, -2.7149, -2.4340, -2.5828,\n",
      "        -2.3400, -2.5000, -2.4490, -2.7966, -2.2989, -2.7778, -2.5147, -2.5865,\n",
      "        -2.4912, -2.3766, -2.5790, -2.5434, -2.6672, -2.7987, -2.7288, -2.7574,\n",
      "        -2.5164, -2.3058], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6188, -2.6098, -2.6395, -2.6263, -2.6291, -2.5845, -2.6561, -2.5910,\n",
      "        -2.6428, -2.6487, -2.6044, -2.6385, -2.6489, -2.6532, -2.6532, -2.6514,\n",
      "        -2.6172, -2.6433, -2.6536, -2.6344, -2.6358, -2.6428, -2.5491, -2.6519,\n",
      "        -2.5796, -2.6158, -2.6518, -2.6564, -2.6401, -2.6449, -2.6423, -2.6529,\n",
      "        -2.6016, -2.6429, -2.5549, -2.5810, -2.6601, -2.6045, -2.6176, -2.6498,\n",
      "        -2.6322, -2.6507, -2.6531, -2.6538, -2.6265, -2.6446, -2.6369, -2.6243,\n",
      "        -2.6540, -2.5818], device='mps:0')\n",
      "mean: tensor(-2.6296, device='mps:0')\n",
      "iter_dt 1.15s; iter 56: train loss 0.79658 temperature: 7.79999999999999\n",
      "mean_logits tensor([-2.5694, -2.3736, -2.6299, -2.5286, -2.6026, -2.5160, -2.4799, -2.7825,\n",
      "        -2.5832, -2.5236, -2.5840, -2.4673, -2.6637, -2.4453, -2.4646, -2.8710,\n",
      "        -2.8410, -2.4535, -2.5117, -2.3037, -2.2719, -2.6927, -2.4977, -2.8005,\n",
      "        -2.5985, -2.5710, -2.7546, -2.5292, -2.6713, -2.8471, -2.4319, -2.3170,\n",
      "        -2.7399, -2.8035, -2.3514, -2.1167, -2.4427, -2.7028, -2.3955, -2.4196,\n",
      "        -2.7881, -2.7836, -2.6914, -2.5871, -2.6756, -2.6646, -2.4310, -2.3977,\n",
      "        -2.5912, -2.2736], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5635, -2.6443, -2.6457, -2.5918, -2.6563, -2.6500, -2.6434, -2.6346,\n",
      "        -2.6296, -2.6512, -2.6438, -2.6454, -2.6510, -2.6427, -2.6056, -2.6357,\n",
      "        -2.5947, -2.6359, -2.6360, -2.6393, -2.6505, -2.6409, -2.6415, -2.5915,\n",
      "        -2.6363, -2.5814, -2.6481, -2.6497, -2.5685, -2.6375, -2.6501, -2.6332,\n",
      "        -2.6522, -2.6533, -2.6392, -2.6524, -2.6370, -2.6506, -2.5843, -2.5827,\n",
      "        -2.5304, -2.6507, -2.6448, -2.6281, -2.6050, -2.6073, -2.6136, -2.6469,\n",
      "        -2.5533, -2.6551], device='mps:0')\n",
      "mean: tensor(-2.6271, device='mps:0')\n",
      "iter_dt 1.12s; iter 57: train loss 1.02597 temperature: 7.84999999999999\n",
      "mean_logits tensor([-2.5161, -2.7149, -2.6323, -2.7039, -2.3314, -2.4459, -2.5880, -2.4914,\n",
      "        -2.6078, -2.7807, -2.9277, -2.6024, -2.6343, -2.5223, -2.3164, -2.5300,\n",
      "        -2.9504, -2.6844, -2.6012, -2.6325, -2.3016, -2.8641, -2.8029, -2.2583,\n",
      "        -2.4937, -2.8469, -2.5357, -2.6145, -2.4574, -2.5021, -2.4653, -2.7393,\n",
      "        -2.2024, -2.5888, -2.7493, -2.7925, -2.3802, -2.6457, -2.5169, -2.4243,\n",
      "        -2.3238, -2.1214, -2.5451, -2.3950, -2.5633, -2.6062, -2.7613, -2.4276,\n",
      "        -3.1224, -2.6373], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5671, -2.6530, -2.6287, -2.5572, -2.6131, -2.5828, -2.5774, -2.6459,\n",
      "        -2.6029, -2.6413, -2.6398, -2.6427, -2.6539, -2.6558, -2.6406, -2.6477,\n",
      "        -2.6407, -2.6557, -2.6533, -2.6438, -2.5994, -2.6399, -2.6167, -2.6348,\n",
      "        -2.6551, -2.5759, -2.6046, -2.6404, -2.5615, -2.6610, -2.6534, -2.6528,\n",
      "        -2.5868, -2.4893, -2.6514, -2.5936, -2.6609, -2.6433, -2.5995, -2.6560,\n",
      "        -2.6437, -2.6399, -2.6386, -2.6526, -2.6321, -2.6212, -2.6462, -2.6298,\n",
      "        -2.6516, -2.6359], device='mps:0')\n",
      "mean: tensor(-2.6262, device='mps:0')\n",
      "iter_dt 1.11s; iter 58: train loss 0.76986 temperature: 7.89999999999999\n",
      "mean_logits tensor([-2.8641, -2.5683, -2.6046, -2.6373, -2.6148, -2.5834, -2.7720, -2.8893,\n",
      "        -2.7275, -2.4469, -2.4559, -2.4762, -2.3562, -2.4861, -2.5296, -2.8150,\n",
      "        -2.5516, -2.7634, -2.7618, -2.3228, -2.7528, -2.5679, -2.9279, -2.6702,\n",
      "        -2.5291, -2.4837, -2.4694, -2.3930, -2.3126, -2.2672, -2.4743, -2.5192,\n",
      "        -2.4537, -2.4991, -2.3556, -2.4829, -2.9904, -2.3276, -2.5563, -2.5500,\n",
      "        -2.6876, -2.5058, -2.5909, -2.6165, -2.2080, -2.5607, -2.3199, -2.7853,\n",
      "        -2.5235, -2.6905], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6433, -2.6494, -2.6074, -2.6524, -2.6403, -2.5676, -2.6408, -2.6539,\n",
      "        -2.5618, -2.6165, -2.5728, -2.6531, -2.6207, -2.5895, -2.6381, -2.5954,\n",
      "        -2.6502, -2.6422, -2.6270, -2.6553, -2.6566, -2.6507, -2.6393, -2.5863,\n",
      "        -2.6217, -2.6496, -2.6414, -2.6524, -2.4709, -2.6534, -2.5705, -2.5739,\n",
      "        -2.6452, -2.5921, -2.6306, -2.6501, -2.6491, -2.6111, -2.6604, -2.6033,\n",
      "        -2.6463, -2.6504, -2.5807, -2.6078, -2.5699, -2.6423, -2.6157, -2.6088,\n",
      "        -2.5768, -2.6298], device='mps:0')\n",
      "mean: tensor(-2.6203, device='mps:0')\n",
      "iter_dt 1.11s; iter 59: train loss 0.79883 temperature: 7.9499999999999895\n",
      "mean_logits tensor([-2.6227, -2.4993, -2.7008, -2.6291, -2.4645, -2.6422, -2.5950, -2.7316,\n",
      "        -2.5698, -2.5115, -2.2444, -2.4562, -2.4295, -2.8294, -2.8192, -2.4527,\n",
      "        -2.5604, -2.6494, -2.5995, -2.6400, -2.5349, -3.1331, -2.5433, -2.6180,\n",
      "        -2.4045, -2.6085, -2.5379, -2.8868, -2.4044, -2.5724, -2.5351, -2.5215,\n",
      "        -2.4287, -2.5550, -2.8445, -2.7151, -2.7466, -2.3608, -2.4845, -2.4504,\n",
      "        -2.0951, -2.6359, -2.5539, -2.3192, -2.5162, -2.5058, -2.6547, -2.4639,\n",
      "        -2.7405, -2.6071], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6566, -2.6452, -2.6133, -2.6532, -2.6230, -2.6490, -2.6221, -2.6530,\n",
      "        -2.5965, -2.6475, -2.6307, -2.6270, -2.6211, -2.6534, -2.6555, -2.6362,\n",
      "        -2.6486, -2.5987, -2.6360, -2.5761, -2.6375, -2.6482, -2.6448, -2.5529,\n",
      "        -2.6385, -2.6556, -2.6382, -2.5916, -2.6476, -2.6368, -2.6566, -2.6434,\n",
      "        -2.5885, -2.6506, -2.6530, -2.4940, -2.6090, -2.6324, -2.5783, -2.6396,\n",
      "        -2.5884, -2.5994, -2.5749, -2.6542, -2.6486, -2.5863, -2.6509, -2.6171,\n",
      "        -2.6542, -2.5804], device='mps:0')\n",
      "mean: tensor(-2.6247, device='mps:0')\n",
      "iter_dt 1.21s; iter 60: train loss 0.81105 temperature: 7.999999999999989\n",
      "mean_logits tensor([-2.6987, -2.7640, -2.4440, -2.5892, -2.6427, -2.5280, -2.5216, -2.6344,\n",
      "        -2.7670, -2.4806, -2.2927, -2.7444, -2.5164, -2.5072, -2.6013, -2.3979,\n",
      "        -2.5587, -2.5043, -2.2701, -2.6381, -2.4313, -2.4753, -2.7628, -2.5515,\n",
      "        -2.7886, -2.8410, -2.3030, -2.5226, -2.7096, -2.7766, -2.3312, -2.8155,\n",
      "        -2.5718, -2.7334, -2.5926, -2.5796, -2.1301, -2.3502, -2.7137, -2.7591,\n",
      "        -2.5748, -2.0381, -2.4253, -2.8556, -2.6943, -2.6516, -2.6638, -2.0523,\n",
      "        -2.5885, -2.5292], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6258, -2.5851, -2.6511, -2.5529, -2.6268, -2.5500, -2.6193, -2.5851,\n",
      "        -2.6069, -2.6416, -2.6461, -2.6380, -2.5799, -2.5762, -2.4508, -2.6460,\n",
      "        -2.6317, -2.6137, -2.6124, -2.6386, -2.6066, -2.5712, -2.6169, -2.5595,\n",
      "        -2.6445, -2.6506, -2.6427, -2.6511, -2.6404, -2.6237, -2.5822, -2.6344,\n",
      "        -2.5956, -2.6595, -2.6371, -2.6517, -2.6183, -2.6370, -2.6409, -2.6373,\n",
      "        -2.5774, -2.6543, -2.6367, -2.6466, -2.6283, -2.5918, -2.6244, -2.6501,\n",
      "        -2.6425, -2.6421], device='mps:0')\n",
      "mean: tensor(-2.6175, device='mps:0')\n",
      "iter_dt 1.11s; iter 61: train loss 0.85854 temperature: 8.04999999999999\n",
      "mean_logits tensor([-2.5884, -2.4502, -2.7136, -2.4915, -2.6137, -2.4345, -2.7401, -2.6402,\n",
      "        -2.4229, -2.6486, -2.2736, -2.5768, -2.7334, -2.7716, -2.4833, -2.6208,\n",
      "        -2.5829, -2.2254, -2.4352, -2.2585, -2.3960, -2.6985, -2.5690, -2.6685,\n",
      "        -2.8118, -2.7629, -2.9379, -2.5455, -2.5071, -2.3302, -2.1923, -2.5445,\n",
      "        -2.6754, -2.4265, -2.8142, -2.3773, -2.5844, -2.4700, -2.2501, -2.4810,\n",
      "        -2.3306, -2.4435, -2.9208, -2.7354, -2.8347, -2.7151, -2.5708, -2.5553,\n",
      "        -2.4428, -2.6077], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5731, -2.6078, -2.6426, -2.5634, -2.6321, -2.6403, -2.5955, -2.5969,\n",
      "        -2.6309, -2.6503, -2.5943, -2.6485, -2.6401, -2.6231, -2.6174, -2.5288,\n",
      "        -2.6413, -2.6375, -2.6526, -2.6015, -2.6502, -2.6118, -2.6452, -2.6504,\n",
      "        -2.6387, -2.6350, -2.5817, -2.5733, -2.6113, -2.6454, -2.6549, -2.6534,\n",
      "        -2.6295, -2.6375, -2.6290, -2.6560, -2.6318, -2.6481, -2.6465, -2.6526,\n",
      "        -2.6334, -2.6355, -2.6599, -2.6423, -2.6256, -2.6457, -2.6463, -2.6111,\n",
      "        -2.6614, -2.6395], device='mps:0')\n",
      "mean: tensor(-2.6280, device='mps:0')\n",
      "iter_dt 1.10s; iter 62: train loss 0.97954 temperature: 8.09999999999999\n",
      "mean_logits tensor([-2.5265, -2.5098, -2.3868, -2.8653, -2.4413, -2.5462, -2.5223, -2.5002,\n",
      "        -2.7596, -2.5228, -2.5638, -2.2916, -2.5113, -2.3941, -2.2636, -2.4929,\n",
      "        -2.7540, -2.4041, -2.3538, -2.6279, -2.5304, -2.2922, -2.5156, -2.2014,\n",
      "        -2.6185, -2.7536, -2.5509, -2.4720, -2.6153, -2.3383, -2.4189, -2.2945,\n",
      "        -2.4874, -2.8340, -2.7514, -2.7323, -2.4964, -2.7292, -2.2739, -2.6189,\n",
      "        -2.0274, -2.4192, -2.4892, -2.1394, -2.6219, -2.9185, -2.4661, -2.5082,\n",
      "        -2.4626, -2.5961], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6376, -2.6105, -2.6560, -2.6559, -2.6116, -2.6530, -2.6553, -2.6549,\n",
      "        -2.5780, -2.6393, -2.6565, -2.5419, -2.6480, -2.5784, -2.6560, -2.6553,\n",
      "        -2.6457, -2.6411, -2.6468, -2.6515, -2.6524, -2.5813, -2.6329, -2.6198,\n",
      "        -2.5660, -2.5596, -2.5426, -2.6541, -2.6444, -2.6527, -2.6250, -2.6422,\n",
      "        -2.6591, -2.6046, -2.6491, -2.6529, -2.6003, -2.6424, -2.5728, -2.6479,\n",
      "        -2.6448, -2.6413, -2.6512, -2.6491, -2.6584, -2.6551, -2.6178, -2.6405,\n",
      "        -2.6587, -2.6398], device='mps:0')\n",
      "mean: tensor(-2.6306, device='mps:0')\n",
      "iter_dt 1.12s; iter 63: train loss 0.69022 temperature: 8.149999999999991\n",
      "mean_logits tensor([-2.7435, -2.7875, -2.4716, -2.3620, -2.5043, -2.5953, -2.7273, -2.5519,\n",
      "        -2.8233, -2.4477, -2.4521, -2.6926, -2.8522, -2.6004, -2.5009, -2.4632,\n",
      "        -2.6280, -2.7946, -2.8205, -2.8950, -2.5658, -2.5189, -2.7635, -2.3478,\n",
      "        -2.6509, -2.4469, -2.9111, -2.5908, -2.4759, -2.7867, -2.5349, -2.6427,\n",
      "        -2.6923, -2.7929, -2.6593, -2.4953, -2.6709, -2.4740, -2.6271, -2.3559,\n",
      "        -2.7016, -2.2742, -2.3585, -2.7365, -2.3189, -2.9223, -2.6519, -2.3091,\n",
      "        -2.6831, -2.6647], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6491, -2.6337, -2.6289, -2.6010, -2.6499, -2.5908, -2.5772, -2.6533,\n",
      "        -2.6536, -2.6199, -2.6303, -2.6410, -2.6402, -2.6129, -2.6520, -2.5708,\n",
      "        -2.5867, -2.6538, -2.6328, -2.6469, -2.5923, -2.6535, -2.6462, -2.6419,\n",
      "        -2.6098, -2.5595, -2.6519, -2.6539, -2.6326, -2.4656, -2.6335, -2.6396,\n",
      "        -2.6528, -2.6574, -2.6492, -2.6368, -2.6532, -2.6329, -2.6388, -2.6464,\n",
      "        -2.6223, -2.6319, -2.6347, -2.6523, -2.5838, -2.6530, -2.6376, -2.5957,\n",
      "        -2.6563, -2.6317], device='mps:0')\n",
      "mean: tensor(-2.6274, device='mps:0')\n",
      "iter_dt 1.13s; iter 64: train loss 0.84847 temperature: 8.199999999999992\n",
      "mean_logits tensor([-2.5577, -2.6249, -2.7107, -2.6190, -2.5811, -2.7019, -2.9083, -2.5327,\n",
      "        -2.4367, -2.6371, -2.6596, -2.2650, -2.6019, -2.4774, -2.6795, -2.7286,\n",
      "        -2.7884, -2.7788, -2.6261, -2.4549, -2.9285, -2.5945, -2.4001, -2.4310,\n",
      "        -2.3789, -2.5299, -2.3082, -2.2110, -2.5724, -2.5159, -2.6280, -2.3877,\n",
      "        -2.7633, -2.4395, -2.7002, -2.3454, -2.6193, -2.6222, -2.4788, -2.2978,\n",
      "        -2.1931, -2.8696, -2.4243, -2.7443, -2.7485, -2.4035, -2.3462, -2.1324,\n",
      "        -2.5969, -2.7433], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6116, -2.5644, -2.6025, -2.6521, -2.6029, -2.5741, -2.5663, -2.6611,\n",
      "        -2.5758, -2.6129, -2.6297, -2.6270, -2.6479, -2.6542, -2.6268, -2.6273,\n",
      "        -2.6482, -2.6379, -2.6446, -2.5836, -2.6265, -2.6453, -2.6391, -2.6380,\n",
      "        -2.5921, -2.5987, -2.6376, -2.5921, -2.6323, -2.6466, -2.5927, -2.6434,\n",
      "        -2.5905, -2.6085, -2.6538, -2.6499, -2.6441, -2.6041, -2.6096, -2.6448,\n",
      "        -2.6523, -2.6488, -2.6297, -2.6315, -2.6511, -2.6371, -2.6064, -2.5677,\n",
      "        -2.6248, -2.5991], device='mps:0')\n",
      "mean: tensor(-2.6218, device='mps:0')\n",
      "iter_dt 1.13s; iter 65: train loss 0.76699 temperature: 8.249999999999993\n",
      "mean_logits tensor([-2.4614, -2.8086, -2.6271, -2.5144, -2.4780, -2.7658, -2.6038, -2.8011,\n",
      "        -2.4808, -2.1921, -2.6555, -2.6202, -2.7783, -2.8952, -2.7015, -2.7188,\n",
      "        -2.6911, -2.7637, -2.6867, -2.7484, -2.7890, -2.5572, -2.7493, -2.4273,\n",
      "        -2.5826, -2.3709, -2.2677, -2.4178, -2.5846, -2.5736, -2.3124, -2.4425,\n",
      "        -2.4236, -2.4629, -2.7237, -2.5174, -2.4728, -2.7569, -2.3851, -2.5312,\n",
      "        -2.3609, -2.5442, -2.5002, -2.8711, -2.1968, -2.4507, -2.8282, -2.7428,\n",
      "        -2.5010, -2.4400], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6440, -2.6484, -2.6102, -2.6503, -2.5979, -2.5215, -2.6339, -2.6456,\n",
      "        -2.6443, -2.5850, -2.6362, -2.6129, -2.6489, -2.6364, -2.6531, -2.6166,\n",
      "        -2.5599, -2.6099, -2.5764, -2.6591, -2.6260, -2.6460, -2.6447, -2.6512,\n",
      "        -2.5935, -2.6510, -2.6279, -2.6441, -2.6361, -2.6542, -2.5826, -2.6513,\n",
      "        -2.6048, -2.6523, -2.6005, -2.6466, -2.6391, -2.6349, -2.6489, -2.6522,\n",
      "        -2.6382, -2.6417, -2.6083, -2.6596, -2.6529, -2.6359, -2.6384, -2.6532,\n",
      "        -2.6311, -2.6126], device='mps:0')\n",
      "mean: tensor(-2.6290, device='mps:0')\n",
      "iter_dt 1.12s; iter 66: train loss 0.75490 temperature: 8.299999999999994\n",
      "mean_logits tensor([-2.6611, -2.6311, -2.3854, -2.5722, -2.1771, -2.6615, -2.3794, -2.5335,\n",
      "        -2.3082, -2.6700, -2.6513, -2.4333, -2.5318, -2.4369, -2.5816, -2.3437,\n",
      "        -2.5382, -2.5752, -2.2717, -2.3915, -2.7158, -2.4803, -2.3181, -2.2488,\n",
      "        -2.7218, -2.7424, -2.4358, -2.3392, -2.4243, -2.5704, -2.7067, -2.4115,\n",
      "        -2.8007, -2.5806, -2.5735, -2.3850, -2.4728, -2.9484, -2.7463, -2.5355,\n",
      "        -2.8183, -2.5692, -2.3405, -2.8261, -2.3906, -2.6083, -2.6374, -2.4551,\n",
      "        -2.4187, -2.6645], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5290, -2.6056, -2.6506, -2.6330, -2.6076, -2.6381, -2.5881, -2.6461,\n",
      "        -2.5793, -2.6369, -2.6510, -2.6535, -2.6030, -2.6483, -2.6550, -2.6005,\n",
      "        -2.6514, -2.5447, -2.6269, -2.6159, -2.6478, -2.6347, -2.6427, -2.5845,\n",
      "        -2.6589, -2.6557, -2.6502, -2.5856, -2.5501, -2.6059, -2.6382, -2.6181,\n",
      "        -2.6504, -2.6428, -2.6377, -2.6559, -2.6207, -2.6136, -2.6336, -2.6411,\n",
      "        -2.6556, -2.6621, -2.6513, -2.6381, -2.6269, -2.6365, -2.6491, -2.5924,\n",
      "        -2.6398, -2.6035], device='mps:0')\n",
      "mean: tensor(-2.6258, device='mps:0')\n",
      "iter_dt 1.17s; iter 67: train loss 0.68922 temperature: 8.349999999999994\n",
      "mean_logits tensor([-2.5542, -2.2393, -2.5892, -2.7954, -2.5140, -2.4197, -2.3638, -2.6085,\n",
      "        -2.5489, -2.5536, -2.6557, -2.5167, -2.5396, -2.3509, -2.3972, -2.6790,\n",
      "        -2.5914, -2.5599, -2.6098, -2.6239, -2.7542, -2.8000, -2.4718, -2.4540,\n",
      "        -2.3916, -2.4281, -2.5648, -2.3912, -2.4915, -2.6141, -2.7179, -2.6046,\n",
      "        -2.7276, -2.5509, -2.6961, -2.4899, -2.5898, -2.7617, -2.7124, -2.6577,\n",
      "        -2.6346, -2.7689, -2.7096, -2.5898, -2.5587, -2.7603, -3.0512, -2.6469,\n",
      "        -2.9485, -2.4469], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5818, -2.6475, -2.6052, -2.6392, -2.6566, -2.6451, -2.6334, -2.6414,\n",
      "        -2.5033, -2.6123, -2.6379, -2.5754, -2.6531, -2.6535, -2.6358, -2.6562,\n",
      "        -2.6535, -2.6353, -2.6361, -2.5697, -2.5894, -2.6240, -2.6287, -2.6223,\n",
      "        -2.6346, -2.6151, -2.5659, -2.6520, -2.6074, -2.6361, -2.6557, -2.6126,\n",
      "        -2.6566, -2.6431, -2.6267, -2.6501, -2.6466, -2.6558, -2.5987, -2.6566,\n",
      "        -2.6362, -2.6513, -2.6528, -2.6388, -2.6310, -2.6560, -2.5875, -2.6321,\n",
      "        -2.5762, -2.6545], device='mps:0')\n",
      "mean: tensor(-2.6273, device='mps:0')\n",
      "iter_dt 1.16s; iter 68: train loss 0.65602 temperature: 8.399999999999995\n",
      "mean_logits tensor([-2.6461, -2.6866, -2.6340, -2.8493, -2.6512, -2.8400, -2.7136, -2.4354,\n",
      "        -2.6770, -2.9006, -2.5279, -2.5365, -2.4870, -2.5395, -2.5430, -2.4226,\n",
      "        -2.5379, -2.3319, -2.4685, -2.4961, -2.4797, -2.6031, -2.6099, -2.1603,\n",
      "        -2.5628, -2.7023, -2.7051, -2.5661, -2.3495, -2.7631, -2.5363, -2.7669,\n",
      "        -2.5233, -2.2122, -2.3562, -2.7242, -2.2478, -2.6577, -2.6905, -2.7109,\n",
      "        -2.6929, -2.8038, -2.8627, -2.4921, -2.3676, -2.5649, -2.4352, -2.5652,\n",
      "        -2.4664, -2.3738], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5528, -2.6240, -2.6506, -2.6533, -2.6542, -2.6436, -2.6323, -2.6555,\n",
      "        -2.6322, -2.6506, -2.6367, -2.6120, -2.6440, -2.6380, -2.6512, -2.5895,\n",
      "        -2.6504, -2.6559, -2.6376, -2.6570, -2.5936, -2.6339, -2.6449, -2.6101,\n",
      "        -2.6516, -2.6423, -2.6417, -2.6395, -2.5831, -2.6174, -2.5759, -2.6560,\n",
      "        -2.6557, -2.6118, -2.6044, -2.6552, -2.6549, -2.6385, -2.6480, -2.6512,\n",
      "        -2.6427, -2.6154, -2.6539, -2.6525, -2.6035, -2.6148, -2.5704, -2.6528,\n",
      "        -2.6406, -2.6134], device='mps:0')\n",
      "mean: tensor(-2.6318, device='mps:0')\n",
      "iter_dt 1.07s; iter 69: train loss 0.71404 temperature: 8.449999999999996\n",
      "mean_logits tensor([-2.6056, -2.3608, -2.3571, -2.5855, -2.6710, -2.4489, -2.5725, -2.1500,\n",
      "        -2.6654, -2.3431, -2.6029, -2.6455, -2.7980, -2.6382, -2.7038, -2.5978,\n",
      "        -2.5336, -2.5751, -2.5145, -2.4816, -2.5973, -2.7352, -2.5076, -2.3777,\n",
      "        -2.2198, -2.4989, -2.7904, -2.3635, -2.6927, -2.7381, -2.2551, -2.7306,\n",
      "        -2.2592, -2.5290, -2.4045, -2.3166, -2.6370, -2.4499, -2.7236, -2.6886,\n",
      "        -2.6426, -2.5000, -2.5542, -2.6378, -2.3185, -2.4699, -2.7577, -2.6043,\n",
      "        -2.4555, -2.4007], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6562, -2.6510, -2.6613, -2.6302, -2.6394, -2.6282, -2.6127, -2.6409,\n",
      "        -2.6325, -2.6501, -2.6105, -2.6547, -2.5740, -2.6442, -2.6507, -2.6422,\n",
      "        -2.5680, -2.6367, -2.6532, -2.6109, -2.6426, -2.6053, -2.6561, -2.6561,\n",
      "        -2.6377, -2.6072, -2.6484, -2.6450, -2.6534, -2.6283, -2.6096, -2.6308,\n",
      "        -2.5942, -2.6570, -2.5973, -2.6419, -2.6409, -2.6498, -2.6339, -2.6558,\n",
      "        -2.6292, -2.6494, -2.5525, -2.6399, -2.6106, -2.6559, -2.6489, -2.6519,\n",
      "        -2.6242, -2.6438], device='mps:0')\n",
      "mean: tensor(-2.6329, device='mps:0')\n",
      "iter_dt 1.10s; iter 70: train loss 0.86559 temperature: 8.499999999999996\n",
      "mean_logits tensor([-2.4679, -2.4170, -2.7943, -2.3299, -2.5504, -2.6335, -2.2625, -2.3527,\n",
      "        -2.4987, -2.3096, -2.7271, -2.6014, -2.5009, -2.6905, -2.5492, -2.4402,\n",
      "        -2.6412, -2.3651, -2.5791, -2.6024, -2.5525, -2.5302, -2.2426, -2.2263,\n",
      "        -2.3165, -2.7730, -2.5919, -2.6847, -2.8473, -2.4613, -2.5851, -2.3310,\n",
      "        -2.7058, -2.5082, -2.5435, -2.6153, -2.6361, -2.5152, -2.4808, -2.0755,\n",
      "        -2.3352, -2.4714, -2.3709, -2.5982, -2.6214, -2.4103, -2.2437, -2.2049,\n",
      "        -2.5961, -2.5426], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6514, -2.6422, -2.6516, -2.5811, -2.6556, -2.6455, -2.5364, -2.6224,\n",
      "        -2.6584, -2.6558, -2.6511, -2.6291, -2.6338, -2.6180, -2.6565, -2.6482,\n",
      "        -2.6289, -2.6298, -2.5825, -2.6567, -2.6173, -2.6478, -2.5477, -2.6444,\n",
      "        -2.6485, -2.5835, -2.6561, -2.6555, -2.6453, -2.6372, -2.6403, -2.6488,\n",
      "        -2.6079, -2.6204, -2.5484, -2.6404, -2.5818, -2.5457, -2.6298, -2.6418,\n",
      "        -2.6358, -2.6513, -2.6536, -2.6028, -2.6369, -2.6168, -2.6390, -2.6407,\n",
      "        -2.6392, -2.6582], device='mps:0')\n",
      "mean: tensor(-2.6280, device='mps:0')\n",
      "iter_dt 1.11s; iter 71: train loss 0.70908 temperature: 8.549999999999997\n",
      "mean_logits tensor([-2.5847, -2.3748, -2.4299, -2.6110, -2.4292, -2.3589, -2.6035, -2.7481,\n",
      "        -2.4412, -2.6536, -2.7711, -2.7641, -2.6176, -2.2807, -2.7305, -2.3857,\n",
      "        -2.7047, -2.7921, -2.7030, -2.4148, -2.5447, -2.8570, -2.4405, -2.6534,\n",
      "        -2.6104, -2.5435, -2.5204, -2.0626, -2.3884, -2.6576, -2.5169, -2.5593,\n",
      "        -2.5967, -2.5629, -2.6941, -2.3828, -2.4529, -2.4976, -2.2890, -2.4743,\n",
      "        -2.3613, -2.6552, -2.7231, -2.8675, -2.6234, -2.4205, -2.7377, -2.5692,\n",
      "        -2.3917, -2.6697], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6535, -2.6522, -2.6452, -2.6290, -2.6287, -2.6532, -2.6503, -2.6595,\n",
      "        -2.6386, -2.6412, -2.6438, -2.6368, -2.6392, -2.6014, -2.6481, -2.6441,\n",
      "        -2.6501, -2.6250, -2.6222, -2.6384, -2.6464, -2.6057, -2.6512, -2.6298,\n",
      "        -2.6398, -2.6430, -2.6387, -2.6558, -2.5923, -2.6534, -2.6452, -2.6429,\n",
      "        -2.6054, -2.6400, -2.6489, -2.6332, -2.6491, -2.6256, -2.5181, -2.6565,\n",
      "        -2.6500, -2.6354, -2.6374, -2.5685, -2.6361, -2.6436, -2.6428, -2.6541,\n",
      "        -2.6033, -2.6128], device='mps:0')\n",
      "mean: tensor(-2.6341, device='mps:0')\n",
      "iter_dt 1.13s; iter 72: train loss 0.51869 temperature: 8.599999999999998\n",
      "mean_logits tensor([-2.4469, -2.3130, -2.7371, -2.6629, -2.5317, -2.5563, -2.5005, -2.7020,\n",
      "        -2.6504, -2.6474, -2.6986, -2.3610, -2.7821, -2.5891, -2.7618, -2.4704,\n",
      "        -2.5297, -2.4307, -2.7270, -2.6062, -2.5272, -2.5839, -2.5993, -2.7103,\n",
      "        -2.4158, -2.5685, -2.5073, -2.6187, -2.5168, -2.5261, -2.4834, -2.4373,\n",
      "        -2.5631, -2.5371, -2.5812, -2.5763, -2.9283, -2.4106, -2.7975, -2.3317,\n",
      "        -2.7201, -2.3799, -2.8530, -2.5954, -2.6489, -2.5959, -2.4493, -2.5613,\n",
      "        -2.2871, -2.6552], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6006, -2.6290, -2.6509, -2.5955, -2.6349, -2.6536, -2.6511, -2.6583,\n",
      "        -2.6570, -2.5747, -2.6491, -2.6405, -2.6512, -2.6424, -2.6161, -2.4983,\n",
      "        -2.6500, -2.6001, -2.6231, -2.6272, -2.6566, -2.6609, -2.6536, -2.6495,\n",
      "        -2.6489, -2.5703, -2.6506, -2.6496, -2.6426, -2.6076, -2.6401, -2.6374,\n",
      "        -2.6069, -2.6406, -2.6096, -2.5647, -2.6362, -2.6385, -2.5847, -2.5770,\n",
      "        -2.6330, -2.6471, -2.6525, -2.6127, -2.6297, -2.6465, -2.6426, -2.6495,\n",
      "        -2.6406, -2.6175], device='mps:0')\n",
      "mean: tensor(-2.6280, device='mps:0')\n",
      "iter_dt 1.21s; iter 73: train loss 0.89908 temperature: 8.649999999999999\n",
      "mean_logits tensor([-2.4435, -2.4644, -2.5322, -2.5843, -2.8270, -2.5933, -2.8626, -2.8911,\n",
      "        -2.5841, -2.8818, -2.7574, -2.5740, -2.2288, -2.7122, -2.5285, -2.5501,\n",
      "        -2.5190, -2.6060, -2.3915, -2.6908, -2.5413, -2.8038, -2.7441, -2.4648,\n",
      "        -2.4474, -2.6987, -2.3448, -2.4274, -2.3933, -2.5669, -2.6085, -2.4929,\n",
      "        -2.6005, -2.5410, -2.7170, -2.6323, -2.7625, -2.7584, -2.5942, -2.8782,\n",
      "        -2.8188, -3.1478, -2.6955, -2.7678, -2.5918, -2.7117, -2.5930, -2.5948,\n",
      "        -2.6187, -2.1136], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6523, -2.6363, -2.5895, -2.6246, -2.6170, -2.6498, -2.6148, -2.6446,\n",
      "        -2.6559, -2.6269, -2.6397, -2.6446, -2.6437, -2.6435, -2.6338, -2.6409,\n",
      "        -2.6268, -2.6463, -2.6457, -2.6304, -2.6567, -2.6382, -2.6523, -2.5904,\n",
      "        -2.6506, -2.6608, -2.6516, -2.6513, -2.6320, -2.6436, -2.5728, -2.6326,\n",
      "        -2.6536, -2.6533, -2.6005, -2.6537, -2.6515, -2.6378, -2.6517, -2.6281,\n",
      "        -2.5651, -2.6439, -2.6507, -2.6510, -2.6537, -2.6560, -2.6429, -2.6622,\n",
      "        -2.6296, -2.6090], device='mps:0')\n",
      "mean: tensor(-2.6367, device='mps:0')\n",
      "iter_dt 1.11s; iter 74: train loss 0.68497 temperature: 8.7\n",
      "mean_logits tensor([-2.5188, -2.7311, -2.5975, -2.9829, -2.2808, -2.5490, -2.3239, -2.6523,\n",
      "        -2.7995, -2.4459, -2.7123, -2.5265, -2.5112, -2.6322, -2.5597, -2.7437,\n",
      "        -2.5332, -2.5840, -2.3303, -2.7619, -2.2944, -2.6217, -2.4358, -2.7351,\n",
      "        -2.5050, -2.5068, -2.6591, -2.4451, -2.5337, -2.4717, -2.4781, -2.4999,\n",
      "        -2.4812, -2.4852, -2.6111, -2.6607, -2.3119, -2.7784, -2.7914, -2.6397,\n",
      "        -2.3292, -2.5217, -2.6588, -2.7358, -2.4959, -2.8752, -2.4129, -2.4984,\n",
      "        -2.4734, -2.7158], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6567, -2.6372, -2.6022, -2.6510, -2.6356, -2.5691, -2.6536, -2.6118,\n",
      "        -2.5993, -2.6288, -2.6550, -2.5776, -2.6440, -2.6463, -2.6377, -2.6302,\n",
      "        -2.6023, -2.6359, -2.6405, -2.6533, -2.6460, -2.6560, -2.6529, -2.6376,\n",
      "        -2.6513, -2.6557, -2.5713, -2.6386, -2.6382, -2.6612, -2.6112, -2.6564,\n",
      "        -2.5976, -2.6131, -2.5715, -2.6398, -2.6353, -2.5850, -2.6432, -2.5858,\n",
      "        -2.5833, -2.6396, -2.6377, -2.6153, -2.6088, -2.5871, -2.6361, -2.6035,\n",
      "        -2.6409, -2.6514], device='mps:0')\n",
      "mean: tensor(-2.6264, device='mps:0')\n",
      "iter_dt 1.10s; iter 75: train loss 0.56768 temperature: 8.75\n",
      "mean_logits tensor([-2.7080, -2.4395, -2.5662, -2.6808, -2.8066, -2.6658, -2.5351, -2.4697,\n",
      "        -2.6321, -2.4743, -2.3256, -2.5657, -2.4446, -2.7639, -2.5815, -2.8393,\n",
      "        -2.7076, -2.6965, -2.7480, -2.5376, -2.8078, -2.4322, -2.5734, -2.9934,\n",
      "        -2.6946, -2.7878, -2.6273, -2.7659, -2.4906, -2.5217, -2.3492, -2.5855,\n",
      "        -2.6975, -2.3385, -2.6740, -2.4170, -2.5742, -2.7440, -2.6190, -2.5027,\n",
      "        -2.5586, -2.7498, -2.8771, -2.7330, -2.3383, -2.5240, -2.6921, -2.6644,\n",
      "        -2.8781, -2.4920], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5812, -2.6616, -2.6410, -2.5818, -2.6499, -2.6049, -2.6556, -2.6526,\n",
      "        -2.6479, -2.6522, -2.5093, -2.5845, -2.6306, -2.6170, -2.6460, -2.6530,\n",
      "        -2.6512, -2.6544, -2.6504, -2.6365, -2.6486, -2.6512, -2.6480, -2.6425,\n",
      "        -2.6307, -2.6615, -2.5731, -2.6522, -2.6125, -2.6078, -2.5863, -2.6401,\n",
      "        -2.6526, -2.6408, -2.6530, -2.5660, -2.6436, -2.6373, -2.6548, -2.6516,\n",
      "        -2.6427, -2.6458, -2.6419, -2.6344, -2.6514, -2.6606, -2.6525, -2.6372,\n",
      "        -2.6519, -2.5863], device='mps:0')\n",
      "mean: tensor(-2.6324, device='mps:0')\n",
      "iter_dt 1.12s; iter 76: train loss 0.76158 temperature: 8.8\n",
      "mean_logits tensor([-2.7173, -2.8635, -2.6851, -2.6319, -2.4386, -2.5227, -2.4178, -2.6841,\n",
      "        -2.6146, -2.5562, -2.7748, -2.3625, -2.4430, -2.6311, -2.7921, -2.5009,\n",
      "        -2.2913, -2.5502, -2.4577, -2.6790, -2.5341, -2.9091, -2.4828, -2.5463,\n",
      "        -2.8024, -2.7238, -2.5323, -2.4482, -2.9118, -2.6202, -2.7189, -2.6796,\n",
      "        -3.0297, -2.7792, -2.7218, -2.5103, -2.1120, -2.5551, -2.6608, -2.5469,\n",
      "        -2.5672, -2.4159, -2.7000, -2.0734, -2.4881, -2.5562, -2.5514, -2.6480,\n",
      "        -2.4369, -2.4408], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6263, -2.6435, -2.6358, -2.6409, -2.5823, -2.6537, -2.5716, -2.6386,\n",
      "        -2.6379, -2.5857, -2.6463, -2.6409, -2.6284, -2.6461, -2.5842, -2.5848,\n",
      "        -2.6440, -2.6509, -2.6485, -2.6568, -2.6545, -2.6586, -2.6352, -2.5472,\n",
      "        -2.5490, -2.6211, -2.6104, -2.6393, -2.6492, -2.6605, -2.6515, -2.6057,\n",
      "        -2.6611, -2.6561, -2.6232, -2.6484, -2.5820, -2.6421, -2.5941, -2.6143,\n",
      "        -2.6463, -2.6415, -2.6487, -2.5911, -2.6462, -2.5936, -2.5894, -2.6483,\n",
      "        -2.6310, -2.6484], device='mps:0')\n",
      "mean: tensor(-2.6267, device='mps:0')\n",
      "iter_dt 1.10s; iter 77: train loss 0.60643 temperature: 8.850000000000001\n",
      "mean_logits tensor([-2.8924, -2.6548, -2.9486, -2.5107, -2.5518, -2.6410, -2.3550, -2.4073,\n",
      "        -2.6951, -2.4504, -2.4927, -2.6400, -2.8960, -2.6908, -2.4721, -2.7251,\n",
      "        -2.5810, -2.8695, -2.4317, -2.6109, -2.6422, -2.3090, -2.5149, -2.9009,\n",
      "        -2.6620, -2.7946, -2.6009, -2.6826, -2.6849, -2.4003, -2.7388, -2.7263,\n",
      "        -2.7519, -2.6710, -2.6896, -2.6017, -2.6382, -2.6898, -2.5465, -2.4330,\n",
      "        -2.4705, -2.6533, -2.7308, -2.3103, -2.6127, -2.6102, -2.5961, -2.7160,\n",
      "        -2.8429, -2.8339], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6533, -2.6309, -2.6464, -2.6371, -2.6511, -2.6331, -2.6342, -2.5770,\n",
      "        -2.5873, -2.6546, -2.6458, -2.6337, -2.6566, -2.6397, -2.5794, -2.6450,\n",
      "        -2.6425, -2.6588, -2.6555, -2.6538, -2.6576, -2.5791, -2.6321, -2.6512,\n",
      "        -2.6610, -2.5870, -2.6540, -2.6513, -2.6485, -2.6462, -2.6426, -2.6507,\n",
      "        -2.6482, -2.6491, -2.6555, -2.5790, -2.5533, -2.6499, -2.6302, -2.6430,\n",
      "        -2.6313, -2.6536, -2.6186, -2.6118, -2.6250, -2.6525, -2.6342, -2.5036,\n",
      "        -2.6292, -2.6473], device='mps:0')\n",
      "mean: tensor(-2.6318, device='mps:0')\n",
      "iter_dt 1.09s; iter 78: train loss 0.78845 temperature: 8.900000000000002\n",
      "mean_logits tensor([-2.6899, -2.6334, -2.6381, -2.6273, -2.3130, -2.3987, -2.5061, -2.5813,\n",
      "        -2.5695, -2.4931, -2.5888, -2.6978, -2.4625, -2.4300, -2.6396, -2.6948,\n",
      "        -2.4469, -2.4980, -2.6176, -2.6310, -2.3656, -2.3192, -2.4295, -2.4590,\n",
      "        -2.7778, -2.8097, -2.3639, -2.6401, -2.7911, -2.6483, -2.6866, -2.6290,\n",
      "        -2.5821, -2.5015, -2.1956, -2.3836, -2.7404, -2.4696, -2.7441, -2.2550,\n",
      "        -2.7405, -2.4562, -2.5646, -2.8369, -2.4078, -2.2368, -2.5415, -3.0384,\n",
      "        -2.4792, -2.4564], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6472, -2.6495, -2.6448, -2.5426, -2.6409, -2.6060, -2.6448, -2.6525,\n",
      "        -2.6520, -2.6550, -2.6443, -2.6547, -2.6202, -2.6203, -2.6619, -2.6204,\n",
      "        -2.6328, -2.5910, -2.5567, -2.6478, -2.6505, -2.6226, -2.6419, -2.6506,\n",
      "        -2.6297, -2.6383, -2.6489, -2.6280, -2.6452, -2.5957, -2.6281, -2.6521,\n",
      "        -2.6556, -2.6530, -2.6304, -2.6368, -2.5688, -2.6553, -2.6601, -2.5975,\n",
      "        -2.6513, -2.5885, -2.6301, -2.6362, -2.6316, -2.6476, -2.6428, -2.6482,\n",
      "        -2.6100, -2.6562], device='mps:0')\n",
      "mean: tensor(-2.6323, device='mps:0')\n",
      "iter_dt 1.09s; iter 79: train loss 0.70953 temperature: 8.950000000000003\n",
      "mean_logits tensor([-2.6114, -2.7030, -2.6563, -2.6194, -2.4249, -2.5916, -2.3386, -2.8418,\n",
      "        -2.4436, -2.5007, -2.5007, -2.8834, -2.6836, -2.8184, -2.5496, -2.6881,\n",
      "        -2.6121, -3.0606, -2.3966, -2.7759, -2.8180, -2.7137, -2.3779, -2.5157,\n",
      "        -2.5230, -2.2944, -2.7026, -2.4055, -2.6944, -2.4066, -2.2868, -2.7784,\n",
      "        -2.6626, -2.5156, -2.4794, -2.7951, -2.5610, -2.6867, -2.6324, -2.2931,\n",
      "        -2.6631, -2.7542, -2.7361, -2.2373, -2.6713, -2.5867, -2.5901, -2.4852,\n",
      "        -2.6699, -2.5897], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6560, -2.6539, -2.6470, -2.5783, -2.6396, -2.6434, -2.5684, -2.6233,\n",
      "        -2.6377, -2.6559, -2.6421, -2.6399, -2.6411, -2.6548, -2.6508, -2.6512,\n",
      "        -2.5991, -2.6397, -2.6096, -2.6418, -2.5855, -2.6331, -2.6462, -2.6004,\n",
      "        -2.6170, -2.6416, -2.5922, -2.6537, -2.6301, -2.6549, -2.4988, -2.6411,\n",
      "        -2.6463, -2.6233, -2.6355, -2.6536, -2.6612, -2.6378, -2.6200, -2.6284,\n",
      "        -2.6167, -2.6464, -2.6384, -2.5805, -2.5945, -2.6487, -2.5608, -2.6427,\n",
      "        -2.6074, -2.6368], device='mps:0')\n",
      "mean: tensor(-2.6269, device='mps:0')\n",
      "iter_dt 1.10s; iter 80: train loss 0.65294 temperature: 9.000000000000004\n",
      "mean_logits tensor([-2.5765, -2.5159, -2.7618, -2.5831, -2.5408, -2.6895, -2.8116, -2.8926,\n",
      "        -2.6787, -2.5436, -2.6423, -2.6250, -2.8152, -2.4237, -2.8007, -2.9933,\n",
      "        -2.6241, -2.5543, -2.9093, -2.5430, -2.7476, -2.5008, -2.6356, -2.8682,\n",
      "        -2.4153, -2.0173, -2.4870, -2.6010, -2.5710, -2.5437, -2.4178, -2.5900,\n",
      "        -2.7396, -2.4124, -2.7176, -2.5768, -2.7033, -2.5074, -2.5631, -2.6304,\n",
      "        -2.6423, -2.6242, -2.5761, -2.3166, -2.5772, -2.5803, -2.7540, -2.5701,\n",
      "        -2.4684, -2.7682], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5961, -2.6352, -2.6473, -2.6429, -2.6331, -2.6553, -2.6362, -2.6501,\n",
      "        -2.6516, -2.6065, -2.6538, -2.6457, -2.6352, -2.6380, -2.6421, -2.6532,\n",
      "        -2.5854, -2.6357, -2.6443, -2.6510, -2.6081, -2.5983, -2.6471, -2.6465,\n",
      "        -2.6307, -2.6549, -2.6387, -2.6410, -2.6262, -2.6511, -2.6435, -2.6508,\n",
      "        -2.6109, -2.6391, -2.6582, -2.5672, -2.5515, -2.6481, -2.6477, -2.6400,\n",
      "        -2.6545, -2.5773, -2.5823, -2.6323, -2.6503, -2.6559, -2.6539, -2.6587,\n",
      "        -2.5880, -2.6217], device='mps:0')\n",
      "mean: tensor(-2.6323, device='mps:0')\n",
      "iter_dt 1.14s; iter 81: train loss 0.80557 temperature: 9.050000000000004\n",
      "mean_logits tensor([-2.7765, -2.9517, -2.6610, -2.4631, -2.5712, -2.5446, -2.2591, -2.5652,\n",
      "        -2.3298, -2.7358, -2.9113, -2.8128, -2.4903, -2.5478, -2.7492, -2.6550,\n",
      "        -2.5204, -2.4444, -2.6799, -2.4588, -2.8048, -2.4667, -2.6499, -2.7858,\n",
      "        -2.4116, -2.8835, -2.5237, -2.5380, -2.5671, -2.4910, -2.6083, -2.1569,\n",
      "        -2.6677, -2.7222, -2.4550, -2.5084, -2.2775, -2.7329, -2.5624, -2.3979,\n",
      "        -2.7819, -2.7546, -2.4487, -2.5061, -2.7463, -2.6621, -2.0736, -2.7105,\n",
      "        -2.5899, -2.4955], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6407, -2.6526, -2.5561, -2.6384, -2.6087, -2.6557, -2.5980, -2.6481,\n",
      "        -2.6031, -2.6498, -2.6404, -2.6398, -2.6319, -2.6489, -2.6611, -2.6402,\n",
      "        -2.5883, -2.6257, -2.5787, -2.6556, -2.6511, -2.6564, -2.5415, -2.6406,\n",
      "        -2.6439, -2.6385, -2.6359, -2.6485, -2.6504, -2.6421, -2.6560, -2.6151,\n",
      "        -2.6370, -2.6327, -2.6591, -2.6213, -2.6439, -2.6039, -2.5971, -2.6432,\n",
      "        -2.5942, -2.6397, -2.6403, -2.6608, -2.6360, -2.6492, -2.6022, -2.5289,\n",
      "        -2.6555, -2.6196], device='mps:0')\n",
      "mean: tensor(-2.6289, device='mps:0')\n",
      "iter_dt 1.11s; iter 82: train loss 0.54254 temperature: 9.100000000000005\n",
      "mean_logits tensor([-2.6774, -2.7095, -2.6671, -2.7415, -2.8991, -2.5279, -2.6391, -2.5340,\n",
      "        -2.6778, -2.6113, -2.6569, -2.4188, -2.4824, -2.4817, -2.6108, -2.8345,\n",
      "        -2.5384, -2.8230, -2.6325, -2.6344, -2.4401, -2.4924, -2.2961, -2.5703,\n",
      "        -2.5136, -2.8318, -2.5666, -2.4097, -2.6645, -2.4523, -2.3154, -2.6420,\n",
      "        -2.5599, -2.3910, -2.7669, -2.5083, -2.4660, -2.6593, -2.7093, -2.5601,\n",
      "        -2.6314, -2.4049, -2.6606, -2.6953, -2.8835, -2.5769, -2.6953, -2.6091,\n",
      "        -2.3216, -2.6143], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6497, -2.6382, -2.6447, -2.6557, -2.6479, -2.6127, -2.6521, -2.6458,\n",
      "        -2.6387, -2.6319, -2.6389, -2.6457, -2.6404, -2.6536, -2.5840, -2.5595,\n",
      "        -2.5630, -2.6543, -2.6475, -2.6492, -2.5983, -2.6536, -2.5985, -2.6266,\n",
      "        -2.6501, -2.6465, -2.5798, -2.6526, -2.6470, -2.6526, -2.6421, -2.5946,\n",
      "        -2.5812, -2.6365, -2.6175, -2.6429, -2.6302, -2.5768, -2.6226, -2.6500,\n",
      "        -2.6450, -2.6616, -2.6314, -2.6450, -2.6265, -2.6375, -2.6350, -2.6558,\n",
      "        -2.6492, -2.6488], device='mps:0')\n",
      "mean: tensor(-2.6318, device='mps:0')\n",
      "iter_dt 1.11s; iter 83: train loss 0.70927 temperature: 9.150000000000006\n",
      "mean_logits tensor([-2.5001, -2.6062, -2.5477, -2.7363, -2.3531, -2.7157, -2.6035, -2.7849,\n",
      "        -2.4590, -2.8025, -2.9295, -2.5171, -2.2510, -2.5476, -2.4599, -2.5249,\n",
      "        -2.6005, -2.5223, -2.6951, -2.5194, -2.4753, -2.6894, -2.7141, -2.3004,\n",
      "        -2.8366, -2.4145, -2.3476, -2.4396, -2.3230, -2.8051, -2.3878, -2.3753,\n",
      "        -2.5302, -2.6012, -2.6295, -2.6710, -2.4717, -2.4661, -2.1439, -2.6406,\n",
      "        -2.5687, -2.4320, -2.5644, -2.6333, -2.7741, -2.7334, -2.6349, -2.7612,\n",
      "        -2.7110, -2.5735], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6552, -2.6592, -2.6557, -2.6353, -2.6505, -2.5414, -2.6557, -2.6528,\n",
      "        -2.6505, -2.6437, -2.6507, -2.6411, -2.6417, -2.6220, -2.6370, -2.6486,\n",
      "        -2.6578, -2.6384, -2.6450, -2.6522, -2.6051, -2.6527, -2.6558, -2.6567,\n",
      "        -2.6459, -2.6373, -2.6541, -2.5756, -2.6409, -2.6490, -2.6395, -2.6014,\n",
      "        -2.6324, -2.6529, -2.6534, -2.6332, -2.6381, -2.6314, -2.6023, -2.6427,\n",
      "        -2.6503, -2.6396, -2.6550, -2.6517, -2.6478, -2.5587, -2.5899, -2.5803,\n",
      "        -2.6484, -2.6531], device='mps:0')\n",
      "mean: tensor(-2.6362, device='mps:0')\n",
      "iter_dt 1.13s; iter 84: train loss 0.40195 temperature: 9.200000000000006\n",
      "mean_logits tensor([-2.7208, -2.3721, -2.6479, -2.5099, -2.4419, -2.5439, -2.8586, -2.7749,\n",
      "        -2.6528, -2.5852, -2.5541, -2.6035, -2.7428, -2.5380, -2.6390, -2.5285,\n",
      "        -2.5047, -2.5809, -2.6058, -2.5217, -2.6133, -2.3339, -2.7363, -2.8231,\n",
      "        -2.7058, -2.6497, -2.6581, -2.6330, -2.6510, -2.5244, -2.3651, -2.4940,\n",
      "        -2.5291, -2.4600, -2.4256, -2.6201, -2.5913, -2.7984, -2.6641, -2.4840,\n",
      "        -2.5947, -2.6988, -2.6798, -2.4963, -2.5315, -2.5829, -2.5586, -2.5224,\n",
      "        -2.5331, -2.7100], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5667, -2.6497, -2.6527, -2.5988, -2.6477, -2.6292, -2.6001, -2.6460,\n",
      "        -2.6566, -2.6500, -2.5823, -2.5793, -2.6471, -2.6498, -2.6519, -2.6574,\n",
      "        -2.6515, -2.5921, -2.6529, -2.6413, -2.5670, -2.6393, -2.6468, -2.5502,\n",
      "        -2.6338, -2.6133, -2.6433, -2.6468, -2.6095, -2.6373, -2.6508, -2.6345,\n",
      "        -2.5813, -2.5996, -2.6480, -2.6243, -2.6448, -2.6516, -2.6312, -2.5594,\n",
      "        -2.6355, -2.6285, -2.5740, -2.6409, -2.6488, -2.6534, -2.6556, -2.6496,\n",
      "        -2.6526, -2.6508], device='mps:0')\n",
      "mean: tensor(-2.6281, device='mps:0')\n",
      "iter_dt 1.14s; iter 85: train loss 0.60465 temperature: 9.250000000000007\n",
      "mean_logits tensor([-2.9229, -2.5349, -2.5846, -2.4720, -2.6038, -2.7654, -2.6107, -2.6038,\n",
      "        -2.7496, -2.5801, -2.5347, -2.6373, -2.5563, -2.5470, -2.7282, -2.6139,\n",
      "        -2.8924, -2.4396, -2.4602, -2.6956, -2.4897, -2.5582, -2.7348, -2.5266,\n",
      "        -2.3109, -2.6234, -2.5024, -2.5899, -2.8663, -2.6325, -2.7511, -2.7689,\n",
      "        -2.2095, -2.8208, -2.8004, -2.9209, -2.5742, -2.5998, -2.2965, -2.6043,\n",
      "        -2.7226, -2.6905, -2.5891, -2.4491, -2.6218, -2.5799, -2.7103, -2.5151,\n",
      "        -2.7136, -2.6329], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6062, -2.5896, -2.6474, -2.5805, -2.6466, -2.6280, -2.5893, -2.6174,\n",
      "        -2.6506, -2.6414, -2.6517, -2.6126, -2.6551, -2.6445, -2.6292, -2.6489,\n",
      "        -2.6139, -2.6293, -2.6454, -2.6053, -2.6334, -2.6454, -2.6484, -2.6419,\n",
      "        -2.6560, -2.6445, -2.6504, -2.6505, -2.6448, -2.6459, -2.6229, -2.6346,\n",
      "        -2.6365, -2.6122, -2.6282, -2.6355, -2.6532, -2.6410, -2.6475, -2.6537,\n",
      "        -2.6102, -2.6373, -2.6364, -2.6407, -2.6343, -2.6083, -2.6456, -2.6348,\n",
      "        -2.6134, -2.6487], device='mps:0')\n",
      "mean: tensor(-2.6334, device='mps:0')\n",
      "iter_dt 1.14s; iter 86: train loss 0.52493 temperature: 9.300000000000008\n",
      "mean_logits tensor([-2.4708, -2.5355, -2.6138, -2.4291, -2.6842, -2.5918, -2.4478, -2.5689,\n",
      "        -2.6603, -2.8253, -2.7286, -2.9566, -2.6430, -2.7246, -2.6314, -2.5703,\n",
      "        -2.6451, -2.6484, -2.5389, -2.7172, -2.5566, -2.5859, -2.6726, -2.4042,\n",
      "        -2.6761, -2.4680, -2.3052, -2.5421, -2.5419, -2.3437, -2.5894, -2.8645,\n",
      "        -2.3042, -2.4926, -2.6391, -2.5702, -2.6071, -2.7748, -2.2942, -2.8234,\n",
      "        -2.6592, -2.8647, -2.4582, -2.5518, -2.5771, -2.3647, -2.6546, -2.4553,\n",
      "        -2.7653, -2.6106], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6336, -2.6510, -2.6349, -2.6458, -2.6341, -2.6258, -2.5862, -2.6615,\n",
      "        -2.6495, -2.6528, -2.6405, -2.6390, -2.6491, -2.6447, -2.6559, -2.6362,\n",
      "        -2.6554, -2.6393, -2.6099, -2.6399, -2.6356, -2.6551, -2.6398, -2.5980,\n",
      "        -2.6468, -2.6464, -2.5562, -2.6559, -2.6559, -2.6103, -2.6550, -2.6452,\n",
      "        -2.5527, -2.6479, -2.6475, -2.6485, -2.6455, -2.5885, -2.6280, -2.6451,\n",
      "        -2.6441, -2.6507, -2.6325, -2.6386, -2.6561, -2.6240, -2.5995, -2.6536,\n",
      "        -2.6222, -2.6295], device='mps:0')\n",
      "mean: tensor(-2.6348, device='mps:0')\n",
      "iter_dt 1.10s; iter 87: train loss 0.60165 temperature: 9.350000000000009\n",
      "mean_logits tensor([-2.8140, -2.5277, -2.4698, -2.6745, -2.5985, -2.7859, -2.7167, -2.5449,\n",
      "        -2.4324, -2.6725, -2.5426, -2.7974, -2.3677, -2.4975, -2.3836, -2.6083,\n",
      "        -2.5577, -2.8690, -2.5363, -2.8811, -2.6896, -2.4925, -2.8573, -2.6029,\n",
      "        -2.6040, -2.5204, -2.7987, -2.6057, -2.8273, -2.3554, -2.7442, -2.5563,\n",
      "        -2.4709, -2.5276, -2.4787, -2.6311, -2.5419, -2.6879, -2.6046, -2.3911,\n",
      "        -2.4900, -2.2839, -2.8033, -2.4645, -2.6286, -2.7657, -2.3955, -2.3909,\n",
      "        -2.7668, -2.5623], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.5749, -2.6308, -2.6210, -2.6572, -2.6533, -2.6374, -2.6471, -2.6527,\n",
      "        -2.6484, -2.6495, -2.6408, -2.6244, -2.6396, -2.6381, -2.5494, -2.6493,\n",
      "        -2.6448, -2.6404, -2.6487, -2.6415, -2.6557, -2.6593, -2.6278, -2.5835,\n",
      "        -2.5448, -2.6439, -2.6432, -2.6513, -2.6511, -2.6357, -2.6472, -2.5800,\n",
      "        -2.6057, -2.6555, -2.6535, -2.6404, -2.6559, -2.6474, -2.6504, -2.6345,\n",
      "        -2.6490, -2.6490, -2.6449, -2.6550, -2.6437, -2.6334, -2.6092, -2.6174,\n",
      "        -2.6519, -2.6530], device='mps:0')\n",
      "mean: tensor(-2.6353, device='mps:0')\n",
      "iter_dt 1.18s; iter 88: train loss 0.66325 temperature: 9.40000000000001\n",
      "mean_logits tensor([-2.9440, -2.7379, -2.6689, -2.6969, -2.7449, -2.5637, -2.5854, -2.4418,\n",
      "        -2.6482, -2.3935, -2.4586, -2.6332, -2.2512, -2.7662, -2.5666, -2.5726,\n",
      "        -2.5674, -2.4215, -2.7363, -2.7979, -2.4819, -2.6308, -2.4250, -2.7251,\n",
      "        -2.6306, -2.5848, -2.4853, -2.5639, -2.9240, -2.5023, -2.6152, -2.8066,\n",
      "        -2.5904, -2.6462, -2.5316, -2.8164, -3.0068, -2.4173, -2.7769, -2.4155,\n",
      "        -2.6417, -2.3876, -2.6067, -2.7290, -2.7243, -2.5931, -2.7035, -2.7684,\n",
      "        -2.7738, -2.2840], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6466, -2.6267, -2.6553, -2.6137, -2.6541, -2.6366, -2.6373, -2.6134,\n",
      "        -2.6375, -2.6253, -2.5719, -2.6561, -2.6431, -2.6271, -2.6330, -2.6123,\n",
      "        -2.6555, -2.5864, -2.6563, -2.6468, -2.6467, -2.5923, -2.5560, -2.5548,\n",
      "        -2.6513, -2.6560, -2.6555, -2.6386, -2.6122, -2.6159, -2.6472, -2.6560,\n",
      "        -2.6409, -2.6388, -2.6423, -2.6506, -2.6511, -2.6532, -2.6510, -2.6530,\n",
      "        -2.6558, -2.6455, -2.6036, -2.6487, -2.6431, -2.6531, -2.6498, -2.6337,\n",
      "        -2.6544, -2.6504], device='mps:0')\n",
      "mean: tensor(-2.6347, device='mps:0')\n",
      "iter_dt 1.31s; iter 89: train loss 0.56530 temperature: 9.45000000000001\n",
      "mean_logits tensor([-2.7888, -2.8534, -2.7544, -2.7514, -2.5145, -2.7058, -2.7259, -2.7897,\n",
      "        -2.6772, -2.7984, -2.7086, -2.7208, -2.5429, -2.4816, -2.5712, -2.5025,\n",
      "        -2.6070, -2.6745, -2.6610, -2.5439, -2.7955, -2.5990, -2.4744, -2.5836,\n",
      "        -2.0853, -2.5567, -2.9327, -2.5749, -2.7454, -2.5820, -2.5391, -2.7786,\n",
      "        -2.5227, -2.6638, -2.5760, -2.6759, -2.3004, -2.7606, -2.7156, -2.3918,\n",
      "        -2.6837, -2.6147, -2.6420, -2.5557, -2.4384, -2.8553, -2.5255, -2.5814,\n",
      "        -2.3594, -2.7760], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6496, -2.5771, -2.6111, -2.6504, -2.5454, -2.6501, -2.6436, -2.6453,\n",
      "        -2.6270, -2.6504, -2.5793, -2.6413, -2.6560, -2.6357, -2.6561, -2.6516,\n",
      "        -2.5732, -2.6342, -2.6520, -2.6462, -2.5991, -2.6175, -2.6558, -2.6390,\n",
      "        -2.6272, -2.6302, -2.6552, -2.6347, -2.6410, -2.6357, -2.6357, -2.6338,\n",
      "        -2.5700, -2.6409, -2.6484, -2.6508, -2.6359, -2.6535, -2.5986, -2.6231,\n",
      "        -2.6472, -2.6557, -2.6412, -2.6533, -2.6481, -2.6454, -2.6503, -2.6543,\n",
      "        -2.6293, -2.6529], device='mps:0')\n",
      "mean: tensor(-2.6336, device='mps:0')\n",
      "iter_dt 1.18s; iter 90: train loss 0.41895 temperature: 9.50000000000001\n",
      "mean_logits tensor([-2.5813, -2.4936, -2.6829, -2.3509, -2.5222, -2.4370, -2.6141, -2.5063,\n",
      "        -2.6648, -2.7370, -2.5593, -2.5963, -2.7648, -2.5456, -2.5778, -2.7012,\n",
      "        -2.7057, -2.7553, -2.8170, -2.7861, -2.3520, -2.4538, -2.6659, -2.6958,\n",
      "        -2.6421, -2.4460, -2.7126, -2.6935, -2.6366, -2.4910, -2.5178, -2.4974,\n",
      "        -2.6928, -2.6694, -2.4875, -2.4830, -2.9049, -2.4382, -2.4871, -2.7681,\n",
      "        -2.4174, -2.5506, -2.6069, -2.4542, -2.6104, -2.7623, -2.6244, -2.5692,\n",
      "        -2.5628, -2.4630], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6025, -2.6550, -2.6389, -2.5674, -2.6460, -2.6042, -2.6520, -2.6514,\n",
      "        -2.6510, -2.6404, -2.6418, -2.6491, -2.6565, -2.5836, -2.6364, -2.5744,\n",
      "        -2.6328, -2.6542, -2.6484, -2.6590, -2.6340, -2.6293, -2.6532, -2.5581,\n",
      "        -2.5701, -2.6462, -2.6280, -2.6505, -2.6506, -2.6350, -2.6478, -2.5916,\n",
      "        -2.6233, -2.6530, -2.6484, -2.5429, -2.5892, -2.6361, -2.6439, -2.6338,\n",
      "        -2.6526, -2.6441, -2.6424, -2.6037, -2.6391, -2.6342, -2.6406, -2.6148,\n",
      "        -2.6468, -2.6490], device='mps:0')\n",
      "mean: tensor(-2.6296, device='mps:0')\n",
      "iter_dt 1.13s; iter 91: train loss 0.51790 temperature: 9.550000000000011\n",
      "mean_logits tensor([-2.5332, -2.5142, -2.4973, -2.4515, -2.7401, -2.6457, -2.5019, -2.4704,\n",
      "        -2.7481, -2.6086, -2.7299, -2.8976, -2.4430, -2.6825, -2.5113, -2.6276,\n",
      "        -2.6636, -2.6020, -2.5123, -2.6515, -2.3804, -2.5898, -2.5515, -2.5025,\n",
      "        -2.4086, -2.6217, -2.5267, -2.5170, -2.7926, -2.7558, -2.7654, -2.5035,\n",
      "        -2.7575, -2.6411, -2.7639, -2.8614, -2.3252, -2.6177, -2.9153, -2.3787,\n",
      "        -2.5323, -2.3737, -2.4946, -2.5097, -2.5589, -2.6754, -2.5656, -2.5094,\n",
      "        -2.5645, -2.4963], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6261, -2.6536, -2.6389, -2.6212, -2.5741, -2.6508, -2.6357, -2.6444,\n",
      "        -2.6523, -2.6516, -2.6460, -2.6417, -2.6464, -2.6407, -2.6466, -2.6411,\n",
      "        -2.6511, -2.6280, -2.6434, -2.6567, -2.6480, -2.6397, -2.6098, -2.6430,\n",
      "        -2.6406, -2.6395, -2.6509, -2.6391, -2.6324, -2.6556, -2.6546, -2.5789,\n",
      "        -2.6431, -2.6558, -2.6412, -2.6424, -2.6382, -2.6413, -2.6558, -2.6483,\n",
      "        -2.5585, -2.6470, -2.6023, -2.6548, -2.6532, -2.6435, -2.6541, -2.6163,\n",
      "        -2.6564, -2.6544], device='mps:0')\n",
      "mean: tensor(-2.6386, device='mps:0')\n",
      "iter_dt 1.15s; iter 92: train loss 0.58140 temperature: 9.600000000000012\n",
      "mean_logits tensor([-2.6786, -2.6769, -2.4895, -2.5912, -2.6349, -2.7008, -2.5924, -2.6005,\n",
      "        -2.6652, -2.4177, -2.7185, -2.4973, -2.6309, -2.7636, -2.6538, -2.6995,\n",
      "        -2.4705, -2.7722, -2.6769, -2.7360, -2.5040, -2.8874, -2.5121, -2.6686,\n",
      "        -2.7277, -2.2861, -2.6523, -2.6419, -2.7237, -2.5599, -2.5801, -2.6657,\n",
      "        -2.6170, -2.9051, -2.7455, -2.6229, -2.6543, -2.5893, -2.7204, -2.4727,\n",
      "        -2.4011, -2.8777, -2.9861, -2.7031, -2.5109, -2.8975, -2.2999, -2.5118,\n",
      "        -2.3982, -2.6753], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6346, -2.6432, -2.6553, -2.6322, -2.6408, -2.6504, -2.6128, -2.6490,\n",
      "        -2.6507, -2.6360, -2.5989, -2.5825, -2.6423, -2.6560, -2.6532, -2.6541,\n",
      "        -2.6509, -2.6505, -2.6428, -2.6113, -2.6532, -2.6515, -2.6357, -2.6261,\n",
      "        -2.6504, -2.6617, -2.6553, -2.6297, -2.6394, -2.5930, -2.6057, -2.6516,\n",
      "        -2.6412, -2.6536, -2.6536, -2.6537, -2.6548, -2.6494, -2.6143, -2.6363,\n",
      "        -2.6507, -2.6330, -2.6560, -2.6559, -2.6561, -2.5730, -2.6367, -2.6514,\n",
      "        -2.5985, -2.6530], device='mps:0')\n",
      "mean: tensor(-2.6384, device='mps:0')\n",
      "iter_dt 1.17s; iter 93: train loss 0.44995 temperature: 9.650000000000013\n",
      "mean_logits tensor([-2.7168, -2.5697, -2.7148, -2.6040, -2.3710, -2.8228, -2.3781, -2.3527,\n",
      "        -2.5678, -2.7468, -2.6451, -2.6034, -2.6245, -2.4478, -2.8347, -2.3763,\n",
      "        -2.3449, -2.5961, -2.6275, -2.6280, -2.4257, -2.6009, -2.3715, -2.5096,\n",
      "        -2.7822, -2.7735, -2.6166, -2.7050, -2.6070, -2.5689, -2.6491, -2.7346,\n",
      "        -2.3518, -2.5154, -2.5034, -2.4415, -2.7198, -2.5681, -2.7495, -2.5469,\n",
      "        -2.6250, -2.6337, -2.4652, -2.7605, -2.5833, -2.6481, -2.5240, -2.5264,\n",
      "        -2.6022, -2.8799], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6385, -2.6159, -2.6499, -2.6522, -2.5642, -2.5964, -2.5623, -2.5928,\n",
      "        -2.6561, -2.6579, -2.6501, -2.6466, -2.6379, -2.6408, -2.6111, -2.6559,\n",
      "        -2.6030, -2.6561, -2.6439, -2.6479, -2.6149, -2.6549, -2.6556, -2.6435,\n",
      "        -2.6461, -2.6415, -2.6405, -2.6419, -2.6281, -2.6081, -2.6470, -2.6507,\n",
      "        -2.6538, -2.6326, -2.6298, -2.6082, -2.6317, -2.6490, -2.6422, -2.6510,\n",
      "        -2.6393, -2.6505, -2.6143, -2.6365, -2.6282, -2.6558, -2.6533, -2.6527,\n",
      "        -2.6463, -2.6522], device='mps:0')\n",
      "mean: tensor(-2.6356, device='mps:0')\n",
      "iter_dt 1.11s; iter 94: train loss 0.58898 temperature: 9.700000000000014\n",
      "mean_logits tensor([-2.3542, -2.5216, -2.2517, -2.8425, -2.5862, -2.6909, -2.8385, -2.7441,\n",
      "        -2.5451, -2.4399, -2.5377, -2.4516, -2.6193, -2.8102, -2.6743, -2.5690,\n",
      "        -2.3006, -2.8774, -2.1982, -2.4101, -2.7402, -2.6224, -2.6718, -2.6650,\n",
      "        -2.6118, -2.7293, -2.6256, -2.6601, -2.4487, -2.4222, -2.7426, -2.5572,\n",
      "        -2.5745, -2.4149, -2.6123, -2.6839, -2.5110, -2.2348, -2.6786, -2.7287,\n",
      "        -2.5856, -2.5187, -2.8164, -2.5077, -2.7240, -2.5172, -2.6382, -2.4899,\n",
      "        -2.6594, -2.4908], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6073, -2.6396, -2.6559, -2.6516, -2.6109, -2.6304, -2.6472, -2.6508,\n",
      "        -2.6396, -2.6427, -2.6521, -2.5946, -2.6516, -2.6556, -2.6559, -2.6444,\n",
      "        -2.6435, -2.5991, -2.5819, -2.6237, -2.6444, -2.6344, -2.6534, -2.6386,\n",
      "        -2.6457, -2.6401, -2.6508, -2.6538, -2.6556, -2.5988, -2.6506, -2.6291,\n",
      "        -2.6411, -2.6538, -2.5200, -2.6300, -2.6301, -2.6549, -2.6340, -2.6505,\n",
      "        -2.6454, -2.6279, -2.6488, -2.6083, -2.6554, -2.6385, -2.6154, -2.6507,\n",
      "        -2.6438, -2.6467], device='mps:0')\n",
      "mean: tensor(-2.6354, device='mps:0')\n",
      "iter_dt 1.09s; iter 95: train loss 0.57291 temperature: 9.750000000000014\n",
      "mean_logits tensor([-2.5258, -2.6311, -2.5846, -2.7151, -2.1635, -2.6558, -2.8160, -2.3602,\n",
      "        -2.8063, -2.5813, -2.5439, -2.6943, -2.8008, -2.6376, -2.7939, -2.5401,\n",
      "        -2.4512, -2.6305, -2.4976, -2.3228, -2.4115, -2.4514, -2.6724, -2.4994,\n",
      "        -2.6220, -2.6006, -2.4410, -2.7156, -2.5546, -2.8241, -2.4848, -2.7320,\n",
      "        -2.3211, -2.7107, -2.5322, -2.6650, -2.4654, -2.6633, -2.5203, -2.5231,\n",
      "        -2.5508, -2.7555, -2.6129, -2.6290, -2.5648, -2.5178, -2.1934, -2.9537,\n",
      "        -2.5182, -2.5496], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6504, -2.6459, -2.6338, -2.6516, -2.6412, -2.6428, -2.6491, -2.6243,\n",
      "        -2.6614, -2.6263, -2.6430, -2.6395, -2.6479, -2.6394, -2.6601, -2.6548,\n",
      "        -2.6504, -2.6424, -2.6537, -2.5803, -2.6148, -2.6353, -2.6383, -2.6278,\n",
      "        -2.6561, -2.6373, -2.6393, -2.6053, -2.5435, -2.6390, -2.5628, -2.6498,\n",
      "        -2.6532, -2.6533, -2.6517, -2.6505, -2.6483, -2.6439, -2.6231, -2.6520,\n",
      "        -2.6501, -2.6475, -2.6358, -2.6539, -2.6446, -2.6436, -2.5570, -2.6122,\n",
      "        -2.6140, -2.6530], device='mps:0')\n",
      "mean: tensor(-2.6355, device='mps:0')\n",
      "iter_dt 1.10s; iter 96: train loss 0.66476 temperature: 9.800000000000015\n",
      "mean_logits tensor([-2.5131, -2.3390, -2.6432, -2.7464, -2.5480, -2.5762, -2.5393, -2.5779,\n",
      "        -2.6882, -2.7606, -2.3651, -2.8751, -2.4047, -2.6097, -2.5437, -2.3533,\n",
      "        -2.4563, -2.6610, -2.3316, -2.7060, -2.7569, -2.6080, -2.5442, -2.7258,\n",
      "        -2.4345, -2.3896, -2.2671, -2.5369, -2.2599, -2.9197, -2.8749, -2.6101,\n",
      "        -2.6676, -2.4982, -2.4861, -2.7498, -2.8350, -2.5732, -2.8611, -2.6411,\n",
      "        -2.8597, -2.2811, -2.5952, -2.7614, -2.5204, -2.6516, -2.7194, -2.6773,\n",
      "        -2.5158, -2.7055], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6552, -2.5823, -2.6506, -2.6569, -2.6213, -2.6561, -2.6362, -2.5770,\n",
      "        -2.6461, -2.6087, -2.6507, -2.6478, -2.6404, -2.6416, -2.6505, -2.4765,\n",
      "        -2.6094, -2.6556, -2.6414, -2.6485, -2.6437, -2.6509, -2.6370, -2.6614,\n",
      "        -2.6062, -2.6527, -2.6058, -2.6422, -2.6443, -2.6532, -2.6301, -2.6359,\n",
      "        -2.6176, -2.6314, -2.6010, -2.6313, -2.6533, -2.5968, -2.6075, -2.6557,\n",
      "        -2.6410, -2.6508, -2.6551, -2.6292, -2.6458, -2.6398, -2.6561, -2.6161,\n",
      "        -2.6033, -2.6339], device='mps:0')\n",
      "mean: tensor(-2.6316, device='mps:0')\n",
      "iter_dt 1.11s; iter 97: train loss 0.54110 temperature: 9.850000000000016\n",
      "mean_logits tensor([-2.8455, -2.5659, -2.4944, -2.5629, -2.8854, -2.5936, -2.5657, -2.4088,\n",
      "        -2.6349, -2.8495, -2.6432, -2.5885, -2.6972, -2.8386, -2.7692, -2.4865,\n",
      "        -2.6378, -2.8882, -2.7610, -2.7653, -2.6382, -2.7250, -2.3858, -2.5809,\n",
      "        -2.5262, -2.4777, -2.4296, -2.6274, -2.6561, -2.6113, -2.6156, -2.6742,\n",
      "        -2.4073, -2.7255, -2.5984, -2.5717, -2.8256, -2.8354, -2.5588, -2.2104,\n",
      "        -2.6084, -2.5728, -2.5617, -2.5647, -2.4852, -2.6710, -2.7247, -2.3652,\n",
      "        -2.6236, -2.6382], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6281, -2.6556, -2.6481, -2.6573, -2.6321, -2.6226, -2.6430, -2.6536,\n",
      "        -2.5782, -2.6296, -2.6556, -2.6460, -2.6388, -2.6010, -2.5970, -2.6521,\n",
      "        -2.6505, -2.6429, -2.6506, -2.6450, -2.6215, -2.6396, -2.6590, -2.6240,\n",
      "        -2.6503, -2.6248, -2.6528, -2.6463, -2.6396, -2.6512, -2.6507, -2.6536,\n",
      "        -2.5813, -2.6506, -2.6504, -2.6504, -2.6559, -2.6554, -2.6387, -2.6421,\n",
      "        -2.6562, -2.6548, -2.5708, -2.6557, -2.5777, -2.5787, -2.6453, -2.6423,\n",
      "        -2.6557, -2.6499], device='mps:0')\n",
      "mean: tensor(-2.6371, device='mps:0')\n",
      "iter_dt 1.15s; iter 98: train loss 0.48723 temperature: 9.900000000000016\n",
      "mean_logits tensor([-2.4566, -2.8397, -2.5991, -2.7821, -2.2569, -2.5731, -2.4919, -2.5999,\n",
      "        -2.7995, -2.6445, -2.6469, -2.8262, -2.4474, -2.7694, -2.7375, -2.6118,\n",
      "        -2.6728, -2.4090, -2.6677, -2.6729, -2.6295, -2.6099, -2.9128, -2.5199,\n",
      "        -2.7353, -2.3243, -2.5129, -2.5987, -2.5820, -2.4388, -2.7059, -2.7443,\n",
      "        -2.5542, -2.4032, -2.7888, -2.5963, -2.4827, -2.6435, -2.3555, -2.6284,\n",
      "        -2.4922, -2.6299, -2.5034, -2.7203, -2.5523, -2.5262, -2.7920, -2.5326,\n",
      "        -2.6805, -2.7813], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6388, -2.6431, -2.6484, -2.6300, -2.6071, -2.6179, -2.6516, -2.5013,\n",
      "        -2.6329, -2.6558, -2.6418, -2.6206, -2.6416, -2.6336, -2.6507, -2.6434,\n",
      "        -2.6545, -2.6483, -2.6557, -2.6533, -2.6173, -2.6535, -2.6548, -2.6404,\n",
      "        -2.6514, -2.5843, -2.6441, -2.6447, -2.6527, -2.6393, -2.6434, -2.6554,\n",
      "        -2.6567, -2.6481, -2.6427, -2.6417, -2.6436, -2.6452, -2.6503, -2.6524,\n",
      "        -2.6532, -2.6229, -2.6428, -2.6507, -2.6388, -2.5862, -2.6532, -2.6104,\n",
      "        -2.6558, -2.6405], device='mps:0')\n",
      "mean: tensor(-2.6377, device='mps:0')\n",
      "iter_dt 1.14s; iter 99: train loss 0.51117 temperature: 9.950000000000017\n",
      "mean_logits tensor([-2.4128, -2.5857, -2.5952, -2.6182, -2.3908, -2.6626, -2.7866, -2.7738,\n",
      "        -2.5089, -2.3226, -2.5235, -2.7419, -2.7663, -2.6963, -2.3606, -2.6224,\n",
      "        -2.2393, -2.5236, -2.6034, -2.4403, -2.6721, -2.8665, -2.5031, -2.5118,\n",
      "        -2.7229, -2.6352, -2.5296, -2.5479, -2.6287, -2.7378, -2.6042, -2.7846,\n",
      "        -2.6283, -2.4412, -2.3716, -2.7932, -2.6568, -2.8068, -2.3741, -2.5814,\n",
      "        -2.5497, -2.7195, -2.6641, -2.6476, -2.7460, -2.7181, -2.5201, -2.4770,\n",
      "        -2.4502, -2.6409], device='mps:0', grad_fn=<SubBackward0>)\n",
      "energies: tensor([-2.6546, -2.6013, -2.6482, -2.6557, -2.6055, -2.6511, -2.6441, -2.6502,\n",
      "        -2.6530, -2.6502, -2.6559, -2.6329, -2.6516, -2.6410, -2.6341, -2.6472,\n",
      "        -2.6523, -2.6485, -2.6495, -2.6090, -2.6362, -2.6234, -2.6297, -2.6433,\n",
      "        -2.6319, -2.6558, -2.6411, -2.6157, -2.6566, -2.6448, -2.6270, -2.5821,\n",
      "        -2.6479, -2.5887, -2.6419, -2.6547, -2.6432, -2.6560, -2.6435, -2.5841,\n",
      "        -2.6292, -2.6328, -2.5734, -2.6429, -2.6519, -2.6511, -2.6511, -2.6439,\n",
      "        -2.6443, -2.5797], device='mps:0')\n",
      "mean: tensor(-2.6357, device='mps:0')\n",
      "current_prefixes: [7278 4037 5557 4534 4632 6985  380 4805 4101 4404 4883  611  346 1045\n",
      " 2273 6235 5773 2879  256  465 6084 8286  375 5500  264  814   67 8921\n",
      "   67 4136 4385 6604  200 1773 2049 8494   86 3932 2808 2015 1661 1504\n",
      " 4149 1661 3803 8007 1292 4308  319 8336 4047 3188 2061  885 3979 5055\n",
      " 8648 8153 9002 1969]\n"
     ]
    }
   ],
   "source": [
    "print_monitors = []\n",
    "file_monitors = []\n",
    "for index in range(num_layers):\n",
    "    file_monitor = FileMonitor()\n",
    "    file_monitors.append(file_monitor)\n",
    "    trainer.set_monitors(index, [PrintMonitor(), file_monitor])\n",
    "trainer.run()\n",
    "#torch.save(model.state_dict(), '../saved_models/gptqe_test_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.144927501678467\n",
      "-2.4615018367767334\n",
      "-2.6674141883850098\n",
      "-2.6935291290283203\n",
      "-2.7183966636657715\n",
      "-2.7465150356292725\n",
      "-2.7500452995300293\n",
      "-2.7533998489379883\n",
      "-2.75622296333313\n",
      "-2.7588882446289062\n",
      "-2.760599136352539\n",
      "-2.762188196182251\n"
     ]
    }
   ],
   "source": [
    "for fm in file_monitors:\n",
    "    print(fm.min_energy)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-28T00:43:24.087005Z",
     "start_time": "2023-09-28T00:43:24.070516Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# cost.sequence.tool = \"qiskit\"\n",
    "# print(file_monitor.min_indices)\n",
    "# cost.sequence._get_circuit(file_monitor.min_indices).qc.draw(output=\"mpl\", plot_barriers=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
