{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A demo using Hydrogen Hamiltonian with GPT-QE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T16:16:11.759652Z",
     "start_time": "2023-09-17T16:16:10.544202Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from gqe.mingpt.utils import set_seed\n",
    "\n",
    "set_seed(31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converged SCF energy = -0.910873554594387\n",
      "Starting to parse FermionOperator using 4 qubits...\n",
      "\n",
      "Operator t:  -0.49178577730353756 [] +\n",
      "-0.0573839840149255 [X0 X1 Y2 Y3] +\n",
      "0.0573839840149255 [X0 Y1 Y2 X3] +\n",
      "0.0573839840149255 [Y0 X1 X2 Y3] +\n",
      "-0.0573839840149255 [Y0 Y1 X2 X3] +\n",
      "0.09345649667701589 [Z0] +\n",
      "0.13817584576560335 [Z0 Z1] +\n",
      "0.08253705488832763 [Z0 Z2] +\n",
      "0.13992103890325314 [Z0 Z3] +\n",
      "0.09345649667701589 [Z1] +\n",
      "0.13992103890325314 [Z1 Z2] +\n",
      "0.08253705488832763 [Z1 Z3] +\n",
      "-0.03564481621009516 [Z2] +\n",
      "0.1458551903009311 [Z2 Z3] +\n",
      "-0.035644816210095145 [Z3]\n",
      "Term, coeff:  () -0.49178577730353756\n",
      "Term, coeff:  ((0, 'Z'),) 0.09345649667701589\n",
      "Index, p_char:  0 Z\n",
      "Term, coeff:  ((1, 'Z'),) 0.09345649667701589\n",
      "Index, p_char:  1 Z\n",
      "Term, coeff:  ((2, 'Z'),) -0.03564481621009516\n",
      "Index, p_char:  2 Z\n",
      "Term, coeff:  ((3, 'Z'),) -0.035644816210095145\n",
      "Index, p_char:  3 Z\n",
      "Term, coeff:  ((0, 'Z'), (1, 'Z')) 0.13817584576560335\n",
      "Index, p_char:  0 Z\n",
      "Index, p_char:  1 Z\n",
      "Term, coeff:  ((0, 'Y'), (1, 'X'), (2, 'X'), (3, 'Y')) 0.0573839840149255\n",
      "Index, p_char:  0 Y\n",
      "Index, p_char:  1 X\n",
      "Index, p_char:  2 X\n",
      "Index, p_char:  3 Y\n",
      "Term, coeff:  ((0, 'Y'), (1, 'Y'), (2, 'X'), (3, 'X')) -0.0573839840149255\n",
      "Index, p_char:  0 Y\n",
      "Index, p_char:  1 Y\n",
      "Index, p_char:  2 X\n",
      "Index, p_char:  3 X\n",
      "Term, coeff:  ((0, 'X'), (1, 'X'), (2, 'Y'), (3, 'Y')) -0.0573839840149255\n",
      "Index, p_char:  0 X\n",
      "Index, p_char:  1 X\n",
      "Index, p_char:  2 Y\n",
      "Index, p_char:  3 Y\n",
      "Term, coeff:  ((0, 'X'), (1, 'Y'), (2, 'Y'), (3, 'X')) 0.0573839840149255\n",
      "Index, p_char:  0 X\n",
      "Index, p_char:  1 Y\n",
      "Index, p_char:  2 Y\n",
      "Index, p_char:  3 X\n",
      "Term, coeff:  ((0, 'Z'), (2, 'Z')) 0.08253705488832763\n",
      "Index, p_char:  0 Z\n",
      "Index, p_char:  2 Z\n",
      "Term, coeff:  ((0, 'Z'), (3, 'Z')) 0.13992103890325314\n",
      "Index, p_char:  0 Z\n",
      "Index, p_char:  3 Z\n",
      "Term, coeff:  ((1, 'Z'), (2, 'Z')) 0.13992103890325314\n",
      "Index, p_char:  1 Z\n",
      "Index, p_char:  2 Z\n",
      "Term, coeff:  ((1, 'Z'), (3, 'Z')) 0.08253705488832763\n",
      "Index, p_char:  1 Z\n",
      "Index, p_char:  3 Z\n",
      "Term, coeff:  ((2, 'Z'), (3, 'Z')) 0.1458551903009311\n",
      "Index, p_char:  2 Z\n",
      "Index, p_char:  3 Z\n",
      "paulis [+IXII, +IXZY, +IYZX, +XIII, +XXXY, +XXYX, +XYXX, +XYYY, +XZYI, +YXXX, +YXYY, +YYXY, +YYYX, +YZXI, +IIII]\n",
      "-0.9108735545943867\n"
     ]
    }
   ],
   "source": [
    "from qwrapper.operator import PauliObservable\n",
    "from gqe.mingpt.cost import EnergyCost\n",
    "from qswift.compiler import DefaultOperatorPool\n",
    "from benchmark.molecule import DiatomicMolecularHamiltonian\n",
    "from gqe.operator_pool.uccsd import UCCSD, generate_molecule\n",
    "from gqe.common.initializer import HFStateInitializer\n",
    "\n",
    "#molecule = generate_molecule(\"H\", \"H\", 0.7414, \"sto-3g\")\n",
    "molecule = generate_molecule(\"H\", \"H\", 1.5, \"sto-3g\", bravyi_kitaev=False)\n",
    "nqubit = 4\n",
    "\n",
    "# prepare Hamiltonian\n",
    "hamiltonian = DiatomicMolecularHamiltonian(nqubit, molecule, bravyi_kitaev=False)\n",
    "\n",
    "# prepare operator_pool\n",
    "uccsd = UCCSD(nqubit, molecule)\n",
    "paulis = uccsd.paulis\n",
    "paulis.append(PauliObservable(\"IIII\"))\n",
    "print('paulis', paulis)\n",
    "num_operators = len(paulis)\n",
    "initializer = HFStateInitializer(n_electrons=2)\n",
    "pool = DefaultOperatorPool(paulis)\n",
    "cost = EnergyCost(hamiltonian, initializer, pool,\n",
    "                  [0.00625, -0.00625, 0.0125, -0.0125, 0.025, -0.025, 0.05,\n",
    "                   -0.05, 0.1, -0.1])\n",
    "print(hamiltonian.exact_value(initializer.init_circuit(4, [], \"qulacs\")))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T16:16:15.465838Z",
     "start_time": "2023-09-17T16:16:11.762899Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## FCI energy by diagonalization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.9981493534714105\n"
     ]
    }
   ],
   "source": [
    "from qwrapper.hamiltonian import compute_ground_state\n",
    "\n",
    "print(compute_ground_state(hamiltonian))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-17T16:16:15.471801Z",
     "start_time": "2023-09-17T16:16:15.467905Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup for GPT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T16:16:17.069628Z",
     "start_time": "2023-09-17T16:16:15.472330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 85.29M\n"
     ]
    }
   ],
   "source": [
    "# create a GPT instance\n",
    "from gqe.mingpt.model import GPT\n",
    "\n",
    "model_config = GPT.get_default_config()\n",
    "model_config.model_type = 'gpt2'\n",
    "model_config.vocab_size = cost.vocab_size()\n",
    "model_config.block_size = cost.vocab_size()\n",
    "model_config.n_gates = 30  # The number of gates for each circuit\n",
    "model_config.temperature = 5  # Each gate is generated with probability exp(-temperature * logit)\n",
    "model_config.embd_pdrop = 0\n",
    "model_config.resid_pdrop = 0\n",
    "model_config.attn_pdrop = 0\n",
    "model = GPT(model_config, cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T16:16:17.114833Z",
     "start_time": "2023-09-17T16:16:17.072755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on device cpu\n"
     ]
    }
   ],
   "source": [
    "# create a Trainer object\n",
    "from gqe.mingpt.trainer import Trainer\n",
    "\n",
    "train_config = Trainer.get_default_config()\n",
    "train_config.learning_rate = 5e-7  # the model we're using is so small that we can go a bit faster\n",
    "train_config.max_iters = 200\n",
    "train_config.num_workers = 0\n",
    "train_config.n_samples = 5\n",
    "trainer = Trainer(train_config, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-17T16:22:31.625008Z",
     "start_time": "2023-09-17T16:16:17.079102Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_logits tensor([-1.1689, -1.2591, -1.1869, -1.1736, -1.1192], grad_fn=<MeanBackward1>)\n",
      "energies: tensor([-0.8855, -0.9064, -0.9053, -0.9339, -0.6590])\n",
      "mean: tensor(-0.8580)\n",
      "iter_dt 0.00ms; iter 0: train loss 0.82493 temperature: 5\n",
      "mean_logits tensor([-1.0082, -1.0401, -0.8968, -0.9146, -1.0482], grad_fn=<MeanBackward1>)\n",
      "energies: tensor([-0.7904, -0.9206, -0.8972, -0.6578, -0.9206])\n",
      "mean: tensor(-0.8373)\n",
      "iter_dt 1694967390198.09ms; iter 1: train loss 0.16511 temperature: 5.01\n",
      "mean_logits tensor([-0.9412, -1.1114, -0.9813, -0.9244, -0.9400], grad_fn=<MeanBackward1>)\n",
      "energies: tensor([-0.7532, -0.7650, -0.8512, -0.6921, -0.7012])\n",
      "mean: tensor(-0.7525)\n",
      "iter_dt 12862.64ms; iter 2: train loss 0.33178 temperature: 5.02\n",
      "mean_logits tensor([-0.8337, -0.9844, -0.9118, -0.9853, -1.0512], grad_fn=<MeanBackward1>)\n",
      "energies: tensor([-0.6933, -0.9356, -0.7941, -0.9814, -0.4976])\n",
      "mean: tensor(-0.7804)\n",
      "iter_dt 12768.82ms; iter 3: train loss 0.33259 temperature: 5.029999999999999\n",
      "mean_logits tensor([-0.9506, -0.9637, -1.0412, -0.8198, -0.7845], grad_fn=<MeanBackward1>)\n",
      "energies: tensor([-0.7092, -0.9082, -0.7237, -0.9725, -0.6577])\n",
      "mean: tensor(-0.7942)\n",
      "iter_dt 12748.32ms; iter 4: train loss 0.22597 temperature: 5.039999999999999\n",
      "mean_logits tensor([-0.8377, -0.9872, -0.7091, -0.7852, -0.7908], grad_fn=<MeanBackward1>)\n",
      "energies: tensor([-0.6435, -0.9426, -0.9204, -0.9409, -0.7394])\n",
      "mean: tensor(-0.8374)\n",
      "iter_dt 12692.49ms; iter 5: train loss 0.11148 temperature: 5.049999999999999\n",
      "mean_logits tensor([-0.7088, -0.8096, -0.8881, -0.8335, -0.8298], grad_fn=<MeanBackward1>)\n",
      "energies: tensor([-0.9200, -0.9812, -0.8554, -0.9597, -0.9278])\n",
      "mean: tensor(-0.9288)\n",
      "iter_dt 12692.86ms; iter 6: train loss 0.11258 temperature: 5.059999999999999\n",
      "mean_logits tensor([-0.6702, -0.6433, -0.8378, -0.7093, -0.7840], grad_fn=<MeanBackward1>)\n",
      "energies: tensor([-0.8833, -0.9237, -0.9731, -0.9160, -0.8777])\n",
      "mean: tensor(-0.9148)\n",
      "iter_dt 12703.82ms; iter 7: train loss 0.19420 temperature: 5.0699999999999985\n",
      "mean_logits tensor([-0.8031, -0.9581, -0.7484, -0.8224, -0.8545], grad_fn=<MeanBackward1>)\n",
      "energies: tensor([-0.8083, -0.9269, -0.8938, -0.8628, -0.7093])\n",
      "mean: tensor(-0.8402)\n",
      "iter_dt 12758.86ms; iter 8: train loss 0.04510 temperature: 5.079999999999998\n",
      "mean_logits tensor([-0.7441, -0.7750, -0.6346, -0.8826, -0.7804], grad_fn=<MeanBackward1>)\n",
      "energies: tensor([-0.9686, -0.8865, -0.9598, -0.6801, -0.8672])\n",
      "mean: tensor(-0.8724)\n",
      "iter_dt 13141.68ms; iter 9: train loss 0.22136 temperature: 5.089999999999998\n",
      "mean_logits tensor([-0.8234, -0.9589, -0.7846, -0.8516, -0.7738], grad_fn=<MeanBackward1>)\n",
      "energies: tensor([-0.9238, -0.9222, -0.9809, -0.9347, -0.9026])\n",
      "mean: tensor(-0.9328)\n",
      "iter_dt 13154.32ms; iter 10: train loss 0.08458 temperature: 5.099999999999998\n",
      "mean_logits tensor([-0.7589, -0.8328, -0.7694, -0.8466, -0.8171], grad_fn=<MeanBackward1>)\n",
      "energies: tensor([-0.9424, -0.9297, -0.9006, -0.9950, -0.9589])\n",
      "mean: tensor(-0.9453)\n",
      "iter_dt 12959.82ms; iter 11: train loss 0.11784 temperature: 5.109999999999998\n",
      "mean_logits tensor([-0.9284, -0.8268, -0.8210, -0.7703, -0.8412], grad_fn=<MeanBackward1>)\n",
      "energies: tensor([-0.8993, -0.8330, -0.9210, -0.8946, -0.8099])\n",
      "mean: tensor(-0.8716)\n",
      "iter_dt 13008.62ms; iter 12: train loss 0.02989 temperature: 5.119999999999997\n",
      "mean_logits tensor([-0.9022, -0.8560, -0.9262, -0.9539, -0.8604], grad_fn=<MeanBackward1>)\n",
      "energies: tensor([-0.9267, -0.8850, -0.8850, -0.9691, -0.6842])\n",
      "mean: tensor(-0.8700)\n",
      "iter_dt 12967.35ms; iter 13: train loss 0.03324 temperature: 5.129999999999997\n",
      "mean_logits tensor([-1.0532, -0.9291, -0.9009, -0.9206, -0.8922], grad_fn=<MeanBackward1>)\n",
      "energies: tensor([-0.9548, -0.9343, -0.8113, -0.8336, -0.9662])\n",
      "mean: tensor(-0.9000)\n",
      "iter_dt 13136.29ms; iter 14: train loss 0.03919 temperature: 5.139999999999997\n",
      "mean_logits tensor([-1.0410, -0.8384, -0.9389, -0.9176, -0.8847], grad_fn=<MeanBackward1>)\n",
      "energies: tensor([-0.9879, -0.7211, -0.8587, -0.8698, -0.9060])\n",
      "mean: tensor(-0.8687)\n",
      "iter_dt 13014.74ms; iter 15: train loss 0.02842 temperature: 5.149999999999997\n",
      "mean_logits tensor([-0.7758, -0.8258, -1.0454, -0.8573, -0.9718], grad_fn=<MeanBackward1>)\n",
      "energies: tensor([-0.8772, -0.9325, -0.9809, -0.9882, -0.9919])\n",
      "mean: tensor(-0.9541)\n",
      "iter_dt 12935.36ms; iter 16: train loss 0.05259 temperature: 5.159999999999997\n",
      "mean_logits tensor([-0.9332, -0.8996, -0.8617, -0.9149, -0.9789], grad_fn=<MeanBackward1>)\n",
      "energies: tensor([-0.8897, -0.9387, -0.8254, -0.9474, -0.7627])\n",
      "mean: tensor(-0.8728)\n",
      "iter_dt 12902.22ms; iter 17: train loss 0.06060 temperature: 5.169999999999996\n",
      "mean_logits tensor([-0.8875, -0.9568, -0.8959, -0.8501, -0.7892], grad_fn=<MeanBackward1>)\n",
      "energies: tensor([-0.9730, -0.9805, -0.9042, -0.9637, -0.9690])\n",
      "mean: tensor(-0.9581)\n",
      "iter_dt 12908.93ms; iter 18: train loss 0.06371 temperature: 5.179999999999996\n",
      "mean_logits tensor([-0.8444, -0.9162, -1.0037, -0.8724, -0.8887], grad_fn=<MeanBackward1>)\n",
      "energies: tensor([-0.9655, -0.9805, -0.9802, -0.8076, -0.9042])\n",
      "mean: tensor(-0.9276)\n",
      "iter_dt 12888.08ms; iter 19: train loss 0.02905 temperature: 5.189999999999996\n",
      "mean_logits tensor([-1.0240, -0.8457, -0.9112, -0.9205, -0.9507], grad_fn=<MeanBackward1>)\n",
      "energies: tensor([-0.8178, -0.9812, -0.8368, -0.8533, -0.9889])\n",
      "mean: tensor(-0.8956)\n",
      "iter_dt 12923.99ms; iter 20: train loss 0.09036 temperature: 5.199999999999996\n",
      "mean_logits tensor([-0.9121, -0.8480, -0.8143, -0.9164, -0.9524], grad_fn=<MeanBackward1>)\n",
      "energies: tensor([-0.9844, -0.8665, -0.8224, -0.9562, -0.9684])\n",
      "mean: tensor(-0.9196)\n",
      "iter_dt 12903.18ms; iter 21: train loss 0.00984 temperature: 5.2099999999999955\n",
      "mean_logits tensor([-0.9729, -0.9025, -1.1185, -0.9899, -1.0311], grad_fn=<MeanBackward1>)\n",
      "energies: tensor([-0.9796, -0.8289, -0.9732, -0.9393, -0.8484])\n",
      "mean: tensor(-0.9139)\n",
      "iter_dt 12951.25ms; iter 22: train loss 0.08779 temperature: 5.219999999999995\n",
      "mean_logits tensor([-1.0916, -0.9774, -0.9332, -1.1044, -0.9485], grad_fn=<MeanBackward1>)\n",
      "energies: tensor([-0.9782, -0.9905, -0.8878, -0.9783, -0.9935])\n",
      "mean: tensor(-0.9656)\n",
      "iter_dt 12821.98ms; iter 23: train loss 0.05161 temperature: 5.229999999999995\n",
      "mean_logits tensor([-0.9764, -0.9112, -1.0663, -0.9997, -0.9704], grad_fn=<MeanBackward1>)\n",
      "energies: tensor([-0.9931, -0.9758, -0.9820, -0.8763, -0.9744])\n",
      "mean: tensor(-0.9603)\n",
      "iter_dt 12857.65ms; iter 24: train loss 0.03684 temperature: 5.239999999999995\n",
      "mean_logits tensor([-1.0526, -0.9946, -1.0011, -0.9981, -0.8932], grad_fn=<MeanBackward1>)\n",
      "energies: tensor([-0.9919, -0.9551, -0.9875, -0.9395, -0.8711])\n",
      "mean: tensor(-0.9490)\n",
      "iter_dt 12875.22ms; iter 25: train loss 0.01352 temperature: 5.249999999999995\n",
      "mean_logits tensor([-1.0052, -0.8722, -0.9478, -0.9661, -1.0404], grad_fn=<MeanBackward1>)\n",
      "energies: tensor([-0.9889, -0.8479, -0.9963, -0.9869, -0.9171])\n",
      "mean: tensor(-0.9474)\n",
      "iter_dt 12772.69ms; iter 26: train loss 0.02650 temperature: 5.2599999999999945\n",
      "mean_logits tensor([-0.9873, -0.9537, -0.9645, -0.9348, -1.0434], grad_fn=<MeanBackward1>)\n",
      "energies: tensor([-0.9841, -0.9926, -0.9905, -0.9867, -0.9703])\n",
      "mean: tensor(-0.9848)\n",
      "iter_dt 12872.48ms; iter 27: train loss 0.01478 temperature: 5.269999999999994\n",
      "mean_logits tensor([-1.0006, -0.9607, -0.9187, -0.9778, -1.0036], grad_fn=<MeanBackward1>)\n",
      "energies: tensor([-0.8776, -0.9176, -0.9560, -0.9770, -0.9657])\n",
      "mean: tensor(-0.9388)\n",
      "iter_dt 12752.07ms; iter 28: train loss 0.02610 temperature: 5.279999999999994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def batch_end_callback(trainer):\n",
    "    if trainer.iter_num % 1 == 0:\n",
    "        print(\n",
    "            f\"iter_dt {trainer.iter_dt * 1000:.2f}ms; iter {trainer.iter_num}: train loss {trainer.loss.item():.5f} temperature: {model.temperature}\")\n",
    "        model.temperature += 0.01\n",
    "\n",
    "\n",
    "trainer.set_callback('on_batch_end', batch_end_callback)\n",
    "trainer.run()\n",
    "torch.save(model.state_dict(), '../saved_models/gptqe_test_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices, logits = model.generate(torch.tensor([[0]]), model_config.n_gates)\n",
    "print(cost.energy(indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.temperature = 20\n",
    "#model.load_state_dict(torch.load('../saved_models/gptqe_test_2'))\n",
    "model.load_state_dict(torch.load('../saved_models/gpt2_model_h2_sto3g_1.5_30_3047.json'))\n",
    "indices, logits = model.generate(torch.zeros(10, 1, dtype=torch.int), model_config.n_gates)\n",
    "cost.sequence.tool = \"qiskit\"\n",
    "index = torch.argmin(cost.energy(indices)).item()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "target = indices.numpy()[index]\n",
    "print(cost.energy(torch.tensor([target])))\n",
    "print(target)\n",
    "cost.sequence._get_circuit(target).qc.draw(output=\"mpl\", plot_barriers=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
