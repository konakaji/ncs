{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A demo using Hydrogen Hamiltonian with GPT-QE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T22:34:33.208406Z",
     "start_time": "2023-10-02T22:34:31.782855Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from gqe.mingpt.utils import set_seed\n",
    "\n",
    "set_seed(31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converged SCF energy = -0.910873554594387\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "skipped\n",
      "paulis [+IYZX, +XXYX, +XYYY, +YXYY, +YYYX, +YZXI, +IIII]\n",
      "-0.9108735545943867\n"
     ]
    }
   ],
   "source": [
    "from qwrapper.operator import PauliObservable\n",
    "from gqe.mingpt.cost import EnergyCost\n",
    "from qswift.compiler import DefaultOperatorPool\n",
    "from benchmark.molecule import DiatomicMolecularHamiltonian\n",
    "from gqe.operator_pool.uccsd import UCCSD, generate_molecule\n",
    "from gqe.common.initializer import HFStateInitializer\n",
    "from gqe.mingpt.callback import DefaultCallback, PrintMonitor, FileMonitor\n",
    "from gqe.util import get_device\n",
    "\n",
    "#molecule = generate_molecule(\"H\", \"H\", 0.7414, \"sto-3g\")\n",
    "molecule = generate_molecule(\"H\", \"H\", 1.5, \"sto-3g\", bravyi_kitaev=False)\n",
    "nqubit = 4\n",
    "\n",
    "# prepare Hamiltonian\n",
    "hamiltonian = DiatomicMolecularHamiltonian(nqubit, molecule, bravyi_kitaev=False)\n",
    "\n",
    "# prepare operator_pool\n",
    "uccsd = UCCSD(nqubit, molecule)\n",
    "paulis = uccsd.paulis\n",
    "paulis.append(PauliObservable(\"IIII\"))\n",
    "print('paulis', paulis)\n",
    "num_operators = len(paulis)\n",
    "initializer = HFStateInitializer(n_electrons=2)\n",
    "pool = DefaultOperatorPool(paulis)\n",
    "cost = EnergyCost(hamiltonian, initializer, pool,\n",
    "                  [0.00625, -0.00625, 0.0125, -0.0125, 0.025, -0.025, 0.05,\n",
    "                   -0.05, 0.1, -0.1], device=get_device())\n",
    "print(hamiltonian.exact_value(initializer.init_circuit(4, [], \"qulacs\")))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-02T22:34:38.117019Z",
     "start_time": "2023-10-02T22:34:33.212032Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## FCI energy by diagonalization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.9981493534714105\n"
     ]
    }
   ],
   "source": [
    "from qwrapper.hamiltonian import compute_ground_state\n",
    "\n",
    "print(compute_ground_state(hamiltonian))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-02T22:34:38.124862Z",
     "start_time": "2023-10-02T22:34:38.118859Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup for GPT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T22:34:39.929538Z",
     "start_time": "2023-10-02T22:34:38.129289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 85.16M\n"
     ]
    }
   ],
   "source": [
    "# create a GPT instance\n",
    "from gqe.mingpt.model import GPT\n",
    "\n",
    "model_config = GPT.get_default_config()\n",
    "model_config.model_type = 'gpt2'\n",
    "model_config.vocab_size = cost.vocab_size()\n",
    "model_config.block_size = cost.vocab_size()\n",
    "model_config.n_gates = 10  # The number of gates for each circuit\n",
    "model_config.temperature = 5  # Each gate is generated with probability exp(-temperature * logit)\n",
    "model_config.embd_pdrop = 0\n",
    "model_config.resid_pdrop = 0\n",
    "model_config.attn_pdrop = 0\n",
    "model = GPT(model_config, cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T22:34:40.018277Z",
     "start_time": "2023-10-02T22:34:39.930084Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on device mps\n"
     ]
    }
   ],
   "source": [
    "# create a Trainer object\n",
    "from gqe.mingpt.trainer import Trainer\n",
    "\n",
    "train_config = Trainer.get_default_config()\n",
    "train_config.learning_rate = 5e-7  # the model we're using is so small that we can go a bit faster\n",
    "train_config.max_iters = 100\n",
    "train_config.num_workers = 0\n",
    "train_config.n_samples = 10\n",
    "trainer = Trainer(train_config, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-02T22:34:44.106090Z",
     "start_time": "2023-10-02T22:34:40.021941Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Size does not match at dimension 1 expected index [10, 10, 1] to be smaller than self [10, 1, 70] apart from dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m callback_generator \u001B[38;5;241m=\u001B[39m DefaultCallback(model, monitors\u001B[38;5;241m=\u001B[39m[PrintMonitor(), file_monitor])\n\u001B[1;32m      4\u001B[0m trainer\u001B[38;5;241m.\u001B[39mset_callback(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mon_batch_end\u001B[39m\u001B[38;5;124m'\u001B[39m, callback_generator\u001B[38;5;241m.\u001B[39mgenerate())\n\u001B[0;32m----> 5\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m torch\u001B[38;5;241m.\u001B[39msave(model\u001B[38;5;241m.\u001B[39mstate_dict(), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../saved_models/gptqe_test_2\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      7\u001B[0m file_monitor\u001B[38;5;241m.\u001B[39msave(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../output/test_batch.json\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/PycharmProjects/gqe/gqe/mingpt/trainer.py:95\u001B[0m, in \u001B[0;36mTrainer.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     93\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m     94\u001B[0m     \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_samples, \u001B[38;5;241m1\u001B[39m, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mint)\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m---> 95\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss, detail \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     96\u001B[0m     \u001B[38;5;66;03m# backprop and update the parameters\u001B[39;00m\n\u001B[1;32m     97\u001B[0m     model\u001B[38;5;241m.\u001B[39mzero_grad(set_to_none\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/PycharmProjects/gqe/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/PycharmProjects/gqe/gqe/mingpt/model.py:354\u001B[0m, in \u001B[0;36mGPT.forward\u001B[0;34m(self, idx, energies)\u001B[0m\n\u001B[1;32m    353\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, idx, energies\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m--> 354\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcost\u001B[49m\u001B[43m(\u001B[49m\u001B[43midx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menergies\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    355\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[0;32m~/PycharmProjects/gqe/gqe/mingpt/model.py:300\u001B[0m, in \u001B[0;36mGPT.cost\u001B[0;34m(self, idx, energies)\u001B[0m\n\u001B[1;32m    298\u001B[0m     idx_output \u001B[38;5;241m=\u001B[39m idx[:, \u001B[38;5;241m1\u001B[39m:]\n\u001B[1;32m    299\u001B[0m logits_base \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgenerate_logits(idx[:, :\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mblock_size])\n\u001B[0;32m--> 300\u001B[0m logits_tensors \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgather\u001B[49m\u001B[43m(\u001B[49m\u001B[43midx_output\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlogits_base\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    301\u001B[0m mean_logits \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmean(logits_tensors, \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    302\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrecord_min(energies, idx_output)\n",
      "File \u001B[0;32m~/PycharmProjects/gqe/gqe/mingpt/model.py:312\u001B[0m, in \u001B[0;36mGPT.gather\u001B[0;34m(self, idx, logits_base)\u001B[0m\n\u001B[1;32m    310\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgather\u001B[39m(\u001B[38;5;28mself\u001B[39m, idx, logits_base):\n\u001B[1;32m    311\u001B[0m     b_size \u001B[38;5;241m=\u001B[39m idx\u001B[38;5;241m.\u001B[39msize(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m--> 312\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgather\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlogits_base\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43midx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreshape\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mreshape(b_size, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Size does not match at dimension 1 expected index [10, 10, 1] to be smaller than self [10, 1, 70] apart from dimension 2"
     ]
    }
   ],
   "source": [
    "file_monitor = FileMonitor()\n",
    "callback_generator = DefaultCallback(model, monitors=[PrintMonitor(), file_monitor])\n",
    "\n",
    "trainer.set_callback('on_batch_end', callback_generator.generate())\n",
    "trainer.run()\n",
    "torch.save(model.state_dict(), '../saved_models/gptqe_test_2')\n",
    "file_monitor.save('../output/test_batch.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices, logits = model.generate(torch.tensor([[0]]).to(get_device()), model_config.n_gates)\n",
    "print(cost.energy(indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.temperature = 20\n",
    "model.load_state_dict(torch.load('../saved_models/gptqe_test_2'))\n",
    "indices, logits = model.generate(torch.zeros(10, 1, dtype=torch.int).to(get_device()), model_config.n_gates)\n",
    "cost.sequence.tool = \"qiskit\"\n",
    "index = torch.argmin(cost.energy(indices)).item()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "target = indices.cpu().numpy()[index]\n",
    "print(cost.energy(torch.tensor([target]).to(get_device())))\n",
    "print(target)\n",
    "cost.sequence.get_circuit(target).qc.draw(output=\"mpl\", plot_barriers=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
