{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A demo using Hydrogen Hamiltonian with GPT-QE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T23:26:56.214705Z",
     "start_time": "2023-09-22T23:26:56.183135Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from gqe.mingpt.utils import set_seed\n",
    "\n",
    "set_seed(3407)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "converged SCF energy = -106.871504045608\n",
      "paulis [+IIIIIXIIIIII, +IIIIIXZYIIII, +IIIIIXZZZYII, +IIIIIXZZZZZY, +IIIIIYZXIIII, +IIIIIYZZZXII, +IIIIIYZZZZZX, +IIIIXIIIIIII, +IIIIXXIIIIXY, +IIIIXXIIIIYX, +IIIIXXIIXYII, +IIIIXXIIYXII, +IIIIXXXYIIII, +IIIIXXYXIIII, +IIIIXYIIIIXX, +IIIIXYIIIIYY, +IIIIXYIIXXII, +IIIIXYIIYYII, +IIIIXYXXIIII, +IIIIXYYYIIII, +IIIIXZYIIIII, +IIIIXZZZYIII, +IIIIXZZZZZYI, +IIIIYXIIIIXX, +IIIIYXIIIIYY, +IIIIYXIIXXII, +IIIIYXIIYYII, +IIIIYXXXIIII, +IIIIYXYYIIII, +IIIIYYIIIIXY, +IIIIYYIIIIYX, +IIIIYYIIXYII, +IIIIYYIIYXII, +IIIIYYXYIIII, +IIIIYYYXIIII, +IIIIYZXIIIII, +IIIIYZZZXIII, +IIIIYZZZZZXI, +IIIXIIIIIIII, +IIIXXIIXYIII, +IIIXXIIYXIII, +IIIXXIXZZYII, +IIIXXIYZZXII, +IIIXYIIXXIII, +IIIXYIIYYIII, +IIIXYIXZZXII, +IIIXYIYZZYII, +IIIXZXIXZYII, +IIIXZXIYZXII, +IIIXZYIXZXII, +IIIXZYIYZYII, +IIIXZZZYIIII, +IIIXZZZZZYII, +IIIXZZZZZZZY, +IIIYXIIXXIII, +IIIYXIIYYIII, +IIIYXIXZZXII, +IIIYXIYZZYII, +IIIYYIIXYIII, +IIIYYIIYXIII, +IIIYYIXZZYII, +IIIYYIYZZXII, +IIIYZXIXZXII, +IIIYZXIYZYII, +IIIYZYIXZYII, +IIIYZYIYZXII, +IIIYZZZXIIII, +IIIYZZZZZXII, +IIIYZZZZZZZX, +IIXIIIIIIIII, +IIXXIIIIIIXY, +IIXXIIIIIIYX, +IIXXIIIIXYII, +IIXXIIIIYXII, +IIXXIIXYIIII, +IIXXIIYXIIII, +IIXYIIIIIIXX, +IIXYIIIIIIYY, +IIXYIIIIXXII, +IIXYIIIIYYII, +IIXYIIXXIIII, +IIXYIIYYIIII, +IIXZXIXZYIII, +IIXZXIYZXIII, +IIXZYIXZXIII, +IIXZYIYZYIII, +IIXZZXIXYIII, +IIXZZXIYXIII, +IIXZZXXZZYII, +IIXZZXYZZXII, +IIXZZYIXXIII, +IIXZZYIYYIII, +IIXZZYXZZXII, +IIXZZYYZZYII, +IIXZZZYIIIII, +IIXZZZZZYIII, +IIXZZZZZZZYI, +IIYXIIIIIIXX, +IIYXIIIIIIYY, +IIYXIIIIXXII, +IIYXIIIIYYII, +IIYXIIXXIIII, +IIYXIIYYIIII, +IIYYIIIIIIXY, +IIYYIIIIIIYX, +IIYYIIIIXYII, +IIYYIIIIYXII, +IIYYIIXYIIII, +IIYYIIYXIIII, +IIYZXIXZXIII, +IIYZXIYZYIII, +IIYZYIXZYIII, +IIYZYIYZXIII, +IIYZZXIXXIII, +IIYZZXIYYIII, +IIYZZXXZZXII, +IIYZZXYZZYII, +IIYZZYIXYIII, +IIYZZYIYXIII, +IIYZZYXZZYII, +IIYZZYYZZXII, +IIYZZZXIIIII, +IIYZZZZZXIII, +IIYZZZZZZZXI, +IXIIIIIIIIII, +IXXIIIIIIXYI, +IXXIIIIIIYXI, +IXXIIIIIXZZY, +IXXIIIIIYZZX, +IXYIIIIIIXXI, +IXYIIIIIIYYI, +IXYIIIIIXZZX, +IXYIIIIIYZZY, +IXZXIIIIIXZY, +IXZXIIIIIYZX, +IXZYIIIIIXZX, +IXZYIIIIIYZY, +IXZZXIIXZZYI, +IXZZXIIYZZXI, +IXZZXIXZZZZY, +IXZZXIYZZZZX, +IXZZYIIXZZXI, +IXZZYIIYZZYI, +IXZZYIXZZZZX, +IXZZYIYZZZZY, +IXZZZXIXZZZY, +IXZZZXIYZZZX, +IXZZZYIXZZZX, +IXZZZYIYZZZY, +IXZZZZZYIIII, +IXZZZZZZZYII, +IXZZZZZZZZZY, +IYXIIIIIIXXI, +IYXIIIIIIYYI, +IYXIIIIIXZZX, +IYXIIIIIYZZY, +IYYIIIIIIXYI, +IYYIIIIIIYXI, +IYYIIIIIXZZY, +IYYIIIIIYZZX, +IYZXIIIIIXZX, +IYZXIIIIIYZY, +IYZYIIIIIXZY, +IYZYIIIIIYZX, +IYZZXIIXZZXI, +IYZZXIIYZZYI, +IYZZXIXZZZZX, +IYZZXIYZZZZY, +IYZZYIIXZZYI, +IYZZYIIYZZXI, +IYZZYIXZZZZY, +IYZZYIYZZZZX, +IYZZZXIXZZZX, +IYZZZXIYZZZY, +IYZZZYIXZZZY, +IYZZZYIYZZZX, +IYZZZZZXIIII, +IYZZZZZZZXII, +IYZZZZZZZZZX, +XIIIIIIIIIII, +XXIIIIIIIIXY, +XXIIIIIIIIYX, +XXIIIIIIXYII, +XXIIIIIIYXII, +XXIIIIXYIIII, +XXIIIIYXIIII, +XYIIIIIIIIXX, +XYIIIIIIIIYY, +XYIIIIIIXXII, +XYIIIIIIYYII, +XYIIIIXXIIII, +XYIIIIYYIIII, +XZXIIIIIXZYI, +XZXIIIIIYZXI, +XZYIIIIIXZXI, +XZYIIIIIYZYI, +XZZXIIIIIXYI, +XZZXIIIIIYXI, +XZZXIIIIXZZY, +XZZXIIIIYZZX, +XZZYIIIIIXXI, +XZZYIIIIIYYI, +XZZYIIIIXZZX, +XZZYIIIIYZZY, +XZZZXIXZZZYI, +XZZZXIYZZZXI, +XZZZYIXZZZXI, +XZZZYIYZZZYI, +XZZZZXIXZZYI, +XZZZZXIYZZXI, +XZZZZXXZZZZY, +XZZZZXYZZZZX, +XZZZZYIXZZXI, +XZZZZYIYZZYI, +XZZZZYXZZZZX, +XZZZZYYZZZZY, +XZZZZZYIIIII, +XZZZZZZZYIII, +XZZZZZZZZZYI, +YXIIIIIIIIXX, +YXIIIIIIIIYY, +YXIIIIIIXXII, +YXIIIIIIYYII, +YXIIIIXXIIII, +YXIIIIYYIIII, +YYIIIIIIIIXY, +YYIIIIIIIIYX, +YYIIIIIIXYII, +YYIIIIIIYXII, +YYIIIIXYIIII, +YYIIIIYXIIII, +YZXIIIIIXZXI, +YZXIIIIIYZYI, +YZYIIIIIXZYI, +YZYIIIIIYZXI, +YZZXIIIIIXXI, +YZZXIIIIIYYI, +YZZXIIIIXZZX, +YZZXIIIIYZZY, +YZZYIIIIIXYI, +YZZYIIIIIYXI, +YZZYIIIIXZZY, +YZZYIIIIYZZX, +YZZZXIXZZZXI, +YZZZXIYZZZYI, +YZZZYIXZZZYI, +YZZZYIYZZZXI, +YZZZZXIXZZXI, +YZZZZXIYZZYI, +YZZZZXXZZZZX, +YZZZZXYZZZZY, +YZZZZYIXZZYI, +YZZZZYIYZZXI, +YZZZZYXZZZZY, +YZZZZYYZZZZX, +YZZZZZXIIIII, +YZZZZZZZXIII, +YZZZZZZZZZXI, +IIIIIIIIIIII]\n"
     ]
    }
   ],
   "source": [
    "from qwrapper.operator import PauliObservable\n",
    "from gqe.mingpt.cost import EnergyCost\n",
    "from qswift.compiler import DefaultOperatorPool\n",
    "from benchmark.molecule import DiatomicMolecularHamiltonian\n",
    "from gqe.operator_pool.uccsd import UCCSD, generate_molecule\n",
    "from gqe.common.initializer import HFStateInitializer\n",
    "from gqe.util import get_device\n",
    "from gqe.mingpt.callback import DefaultCallback, PrintMonitor, FileMonitor\n",
    "import logging\n",
    "\n",
    "logging.getLogger('benchmark.molecule').setLevel(logging.WARNING)\n",
    "\n",
    "# molecule = generate_molecule(\"Li\", \"H\", 1.596, \"sto-3g\", bravyi_kitaev=False)\n",
    "molecule = generate_molecule(\"N\", \"N\", 2.0, \"sto-3g\", active_orbitals=[4, 5, 6, 7, 8, 9],\n",
    "                             bravyi_kitaev=False)\n",
    "nqubit = 12\n",
    "\n",
    "# prepare Hamiltonian\n",
    "hamiltonian = DiatomicMolecularHamiltonian(nqubit, molecule, bravyi_kitaev=False)\n",
    "\n",
    "# prepare operator_pool\n",
    "uccsd = UCCSD(nqubit, molecule)\n",
    "paulis = uccsd.paulis\n",
    "paulis.append(PauliObservable(\"IIIIIIIIIIII\"))\n",
    "print('paulis', paulis)\n",
    "num_operators = len(paulis)\n",
    "initializer = HFStateInitializer(n_electrons=6)\n",
    "pool = DefaultOperatorPool(paulis)\n",
    "cost = EnergyCost(hamiltonian, initializer, pool,\n",
    "                  [0.00625, -0.00625, 0.0125, -0.0125, 0.025, -0.025, 0.05, -0.05, 0.1, -0.1, 0.2, -0.2],\n",
    "                  tool='qulacs')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T23:26:57.064970Z",
     "start_time": "2023-09-22T23:26:56.663562Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## FCI energy by diagonalization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-107.43702368448199\n"
     ]
    }
   ],
   "source": [
    "from qwrapper.hamiltonian import compute_ground_state\n",
    "\n",
    "print(compute_ground_state(hamiltonian))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T23:28:47.599784Z",
     "start_time": "2023-09-22T23:26:57.066723Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hf state: -106.8715040456087\n"
     ]
    }
   ],
   "source": [
    "print(\"hf state:\", hamiltonian.exact_value(initializer.init_circuit(12, [], \"qulacs\")))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T23:28:47.608475Z",
     "start_time": "2023-09-22T23:28:47.605744Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup for GPT"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T23:28:49.286058Z",
     "start_time": "2023-09-22T23:28:47.612185Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 87.49M\n"
     ]
    }
   ],
   "source": [
    "# create a GPT instance\n",
    "from gqe.mingpt.model import GPT\n",
    "\n",
    "model_config = GPT.get_default_config()\n",
    "model_config.model_type = 'gpt2'\n",
    "model_config.vocab_size = cost.vocab_size()\n",
    "model_config.n_gates = 60  # The number of gates for each circuit\n",
    "model_config.block_size = model_config.n_gates\n",
    "model_config.temperature = 5  # Each gate is generated with probability exp(-temperature * logit)\n",
    "model_config.embd_pdrop = 0.1\n",
    "model_config.resid_pdrop = 0.1\n",
    "model_config.attn_pdrop = 0.1\n",
    "model_config.std = 0.02\n",
    "model_config.energy_offset = 106\n",
    "model = GPT(model_config, cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T23:28:49.655330Z",
     "start_time": "2023-09-22T23:28:49.290073Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running on device mps\n"
     ]
    }
   ],
   "source": [
    "# create a Trainer object\n",
    "from gqe.mingpt.trainer import Trainer\n",
    "\n",
    "train_config = Trainer.get_default_config()\n",
    "train_config.learning_rate = 5e-7  # the model we're using is so small that we can go a bit faster\n",
    "train_config.max_iters = 500\n",
    "train_config.num_workers = 10\n",
    "train_config.n_samples = 50\n",
    "trainer = Trainer(train_config, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-22T23:31:53.893294Z",
     "start_time": "2023-09-22T23:28:49.662107Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'QuantumStateGpu' from 'qulacs' (/Users/koheinakaji/PycharmProjects/gqe/venv/lib/python3.8/site-packages/qulacs/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[14], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m callback_generator \u001B[38;5;241m=\u001B[39m DefaultCallback(model, monitors\u001B[38;5;241m=\u001B[39m[PrintMonitor(), file_monitor])\n\u001B[1;32m      3\u001B[0m trainer\u001B[38;5;241m.\u001B[39mset_callback(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mon_batch_end\u001B[39m\u001B[38;5;124m'\u001B[39m, callback_generator\u001B[38;5;241m.\u001B[39mgenerate())\n\u001B[0;32m----> 4\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m torch\u001B[38;5;241m.\u001B[39msave(model\u001B[38;5;241m.\u001B[39mstate_dict(), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../saved_models/gptqe_test_2\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28mprint\u001B[39m(file_monitor\u001B[38;5;241m.\u001B[39mmin_energy)\n",
      "File \u001B[0;32m~/PycharmProjects/gqe/gqe/mingpt/trainer.py:71\u001B[0m, in \u001B[0;36mTrainer.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     69\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m     70\u001B[0m     \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_samples, \u001B[38;5;241m1\u001B[39m, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mint)\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[0;32m---> 71\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss, detail \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;66;03m# backprop and update the parameters\u001B[39;00m\n\u001B[1;32m     73\u001B[0m     model\u001B[38;5;241m.\u001B[39mzero_grad(set_to_none\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/PycharmProjects/gqe/venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1190\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1193\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1194\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1195\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1196\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/PycharmProjects/gqe/gqe/mingpt/model.py:320\u001B[0m, in \u001B[0;36mGPT.forward\u001B[0;34m(self, idx)\u001B[0m\n\u001B[1;32m    319\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, idx):\n\u001B[0;32m--> 320\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcost\u001B[49m\u001B[43m(\u001B[49m\u001B[43midx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    321\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m loss\n",
      "File \u001B[0;32m~/PycharmProjects/gqe/gqe/mingpt/model.py:292\u001B[0m, in \u001B[0;36mGPT.cost\u001B[0;34m(self, idx)\u001B[0m\n\u001B[1;32m    290\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcost\u001B[39m(\u001B[38;5;28mself\u001B[39m, idx):\n\u001B[1;32m    291\u001B[0m     idx_output, logits_tensor \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgenerate(idx, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_gates)\n\u001B[0;32m--> 292\u001B[0m     energies \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cost\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43menergy\u001B[49m\u001B[43m(\u001B[49m\u001B[43midx_output\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    293\u001B[0m     mean_logits \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mmean(logits_tensor, \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    294\u001B[0m     detail \u001B[38;5;241m=\u001B[39m ComputationDetail(indices\u001B[38;5;241m=\u001B[39midx_output,\n\u001B[1;32m    295\u001B[0m                                logits\u001B[38;5;241m=\u001B[39mlogits_tensor,\n\u001B[1;32m    296\u001B[0m                                energies\u001B[38;5;241m=\u001B[39menergies)\n",
      "File \u001B[0;32m~/PycharmProjects/gqe/gqe/mingpt/cost.py:44\u001B[0m, in \u001B[0;36mEnergyCost.energy\u001B[0;34m(self, idx)\u001B[0m\n\u001B[1;32m     42\u001B[0m energies \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m seq \u001B[38;5;129;01min\u001B[39;00m idx:\n\u001B[0;32m---> 44\u001B[0m     energies\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msequence\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mseq\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdetach\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcpu\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     45\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mtensor(energies, dtype\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mfloat)\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n",
      "File \u001B[0;32m~/PycharmProjects/gqe/venv/lib/python3.8/site-packages/qswift/sequence.py:31\u001B[0m, in \u001B[0;36mSequence.evaluate\u001B[0;34m(self, indices)\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mevaluate\u001B[39m(\u001B[38;5;28mself\u001B[39m, indices):\n\u001B[1;32m     30\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnshot \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m---> 31\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mobservable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexact_value\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_circuit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindices\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     32\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m     33\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m h, p \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobservable\u001B[38;5;241m.\u001B[39mhs, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobservable\u001B[38;5;241m.\u001B[39mpaulis):\n",
      "File \u001B[0;32m~/PycharmProjects/gqe/venv/lib/python3.8/site-packages/qwrapper/obs.py:164\u001B[0m, in \u001B[0;36mHamiltonian.exact_value\u001B[0;34m(self, qc)\u001B[0m\n\u001B[1;32m    162\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_qulacs_obs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    163\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_qulacs_obs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_qulacs_obs()\n\u001B[0;32m--> 164\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_qulacs_obs\u001B[38;5;241m.\u001B[39mget_expectation_value(\u001B[43mqc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_state\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_identity\n\u001B[1;32m    165\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_matrix \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    166\u001B[0m     matrix \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mdiag(np\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;28mpow\u001B[39m(\u001B[38;5;241m2\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnqubit), dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mcomplex128))\n",
      "File \u001B[0;32m~/PycharmProjects/gqe/venv/lib/python3.8/site-packages/qwrapper/circuit.py:263\u001B[0m, in \u001B[0;36mQulacsCircuit.get_state\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    262\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_state\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 263\u001B[0m     state \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_ref_state\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    264\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcircuit\u001B[38;5;241m.\u001B[39mupdate_quantum_state(state)\n\u001B[1;32m    265\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m state\n",
      "File \u001B[0;32m~/PycharmProjects/gqe/venv/lib/python3.8/site-packages/qwrapper/circuit.py:288\u001B[0m, in \u001B[0;36mQulacsCircuit._get_ref_state\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    286\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_ref_state\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[1;32m    287\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgpu:\n\u001B[0;32m--> 288\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mqulacs\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m QuantumStateGpu\n\u001B[1;32m    289\u001B[0m     state \u001B[38;5;241m=\u001B[39m QuantumStateGpu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnqubit)\n\u001B[1;32m    290\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'QuantumStateGpu' from 'qulacs' (/Users/koheinakaji/PycharmProjects/gqe/venv/lib/python3.8/site-packages/qulacs/__init__.py)"
     ]
    }
   ],
   "source": [
    "file_monitor = FileMonitor()\n",
    "callback_generator = DefaultCallback(model, monitors=[PrintMonitor(), file_monitor])\n",
    "trainer.set_callback('on_batch_end', callback_generator.generate())\n",
    "trainer.run()\n",
    "torch.save(model.state_dict(), '../saved_models/gptqe_test_2')\n",
    "print(file_monitor.min_energy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cost.sequence.tool = \"qiskit\"\n",
    "indices = file_monitor.min_indices\n",
    "cost.sequence._get_circuit(indices).qc.draw(output=\"mpl\", plot_barriers=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-09-22T23:31:53.884434Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ad933181bd8a04b432d3370b9dc3b0662ad032c4dfaa4e4f1596c548f763858"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
